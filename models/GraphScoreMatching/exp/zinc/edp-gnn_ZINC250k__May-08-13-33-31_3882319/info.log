| 05-08 13:33:31 EXPERIMENT BEGIN: 
| 05-08 13:33:31 logging into exp/zinc/edp-gnn_ZINC250k__May-08-13-33-31_3882319/info.log
| 05-08 13:34:49 model: EdgeDensePredictionGraphScoreNetwork(
  (gnn_list): ModuleList(
    (0): EdgeDensePredictionGNNLayer(
      (multi_channel_gnn_module): GIN(
        (linear_prediction): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=11, out_features=32, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=32, out_features=16, bias=True)
          )
          (1): Sequential(
            (0): Linear(in_features=16, out_features=32, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=32, out_features=16, bias=True)
          )
          (2): Sequential(
            (0): Linear(in_features=16, out_features=32, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=32, out_features=16, bias=True)
          )
          (3): Sequential(
            (0): Linear(in_features=16, out_features=32, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=32, out_features=16, bias=True)
          )
          (4): Sequential(
            (0): Linear(in_features=16, out_features=32, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=32, out_features=16, bias=True)
          )
        )
        (layers): ModuleList(
          (0): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=22, out_features=32, bias=True)
              (1): Linear(in_features=32, out_features=16, bias=True)
            )
          )
          (1): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=32, bias=True)
              (1): Linear(in_features=32, out_features=16, bias=True)
            )
          )
          (2): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=32, bias=True)
              (1): Linear(in_features=32, out_features=16, bias=True)
            )
          )
          (3): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=32, bias=True)
              (1): Linear(in_features=32, out_features=16, bias=True)
            )
          )
        )
      )
      (translate_mlp): MLP(
        (linears): ModuleList(
          (0): Linear(in_features=34, out_features=4, bias=True)
          (1): Linear(in_features=4, out_features=4, bias=True)
          (2): Linear(in_features=4, out_features=2, bias=True)
        )
        (batch_norms): ModuleList(
          (0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cond_layers): ModuleList(
          (0): ConditionalLayer1d()
          (1): ConditionalLayer1d()
        )
      )
    )
    (1): EdgeDensePredictionGNNLayer(
      (multi_channel_gnn_module): GIN(
        (linear_prediction): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=18, out_features=36, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=36, out_features=16, bias=True)
          )
          (1): Sequential(
            (0): Linear(in_features=16, out_features=36, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=36, out_features=16, bias=True)
          )
          (2): Sequential(
            (0): Linear(in_features=16, out_features=36, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=36, out_features=16, bias=True)
          )
          (3): Sequential(
            (0): Linear(in_features=16, out_features=36, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=36, out_features=16, bias=True)
          )
          (4): Sequential(
            (0): Linear(in_features=16, out_features=36, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=36, out_features=16, bias=True)
          )
        )
        (layers): ModuleList(
          (0): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=36, out_features=36, bias=True)
              (1): Linear(in_features=36, out_features=16, bias=True)
            )
          )
          (1): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=36, bias=True)
              (1): Linear(in_features=36, out_features=16, bias=True)
            )
          )
          (2): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=36, bias=True)
              (1): Linear(in_features=36, out_features=16, bias=True)
            )
          )
          (3): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=36, bias=True)
              (1): Linear(in_features=36, out_features=16, bias=True)
            )
          )
        )
      )
      (translate_mlp): MLP(
        (linears): ModuleList(
          (0): Linear(in_features=34, out_features=8, bias=True)
          (1): Linear(in_features=8, out_features=8, bias=True)
          (2): Linear(in_features=8, out_features=4, bias=True)
        )
        (batch_norms): ModuleList(
          (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cond_layers): ModuleList(
          (0): ConditionalLayer1d()
          (1): ConditionalLayer1d()
        )
      )
    )
    (2): EdgeDensePredictionGNNLayer(
      (multi_channel_gnn_module): GIN(
        (linear_prediction): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=20, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (1): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (2): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (3): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (4): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
        )
        (layers): ModuleList(
          (0): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=80, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (1): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (2): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (3): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
        )
      )
      (translate_mlp): MLP(
        (linears): ModuleList(
          (0): Linear(in_features=36, out_features=8, bias=True)
          (1): Linear(in_features=8, out_features=8, bias=True)
          (2): Linear(in_features=8, out_features=4, bias=True)
        )
        (batch_norms): ModuleList(
          (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cond_layers): ModuleList(
          (0): ConditionalLayer1d()
          (1): ConditionalLayer1d()
        )
      )
    )
    (3): EdgeDensePredictionGNNLayer(
      (multi_channel_gnn_module): GIN(
        (linear_prediction): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=20, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (1): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (2): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (3): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (4): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
        )
        (layers): ModuleList(
          (0): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=80, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (1): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (2): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (3): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
        )
      )
      (translate_mlp): MLP(
        (linears): ModuleList(
          (0): Linear(in_features=36, out_features=8, bias=True)
          (1): Linear(in_features=8, out_features=8, bias=True)
          (2): Linear(in_features=8, out_features=4, bias=True)
        )
        (batch_norms): ModuleList(
          (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cond_layers): ModuleList(
          (0): ConditionalLayer1d()
          (1): ConditionalLayer1d()
        )
      )
    )
    (4): EdgeDensePredictionGNNLayer(
      (multi_channel_gnn_module): GIN(
        (linear_prediction): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=20, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (1): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (2): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (3): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (4): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
        )
        (layers): ModuleList(
          (0): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=80, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (1): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (2): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (3): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
        )
      )
      (translate_mlp): MLP(
        (linears): ModuleList(
          (0): Linear(in_features=36, out_features=8, bias=True)
          (1): Linear(in_features=8, out_features=8, bias=True)
          (2): Linear(in_features=8, out_features=2, bias=True)
        )
        (batch_norms): ModuleList(
          (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cond_layers): ModuleList(
          (0): ConditionalLayer1d()
          (1): ConditionalLayer1d()
        )
      )
    )
  )
  (final_read_score): MLP(
    (linears): ModuleList(
      (0): Linear(in_features=18, out_features=36, bias=True)
      (1): Linear(in_features=36, out_features=36, bias=True)
      (2): Linear(in_features=36, out_features=1, bias=True)
    )
    (cond_layers): ModuleList(
      (0): ConditionalLayer1d()
      (1): ConditionalLayer1d()
    )
  )
)
| 05-08 13:34:49 Parameters: 
gnn_list.0.multi_channel_gnn_module.eps ........................................................................ torch.Size([4])
gnn_list.0.multi_channel_gnn_module.linear_prediction.0.0.weight .......................................... torch.Size([32, 11])
gnn_list.0.multi_channel_gnn_module.linear_prediction.0.0.bias ................................................ torch.Size([32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.0.2.weight .......................................... torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.0.2.bias ................................................ torch.Size([16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.1.0.weight .......................................... torch.Size([32, 16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.1.0.bias ................................................ torch.Size([32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.1.2.weight .......................................... torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.1.2.bias ................................................ torch.Size([16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.2.0.weight .......................................... torch.Size([32, 16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.2.0.bias ................................................ torch.Size([32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.2.2.weight .......................................... torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.2.2.bias ................................................ torch.Size([16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.3.0.weight .......................................... torch.Size([32, 16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.3.0.bias ................................................ torch.Size([32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.3.2.weight .......................................... torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.3.2.bias ................................................ torch.Size([16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.4.0.weight .......................................... torch.Size([32, 16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.4.0.bias ................................................ torch.Size([32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.4.2.weight .......................................... torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.4.2.bias ................................................ torch.Size([16])
gnn_list.0.multi_channel_gnn_module.layers.0.linears.0.weight ............................................. torch.Size([32, 22])
gnn_list.0.multi_channel_gnn_module.layers.0.linears.0.bias ................................................... torch.Size([32])
gnn_list.0.multi_channel_gnn_module.layers.0.linears.1.weight ............................................. torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.layers.0.linears.1.bias ................................................... torch.Size([16])
gnn_list.0.multi_channel_gnn_module.layers.1.linears.0.weight ............................................. torch.Size([32, 32])
gnn_list.0.multi_channel_gnn_module.layers.1.linears.0.bias ................................................... torch.Size([32])
gnn_list.0.multi_channel_gnn_module.layers.1.linears.1.weight ............................................. torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.layers.1.linears.1.bias ................................................... torch.Size([16])
gnn_list.0.multi_channel_gnn_module.layers.2.linears.0.weight ............................................. torch.Size([32, 32])
gnn_list.0.multi_channel_gnn_module.layers.2.linears.0.bias ................................................... torch.Size([32])
gnn_list.0.multi_channel_gnn_module.layers.2.linears.1.weight ............................................. torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.layers.2.linears.1.bias ................................................... torch.Size([16])
gnn_list.0.multi_channel_gnn_module.layers.3.linears.0.weight ............................................. torch.Size([32, 32])
gnn_list.0.multi_channel_gnn_module.layers.3.linears.0.bias ................................................... torch.Size([32])
gnn_list.0.multi_channel_gnn_module.layers.3.linears.1.weight ............................................. torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.layers.3.linears.1.bias ................................................... torch.Size([16])
gnn_list.0.translate_mlp.linears.0.weight .................................................................. torch.Size([4, 34])
gnn_list.0.translate_mlp.linears.0.bias ........................................................................ torch.Size([4])
gnn_list.0.translate_mlp.linears.1.weight ................................................................... torch.Size([4, 4])
gnn_list.0.translate_mlp.linears.1.bias ........................................................................ torch.Size([4])
gnn_list.0.translate_mlp.linears.2.weight ................................................................... torch.Size([2, 4])
gnn_list.0.translate_mlp.linears.2.bias ........................................................................ torch.Size([2])
gnn_list.0.translate_mlp.batch_norms.0.weight .................................................................. torch.Size([4])
gnn_list.0.translate_mlp.batch_norms.0.bias .................................................................... torch.Size([4])
gnn_list.0.translate_mlp.batch_norms.1.weight .................................................................. torch.Size([4])
gnn_list.0.translate_mlp.batch_norms.1.bias .................................................................... torch.Size([4])
gnn_list.0.translate_mlp.cond_layers.0.gain .............................................................. torch.Size([6, 1, 4])
gnn_list.0.translate_mlp.cond_layers.0.bias .............................................................. torch.Size([6, 1, 4])
gnn_list.0.translate_mlp.cond_layers.1.gain .............................................................. torch.Size([6, 1, 4])
gnn_list.0.translate_mlp.cond_layers.1.bias .............................................................. torch.Size([6, 1, 4])
gnn_list.1.multi_channel_gnn_module.eps ........................................................................ torch.Size([4])
gnn_list.1.multi_channel_gnn_module.linear_prediction.0.0.weight .......................................... torch.Size([36, 18])
gnn_list.1.multi_channel_gnn_module.linear_prediction.0.0.bias ................................................ torch.Size([36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.0.2.weight .......................................... torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.0.2.bias ................................................ torch.Size([16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.1.0.weight .......................................... torch.Size([36, 16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.1.0.bias ................................................ torch.Size([36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.1.2.weight .......................................... torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.1.2.bias ................................................ torch.Size([16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.2.0.weight .......................................... torch.Size([36, 16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.2.0.bias ................................................ torch.Size([36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.2.2.weight .......................................... torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.2.2.bias ................................................ torch.Size([16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.3.0.weight .......................................... torch.Size([36, 16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.3.0.bias ................................................ torch.Size([36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.3.2.weight .......................................... torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.3.2.bias ................................................ torch.Size([16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.4.0.weight .......................................... torch.Size([36, 16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.4.0.bias ................................................ torch.Size([36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.4.2.weight .......................................... torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.4.2.bias ................................................ torch.Size([16])
gnn_list.1.multi_channel_gnn_module.layers.0.linears.0.weight ............................................. torch.Size([36, 36])
gnn_list.1.multi_channel_gnn_module.layers.0.linears.0.bias ................................................... torch.Size([36])
gnn_list.1.multi_channel_gnn_module.layers.0.linears.1.weight ............................................. torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.layers.0.linears.1.bias ................................................... torch.Size([16])
gnn_list.1.multi_channel_gnn_module.layers.1.linears.0.weight ............................................. torch.Size([36, 32])
gnn_list.1.multi_channel_gnn_module.layers.1.linears.0.bias ................................................... torch.Size([36])
gnn_list.1.multi_channel_gnn_module.layers.1.linears.1.weight ............................................. torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.layers.1.linears.1.bias ................................................... torch.Size([16])
gnn_list.1.multi_channel_gnn_module.layers.2.linears.0.weight ............................................. torch.Size([36, 32])
gnn_list.1.multi_channel_gnn_module.layers.2.linears.0.bias ................................................... torch.Size([36])
gnn_list.1.multi_channel_gnn_module.layers.2.linears.1.weight ............................................. torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.layers.2.linears.1.bias ................................................... torch.Size([16])
gnn_list.1.multi_channel_gnn_module.layers.3.linears.0.weight ............................................. torch.Size([36, 32])
gnn_list.1.multi_channel_gnn_module.layers.3.linears.0.bias ................................................... torch.Size([36])
gnn_list.1.multi_channel_gnn_module.layers.3.linears.1.weight ............................................. torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.layers.3.linears.1.bias ................................................... torch.Size([16])
gnn_list.1.translate_mlp.linears.0.weight .................................................................. torch.Size([8, 34])
gnn_list.1.translate_mlp.linears.0.bias ........................................................................ torch.Size([8])
gnn_list.1.translate_mlp.linears.1.weight ................................................................... torch.Size([8, 8])
gnn_list.1.translate_mlp.linears.1.bias ........................................................................ torch.Size([8])
gnn_list.1.translate_mlp.linears.2.weight ................................................................... torch.Size([4, 8])
gnn_list.1.translate_mlp.linears.2.bias ........................................................................ torch.Size([4])
gnn_list.1.translate_mlp.batch_norms.0.weight .................................................................. torch.Size([8])
gnn_list.1.translate_mlp.batch_norms.0.bias .................................................................... torch.Size([8])
gnn_list.1.translate_mlp.batch_norms.1.weight .................................................................. torch.Size([8])
gnn_list.1.translate_mlp.batch_norms.1.bias .................................................................... torch.Size([8])
gnn_list.1.translate_mlp.cond_layers.0.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.1.translate_mlp.cond_layers.0.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.1.translate_mlp.cond_layers.1.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.1.translate_mlp.cond_layers.1.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.2.multi_channel_gnn_module.eps ........................................................................ torch.Size([4])
gnn_list.2.multi_channel_gnn_module.linear_prediction.0.0.weight .......................................... torch.Size([40, 20])
gnn_list.2.multi_channel_gnn_module.linear_prediction.0.0.bias ................................................ torch.Size([40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.0.2.weight .......................................... torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.0.2.bias ................................................ torch.Size([16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.1.0.weight .......................................... torch.Size([40, 16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.1.0.bias ................................................ torch.Size([40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.1.2.weight .......................................... torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.1.2.bias ................................................ torch.Size([16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.2.0.weight .......................................... torch.Size([40, 16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.2.0.bias ................................................ torch.Size([40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.2.2.weight .......................................... torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.2.2.bias ................................................ torch.Size([16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.3.0.weight .......................................... torch.Size([40, 16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.3.0.bias ................................................ torch.Size([40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.3.2.weight .......................................... torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.3.2.bias ................................................ torch.Size([16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.4.0.weight .......................................... torch.Size([40, 16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.4.0.bias ................................................ torch.Size([40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.4.2.weight .......................................... torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.4.2.bias ................................................ torch.Size([16])
gnn_list.2.multi_channel_gnn_module.layers.0.linears.0.weight ............................................. torch.Size([40, 80])
gnn_list.2.multi_channel_gnn_module.layers.0.linears.0.bias ................................................... torch.Size([40])
gnn_list.2.multi_channel_gnn_module.layers.0.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.layers.0.linears.1.bias ................................................... torch.Size([16])
gnn_list.2.multi_channel_gnn_module.layers.1.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.2.multi_channel_gnn_module.layers.1.linears.0.bias ................................................... torch.Size([40])
gnn_list.2.multi_channel_gnn_module.layers.1.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.layers.1.linears.1.bias ................................................... torch.Size([16])
gnn_list.2.multi_channel_gnn_module.layers.2.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.2.multi_channel_gnn_module.layers.2.linears.0.bias ................................................... torch.Size([40])
gnn_list.2.multi_channel_gnn_module.layers.2.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.layers.2.linears.1.bias ................................................... torch.Size([16])
gnn_list.2.multi_channel_gnn_module.layers.3.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.2.multi_channel_gnn_module.layers.3.linears.0.bias ................................................... torch.Size([40])
gnn_list.2.multi_channel_gnn_module.layers.3.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.layers.3.linears.1.bias ................................................... torch.Size([16])
gnn_list.2.translate_mlp.linears.0.weight .................................................................. torch.Size([8, 36])
gnn_list.2.translate_mlp.linears.0.bias ........................................................................ torch.Size([8])
gnn_list.2.translate_mlp.linears.1.weight ................................................................... torch.Size([8, 8])
gnn_list.2.translate_mlp.linears.1.bias ........................................................................ torch.Size([8])
gnn_list.2.translate_mlp.linears.2.weight ................................................................... torch.Size([4, 8])
gnn_list.2.translate_mlp.linears.2.bias ........................................................................ torch.Size([4])
gnn_list.2.translate_mlp.batch_norms.0.weight .................................................................. torch.Size([8])
gnn_list.2.translate_mlp.batch_norms.0.bias .................................................................... torch.Size([8])
gnn_list.2.translate_mlp.batch_norms.1.weight .................................................................. torch.Size([8])
gnn_list.2.translate_mlp.batch_norms.1.bias .................................................................... torch.Size([8])
gnn_list.2.translate_mlp.cond_layers.0.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.2.translate_mlp.cond_layers.0.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.2.translate_mlp.cond_layers.1.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.2.translate_mlp.cond_layers.1.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.3.multi_channel_gnn_module.eps ........................................................................ torch.Size([4])
gnn_list.3.multi_channel_gnn_module.linear_prediction.0.0.weight .......................................... torch.Size([40, 20])
gnn_list.3.multi_channel_gnn_module.linear_prediction.0.0.bias ................................................ torch.Size([40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.0.2.weight .......................................... torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.0.2.bias ................................................ torch.Size([16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.1.0.weight .......................................... torch.Size([40, 16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.1.0.bias ................................................ torch.Size([40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.1.2.weight .......................................... torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.1.2.bias ................................................ torch.Size([16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.2.0.weight .......................................... torch.Size([40, 16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.2.0.bias ................................................ torch.Size([40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.2.2.weight .......................................... torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.2.2.bias ................................................ torch.Size([16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.3.0.weight .......................................... torch.Size([40, 16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.3.0.bias ................................................ torch.Size([40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.3.2.weight .......................................... torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.3.2.bias ................................................ torch.Size([16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.4.0.weight .......................................... torch.Size([40, 16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.4.0.bias ................................................ torch.Size([40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.4.2.weight .......................................... torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.4.2.bias ................................................ torch.Size([16])
gnn_list.3.multi_channel_gnn_module.layers.0.linears.0.weight ............................................. torch.Size([40, 80])
gnn_list.3.multi_channel_gnn_module.layers.0.linears.0.bias ................................................... torch.Size([40])
gnn_list.3.multi_channel_gnn_module.layers.0.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.layers.0.linears.1.bias ................................................... torch.Size([16])
gnn_list.3.multi_channel_gnn_module.layers.1.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.3.multi_channel_gnn_module.layers.1.linears.0.bias ................................................... torch.Size([40])
gnn_list.3.multi_channel_gnn_module.layers.1.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.layers.1.linears.1.bias ................................................... torch.Size([16])
gnn_list.3.multi_channel_gnn_module.layers.2.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.3.multi_channel_gnn_module.layers.2.linears.0.bias ................................................... torch.Size([40])
gnn_list.3.multi_channel_gnn_module.layers.2.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.layers.2.linears.1.bias ................................................... torch.Size([16])
gnn_list.3.multi_channel_gnn_module.layers.3.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.3.multi_channel_gnn_module.layers.3.linears.0.bias ................................................... torch.Size([40])
gnn_list.3.multi_channel_gnn_module.layers.3.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.layers.3.linears.1.bias ................................................... torch.Size([16])
gnn_list.3.translate_mlp.linears.0.weight .................................................................. torch.Size([8, 36])
gnn_list.3.translate_mlp.linears.0.bias ........................................................................ torch.Size([8])
gnn_list.3.translate_mlp.linears.1.weight ................................................................... torch.Size([8, 8])
gnn_list.3.translate_mlp.linears.1.bias ........................................................................ torch.Size([8])
gnn_list.3.translate_mlp.linears.2.weight ................................................................... torch.Size([4, 8])
gnn_list.3.translate_mlp.linears.2.bias ........................................................................ torch.Size([4])
gnn_list.3.translate_mlp.batch_norms.0.weight .................................................................. torch.Size([8])
gnn_list.3.translate_mlp.batch_norms.0.bias .................................................................... torch.Size([8])
gnn_list.3.translate_mlp.batch_norms.1.weight .................................................................. torch.Size([8])
gnn_list.3.translate_mlp.batch_norms.1.bias .................................................................... torch.Size([8])
gnn_list.3.translate_mlp.cond_layers.0.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.3.translate_mlp.cond_layers.0.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.3.translate_mlp.cond_layers.1.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.3.translate_mlp.cond_layers.1.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.4.multi_channel_gnn_module.eps ........................................................................ torch.Size([4])
gnn_list.4.multi_channel_gnn_module.linear_prediction.0.0.weight .......................................... torch.Size([40, 20])
gnn_list.4.multi_channel_gnn_module.linear_prediction.0.0.bias ................................................ torch.Size([40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.0.2.weight .......................................... torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.0.2.bias ................................................ torch.Size([16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.1.0.weight .......................................... torch.Size([40, 16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.1.0.bias ................................................ torch.Size([40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.1.2.weight .......................................... torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.1.2.bias ................................................ torch.Size([16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.2.0.weight .......................................... torch.Size([40, 16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.2.0.bias ................................................ torch.Size([40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.2.2.weight .......................................... torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.2.2.bias ................................................ torch.Size([16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.3.0.weight .......................................... torch.Size([40, 16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.3.0.bias ................................................ torch.Size([40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.3.2.weight .......................................... torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.3.2.bias ................................................ torch.Size([16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.4.0.weight .......................................... torch.Size([40, 16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.4.0.bias ................................................ torch.Size([40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.4.2.weight .......................................... torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.4.2.bias ................................................ torch.Size([16])
gnn_list.4.multi_channel_gnn_module.layers.0.linears.0.weight ............................................. torch.Size([40, 80])
gnn_list.4.multi_channel_gnn_module.layers.0.linears.0.bias ................................................... torch.Size([40])
gnn_list.4.multi_channel_gnn_module.layers.0.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.layers.0.linears.1.bias ................................................... torch.Size([16])
gnn_list.4.multi_channel_gnn_module.layers.1.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.4.multi_channel_gnn_module.layers.1.linears.0.bias ................................................... torch.Size([40])
gnn_list.4.multi_channel_gnn_module.layers.1.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.layers.1.linears.1.bias ................................................... torch.Size([16])
gnn_list.4.multi_channel_gnn_module.layers.2.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.4.multi_channel_gnn_module.layers.2.linears.0.bias ................................................... torch.Size([40])
gnn_list.4.multi_channel_gnn_module.layers.2.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.layers.2.linears.1.bias ................................................... torch.Size([16])
gnn_list.4.multi_channel_gnn_module.layers.3.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.4.multi_channel_gnn_module.layers.3.linears.0.bias ................................................... torch.Size([40])
gnn_list.4.multi_channel_gnn_module.layers.3.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.layers.3.linears.1.bias ................................................... torch.Size([16])
gnn_list.4.translate_mlp.linears.0.weight .................................................................. torch.Size([8, 36])
gnn_list.4.translate_mlp.linears.0.bias ........................................................................ torch.Size([8])
gnn_list.4.translate_mlp.linears.1.weight ................................................................... torch.Size([8, 8])
gnn_list.4.translate_mlp.linears.1.bias ........................................................................ torch.Size([8])
gnn_list.4.translate_mlp.linears.2.weight ................................................................... torch.Size([2, 8])
gnn_list.4.translate_mlp.linears.2.bias ........................................................................ torch.Size([2])
gnn_list.4.translate_mlp.batch_norms.0.weight .................................................................. torch.Size([8])
gnn_list.4.translate_mlp.batch_norms.0.bias .................................................................... torch.Size([8])
gnn_list.4.translate_mlp.batch_norms.1.weight .................................................................. torch.Size([8])
gnn_list.4.translate_mlp.batch_norms.1.bias .................................................................... torch.Size([8])
gnn_list.4.translate_mlp.cond_layers.0.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.4.translate_mlp.cond_layers.0.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.4.translate_mlp.cond_layers.1.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.4.translate_mlp.cond_layers.1.bias .............................................................. torch.Size([6, 1, 8])
final_read_score.linears.0.weight ......................................................................... torch.Size([36, 18])
final_read_score.linears.0.bias ............................................................................... torch.Size([36])
final_read_score.linears.1.weight ......................................................................... torch.Size([36, 36])
final_read_score.linears.1.bias ............................................................................... torch.Size([36])
final_read_score.linears.2.weight .......................................................................... torch.Size([1, 36])
final_read_score.linears.2.bias ................................................................................ torch.Size([1])
final_read_score.cond_layers.0.gain ..................................................................... torch.Size([6, 1, 36])
final_read_score.cond_layers.0.bias ..................................................................... torch.Size([6, 1, 36])
final_read_score.cond_layers.1.gain ..................................................................... torch.Size([6, 1, 36])
final_read_score.cond_layers.1.bias ..................................................................... torch.Size([6, 1, 36])
| 05-08 13:34:49 Parameters Count: 91781, Trainable: 91781
| 05-08 13:34:49 [0.1, 0.2, 0.4, 0.6, 0.8, 1.6], 0.0
| 05-08 14:06:20 epoch: 000| time: 1891.1s| train loss: +2.400e+02 | test loss: +1.569e+02 | 
| 05-08 14:06:20 epoch: 000| train loss i: [84.5 	71.89	38.72	22.26	14.88	 7.76] test loss i: [54.66	56.94	24.21	12.05	 7.1 	 1.89] | 
| 05-08 14:37:50 epoch: 001| time: 1890.3s| train loss: +1.608e+02 | test loss: +1.525e+02 | 
| 05-08 14:37:50 epoch: 001| train loss i: [58.56	54.04	25.49	12.76	 7.47	 2.45] test loss i: [54.87	52.71	24.18	11.85	 6.92	 1.98] | 
| 05-08 15:09:20 epoch: 002| time: 1889.4s| train loss: +1.456e+02 | test loss: +1.424e+02 | 
| 05-08 15:09:20 epoch: 002| train loss i: [51.34	49.75	23.87	11.83	 6.91	 1.87] test loss i: [49.21	49.01	23.71	11.78	 6.87	 1.84] | 
| 05-08 15:44:06 epoch: 003| time: 2086.1s| train loss: +1.418e+02 | test loss: +1.427e+02 | 
| 05-08 15:44:06 epoch: 003| train loss i: [48.3 	49.15	23.79	11.82	 6.89	 1.87] test loss i: [48.5 	50.27	23.6 	11.72	 6.82	 1.77] | 
| 05-08 16:22:27 epoch: 004| time: 2300.8s| train loss: +1.350e+02 | test loss: +1.639e+02 | 
| 05-08 16:22:27 epoch: 004| train loss i: [42.99	48.07	23.56	11.73	 6.83	 1.8 ] test loss i: [62.98	54.58	25.16	12.17	 7.07	 1.98] | 
| 05-08 17:01:03 epoch: 005| time: 2316.1s| train loss: +1.300e+02 | test loss: +1.286e+02 | 
| 05-08 17:01:03 epoch: 005| train loss i: [38.92	47.19	23.52	11.73	 6.83	 1.81] test loss i: [38.02	46.68	23.51	11.75	 6.85	 1.77] | 
| 05-08 17:39:45 epoch: 006| time: 2322.3s| train loss: +1.256e+02 | test loss: +1.310e+02 | 
| 05-08 17:39:45 epoch: 006| train loss i: [35.47	46.32	23.48	11.72	 6.82	 1.8 ] test loss i: [37.84	48.76	24.08	11.76	 6.82	 1.78] | 
| 05-08 18:20:58 epoch: 007| time: 2472.7s| train loss: +1.225e+02 | test loss: +1.217e+02 | 
| 05-08 18:20:58 epoch: 007| train loss i: [33.07	45.7 	23.41	11.72	 6.82	 1.81] test loss i: [32.59	45.35	23.42	11.71	 6.81	 1.79] | 
| 05-08 19:02:38 epoch: 008| time: 2500.4s| train loss: +1.200e+02 | test loss: +1.246e+02 | 
| 05-08 19:02:38 epoch: 008| train loss i: [30.96	45.31	23.37	11.7 	 6.81	 1.8 ] test loss i: [35.48	45.6 	23.29	11.66	 6.8 	 1.78] | 
| 05-08 19:42:51 epoch: 009| time: 2412.2s| train loss: +1.177e+02 | test loss: +1.175e+02 | 
| 05-08 19:42:51 epoch: 009| train loss i: [29.26	44.83	23.29	11.69	 6.81	 1.79] test loss i: [29.15	44.55	23.4 	11.7 	 6.83	 1.85] | 
| 05-08 20:25:32 epoch: 010| time: 2561.6s| train loss: +1.159e+02 | test loss: +1.201e+02 | 
| 05-08 20:25:32 epoch: 010| train loss i: [27.99	44.41	23.21	11.67	 6.8 	 1.78] test loss i: [31.71	44.72	23.26	11.7 	 6.84	 1.86] | 
| 05-08 21:04:48 epoch: 011| time: 2355.5s| train loss: +1.147e+02 | test loss: +1.149e+02 | 
| 05-08 21:04:48 epoch: 011| train loss i: [27.2 	44.1 	23.14	11.66	 6.8 	 1.78] test loss i: [27.63	43.89	23.19	11.63	 6.77	 1.75] | 
| 05-08 21:43:21 epoch: 012| time: 2313.6s| train loss: +1.134e+02 | test loss: +1.192e+02 | 
| 05-08 21:43:21 epoch: 012| train loss i: [26.34	43.77	23.12	11.63	 6.78	 1.79] test loss i: [30.56	45.31	23.09	11.61	 6.77	 1.89] | 
| 05-08 22:39:43 epoch: 013| time: 3381.5s| train loss: +1.124e+02 | test loss: +1.122e+02 | 
| 05-08 22:39:43 epoch: 013| train loss i: [25.71	43.46	23.09	11.61	 6.77	 1.78] test loss i: [25.38	43.53	23.11	11.65	 6.79	 1.75] | 
| 05-08 23:19:02 epoch: 014| time: 2359.3s| train loss: +1.116e+02 | test loss: +1.173e+02 | 
| 05-08 23:19:02 epoch: 014| train loss i: [25.08	43.29	23.07	11.6 	 6.77	 1.78] test loss i: [29.36	44.41	23.31	11.66	 6.8 	 1.8 ] | 
| 05-08 23:58:23 epoch: 015| time: 2361.3s| train loss: +1.108e+02 | test loss: +1.112e+02 | 
| 05-08 23:58:23 epoch: 015| train loss i: [24.49	43.15	23.04	11.6 	 6.77	 1.78] test loss i: [24.55	43.46	23.05	11.58	 6.76	 1.75] | 
| 05-09 00:37:48 epoch: 016| time: 2365.0s| train loss: +1.103e+02 | test loss: +1.116e+02 | 
| 05-09 00:37:48 epoch: 016| train loss i: [24.12	43.  	23.03	11.59	 6.76	 1.78] test loss i: [25.33	43.11	23.06	11.59	 6.75	 1.75] | 
| 05-09 01:13:01 epoch: 017| time: 2112.9s| train loss: +1.097e+02 | test loss: +1.100e+02 | 
| 05-09 01:13:01 epoch: 017| train loss i: [23.75	42.84	23.01	11.58	 6.76	 1.78] test loss i: [23.88	42.93	23.06	11.63	 6.77	 1.76] | 
| 05-09 01:44:31 epoch: 018| time: 1890.1s| train loss: +1.093e+02 | test loss: +1.099e+02 | 
| 05-09 01:44:31 epoch: 018| train loss i: [23.41	42.74	23.  	11.58	 6.76	 1.78] test loss i: [24.14	42.65	23.  	11.6 	 6.79	 1.76] | 
| 05-09 02:16:03 epoch: 019| time: 1891.5s| train loss: +1.089e+02 | test loss: +1.109e+02 | 
| 05-09 02:16:03 epoch: 019| train loss i: [23.1 	42.65	23.  	11.58	 6.75	 1.77] test loss i: [24.84	42.98	23.04	11.56	 6.74	 1.75] | 
| 05-09 02:47:34 epoch: 020| time: 1891.2s| train loss: +1.085e+02 | test loss: +1.101e+02 | 
| 05-09 02:47:34 epoch: 020| train loss i: [22.82	42.57	22.98	11.57	 6.75	 1.78] test loss i: [24.31	42.69	23.03	11.58	 6.76	 1.76] | 
| 05-09 03:19:05 epoch: 021| time: 1891.1s| train loss: +1.082e+02 | test loss: +1.089e+02 | 
| 05-09 03:19:05 epoch: 021| train loss i: [22.64	42.47	22.97	11.57	 6.75	 1.78] test loss i: [23.21	42.63	23.01	11.58	 6.75	 1.75] | 
| 05-09 03:50:35 epoch: 022| time: 1890.2s| train loss: +1.078e+02 | test loss: +1.113e+02 | 
| 05-09 03:50:35 epoch: 022| train loss i: [22.35	42.37	22.95	11.56	 6.75	 1.77] test loss i: [25.66	42.58	22.98	11.56	 6.75	 1.75] | 
| 05-09 04:22:07 epoch: 023| time: 1891.9s| train loss: +1.075e+02 | test loss: +1.090e+02 | 
| 05-09 04:22:07 epoch: 023| train loss i: [22.1 	42.33	22.94	11.56	 6.75	 1.77] test loss i: [23.4 	42.52	22.95	11.58	 6.74	 1.78] | 
| 05-09 04:53:39 epoch: 024| time: 1892.0s| train loss: +1.072e+02 | test loss: +1.089e+02 | 
| 05-09 04:53:39 epoch: 024| train loss i: [21.87	42.27	22.95	11.56	 6.75	 1.78] test loss i: [23.24	42.67	22.93	11.55	 6.73	 1.75] | 
| 05-09 05:25:14 epoch: 025| time: 1894.3s| train loss: +1.069e+02 | test loss: +1.082e+02 | 
| 05-09 05:25:14 epoch: 025| train loss i: [21.63	42.23	22.94	11.56	 6.75	 1.78] test loss i: [22.6 	42.5 	23.06	11.57	 6.73	 1.76] | 
| 05-09 05:56:45 epoch: 026| time: 1891.7s| train loss: +1.065e+02 | test loss: +1.070e+02 | 
| 05-09 05:56:45 epoch: 026| train loss i: [21.42	42.13	22.92	11.56	 6.74	 1.77] test loss i: [22.02	42.  	22.94	11.55	 6.74	 1.76] | 
| 05-09 06:28:12 epoch: 027| time: 1886.3s| train loss: +1.063e+02 | test loss: +1.071e+02 | 
| 05-09 06:28:12 epoch: 027| train loss i: [21.17	42.13	22.92	11.56	 6.74	 1.77] test loss i: [21.92	42.07	22.99	11.59	 6.76	 1.79] | 
| 05-09 06:59:37 epoch: 028| time: 1885.4s| train loss: +1.060e+02 | test loss: +1.066e+02 | 
| 05-09 06:59:37 epoch: 028| train loss i: [21.02	42.04	22.9 	11.56	 6.74	 1.77] test loss i: [21.64	42.06	22.88	11.55	 6.73	 1.76] | 
| 05-09 07:31:00 epoch: 029| time: 1882.3s| train loss: +1.057e+02 | test loss: +1.058e+02 | 
| 05-09 07:31:00 epoch: 029| train loss i: [20.74	42.03	22.91	11.55	 6.74	 1.77] test loss i: [20.75	42.08	22.92	11.56	 6.74	 1.77] | 
| 05-09 08:02:24 epoch: 030| time: 1884.9s| train loss: +1.056e+02 | test loss: +1.057e+02 | 
| 05-09 08:02:24 epoch: 030| train loss i: [20.62	42.  	22.89	11.55	 6.74	 1.77] test loss i: [20.74	42.05	22.91	11.55	 6.74	 1.75] | 
| 05-09 08:33:50 epoch: 031| time: 1885.3s| train loss: +1.053e+02 | test loss: +1.051e+02 | 
| 05-09 08:33:50 epoch: 031| train loss i: [20.44	41.93	22.88	11.55	 6.74	 1.77] test loss i: [20.25	41.9 	22.88	11.54	 6.74	 1.79] | 
| 05-09 09:05:16 epoch: 032| time: 1886.0s| train loss: +1.052e+02 | test loss: +1.060e+02 | 
| 05-09 09:05:16 epoch: 032| train loss i: [20.34	41.91	22.89	11.55	 6.74	 1.77] test loss i: [21.19	41.92	22.85	11.55	 6.73	 1.75] | 
| 05-09 09:36:42 epoch: 033| time: 1885.7s| train loss: +1.051e+02 | test loss: +1.067e+02 | 
| 05-09 09:36:42 epoch: 033| train loss i: [20.21	41.91	22.87	11.55	 6.74	 1.77] test loss i: [21.43	42.27	22.95	11.58	 6.76	 1.75] | 
| 05-09 10:08:08 epoch: 034| time: 1886.3s| train loss: +1.049e+02 | test loss: +1.057e+02 | 
| 05-09 10:08:08 epoch: 034| train loss i: [20.11	41.84	22.86	11.55	 6.74	 1.77] test loss i: [20.64	41.97	22.93	11.58	 6.77	 1.79] | 
| 05-09 10:39:32 epoch: 035| time: 1884.4s| train loss: +1.047e+02 | test loss: +1.046e+02 | 
| 05-09 10:39:32 epoch: 035| train loss i: [20.  	41.83	22.86	11.54	 6.74	 1.77] test loss i: [19.94	41.79	22.85	11.54	 6.73	 1.75] | 
| 05-09 11:10:58 epoch: 036| time: 1886.1s| train loss: +1.045e+02 | test loss: +1.047e+02 | 
| 05-09 11:10:58 epoch: 036| train loss i: [19.86	41.79	22.86	11.54	 6.74	 1.77] test loss i: [19.9 	41.9 	22.87	11.53	 6.73	 1.76] | 
| 05-09 11:42:26 epoch: 037| time: 1887.9s| train loss: +1.044e+02 | test loss: +1.057e+02 | 
| 05-09 11:42:26 epoch: 037| train loss i: [19.72	41.73	22.85	11.54	 6.74	 1.77] test loss i: [20.72	41.91	23.  	11.55	 6.73	 1.75] | 
| 05-09 12:13:55 epoch: 038| time: 1888.6s| train loss: +1.042e+02 | test loss: +1.050e+02 | 
| 05-09 12:13:55 epoch: 038| train loss i: [19.6 	41.74	22.85	11.54	 6.74	 1.77] test loss i: [20.31	41.74	22.88	11.54	 6.74	 1.75] | 
| 05-09 12:45:21 epoch: 039| time: 1886.5s| train loss: +1.041e+02 | test loss: +1.050e+02 | 
| 05-09 12:45:21 epoch: 039| train loss i: [19.54	41.71	22.84	11.54	 6.74	 1.77] test loss i: [19.98	42.08	22.92	11.54	 6.74	 1.75] | 
| 05-09 13:16:48 epoch: 040| time: 1886.3s| train loss: +1.040e+02 | test loss: +1.040e+02 | 
| 05-09 13:16:48 epoch: 040| train loss i: [19.42	41.69	22.84	11.54	 6.73	 1.77] test loss i: [19.23	41.87	22.85	11.54	 6.74	 1.76] | 
| 05-09 13:48:16 epoch: 041| time: 1888.3s| train loss: +1.038e+02 | test loss: +1.038e+02 | 
| 05-09 13:48:16 epoch: 041| train loss i: [19.29	41.63	22.84	11.54	 6.73	 1.77] test loss i: [19.38	41.63	22.84	11.53	 6.72	 1.75] | 
| 05-09 14:19:41 epoch: 042| time: 1885.1s| train loss: +1.038e+02 | test loss: +1.042e+02 | 
| 05-09 14:19:41 epoch: 042| train loss i: [19.23	41.66	22.83	11.54	 6.73	 1.77] test loss i: [19.5 	41.85	22.83	11.53	 6.73	 1.77] | 
| 05-09 14:51:06 epoch: 043| time: 1884.5s| train loss: +1.036e+02 | test loss: +1.040e+02 | 
| 05-09 14:51:06 epoch: 043| train loss i: [19.12	41.63	22.84	11.54	 6.73	 1.77] test loss i: [19.44	41.75	22.83	11.52	 6.72	 1.75] | 
| 05-09 15:22:30 epoch: 044| time: 1884.7s| train loss: +1.035e+02 | test loss: +1.036e+02 | 
| 05-09 15:22:30 epoch: 044| train loss i: [19.06	41.6 	22.82	11.53	 6.73	 1.77] test loss i: [19.13	41.68	22.79	11.54	 6.72	 1.77] | 
| 05-09 15:53:57 epoch: 045| time: 1886.7s| train loss: +1.034e+02 | test loss: +1.046e+02 | 
| 05-09 15:53:57 epoch: 045| train loss i: [18.96	41.57	22.81	11.53	 6.73	 1.77] test loss i: [19.83	41.82	22.85	11.53	 6.74	 1.82] | 
| 05-09 16:25:24 epoch: 046| time: 1887.0s| train loss: +1.032e+02 | test loss: +1.031e+02 | 
| 05-09 16:25:24 epoch: 046| train loss i: [18.85	41.56	22.8 	11.53	 6.73	 1.77] test loss i: [18.72	41.59	22.82	11.53	 6.73	 1.75] | 
| 05-09 16:57:00 epoch: 047| time: 1896.1s| train loss: +1.032e+02 | test loss: +1.040e+02 | 
| 05-09 16:57:00 epoch: 047| train loss i: [18.79	41.55	22.82	11.53	 6.73	 1.77] test loss i: [19.35	41.72	22.85	11.54	 6.73	 1.8 ] | 
| 05-09 17:28:33 epoch: 048| time: 1892.6s| train loss: +1.030e+02 | test loss: +1.031e+02 | 
| 05-09 17:28:33 epoch: 048| train loss i: [18.67	41.48	22.81	11.53	 6.73	 1.77] test loss i: [18.91	41.43	22.81	11.52	 6.72	 1.75] | 
| 05-09 18:00:07 epoch: 049| time: 1894.0s| train loss: +1.029e+02 | test loss: +1.028e+02 | 
| 05-09 18:00:07 epoch: 049| train loss i: [18.57	41.47	22.81	11.53	 6.73	 1.77] test loss i: [18.36	41.62	22.81	11.53	 6.73	 1.75] | 
| 05-09 18:31:37 epoch: 050| time: 1890.5s| train loss: +1.029e+02 | test loss: +1.033e+02 | 
| 05-09 18:31:37 epoch: 050| train loss i: [18.54	41.52	22.81	11.53	 6.73	 1.76] test loss i: [18.89	41.57	22.83	11.52	 6.72	 1.75] | 
| 05-09 19:03:11 epoch: 051| time: 1893.8s| train loss: +1.028e+02 | test loss: +1.029e+02 | 
| 05-09 19:03:11 epoch: 051| train loss i: [18.47	41.51	22.82	11.53	 6.73	 1.76] test loss i: [18.55	41.5 	22.8 	11.53	 6.73	 1.77] | 
| 05-09 19:35:07 epoch: 052| time: 1915.5s| train loss: +1.027e+02 | test loss: +1.032e+02 | 
| 05-09 19:35:07 epoch: 052| train loss i: [18.37	41.48	22.81	11.53	 6.73	 1.77] test loss i: [18.55	41.81	22.82	11.54	 6.74	 1.75] | 
| 05-09 20:06:38 epoch: 053| time: 1891.0s| train loss: +1.026e+02 | test loss: +1.025e+02 | 
| 05-09 20:06:38 epoch: 053| train loss i: [18.29	41.46	22.81	11.53	 6.73	 1.76] test loss i: [18.32	41.38	22.82	11.51	 6.72	 1.75] | 
| 05-09 20:38:10 epoch: 054| time: 1892.0s| train loss: +1.025e+02 | test loss: +1.032e+02 | 
| 05-09 20:38:10 epoch: 054| train loss i: [18.23	41.44	22.8 	11.53	 6.73	 1.76] test loss i: [18.63	41.82	22.8 	11.51	 6.72	 1.74] | 
| 05-09 21:09:44 epoch: 055| time: 1894.1s| train loss: +1.024e+02 | test loss: +1.029e+02 | 
| 05-09 21:09:44 epoch: 055| train loss i: [18.21	41.39	22.8 	11.53	 6.73	 1.76] test loss i: [18.63	41.42	22.86	11.55	 6.74	 1.75] | 
| 05-09 21:41:19 epoch: 056| time: 1894.9s| train loss: +1.023e+02 | test loss: +1.023e+02 | 
| 05-09 21:41:19 epoch: 056| train loss i: [18.07	41.39	22.8 	11.53	 6.73	 1.76] test loss i: [17.81	41.64	22.82	11.53	 6.73	 1.74] | 
| 05-09 22:13:03 epoch: 057| time: 1904.4s| train loss: +1.023e+02 | test loss: +1.022e+02 | 
| 05-09 22:13:03 epoch: 057| train loss i: [18.08	41.39	22.79	11.53	 6.73	 1.76] test loss i: [18.15	41.28	22.77	11.52	 6.72	 1.75] | 
| 05-09 22:44:43 epoch: 058| time: 1899.5s| train loss: +1.022e+02 | test loss: +1.028e+02 | 
| 05-09 22:44:43 epoch: 058| train loss i: [18.03	41.4 	22.8 	11.53	 6.73	 1.76] test loss i: [18.49	41.54	22.8 	11.53	 6.73	 1.75] | 
| 05-09 23:16:18 epoch: 059| time: 1895.0s| train loss: +1.022e+02 | test loss: +1.023e+02 | 
| 05-09 23:16:18 epoch: 059| train loss i: [18.  	41.4 	22.8 	11.53	 6.73	 1.76] test loss i: [17.96	41.64	22.75	11.51	 6.72	 1.74] | 
| 05-09 23:47:52 epoch: 060| time: 1894.2s| train loss: +1.021e+02 | test loss: +1.019e+02 | 
| 05-09 23:47:52 epoch: 060| train loss i: [17.94	41.38	22.8 	11.53	 6.73	 1.76] test loss i: [17.85	41.29	22.79	11.52	 6.72	 1.76] | 
| 05-10 00:19:25 epoch: 061| time: 1892.4s| train loss: +1.020e+02 | test loss: +1.020e+02 | 
| 05-10 00:19:25 epoch: 061| train loss i: [17.84	41.36	22.79	11.53	 6.73	 1.76] test loss i: [17.86	41.4 	22.75	11.52	 6.72	 1.74] | 
| 05-10 00:51:04 epoch: 062| time: 1898.9s| train loss: +1.019e+02 | test loss: +1.026e+02 | 
| 05-10 00:51:04 epoch: 062| train loss i: [17.77	41.35	22.79	11.52	 6.73	 1.76] test loss i: [18.55	41.3 	22.77	11.52	 6.72	 1.74] | 
| 05-10 01:22:36 epoch: 063| time: 1891.8s| train loss: +1.019e+02 | test loss: +1.018e+02 | 
| 05-10 01:22:36 epoch: 063| train loss i: [17.78	41.31	22.78	11.52	 6.73	 1.76] test loss i: [17.69	41.29	22.8 	11.52	 6.72	 1.75] | 
| 05-10 01:54:08 epoch: 064| time: 1892.2s| train loss: +1.018e+02 | test loss: +1.021e+02 | 
| 05-10 01:54:08 epoch: 064| train loss i: [17.68	41.28	22.78	11.52	 6.73	 1.76] test loss i: [17.88	41.47	22.79	11.51	 6.72	 1.75] | 
| 05-10 02:25:37 epoch: 065| time: 1889.7s| train loss: +1.017e+02 | test loss: +1.019e+02 | 
| 05-10 02:25:37 epoch: 065| train loss i: [17.61	41.28	22.78	11.52	 6.73	 1.75] test loss i: [17.8 	41.27	22.79	11.53	 6.72	 1.74] | 
| 05-10 02:57:10 epoch: 066| time: 1892.5s| train loss: +1.016e+02 | test loss: +1.017e+02 | 
| 05-10 02:57:10 epoch: 066| train loss i: [17.59	41.28	22.77	11.52	 6.73	 1.76] test loss i: [17.63	41.29	22.78	11.52	 6.72	 1.74] | 
| 05-10 03:28:43 epoch: 067| time: 1892.7s| train loss: +1.015e+02 | test loss: +1.014e+02 | 
| 05-10 03:28:43 epoch: 067| train loss i: [17.52	41.22	22.77	11.52	 6.73	 1.76] test loss i: [17.46	41.16	22.76	11.52	 6.72	 1.76] | 
| 05-10 04:00:21 epoch: 068| time: 1898.7s| train loss: +1.015e+02 | test loss: +1.026e+02 | 
| 05-10 04:00:21 epoch: 068| train loss i: [17.48	41.2 	22.78	11.52	 6.73	 1.76] test loss i: [18.28	41.56	22.78	11.52	 6.72	 1.74] | 
| 05-10 04:31:51 epoch: 069| time: 1890.1s| train loss: +1.015e+02 | test loss: +1.014e+02 | 
| 05-10 04:31:51 epoch: 069| train loss i: [17.45	41.22	22.78	11.52	 6.73	 1.76] test loss i: [17.29	41.3 	22.79	11.52	 6.72	 1.75] | 
| 05-10 05:03:16 epoch: 070| time: 1884.9s| train loss: +1.014e+02 | test loss: +1.016e+02 | 
| 05-10 05:03:16 epoch: 070| train loss i: [17.46	41.2 	22.78	11.52	 6.73	 1.76] test loss i: [17.43	41.38	22.77	11.52	 6.73	 1.76] | 
| 05-10 05:34:43 epoch: 071| time: 1886.2s| train loss: +1.013e+02 | test loss: +1.015e+02 | 
| 05-10 05:34:43 epoch: 071| train loss i: [17.37	41.15	22.78	11.52	 6.73	 1.76] test loss i: [17.61	41.18	22.76	11.5 	 6.72	 1.75] | 
| 05-10 06:06:19 epoch: 072| time: 1896.8s| train loss: +1.013e+02 | test loss: +1.018e+02 | 
| 05-10 06:06:19 epoch: 072| train loss i: [17.32	41.19	22.78	11.52	 6.73	 1.75] test loss i: [17.61	41.26	22.8 	11.55	 6.75	 1.82] | 
| 05-10 06:37:47 epoch: 073| time: 1887.4s| train loss: +1.012e+02 | test loss: +1.013e+02 | 
| 05-10 06:37:47 epoch: 073| train loss i: [17.29	41.14	22.77	11.52	 6.73	 1.75] test loss i: [17.35	41.14	22.78	11.52	 6.72	 1.75] | 
| 05-10 07:09:15 epoch: 074| time: 1888.6s| train loss: +1.012e+02 | test loss: +1.014e+02 | 
| 05-10 07:09:15 epoch: 074| train loss i: [17.27	41.12	22.77	11.52	 6.73	 1.76] test loss i: [17.54	41.12	22.77	11.52	 6.72	 1.75] | 
| 05-10 07:40:47 epoch: 075| time: 1891.7s| train loss: +1.011e+02 | test loss: +1.013e+02 | 
| 05-10 07:40:47 epoch: 075| train loss i: [17.19	41.13	22.77	11.52	 6.73	 1.76] test loss i: [17.45	41.1 	22.76	11.52	 6.73	 1.77] | 
| 05-10 08:12:16 epoch: 076| time: 1889.0s| train loss: +1.011e+02 | test loss: +1.014e+02 | 
| 05-10 08:12:16 epoch: 076| train loss i: [17.19	41.09	22.78	11.52	 6.72	 1.75] test loss i: [17.49	41.12	22.75	11.52	 6.73	 1.78] | 
| 05-10 08:43:44 epoch: 077| time: 1887.6s| train loss: +1.010e+02 | test loss: +1.010e+02 | 
| 05-10 08:43:44 epoch: 077| train loss i: [17.13	41.12	22.77	11.52	 6.72	 1.75] test loss i: [17.22	41.02	22.78	11.5 	 6.72	 1.76] | 
| 05-10 09:15:16 epoch: 078| time: 1892.4s| train loss: +1.010e+02 | test loss: +1.008e+02 | 
| 05-10 09:15:16 epoch: 078| train loss i: [17.11	41.12	22.78	11.52	 6.73	 1.75] test loss i: [17.01	41.04	22.79	11.51	 6.72	 1.75] | 
| 05-10 09:46:43 epoch: 079| time: 1886.9s| train loss: +1.009e+02 | test loss: +1.007e+02 | 
| 05-10 09:46:43 epoch: 079| train loss i: [17.08	41.08	22.76	11.52	 6.72	 1.75] test loss i: [17.04	40.96	22.75	11.5 	 6.72	 1.74] | 
| 05-10 10:18:11 epoch: 080| time: 1887.8s| train loss: +1.009e+02 | test loss: +1.011e+02 | 
| 05-10 10:18:11 epoch: 080| train loss i: [17.08	41.07	22.76	11.52	 6.72	 1.75] test loss i: [17.14	41.15	22.79	11.52	 6.72	 1.75] | 
| 05-10 10:49:44 epoch: 081| time: 1893.5s| train loss: +1.009e+02 | test loss: +1.012e+02 | 
| 05-10 10:49:44 epoch: 081| train loss i: [17.05	41.07	22.77	11.52	 6.72	 1.75] test loss i: [17.36	41.16	22.73	11.52	 6.72	 1.75] | 
| 05-10 11:21:26 epoch: 082| time: 1901.6s| train loss: +1.008e+02 | test loss: +1.012e+02 | 
| 05-10 11:21:26 epoch: 082| train loss i: [17.02	41.01	22.77	11.52	 6.73	 1.75] test loss i: [17.2 	41.2 	22.83	11.52	 6.73	 1.74] | 
| 05-10 11:52:59 epoch: 083| time: 1893.5s| train loss: +1.007e+02 | test loss: +1.014e+02 | 
| 05-10 11:52:59 epoch: 083| train loss i: [16.94	41.03	22.78	11.52	 6.73	 1.75] test loss i: [17.44	41.06	22.85	11.53	 6.73	 1.75] | 
| 05-10 12:24:30 epoch: 084| time: 1890.2s| train loss: +1.007e+02 | test loss: +1.015e+02 | 
| 05-10 12:24:30 epoch: 084| train loss i: [16.9 	41.07	22.77	11.52	 6.72	 1.75] test loss i: [17.55	41.16	22.8 	11.52	 6.72	 1.75] | 
| 05-10 12:56:00 epoch: 085| time: 1890.0s| train loss: +1.007e+02 | test loss: +1.005e+02 | 
| 05-10 12:56:00 epoch: 085| train loss i: [16.93	40.96	22.77	11.52	 6.72	 1.75] test loss i: [16.69	41.03	22.77	11.52	 6.73	 1.77] | 
| 05-10 13:27:32 epoch: 086| time: 1892.7s| train loss: +1.006e+02 | test loss: +1.008e+02 | 
| 05-10 13:27:32 epoch: 086| train loss i: [16.91	40.98	22.76	11.52	 6.72	 1.75] test loss i: [16.93	41.12	22.76	11.52	 6.72	 1.74] | 
| 05-10 13:59:01 epoch: 087| time: 1888.4s| train loss: +1.007e+02 | test loss: +1.012e+02 | 
| 05-10 13:59:01 epoch: 087| train loss i: [16.88	41.05	22.76	11.52	 6.72	 1.75] test loss i: [17.33	41.1 	22.77	11.52	 6.74	 1.77] | 
| 05-10 14:30:37 epoch: 088| time: 1896.0s| train loss: +1.005e+02 | test loss: +1.010e+02 | 
| 05-10 14:30:37 epoch: 088| train loss i: [16.79	41.  	22.76	11.52	 6.72	 1.75] test loss i: [17.06	41.15	22.8 	11.5 	 6.72	 1.75] | 
| 05-10 15:02:12 epoch: 089| time: 1895.8s| train loss: +1.005e+02 | test loss: +1.012e+02 | 
| 05-10 15:02:12 epoch: 089| train loss i: [16.84	40.95	22.76	11.52	 6.72	 1.75] test loss i: [17.27	41.07	22.77	11.53	 6.75	 1.79] | 
| 05-10 15:33:42 epoch: 090| time: 1889.1s| train loss: +1.004e+02 | test loss: +1.012e+02 | 
| 05-10 15:33:42 epoch: 090| train loss i: [16.76	40.93	22.77	11.51	 6.72	 1.75] test loss i: [17.21	41.18	22.76	11.52	 6.73	 1.78] | 
| 05-10 16:05:16 epoch: 091| time: 1894.0s| train loss: +1.004e+02 | test loss: +1.007e+02 | 
| 05-10 16:05:16 epoch: 091| train loss i: [16.73	40.91	22.76	11.51	 6.72	 1.75] test loss i: [16.98	40.93	22.79	11.5 	 6.72	 1.74] | 
| 05-10 16:36:45 epoch: 092| time: 1889.7s| train loss: +1.005e+02 | test loss: +1.007e+02 | 
| 05-10 16:36:45 epoch: 092| train loss i: [16.78	40.96	22.77	11.52	 6.72	 1.75] test loss i: [16.93	41.04	22.77	11.51	 6.72	 1.75] | 
| 05-10 17:08:19 epoch: 093| time: 1893.7s| train loss: +1.003e+02 | test loss: +1.007e+02 | 
| 05-10 17:08:19 epoch: 093| train loss i: [16.68	40.92	22.75	11.52	 6.73	 1.75] test loss i: [16.85	41.06	22.81	11.53	 6.73	 1.77] | 
| 05-10 17:39:52 epoch: 094| time: 1893.0s| train loss: +1.003e+02 | test loss: +1.003e+02 | 
| 05-10 17:39:52 epoch: 094| train loss i: [16.67	40.91	22.76	11.52	 6.72	 1.75] test loss i: [16.69	40.88	22.74	11.51	 6.72	 1.74] | 
| 05-10 18:11:35 epoch: 095| time: 1902.7s| train loss: +1.003e+02 | test loss: +1.004e+02 | 
| 05-10 18:11:35 epoch: 095| train loss i: [16.67	40.9 	22.77	11.52	 6.72	 1.75] test loss i: [16.75	40.96	22.77	11.51	 6.71	 1.74] | 
| 05-10 18:43:12 epoch: 096| time: 1897.4s| train loss: +1.003e+02 | test loss: +1.006e+02 | 
| 05-10 18:43:12 epoch: 096| train loss i: [16.61	40.92	22.77	11.52	 6.72	 1.75] test loss i: [16.9 	40.97	22.75	11.51	 6.72	 1.75] | 
| 05-10 19:14:43 epoch: 097| time: 1890.5s| train loss: +1.003e+02 | test loss: +1.009e+02 | 
| 05-10 19:14:43 epoch: 097| train loss i: [16.57	40.94	22.77	11.51	 6.72	 1.75] test loss i: [17.  	41.09	22.79	11.51	 6.72	 1.74] | 
| 05-10 19:46:14 epoch: 098| time: 1891.7s| train loss: +1.002e+02 | test loss: +9.999e+01 | 
| 05-10 19:46:14 epoch: 098| train loss i: [16.6 	40.87	22.77	11.51	 6.72	 1.75] test loss i: [16.23	40.99	22.76	11.51	 6.72	 1.78] | 
| 05-10 20:18:09 epoch: 099| time: 1914.7s| train loss: +1.002e+02 | test loss: +1.002e+02 | 
| 05-10 20:18:09 epoch: 099| train loss i: [16.58	40.9 	22.77	11.51	 6.72	 1.75] test loss i: [16.61	40.88	22.78	11.5 	 6.71	 1.73] | 
| 05-10 20:50:12 epoch: 100| time: 1923.5s| train loss: +1.001e+02 | test loss: +1.003e+02 | 
| 05-10 20:50:12 epoch: 100| train loss i: [16.51	40.89	22.76	11.51	 6.72	 1.75] test loss i: [16.56	41.01	22.76	11.52	 6.72	 1.74] | 
