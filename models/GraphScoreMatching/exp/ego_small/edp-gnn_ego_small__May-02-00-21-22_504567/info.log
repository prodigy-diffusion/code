| 05-02 00:21:22 EXPERIMENT BEGIN: 
| 05-02 00:21:22 logging into exp/ego_small/edp-gnn_ego_small__May-02-00-21-22_504567/info.log
| 05-02 00:21:22 load dataset: ego_small
200
| 05-02 00:21:29 model: EdgeDensePredictionGraphScoreNetwork(
  (gnn_list): ModuleList(
    (0): EdgeDensePredictionGNNLayer(
      (multi_channel_gnn_module): GIN(
        (linear_prediction): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=3, out_features=32, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=32, out_features=16, bias=True)
          )
          (1): Sequential(
            (0): Linear(in_features=16, out_features=32, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=32, out_features=16, bias=True)
          )
          (2): Sequential(
            (0): Linear(in_features=16, out_features=32, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=32, out_features=16, bias=True)
          )
          (3): Sequential(
            (0): Linear(in_features=16, out_features=32, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=32, out_features=16, bias=True)
          )
          (4): Sequential(
            (0): Linear(in_features=16, out_features=32, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=32, out_features=16, bias=True)
          )
        )
        (layers): ModuleList(
          (0): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=6, out_features=32, bias=True)
              (1): Linear(in_features=32, out_features=16, bias=True)
            )
          )
          (1): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=32, bias=True)
              (1): Linear(in_features=32, out_features=16, bias=True)
            )
          )
          (2): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=32, bias=True)
              (1): Linear(in_features=32, out_features=16, bias=True)
            )
          )
          (3): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=32, bias=True)
              (1): Linear(in_features=32, out_features=16, bias=True)
            )
          )
        )
      )
      (translate_mlp): MLP(
        (linears): ModuleList(
          (0): Linear(in_features=34, out_features=4, bias=True)
          (1): Linear(in_features=4, out_features=4, bias=True)
          (2): Linear(in_features=4, out_features=2, bias=True)
        )
        (batch_norms): ModuleList(
          (0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cond_layers): ModuleList(
          (0): ConditionalLayer1d()
          (1): ConditionalLayer1d()
        )
      )
    )
    (1): EdgeDensePredictionGNNLayer(
      (multi_channel_gnn_module): GIN(
        (linear_prediction): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=18, out_features=36, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=36, out_features=16, bias=True)
          )
          (1): Sequential(
            (0): Linear(in_features=16, out_features=36, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=36, out_features=16, bias=True)
          )
          (2): Sequential(
            (0): Linear(in_features=16, out_features=36, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=36, out_features=16, bias=True)
          )
          (3): Sequential(
            (0): Linear(in_features=16, out_features=36, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=36, out_features=16, bias=True)
          )
          (4): Sequential(
            (0): Linear(in_features=16, out_features=36, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=36, out_features=16, bias=True)
          )
        )
        (layers): ModuleList(
          (0): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=36, out_features=36, bias=True)
              (1): Linear(in_features=36, out_features=16, bias=True)
            )
          )
          (1): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=36, bias=True)
              (1): Linear(in_features=36, out_features=16, bias=True)
            )
          )
          (2): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=36, bias=True)
              (1): Linear(in_features=36, out_features=16, bias=True)
            )
          )
          (3): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=32, out_features=36, bias=True)
              (1): Linear(in_features=36, out_features=16, bias=True)
            )
          )
        )
      )
      (translate_mlp): MLP(
        (linears): ModuleList(
          (0): Linear(in_features=34, out_features=8, bias=True)
          (1): Linear(in_features=8, out_features=8, bias=True)
          (2): Linear(in_features=8, out_features=4, bias=True)
        )
        (batch_norms): ModuleList(
          (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cond_layers): ModuleList(
          (0): ConditionalLayer1d()
          (1): ConditionalLayer1d()
        )
      )
    )
    (2): EdgeDensePredictionGNNLayer(
      (multi_channel_gnn_module): GIN(
        (linear_prediction): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=20, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (1): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (2): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (3): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (4): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
        )
        (layers): ModuleList(
          (0): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=80, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (1): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (2): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (3): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
        )
      )
      (translate_mlp): MLP(
        (linears): ModuleList(
          (0): Linear(in_features=36, out_features=8, bias=True)
          (1): Linear(in_features=8, out_features=8, bias=True)
          (2): Linear(in_features=8, out_features=4, bias=True)
        )
        (batch_norms): ModuleList(
          (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cond_layers): ModuleList(
          (0): ConditionalLayer1d()
          (1): ConditionalLayer1d()
        )
      )
    )
    (3): EdgeDensePredictionGNNLayer(
      (multi_channel_gnn_module): GIN(
        (linear_prediction): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=20, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (1): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (2): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (3): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (4): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
        )
        (layers): ModuleList(
          (0): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=80, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (1): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (2): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (3): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
        )
      )
      (translate_mlp): MLP(
        (linears): ModuleList(
          (0): Linear(in_features=36, out_features=8, bias=True)
          (1): Linear(in_features=8, out_features=8, bias=True)
          (2): Linear(in_features=8, out_features=4, bias=True)
        )
        (batch_norms): ModuleList(
          (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cond_layers): ModuleList(
          (0): ConditionalLayer1d()
          (1): ConditionalLayer1d()
        )
      )
    )
    (4): EdgeDensePredictionGNNLayer(
      (multi_channel_gnn_module): GIN(
        (linear_prediction): ModuleList(
          (0): Sequential(
            (0): Linear(in_features=20, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (1): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (2): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (3): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
          (4): Sequential(
            (0): Linear(in_features=16, out_features=40, bias=True)
            (1): LeakyReLU(negative_slope=0.01)
            (2): Linear(in_features=40, out_features=16, bias=True)
          )
        )
        (layers): ModuleList(
          (0): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=80, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (1): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (2): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
          (3): MLP(
            (linears): ModuleList(
              (0): Linear(in_features=64, out_features=40, bias=True)
              (1): Linear(in_features=40, out_features=16, bias=True)
            )
          )
        )
      )
      (translate_mlp): MLP(
        (linears): ModuleList(
          (0): Linear(in_features=36, out_features=8, bias=True)
          (1): Linear(in_features=8, out_features=8, bias=True)
          (2): Linear(in_features=8, out_features=2, bias=True)
        )
        (batch_norms): ModuleList(
          (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cond_layers): ModuleList(
          (0): ConditionalLayer1d()
          (1): ConditionalLayer1d()
        )
      )
    )
  )
  (final_read_score): MLP(
    (linears): ModuleList(
      (0): Linear(in_features=18, out_features=36, bias=True)
      (1): Linear(in_features=36, out_features=36, bias=True)
      (2): Linear(in_features=36, out_features=1, bias=True)
    )
    (cond_layers): ModuleList(
      (0): ConditionalLayer1d()
      (1): ConditionalLayer1d()
    )
  )
)
| 05-02 00:21:29 Parameters: 
gnn_list.0.multi_channel_gnn_module.eps ........................................................................ torch.Size([4])
gnn_list.0.multi_channel_gnn_module.linear_prediction.0.0.weight ........................................... torch.Size([32, 3])
gnn_list.0.multi_channel_gnn_module.linear_prediction.0.0.bias ................................................ torch.Size([32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.0.2.weight .......................................... torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.0.2.bias ................................................ torch.Size([16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.1.0.weight .......................................... torch.Size([32, 16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.1.0.bias ................................................ torch.Size([32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.1.2.weight .......................................... torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.1.2.bias ................................................ torch.Size([16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.2.0.weight .......................................... torch.Size([32, 16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.2.0.bias ................................................ torch.Size([32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.2.2.weight .......................................... torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.2.2.bias ................................................ torch.Size([16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.3.0.weight .......................................... torch.Size([32, 16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.3.0.bias ................................................ torch.Size([32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.3.2.weight .......................................... torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.3.2.bias ................................................ torch.Size([16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.4.0.weight .......................................... torch.Size([32, 16])
gnn_list.0.multi_channel_gnn_module.linear_prediction.4.0.bias ................................................ torch.Size([32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.4.2.weight .......................................... torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.linear_prediction.4.2.bias ................................................ torch.Size([16])
gnn_list.0.multi_channel_gnn_module.layers.0.linears.0.weight .............................................. torch.Size([32, 6])
gnn_list.0.multi_channel_gnn_module.layers.0.linears.0.bias ................................................... torch.Size([32])
gnn_list.0.multi_channel_gnn_module.layers.0.linears.1.weight ............................................. torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.layers.0.linears.1.bias ................................................... torch.Size([16])
gnn_list.0.multi_channel_gnn_module.layers.1.linears.0.weight ............................................. torch.Size([32, 32])
gnn_list.0.multi_channel_gnn_module.layers.1.linears.0.bias ................................................... torch.Size([32])
gnn_list.0.multi_channel_gnn_module.layers.1.linears.1.weight ............................................. torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.layers.1.linears.1.bias ................................................... torch.Size([16])
gnn_list.0.multi_channel_gnn_module.layers.2.linears.0.weight ............................................. torch.Size([32, 32])
gnn_list.0.multi_channel_gnn_module.layers.2.linears.0.bias ................................................... torch.Size([32])
gnn_list.0.multi_channel_gnn_module.layers.2.linears.1.weight ............................................. torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.layers.2.linears.1.bias ................................................... torch.Size([16])
gnn_list.0.multi_channel_gnn_module.layers.3.linears.0.weight ............................................. torch.Size([32, 32])
gnn_list.0.multi_channel_gnn_module.layers.3.linears.0.bias ................................................... torch.Size([32])
gnn_list.0.multi_channel_gnn_module.layers.3.linears.1.weight ............................................. torch.Size([16, 32])
gnn_list.0.multi_channel_gnn_module.layers.3.linears.1.bias ................................................... torch.Size([16])
gnn_list.0.translate_mlp.linears.0.weight .................................................................. torch.Size([4, 34])
gnn_list.0.translate_mlp.linears.0.bias ........................................................................ torch.Size([4])
gnn_list.0.translate_mlp.linears.1.weight ................................................................... torch.Size([4, 4])
gnn_list.0.translate_mlp.linears.1.bias ........................................................................ torch.Size([4])
gnn_list.0.translate_mlp.linears.2.weight ................................................................... torch.Size([2, 4])
gnn_list.0.translate_mlp.linears.2.bias ........................................................................ torch.Size([2])
gnn_list.0.translate_mlp.batch_norms.0.weight .................................................................. torch.Size([4])
gnn_list.0.translate_mlp.batch_norms.0.bias .................................................................... torch.Size([4])
gnn_list.0.translate_mlp.batch_norms.1.weight .................................................................. torch.Size([4])
gnn_list.0.translate_mlp.batch_norms.1.bias .................................................................... torch.Size([4])
gnn_list.0.translate_mlp.cond_layers.0.gain .............................................................. torch.Size([6, 1, 4])
gnn_list.0.translate_mlp.cond_layers.0.bias .............................................................. torch.Size([6, 1, 4])
gnn_list.0.translate_mlp.cond_layers.1.gain .............................................................. torch.Size([6, 1, 4])
gnn_list.0.translate_mlp.cond_layers.1.bias .............................................................. torch.Size([6, 1, 4])
gnn_list.1.multi_channel_gnn_module.eps ........................................................................ torch.Size([4])
gnn_list.1.multi_channel_gnn_module.linear_prediction.0.0.weight .......................................... torch.Size([36, 18])
gnn_list.1.multi_channel_gnn_module.linear_prediction.0.0.bias ................................................ torch.Size([36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.0.2.weight .......................................... torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.0.2.bias ................................................ torch.Size([16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.1.0.weight .......................................... torch.Size([36, 16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.1.0.bias ................................................ torch.Size([36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.1.2.weight .......................................... torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.1.2.bias ................................................ torch.Size([16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.2.0.weight .......................................... torch.Size([36, 16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.2.0.bias ................................................ torch.Size([36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.2.2.weight .......................................... torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.2.2.bias ................................................ torch.Size([16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.3.0.weight .......................................... torch.Size([36, 16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.3.0.bias ................................................ torch.Size([36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.3.2.weight .......................................... torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.3.2.bias ................................................ torch.Size([16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.4.0.weight .......................................... torch.Size([36, 16])
gnn_list.1.multi_channel_gnn_module.linear_prediction.4.0.bias ................................................ torch.Size([36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.4.2.weight .......................................... torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.linear_prediction.4.2.bias ................................................ torch.Size([16])
gnn_list.1.multi_channel_gnn_module.layers.0.linears.0.weight ............................................. torch.Size([36, 36])
gnn_list.1.multi_channel_gnn_module.layers.0.linears.0.bias ................................................... torch.Size([36])
gnn_list.1.multi_channel_gnn_module.layers.0.linears.1.weight ............................................. torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.layers.0.linears.1.bias ................................................... torch.Size([16])
gnn_list.1.multi_channel_gnn_module.layers.1.linears.0.weight ............................................. torch.Size([36, 32])
gnn_list.1.multi_channel_gnn_module.layers.1.linears.0.bias ................................................... torch.Size([36])
gnn_list.1.multi_channel_gnn_module.layers.1.linears.1.weight ............................................. torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.layers.1.linears.1.bias ................................................... torch.Size([16])
gnn_list.1.multi_channel_gnn_module.layers.2.linears.0.weight ............................................. torch.Size([36, 32])
gnn_list.1.multi_channel_gnn_module.layers.2.linears.0.bias ................................................... torch.Size([36])
gnn_list.1.multi_channel_gnn_module.layers.2.linears.1.weight ............................................. torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.layers.2.linears.1.bias ................................................... torch.Size([16])
gnn_list.1.multi_channel_gnn_module.layers.3.linears.0.weight ............................................. torch.Size([36, 32])
gnn_list.1.multi_channel_gnn_module.layers.3.linears.0.bias ................................................... torch.Size([36])
gnn_list.1.multi_channel_gnn_module.layers.3.linears.1.weight ............................................. torch.Size([16, 36])
gnn_list.1.multi_channel_gnn_module.layers.3.linears.1.bias ................................................... torch.Size([16])
gnn_list.1.translate_mlp.linears.0.weight .................................................................. torch.Size([8, 34])
gnn_list.1.translate_mlp.linears.0.bias ........................................................................ torch.Size([8])
gnn_list.1.translate_mlp.linears.1.weight ................................................................... torch.Size([8, 8])
gnn_list.1.translate_mlp.linears.1.bias ........................................................................ torch.Size([8])
gnn_list.1.translate_mlp.linears.2.weight ................................................................... torch.Size([4, 8])
gnn_list.1.translate_mlp.linears.2.bias ........................................................................ torch.Size([4])
gnn_list.1.translate_mlp.batch_norms.0.weight .................................................................. torch.Size([8])
gnn_list.1.translate_mlp.batch_norms.0.bias .................................................................... torch.Size([8])
gnn_list.1.translate_mlp.batch_norms.1.weight .................................................................. torch.Size([8])
gnn_list.1.translate_mlp.batch_norms.1.bias .................................................................... torch.Size([8])
gnn_list.1.translate_mlp.cond_layers.0.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.1.translate_mlp.cond_layers.0.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.1.translate_mlp.cond_layers.1.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.1.translate_mlp.cond_layers.1.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.2.multi_channel_gnn_module.eps ........................................................................ torch.Size([4])
gnn_list.2.multi_channel_gnn_module.linear_prediction.0.0.weight .......................................... torch.Size([40, 20])
gnn_list.2.multi_channel_gnn_module.linear_prediction.0.0.bias ................................................ torch.Size([40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.0.2.weight .......................................... torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.0.2.bias ................................................ torch.Size([16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.1.0.weight .......................................... torch.Size([40, 16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.1.0.bias ................................................ torch.Size([40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.1.2.weight .......................................... torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.1.2.bias ................................................ torch.Size([16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.2.0.weight .......................................... torch.Size([40, 16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.2.0.bias ................................................ torch.Size([40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.2.2.weight .......................................... torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.2.2.bias ................................................ torch.Size([16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.3.0.weight .......................................... torch.Size([40, 16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.3.0.bias ................................................ torch.Size([40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.3.2.weight .......................................... torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.3.2.bias ................................................ torch.Size([16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.4.0.weight .......................................... torch.Size([40, 16])
gnn_list.2.multi_channel_gnn_module.linear_prediction.4.0.bias ................................................ torch.Size([40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.4.2.weight .......................................... torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.linear_prediction.4.2.bias ................................................ torch.Size([16])
gnn_list.2.multi_channel_gnn_module.layers.0.linears.0.weight ............................................. torch.Size([40, 80])
gnn_list.2.multi_channel_gnn_module.layers.0.linears.0.bias ................................................... torch.Size([40])
gnn_list.2.multi_channel_gnn_module.layers.0.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.layers.0.linears.1.bias ................................................... torch.Size([16])
gnn_list.2.multi_channel_gnn_module.layers.1.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.2.multi_channel_gnn_module.layers.1.linears.0.bias ................................................... torch.Size([40])
gnn_list.2.multi_channel_gnn_module.layers.1.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.layers.1.linears.1.bias ................................................... torch.Size([16])
gnn_list.2.multi_channel_gnn_module.layers.2.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.2.multi_channel_gnn_module.layers.2.linears.0.bias ................................................... torch.Size([40])
gnn_list.2.multi_channel_gnn_module.layers.2.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.layers.2.linears.1.bias ................................................... torch.Size([16])
gnn_list.2.multi_channel_gnn_module.layers.3.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.2.multi_channel_gnn_module.layers.3.linears.0.bias ................................................... torch.Size([40])
gnn_list.2.multi_channel_gnn_module.layers.3.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.2.multi_channel_gnn_module.layers.3.linears.1.bias ................................................... torch.Size([16])
gnn_list.2.translate_mlp.linears.0.weight .................................................................. torch.Size([8, 36])
gnn_list.2.translate_mlp.linears.0.bias ........................................................................ torch.Size([8])
gnn_list.2.translate_mlp.linears.1.weight ................................................................... torch.Size([8, 8])
gnn_list.2.translate_mlp.linears.1.bias ........................................................................ torch.Size([8])
gnn_list.2.translate_mlp.linears.2.weight ................................................................... torch.Size([4, 8])
gnn_list.2.translate_mlp.linears.2.bias ........................................................................ torch.Size([4])
gnn_list.2.translate_mlp.batch_norms.0.weight .................................................................. torch.Size([8])
gnn_list.2.translate_mlp.batch_norms.0.bias .................................................................... torch.Size([8])
gnn_list.2.translate_mlp.batch_norms.1.weight .................................................................. torch.Size([8])
gnn_list.2.translate_mlp.batch_norms.1.bias .................................................................... torch.Size([8])
gnn_list.2.translate_mlp.cond_layers.0.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.2.translate_mlp.cond_layers.0.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.2.translate_mlp.cond_layers.1.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.2.translate_mlp.cond_layers.1.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.3.multi_channel_gnn_module.eps ........................................................................ torch.Size([4])
gnn_list.3.multi_channel_gnn_module.linear_prediction.0.0.weight .......................................... torch.Size([40, 20])
gnn_list.3.multi_channel_gnn_module.linear_prediction.0.0.bias ................................................ torch.Size([40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.0.2.weight .......................................... torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.0.2.bias ................................................ torch.Size([16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.1.0.weight .......................................... torch.Size([40, 16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.1.0.bias ................................................ torch.Size([40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.1.2.weight .......................................... torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.1.2.bias ................................................ torch.Size([16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.2.0.weight .......................................... torch.Size([40, 16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.2.0.bias ................................................ torch.Size([40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.2.2.weight .......................................... torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.2.2.bias ................................................ torch.Size([16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.3.0.weight .......................................... torch.Size([40, 16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.3.0.bias ................................................ torch.Size([40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.3.2.weight .......................................... torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.3.2.bias ................................................ torch.Size([16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.4.0.weight .......................................... torch.Size([40, 16])
gnn_list.3.multi_channel_gnn_module.linear_prediction.4.0.bias ................................................ torch.Size([40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.4.2.weight .......................................... torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.linear_prediction.4.2.bias ................................................ torch.Size([16])
gnn_list.3.multi_channel_gnn_module.layers.0.linears.0.weight ............................................. torch.Size([40, 80])
gnn_list.3.multi_channel_gnn_module.layers.0.linears.0.bias ................................................... torch.Size([40])
gnn_list.3.multi_channel_gnn_module.layers.0.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.layers.0.linears.1.bias ................................................... torch.Size([16])
gnn_list.3.multi_channel_gnn_module.layers.1.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.3.multi_channel_gnn_module.layers.1.linears.0.bias ................................................... torch.Size([40])
gnn_list.3.multi_channel_gnn_module.layers.1.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.layers.1.linears.1.bias ................................................... torch.Size([16])
gnn_list.3.multi_channel_gnn_module.layers.2.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.3.multi_channel_gnn_module.layers.2.linears.0.bias ................................................... torch.Size([40])
gnn_list.3.multi_channel_gnn_module.layers.2.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.layers.2.linears.1.bias ................................................... torch.Size([16])
gnn_list.3.multi_channel_gnn_module.layers.3.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.3.multi_channel_gnn_module.layers.3.linears.0.bias ................................................... torch.Size([40])
gnn_list.3.multi_channel_gnn_module.layers.3.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.3.multi_channel_gnn_module.layers.3.linears.1.bias ................................................... torch.Size([16])
gnn_list.3.translate_mlp.linears.0.weight .................................................................. torch.Size([8, 36])
gnn_list.3.translate_mlp.linears.0.bias ........................................................................ torch.Size([8])
gnn_list.3.translate_mlp.linears.1.weight ................................................................... torch.Size([8, 8])
gnn_list.3.translate_mlp.linears.1.bias ........................................................................ torch.Size([8])
gnn_list.3.translate_mlp.linears.2.weight ................................................................... torch.Size([4, 8])
gnn_list.3.translate_mlp.linears.2.bias ........................................................................ torch.Size([4])
gnn_list.3.translate_mlp.batch_norms.0.weight .................................................................. torch.Size([8])
gnn_list.3.translate_mlp.batch_norms.0.bias .................................................................... torch.Size([8])
gnn_list.3.translate_mlp.batch_norms.1.weight .................................................................. torch.Size([8])
gnn_list.3.translate_mlp.batch_norms.1.bias .................................................................... torch.Size([8])
gnn_list.3.translate_mlp.cond_layers.0.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.3.translate_mlp.cond_layers.0.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.3.translate_mlp.cond_layers.1.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.3.translate_mlp.cond_layers.1.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.4.multi_channel_gnn_module.eps ........................................................................ torch.Size([4])
gnn_list.4.multi_channel_gnn_module.linear_prediction.0.0.weight .......................................... torch.Size([40, 20])
gnn_list.4.multi_channel_gnn_module.linear_prediction.0.0.bias ................................................ torch.Size([40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.0.2.weight .......................................... torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.0.2.bias ................................................ torch.Size([16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.1.0.weight .......................................... torch.Size([40, 16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.1.0.bias ................................................ torch.Size([40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.1.2.weight .......................................... torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.1.2.bias ................................................ torch.Size([16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.2.0.weight .......................................... torch.Size([40, 16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.2.0.bias ................................................ torch.Size([40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.2.2.weight .......................................... torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.2.2.bias ................................................ torch.Size([16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.3.0.weight .......................................... torch.Size([40, 16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.3.0.bias ................................................ torch.Size([40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.3.2.weight .......................................... torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.3.2.bias ................................................ torch.Size([16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.4.0.weight .......................................... torch.Size([40, 16])
gnn_list.4.multi_channel_gnn_module.linear_prediction.4.0.bias ................................................ torch.Size([40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.4.2.weight .......................................... torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.linear_prediction.4.2.bias ................................................ torch.Size([16])
gnn_list.4.multi_channel_gnn_module.layers.0.linears.0.weight ............................................. torch.Size([40, 80])
gnn_list.4.multi_channel_gnn_module.layers.0.linears.0.bias ................................................... torch.Size([40])
gnn_list.4.multi_channel_gnn_module.layers.0.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.layers.0.linears.1.bias ................................................... torch.Size([16])
gnn_list.4.multi_channel_gnn_module.layers.1.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.4.multi_channel_gnn_module.layers.1.linears.0.bias ................................................... torch.Size([40])
gnn_list.4.multi_channel_gnn_module.layers.1.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.layers.1.linears.1.bias ................................................... torch.Size([16])
gnn_list.4.multi_channel_gnn_module.layers.2.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.4.multi_channel_gnn_module.layers.2.linears.0.bias ................................................... torch.Size([40])
gnn_list.4.multi_channel_gnn_module.layers.2.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.layers.2.linears.1.bias ................................................... torch.Size([16])
gnn_list.4.multi_channel_gnn_module.layers.3.linears.0.weight ............................................. torch.Size([40, 64])
gnn_list.4.multi_channel_gnn_module.layers.3.linears.0.bias ................................................... torch.Size([40])
gnn_list.4.multi_channel_gnn_module.layers.3.linears.1.weight ............................................. torch.Size([16, 40])
gnn_list.4.multi_channel_gnn_module.layers.3.linears.1.bias ................................................... torch.Size([16])
gnn_list.4.translate_mlp.linears.0.weight .................................................................. torch.Size([8, 36])
gnn_list.4.translate_mlp.linears.0.bias ........................................................................ torch.Size([8])
gnn_list.4.translate_mlp.linears.1.weight ................................................................... torch.Size([8, 8])
gnn_list.4.translate_mlp.linears.1.bias ........................................................................ torch.Size([8])
gnn_list.4.translate_mlp.linears.2.weight ................................................................... torch.Size([2, 8])
gnn_list.4.translate_mlp.linears.2.bias ........................................................................ torch.Size([2])
gnn_list.4.translate_mlp.batch_norms.0.weight .................................................................. torch.Size([8])
gnn_list.4.translate_mlp.batch_norms.0.bias .................................................................... torch.Size([8])
gnn_list.4.translate_mlp.batch_norms.1.weight .................................................................. torch.Size([8])
gnn_list.4.translate_mlp.batch_norms.1.bias .................................................................... torch.Size([8])
gnn_list.4.translate_mlp.cond_layers.0.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.4.translate_mlp.cond_layers.0.bias .............................................................. torch.Size([6, 1, 8])
gnn_list.4.translate_mlp.cond_layers.1.gain .............................................................. torch.Size([6, 1, 8])
gnn_list.4.translate_mlp.cond_layers.1.bias .............................................................. torch.Size([6, 1, 8])
final_read_score.linears.0.weight ......................................................................... torch.Size([36, 18])
final_read_score.linears.0.bias ............................................................................... torch.Size([36])
final_read_score.linears.1.weight ......................................................................... torch.Size([36, 36])
final_read_score.linears.1.bias ............................................................................... torch.Size([36])
final_read_score.linears.2.weight .......................................................................... torch.Size([1, 36])
final_read_score.linears.2.bias ................................................................................ torch.Size([1])
final_read_score.cond_layers.0.gain ..................................................................... torch.Size([6, 1, 36])
final_read_score.cond_layers.0.bias ..................................................................... torch.Size([6, 1, 36])
final_read_score.cond_layers.1.gain ..................................................................... torch.Size([6, 1, 36])
final_read_score.cond_layers.1.bias ..................................................................... torch.Size([6, 1, 36])
| 05-02 00:21:29 Parameters Count: 91013, Trainable: 91013
| 05-02 00:21:29 [0.1, 0.2, 0.4, 0.6, 0.8, 1.6], 0.0
| 05-02 00:21:31 epoch: 000| time: 2.7s| train loss: +1.119e+02 | test loss: +1.406e+02 | 
| 05-02 00:21:31 epoch: 000| train loss i: [20.62	20.51	20.51	19.01	17.99	13.23] test loss i: [27.7 	28.23	26.94	24.33	22.78	10.63] | 
| 05-02 00:21:34 epoch: 001| time: 2.4s| train loss: +1.040e+02 | test loss: +1.112e+02 | 
| 05-02 00:21:34 epoch: 001| train loss i: [21.93	20.22	20.58	18.02	16.7 	 6.57] test loss i: [23.12	24.24	20.69	19.76	18.16	 5.23] | 
| 05-02 00:21:36 epoch: 002| time: 2.5s| train loss: +9.500e+01 | test loss: +1.158e+02 | 
| 05-02 00:21:36 epoch: 002| train loss i: [20.76	21.23	18.94	16.95	13.8 	 3.31] test loss i: [26.73	27.07	22.43	19.96	15.46	 4.11] | 
| 05-02 00:21:39 epoch: 003| time: 2.4s| train loss: +8.874e+01 | test loss: +1.099e+02 | 
| 05-02 00:21:39 epoch: 003| train loss i: [20.54	19.68	18.47	15.49	12.09	 2.47] test loss i: [27.09	25.17	21.25	17.1 	14.23	 5.04] | 
| 05-02 00:21:41 epoch: 004| time: 2.5s| train loss: +8.750e+01 | test loss: +1.028e+02 | 
| 05-02 00:21:41 epoch: 004| train loss i: [21.07	19.34	17.87	14.19	10.68	 4.35] test loss i: [24.65	22.15	21.06	15.19	12.21	 7.54] | 
| 05-02 00:21:44 epoch: 005| time: 2.5s| train loss: +8.872e+01 | test loss: +1.125e+02 | 
| 05-02 00:21:44 epoch: 005| train loss i: [21.03	20.27	17.28	14.37	10.18	 5.59] test loss i: [26.53	23.38	24.  	16.73	12.9 	 8.93] | 
| 05-02 00:21:46 epoch: 006| time: 2.5s| train loss: +8.594e+01 | test loss: +9.553e+01 | 
| 05-02 00:21:46 epoch: 006| train loss i: [19.86	19.16	17.17	14.19	 9.77	 5.8 ] test loss i: [21.33	21.08	19.74	16.22	10.87	 6.29] | 
| 05-02 00:21:48 epoch: 007| time: 2.4s| train loss: +8.504e+01 | test loss: +1.127e+02 | 
| 05-02 00:21:48 epoch: 007| train loss i: [20.65	19.53	16.86	13.27	 9.76	 4.97] test loss i: [25.31	27.19	25.17	17.19	12.64	 5.21] | 
| 05-02 00:21:51 epoch: 008| time: 2.4s| train loss: +8.688e+01 | test loss: +1.349e+02 | 
| 05-02 00:21:51 epoch: 008| train loss i: [21.08	19.91	17.41	14.49	 9.71	 4.27] test loss i: [34.23	29.66	27.54	21.5 	16.66	 5.26] | 
| 05-02 00:21:53 epoch: 009| time: 2.4s| train loss: +8.533e+01 | test loss: +1.173e+02 | 
| 05-02 00:21:53 epoch: 009| train loss i: [21.  	19.87	17.58	13.68	 9.56	 3.64] test loss i: [26.55	26.87	26.19	18.1 	14.6 	 5.02] | 
| 05-02 00:21:56 epoch: 010| time: 2.5s| train loss: +8.403e+01 | test loss: +1.478e+02 | 
| 05-02 00:21:56 epoch: 010| train loss i: [19.51	19.76	17.93	13.61	 9.51	 3.71] test loss i: [36.09	36.73	27.9 	22.46	17.63	 7.01] | 
| 05-02 00:21:58 epoch: 011| time: 2.5s| train loss: +8.615e+01 | test loss: +8.240e+01 | 
| 05-02 00:21:58 epoch: 011| train loss i: [20.89	21.06	17.41	13.46	 9.46	 3.88] test loss i: [21.59	20.49	14.87	12.67	 9.07	 3.71] | 
| 05-02 00:22:01 epoch: 012| time: 2.5s| train loss: +8.194e+01 | test loss: +9.773e+01 | 
| 05-02 00:22:01 epoch: 012| train loss i: [20.33	18.48	17.44	12.92	 8.85	 3.93] test loss i: [21.74	24.  	20.56	16.03	10.68	 4.72] | 
| 05-02 00:22:03 epoch: 013| time: 2.4s| train loss: +8.252e+01 | test loss: +1.144e+02 | 
| 05-02 00:22:03 epoch: 013| train loss i: [20.5 	18.85	16.89	13.11	 8.77	 4.4 ] test loss i: [24.38	25.84	24.31	18.81	12.48	 8.61] | 
| 05-02 00:22:06 epoch: 014| time: 2.5s| train loss: +8.257e+01 | test loss: +9.129e+01 | 
| 05-02 00:22:06 epoch: 014| train loss i: [20.51	20.29	16.3 	13.07	 8.22	 4.17] test loss i: [22.74	21.87	17.69	14.4 	 8.99	 5.6 ] | 
| 05-02 00:22:08 epoch: 015| time: 2.4s| train loss: +8.206e+01 | test loss: +1.002e+02 | 
| 05-02 00:22:08 epoch: 015| train loss i: [20.84	19.32	17.12	12.41	 8.29	 4.09] test loss i: [25.47	24.  	19.67	15.39	10.59	 5.13] | 
| 05-02 00:22:11 epoch: 016| time: 2.5s| train loss: +7.980e+01 | test loss: +1.051e+02 | 
| 05-02 00:22:11 epoch: 016| train loss i: [20.27	19.03	16.24	12.56	 7.56	 4.14] test loss i: [24.72	27.28	20.8 	15.26	10.56	 6.5 ] | 
| 05-02 00:22:13 epoch: 017| time: 2.5s| train loss: +7.892e+01 | test loss: +1.169e+02 | 
| 05-02 00:22:13 epoch: 017| train loss i: [19.77	19.22	16.5 	12.3 	 7.49	 3.65] test loss i: [29.21	31.36	23.53	16.31	10.86	 5.65] | 
| 05-02 00:22:15 epoch: 018| time: 2.4s| train loss: +7.895e+01 | test loss: +9.381e+01 | 
| 05-02 00:22:15 epoch: 018| train loss i: [20.32	20.21	15.62	11.97	 7.12	 3.72] test loss i: [22.61	23.07	21.49	13.12	 8.24	 5.29] | 
| 05-02 00:22:18 epoch: 019| time: 2.5s| train loss: +7.990e+01 | test loss: +1.186e+02 | 
| 05-02 00:22:18 epoch: 019| train loss i: [22.27	19.47	16.48	11.2 	 6.92	 3.57] test loss i: [29.95	28.08	25.8 	16.64	10.68	 7.45] | 
| 05-02 00:22:20 epoch: 020| time: 2.4s| train loss: +7.685e+01 | test loss: +1.241e+02 | 
| 05-02 00:22:20 epoch: 020| train loss i: [20.31	18.92	16.47	11.19	 6.6 	 3.36] test loss i: [27.82	27.02	22.97	16.03	11.51	18.71] | 
| 05-02 00:22:23 epoch: 021| time: 2.5s| train loss: +7.630e+01 | test loss: +8.931e+01 | 
| 05-02 00:22:23 epoch: 021| train loss i: [20.83	19.62	15.92	10.49	 5.82	 3.63] test loss i: [23.51	22.93	19.79	11.18	 7.17	 4.74] | 
| 05-02 00:22:25 epoch: 022| time: 2.4s| train loss: +7.349e+01 | test loss: +9.357e+01 | 
| 05-02 00:22:25 epoch: 022| train loss i: [20.39	19.16	15.11	 9.83	 5.69	 3.3 ] test loss i: [23.45	25.61	18.51	12.32	 7.28	 6.41] | 
| 05-02 00:22:28 epoch: 023| time: 2.5s| train loss: +7.210e+01 | test loss: +8.363e+01 | 
| 05-02 00:22:28 epoch: 023| train loss i: [20.34	18.73	14.91	 9.46	 5.36	 3.3 ] test loss i: [23.45	23.3 	17.77	 9.74	 5.53	 3.83] | 
| 05-02 00:22:30 epoch: 024| time: 2.5s| train loss: +6.940e+01 | test loss: +8.754e+01 | 
| 05-02 00:22:30 epoch: 024| train loss i: [19.98	17.88	14.53	 8.71	 4.81	 3.48] test loss i: [23.72	23.57	17.35	10.66	 6.02	 6.23] | 
| 05-02 00:22:33 epoch: 025| time: 2.5s| train loss: +7.004e+01 | test loss: +1.152e+02 | 
| 05-02 00:22:33 epoch: 025| train loss i: [20.91	19.21	13.86	 8.55	 4.64	 2.86] test loss i: [31.46	28.33	21.25	13.51	 7.57	13.11] | 
| 05-02 00:22:35 epoch: 026| time: 2.5s| train loss: +6.896e+01 | test loss: +9.823e+01 | 
| 05-02 00:22:35 epoch: 026| train loss i: [21.23	18.24	13.7 	 8.16	 4.69	 2.93] test loss i: [29.35	25.97	18.27	10.31	 5.64	 8.7 ] | 
| 05-02 00:22:38 epoch: 027| time: 2.5s| train loss: +6.770e+01 | test loss: +7.752e+01 | 
| 05-02 00:22:38 epoch: 027| train loss i: [21.18	18.26	13.13	 7.63	 4.44	 3.06] test loss i: [23.36	19.79	15.19	 8.22	 5.22	 5.73] | 
| 05-02 00:22:40 epoch: 028| time: 2.5s| train loss: +6.545e+01 | test loss: +8.301e+01 | 
| 05-02 00:22:40 epoch: 028| train loss i: [19.66	18.43	13.01	 6.82	 4.55	 2.97] test loss i: [23.57	21.57	14.37	 8.06	 4.83	10.61] | 
| 05-02 00:22:43 epoch: 029| time: 2.4s| train loss: +6.376e+01 | test loss: +1.229e+02 | 
| 05-02 00:22:43 epoch: 029| train loss i: [19.72	17.48	12.22	 7.03	 4.81	 2.5 ] test loss i: [29.13	28.39	19.05	11.5 	 9.25	25.62] | 
| 05-02 00:22:45 epoch: 030| time: 2.5s| train loss: +6.354e+01 | test loss: +1.154e+02 | 
| 05-02 00:22:45 epoch: 030| train loss i: [19.93	17.73	12.58	 6.14	 4.82	 2.35] test loss i: [31.82	28.13	21.56	13.2 	 9.51	11.19] | 
| 05-02 00:22:48 epoch: 031| time: 2.5s| train loss: +6.610e+01 | test loss: +8.415e+01 | 
| 05-02 00:22:48 epoch: 031| train loss i: [20.64	18.77	12.34	 6.74	 5.27	 2.34] test loss i: [25.99	23.12	15.85	 8.33	 6.68	 4.19] | 
| 05-02 00:22:50 epoch: 032| time: 2.4s| train loss: +6.310e+01 | test loss: +6.374e+01 | 
| 05-02 00:22:50 epoch: 032| train loss i: [20.52	17.43	11.79	 6.42	 4.86	 2.08] test loss i: [18.64	17.69	11.89	 5.94	 7.01	 2.57] | 
| 05-02 00:22:52 epoch: 033| time: 2.5s| train loss: +6.170e+01 | test loss: +7.894e+01 | 
| 05-02 00:22:52 epoch: 033| train loss i: [19.53	18.05	11.08	 6.01	 4.87	 2.16] test loss i: [27.2 	22.65	13.89	 6.73	 5.37	 3.11] | 
| 05-02 00:22:55 epoch: 034| time: 2.5s| train loss: +6.264e+01 | test loss: +6.347e+01 | 
| 05-02 00:22:55 epoch: 034| train loss i: [21.22	17.89	11.01	 5.78	 4.56	 2.19] test loss i: [20.57	18.95	11.08	 5.46	 4.96	 2.45] | 
| 05-02 00:22:57 epoch: 035| time: 2.5s| train loss: +6.128e+01 | test loss: +6.903e+01 | 
| 05-02 00:22:57 epoch: 035| train loss i: [20.98	17.5 	10.44	 5.59	 4.67	 2.1 ] test loss i: [23.02	18.35	11.92	 7.71	 4.73	 3.3 ] | 
| 05-02 00:23:00 epoch: 036| time: 2.5s| train loss: +6.081e+01 | test loss: +6.255e+01 | 
| 05-02 00:23:00 epoch: 036| train loss i: [20.27	17.44	10.39	 5.85	 4.68	 2.19] test loss i: [19.9 	20.61	 9.43	 5.22	 4.92	 2.48] | 
| 05-02 00:23:02 epoch: 037| time: 2.4s| train loss: +6.041e+01 | test loss: +5.458e+01 | 
| 05-02 00:23:02 epoch: 037| train loss i: [20.1 	17.95	10.  	 5.55	 4.66	 2.15] test loss i: [17.88	17.03	 9.27	 4.93	 3.67	 1.81] | 
| 05-02 00:23:05 epoch: 038| time: 2.5s| train loss: +5.963e+01 | test loss: +8.611e+01 | 
| 05-02 00:23:05 epoch: 038| train loss i: [19.96	16.86	10.08	 5.91	 4.63	 2.19] test loss i: [28.1 	26.57	14.75	 7.2 	 6.13	 3.36] | 
| 05-02 00:23:07 epoch: 039| time: 2.5s| train loss: +5.919e+01 | test loss: +7.339e+01 | 
| 05-02 00:23:07 epoch: 039| train loss i: [19.94	17.42	 9.57	 5.66	 4.62	 1.96] test loss i: [26.22	21.64	11.47	 6.32	 5.18	 2.57] | 
| 05-02 00:23:10 epoch: 040| time: 2.5s| train loss: +5.974e+01 | test loss: +7.667e+01 | 
| 05-02 00:23:10 epoch: 040| train loss i: [20.71	17.02	 9.28	 6.16	 4.47	 2.1 ] test loss i: [23.23	23.82	11.9 	 8.3 	 6.61	 2.8 ] | 
| 05-02 00:23:12 epoch: 041| time: 2.5s| train loss: +5.902e+01 | test loss: +8.150e+01 | 
| 05-02 00:23:12 epoch: 041| train loss i: [20.33	16.95	 9.51	 5.66	 4.5 	 2.07] test loss i: [29.38	24.49	11.76	 6.98	 5.24	 3.65] | 
| 05-02 00:23:15 epoch: 042| time: 2.5s| train loss: +5.841e+01 | test loss: +7.075e+01 | 
| 05-02 00:23:15 epoch: 042| train loss i: [19.61	17.12	 9.4 	 5.92	 4.45	 1.91] test loss i: [25.34	19.78	11.42	 6.41	 4.8 	 3.01] | 
| 05-02 00:23:17 epoch: 043| time: 2.5s| train loss: +5.821e+01 | test loss: +6.024e+01 | 
| 05-02 00:23:17 epoch: 043| train loss i: [19.47	17.09	 9.1 	 6.03	 4.37	 2.15] test loss i: [21.71	17.87	 8.83	 5.24	 3.79	 2.8 ] | 
| 05-02 00:23:20 epoch: 044| time: 2.5s| train loss: +5.739e+01 | test loss: +7.033e+01 | 
| 05-02 00:23:20 epoch: 044| train loss i: [20.43	16.24	 8.82	 5.79	 4.25	 1.85] test loss i: [24.73	20.12	 9.92	 7.11	 5.58	 2.87] | 
| 05-02 00:23:22 epoch: 045| time: 2.5s| train loss: +5.699e+01 | test loss: +6.439e+01 | 
| 05-02 00:23:22 epoch: 045| train loss i: [19.43	16.98	 8.74	 5.95	 4.04	 1.86] test loss i: [21.2 	18.33	10.55	 6.93	 4.95	 2.44] | 
| 05-02 00:23:25 epoch: 046| time: 2.5s| train loss: +5.710e+01 | test loss: +7.220e+01 | 
| 05-02 00:23:25 epoch: 046| train loss i: [19.73	16.33	 8.5 	 5.96	 4.63	 1.95] test loss i: [24.95	21.34	10.7 	 7.04	 5.17	 3.  ] | 
| 05-02 00:23:27 epoch: 047| time: 2.5s| train loss: +5.615e+01 | test loss: +7.785e+01 | 
| 05-02 00:23:27 epoch: 047| train loss i: [19.37	15.9 	 8.3 	 5.96	 4.57	 2.06] test loss i: [23.61	20.99	12.64	 8.83	 9.2 	 2.58] | 
| 05-02 00:23:30 epoch: 048| time: 2.5s| train loss: +5.721e+01 | test loss: +7.872e+01 | 
| 05-02 00:23:30 epoch: 048| train loss i: [19.85	16.36	 8.3 	 6.09	 4.51	 2.1 ] test loss i: [31.13	22.04	10.55	 7.02	 5.46	 2.52] | 
| 05-02 00:23:32 epoch: 049| time: 2.5s| train loss: +5.563e+01 | test loss: +5.751e+01 | 
| 05-02 00:23:32 epoch: 049| train loss i: [19.49	16.07	 8.12	 5.81	 4.3 	 1.83] test loss i: [20.48	16.79	 7.8 	 6.17	 4.27	 2.  ] | 
| 05-02 00:23:35 epoch: 050| time: 2.5s| train loss: +5.439e+01 | test loss: +6.013e+01 | 
| 05-02 00:23:35 epoch: 050| train loss i: [19.44	15.55	 7.98	 5.35	 4.13	 1.94] test loss i: [22.83	17.37	 8.62	 5.06	 4.22	 2.04] | 
| 05-02 00:23:37 epoch: 051| time: 2.5s| train loss: +5.462e+01 | test loss: +5.817e+01 | 
| 05-02 00:23:37 epoch: 051| train loss i: [19.45	15.66	 8.12	 5.53	 4.01	 1.85] test loss i: [21.53	16.33	 8.86	 5.53	 4.11	 1.81] | 
| 05-02 00:23:40 epoch: 052| time: 2.5s| train loss: +5.404e+01 | test loss: +6.337e+01 | 
| 05-02 00:23:40 epoch: 052| train loss i: [19.56	15.62	 7.57	 5.49	 4.01	 1.78] test loss i: [22.21	16.83	10.66	 6.86	 4.5 	 2.32] | 
| 05-02 00:23:42 epoch: 053| time: 2.5s| train loss: +5.384e+01 | test loss: +5.481e+01 | 
| 05-02 00:23:42 epoch: 053| train loss i: [19.82	14.59	 7.89	 5.36	 4.39	 1.78] test loss i: [19.94	16.17	 7.06	 5.35	 3.97	 2.33] | 
| 05-02 00:23:45 epoch: 054| time: 2.5s| train loss: +5.292e+01 | test loss: +7.252e+01 | 
| 05-02 00:23:45 epoch: 054| train loss i: [19.65	14.56	 7.95	 4.94	 3.99	 1.83] test loss i: [26.78	20.74	 9.28	 6.99	 5.83	 2.91] | 
| 05-02 00:23:47 epoch: 055| time: 2.5s| train loss: +5.418e+01 | test loss: +6.251e+01 | 
| 05-02 00:23:47 epoch: 055| train loss i: [19.15	14.78	 8.32	 5.85	 4.17	 1.91] test loss i: [22.42	16.91	 8.52	 6.63	 5.43	 2.61] | 
| 05-02 00:23:50 epoch: 056| time: 2.5s| train loss: +5.406e+01 | test loss: +8.191e+01 | 
| 05-02 00:23:50 epoch: 056| train loss i: [19.23	15.04	 8.15	 5.54	 4.23	 1.89] test loss i: [29.03	23.54	12.37	 8.54	 5.85	 2.59] | 
| 05-02 00:23:52 epoch: 057| time: 2.5s| train loss: +5.275e+01 | test loss: +6.235e+01 | 
| 05-02 00:23:52 epoch: 057| train loss i: [19.76	14.15	 7.61	 5.24	 4.33	 1.66] test loss i: [23.09	18.3 	 8.34	 5.77	 4.48	 2.37] | 
| 05-02 00:23:54 epoch: 058| time: 2.5s| train loss: +5.352e+01 | test loss: +6.252e+01 | 
| 05-02 00:23:54 epoch: 058| train loss i: [19.5 	15.01	 7.5 	 5.64	 4.15	 1.72] test loss i: [25.62	18.45	 7.49	 4.76	 4.12	 2.07] | 
| 05-02 00:23:57 epoch: 059| time: 2.5s| train loss: +5.217e+01 | test loss: +6.223e+01 | 
| 05-02 00:23:57 epoch: 059| train loss i: [19.12	14.22	 7.85	 5.  	 4.18	 1.79] test loss i: [23.98	17.32	 7.86	 5.83	 4.66	 2.58] | 
| 05-02 00:23:59 epoch: 060| time: 2.5s| train loss: +5.071e+01 | test loss: +7.770e+01 | 
| 05-02 00:23:59 epoch: 060| train loss i: [18.54	13.59	 7.38	 5.32	 4.05	 1.83] test loss i: [30.34	20.88	11.98	 6.67	 5.04	 2.79] | 
| 05-02 00:24:02 epoch: 061| time: 2.5s| train loss: +5.086e+01 | test loss: +5.480e+01 | 
| 05-02 00:24:02 epoch: 061| train loss i: [18.7 	13.59	 7.41	 5.26	 4.02	 1.89] test loss i: [19.4 	16.1 	 7.71	 5.43	 4.36	 1.79] | 
| 05-02 00:24:04 epoch: 062| time: 2.5s| train loss: +4.981e+01 | test loss: +6.787e+01 | 
| 05-02 00:24:04 epoch: 062| train loss i: [17.62	13.57	 7.25	 5.15	 4.21	 2.  ] test loss i: [27.35	17.02	 9.2 	 6.83	 4.7 	 2.78] | 
| 05-02 00:24:07 epoch: 063| time: 2.5s| train loss: +5.054e+01 | test loss: +6.924e+01 | 
| 05-02 00:24:07 epoch: 063| train loss i: [18.64	13.2 	 7.27	 5.47	 4.1 	 1.86] test loss i: [26.04	17.33	10.  	 7.87	 5.72	 2.27] | 
| 05-02 00:24:09 epoch: 064| time: 2.5s| train loss: +4.949e+01 | test loss: +5.583e+01 | 
| 05-02 00:24:09 epoch: 064| train loss i: [18.46	12.4 	 7.21	 4.92	 4.34	 2.16] test loss i: [20.9 	14.63	 7.33	 6.17	 4.6 	 2.21] | 
| 05-02 00:24:12 epoch: 065| time: 2.5s| train loss: +5.116e+01 | test loss: +5.492e+01 | 
| 05-02 00:24:12 epoch: 065| train loss i: [18.69	13.63	 7.33	 5.32	 4.22	 1.97] test loss i: [21.15	14.23	 7.72	 6.13	 3.75	 1.93] | 
| 05-02 00:24:14 epoch: 066| time: 2.5s| train loss: +5.024e+01 | test loss: +7.157e+01 | 
| 05-02 00:24:14 epoch: 066| train loss i: [19.25	12.89	 6.97	 4.79	 4.45	 1.9 ] test loss i: [27.27	19.44	10.65	 6.49	 5.17	 2.56] | 
| 05-02 00:24:17 epoch: 067| time: 2.5s| train loss: +4.963e+01 | test loss: +4.950e+01 | 
| 05-02 00:24:17 epoch: 067| train loss i: [17.79	13.07	 7.61	 5.2 	 4.22	 1.75] test loss i: [19.29	12.52	 6.74	 4.53	 4.46	 1.95] | 
| 05-02 00:24:19 epoch: 068| time: 2.5s| train loss: +4.953e+01 | test loss: +5.843e+01 | 
| 05-02 00:24:19 epoch: 068| train loss i: [18.57	12.44	 6.84	 5.59	 4.21	 1.88] test loss i: [23.35	14.56	 7.58	 5.72	 5.21	 2.02] | 
| 05-02 00:24:22 epoch: 069| time: 2.5s| train loss: +4.847e+01 | test loss: +4.627e+01 | 
| 05-02 00:24:22 epoch: 069| train loss i: [18.2 	12.38	 6.8 	 5.12	 4.17	 1.8 ] test loss i: [17.93	10.37	 6.74	 5.08	 4.29	 1.86] | 
| 05-02 00:24:24 epoch: 070| time: 2.4s| train loss: +4.939e+01 | test loss: +5.069e+01 | 
| 05-02 00:24:24 epoch: 070| train loss i: [18.36	12.2 	 7.22	 5.56	 4.22	 1.82] test loss i: [18.31	12.98	 7.92	 5.22	 4.5 	 1.76] | 
| 05-02 00:24:27 epoch: 071| time: 2.5s| train loss: +4.692e+01 | test loss: +5.851e+01 | 
| 05-02 00:24:27 epoch: 071| train loss i: [17.47	12.19	 6.88	 4.88	 3.83	 1.67] test loss i: [23.78	14.34	 8.06	 6.06	 4.44	 1.84] | 
| 05-02 00:24:29 epoch: 072| time: 2.5s| train loss: +4.749e+01 | test loss: +5.446e+01 | 
| 05-02 00:24:29 epoch: 072| train loss i: [17.67	11.83	 7.01	 5.17	 4.05	 1.77] test loss i: [21.45	12.95	 7.99	 6.06	 3.75	 2.27] | 
| 05-02 00:24:32 epoch: 073| time: 2.4s| train loss: +4.711e+01 | test loss: +6.344e+01 | 
| 05-02 00:24:32 epoch: 073| train loss i: [17.03	11.43	 7.41	 5.14	 4.26	 1.84] test loss i: [26.76	15.84	 7.33	 5.82	 5.33	 2.35] | 
| 05-02 00:24:34 epoch: 074| time: 2.5s| train loss: +4.714e+01 | test loss: +6.090e+01 | 
| 05-02 00:24:34 epoch: 074| train loss i: [17.26	11.18	 7.04	 5.23	 4.35	 2.08] test loss i: [23.36	16.05	 9.02	 5.58	 4.3 	 2.58] | 
| 05-02 00:24:37 epoch: 075| time: 2.5s| train loss: +4.755e+01 | test loss: +4.829e+01 | 
| 05-02 00:24:37 epoch: 075| train loss i: [17.67	11.33	 6.98	 5.77	 4.04	 1.77] test loss i: [17.12	11.98	 6.96	 5.13	 4.85	 2.24] | 
| 05-02 00:24:39 epoch: 076| time: 2.5s| train loss: +4.768e+01 | test loss: +5.518e+01 | 
| 05-02 00:24:39 epoch: 076| train loss i: [17.17	11.34	 7.59	 5.42	 4.15	 2.01] test loss i: [22.02	13.99	 6.68	 5.75	 4.64	 2.1 ] | 
| 05-02 00:24:42 epoch: 077| time: 2.5s| train loss: +4.793e+01 | test loss: +5.853e+01 | 
| 05-02 00:24:42 epoch: 077| train loss i: [17.87	11.1 	 7.31	 5.51	 4.34	 1.8 ] test loss i: [24.56	13.85	 8.14	 5.46	 4.52	 2.  ] | 
| 05-02 00:24:44 epoch: 078| time: 2.5s| train loss: +4.803e+01 | test loss: +6.044e+01 | 
| 05-02 00:24:44 epoch: 078| train loss i: [17.19	11.9 	 7.26	 5.49	 4.32	 1.87] test loss i: [20.04	15.37	 9.8 	 7.62	 5.21	 2.39] | 
| 05-02 00:24:46 epoch: 079| time: 2.5s| train loss: +4.805e+01 | test loss: +6.720e+01 | 
| 05-02 00:24:46 epoch: 079| train loss i: [16.97	12.  	 7.06	 5.76	 4.26	 1.99] test loss i: [23.99	16.44	12.11	 6.96	 5.21	 2.48] | 
| 05-02 00:24:49 epoch: 080| time: 2.5s| train loss: +4.783e+01 | test loss: +4.695e+01 | 
| 05-02 00:24:49 epoch: 080| train loss i: [17.06	11.71	 7.28	 5.38	 4.49	 1.92] test loss i: [18.17	10.78	 6.33	 6.04	 3.58	 2.05] | 
| 05-02 00:24:51 epoch: 081| time: 2.5s| train loss: +4.606e+01 | test loss: +4.307e+01 | 
| 05-02 00:24:51 epoch: 081| train loss i: [17.16	10.89	 6.59	 5.26	 4.3 	 1.86] test loss i: [16.86	 9.09	 6.55	 4.71	 4.09	 1.77] | 
| 05-02 00:24:54 epoch: 082| time: 2.4s| train loss: +4.573e+01 | test loss: +4.788e+01 | 
| 05-02 00:24:54 epoch: 082| train loss i: [17.09	10.43	 6.97	 5.41	 4.12	 1.71] test loss i: [18.84	11.01	 7.2 	 5.11	 3.6 	 2.12] | 
| 05-02 00:24:56 epoch: 083| time: 2.5s| train loss: +4.328e+01 | test loss: +5.196e+01 | 
| 05-02 00:24:56 epoch: 083| train loss i: [16.16	 9.92	 6.62	 4.78	 4.06	 1.73] test loss i: [21.72	11.34	 7.84	 4.9 	 4.3 	 1.86] | 
| 05-02 00:24:59 epoch: 084| time: 2.4s| train loss: +4.362e+01 | test loss: +4.628e+01 | 
| 05-02 00:24:59 epoch: 084| train loss i: [16.36	 9.42	 6.72	 5.18	 4.1 	 1.85] test loss i: [20.57	 9.62	 5.89	 4.86	 3.64	 1.69] | 
| 05-02 00:25:01 epoch: 085| time: 2.4s| train loss: +4.328e+01 | test loss: +5.522e+01 | 
| 05-02 00:25:01 epoch: 085| train loss i: [15.47	 9.61	 6.9 	 5.32	 4.09	 1.9 ] test loss i: [21.31	12.1 	 8.9 	 5.87	 4.88	 2.17] | 
| 05-02 00:25:04 epoch: 086| time: 2.5s| train loss: +4.221e+01 | test loss: +4.122e+01 | 
| 05-02 00:25:04 epoch: 086| train loss i: [15.09	 9.02	 6.96	 5.01	 4.24	 1.89] test loss i: [15.64	 8.42	 6.78	 4.43	 3.79	 2.17] | 
| 05-02 00:25:06 epoch: 087| time: 2.4s| train loss: +4.337e+01 | test loss: +4.371e+01 | 
| 05-02 00:25:06 epoch: 087| train loss i: [15.1 	 9.74	 7.29	 5.19	 4.01	 2.04] test loss i: [16.4 	 9.81	 7.08	 4.83	 3.7 	 1.87] | 
| 05-02 00:25:09 epoch: 088| time: 2.5s| train loss: +4.423e+01 | test loss: +7.705e+01 | 
| 05-02 00:25:09 epoch: 088| train loss i: [15.69	 9.61	 6.95	 5.34	 4.46	 2.18] test loss i: [27.69	17.33	12.99	 8.21	 7.1 	 3.73] | 
| 05-02 00:25:11 epoch: 089| time: 2.5s| train loss: +4.585e+01 | test loss: +4.479e+01 | 
| 05-02 00:25:11 epoch: 089| train loss i: [16.03	10.85	 7.24	 5.44	 4.25	 2.05] test loss i: [16.13	10.8 	 7.1 	 4.67	 4.29	 1.79] | 
| 05-02 00:25:14 epoch: 090| time: 2.5s| train loss: +4.198e+01 | test loss: +3.951e+01 | 
| 05-02 00:25:14 epoch: 090| train loss i: [14.9 	 9.18	 6.54	 5.36	 4.06	 1.93] test loss i: [13.93	 8.67	 5.82	 5.37	 3.69	 2.04] | 
| 05-02 00:25:16 epoch: 091| time: 2.5s| train loss: +4.265e+01 | test loss: +4.052e+01 | 
| 05-02 00:25:16 epoch: 091| train loss i: [14.8 	 8.83	 6.93	 5.57	 4.65	 1.86] test loss i: [14.76	 8.52	 6.22	 5.08	 4.12	 1.81] | 
| 05-02 00:25:19 epoch: 092| time: 2.5s| train loss: +3.996e+01 | test loss: +5.203e+01 | 
| 05-02 00:25:19 epoch: 092| train loss i: [13.47	 8.55	 6.92	 4.92	 4.33	 1.77] test loss i: [19.37	11.63	 8.11	 6.16	 4.55	 2.22] | 
| 05-02 00:25:21 epoch: 093| time: 2.5s| train loss: +4.203e+01 | test loss: +7.343e+01 | 
| 05-02 00:25:21 epoch: 093| train loss i: [14.37	 8.94	 7.03	 5.7 	 4.04	 1.95] test loss i: [26.15	19.77	11.23	 8.29	 5.66	 2.32] | 
| 05-02 00:25:24 epoch: 094| time: 2.5s| train loss: +4.185e+01 | test loss: +5.155e+01 | 
| 05-02 00:25:24 epoch: 094| train loss i: [13.84	 9.26	 7.22	 5.43	 4.11	 1.98] test loss i: [18.22	 9.79	 8.65	 7.25	 5.69	 1.96] | 
| 05-02 00:25:26 epoch: 095| time: 2.5s| train loss: +3.961e+01 | test loss: +5.682e+01 | 
| 05-02 00:25:26 epoch: 095| train loss i: [13.44	 7.95	 6.75	 5.59	 4.1 	 1.78] test loss i: [20.16	11.24	10.38	 6.7 	 5.93	 2.4 ] | 
| 05-02 00:25:29 epoch: 096| time: 2.4s| train loss: +4.189e+01 | test loss: +3.608e+01 | 
| 05-02 00:25:29 epoch: 096| train loss i: [13.8 	 9.46	 7.28	 5.29	 4.18	 1.88] test loss i: [12.04	 6.48	 6.31	 4.99	 4.07	 2.2 ] | 
| 05-02 00:25:31 epoch: 097| time: 2.5s| train loss: +4.185e+01 | test loss: +5.573e+01 | 
| 05-02 00:25:31 epoch: 097| train loss i: [13.47	 9.39	 7.18	 5.34	 4.57	 1.9 ] test loss i: [18.93	14.99	 9.39	 5.79	 4.63	 2.  ] | 
| 05-02 00:25:33 epoch: 098| time: 2.4s| train loss: +4.021e+01 | test loss: +6.312e+01 | 
| 05-02 00:25:33 epoch: 098| train loss i: [13.15	 8.78	 6.81	 5.42	 4.18	 1.88] test loss i: [20.29	13.46	12.07	 9.41	 5.36	 2.53] | 
| 05-02 00:25:36 epoch: 099| time: 2.5s| train loss: +3.904e+01 | test loss: +5.255e+01 | 
| 05-02 00:25:36 epoch: 099| train loss i: [12.8 	 8.56	 6.58	 5.44	 3.74	 1.93] test loss i: [16.01	10.86	10.21	 7.63	 5.43	 2.4 ] | 
| 05-02 00:25:38 epoch: 100| time: 2.5s| train loss: +3.848e+01 | test loss: +5.097e+01 | 
| 05-02 00:25:38 epoch: 100| train loss i: [12.62	 8.04	 6.59	 5.17	 4.34	 1.72] test loss i: [16.87	10.1 	 7.6 	 8.38	 5.88	 2.14] | 
| 05-02 00:25:41 epoch: 101| time: 2.5s| train loss: +3.888e+01 | test loss: +6.979e+01 | 
| 05-02 00:25:41 epoch: 101| train loss i: [12.53	 8.27	 6.99	 4.9 	 4.38	 1.82] test loss i: [23.31	18.33	10.57	 7.62	 7.  	 2.96] | 
| 05-02 00:25:43 epoch: 102| time: 2.5s| train loss: +3.843e+01 | test loss: +4.978e+01 | 
| 05-02 00:25:43 epoch: 102| train loss i: [11.87	 8.32	 6.82	 5.39	 4.21	 1.82] test loss i: [18.85	12.05	 7.02	 5.92	 3.92	 2.  ] | 
| 05-02 00:25:46 epoch: 103| time: 2.5s| train loss: +3.666e+01 | test loss: +2.983e+01 | 
| 05-02 00:25:46 epoch: 103| train loss i: [10.68	 7.9 	 6.78	 5.19	 4.31	 1.79] test loss i: [9.1 	6.29	5.84	3.66	3.47	1.46] | 
| 05-02 00:25:48 epoch: 104| time: 2.4s| train loss: +3.624e+01 | test loss: +3.592e+01 | 
| 05-02 00:25:48 epoch: 104| train loss i: [10.32	 7.47	 7.06	 5.38	 4.32	 1.68] test loss i: [10.13	 7.7 	 6.87	 5.47	 4.09	 1.66] | 
| 05-02 00:25:51 epoch: 105| time: 2.4s| train loss: +3.733e+01 | test loss: +4.894e+01 | 
| 05-02 00:25:51 epoch: 105| train loss i: [10.43	 8.09	 6.87	 5.61	 4.27	 2.06] test loss i: [15.46	 9.99	 7.15	 8.9 	 5.06	 2.38] | 
| 05-02 00:25:53 epoch: 106| time: 2.5s| train loss: +3.699e+01 | test loss: +3.924e+01 | 
| 05-02 00:25:53 epoch: 106| train loss i: [10.07	 8.25	 7.21	 5.15	 4.24	 2.08] test loss i: [12.48	 7.8 	 7.09	 5.81	 3.62	 2.45] | 
| 05-02 00:25:56 epoch: 107| time: 2.4s| train loss: +3.587e+01 | test loss: +4.970e+01 | 
| 05-02 00:25:56 epoch: 107| train loss i: [9.8 	7.51	6.94	5.3 	4.4 	1.91] test loss i: [15.06	 9.11	 9.86	 7.41	 5.99	 2.27] | 
| 05-02 00:25:58 epoch: 108| time: 2.5s| train loss: +3.450e+01 | test loss: +4.105e+01 | 
| 05-02 00:25:58 epoch: 108| train loss i: [9.42	7.74	6.33	5.34	3.92	1.76] test loss i: [12.18	10.49	 7.46	 4.97	 4.02	 1.93] | 
| 05-02 00:26:01 epoch: 109| time: 2.5s| train loss: +3.487e+01 | test loss: +3.331e+01 | 
| 05-02 00:26:01 epoch: 109| train loss i: [8.82	7.72	6.97	5.33	4.31	1.71] test loss i: [8.14	6.49	5.43	6.47	4.97	1.81] | 
| 05-02 00:26:03 epoch: 110| time: 2.4s| train loss: +3.514e+01 | test loss: +4.629e+01 | 
| 05-02 00:26:03 epoch: 110| train loss i: [9.47	7.45	6.89	5.6 	3.94	1.79] test loss i: [11.37	 9.96	 9.35	 7.13	 6.01	 2.47] | 
| 05-02 00:26:05 epoch: 111| time: 2.4s| train loss: +3.541e+01 | test loss: +4.796e+01 | 
| 05-02 00:26:05 epoch: 111| train loss i: [9.48	7.65	6.5 	5.77	4.26	1.76] test loss i: [13.04	10.18	10.66	 6.72	 5.24	 2.12] | 
| 05-02 00:26:08 epoch: 112| time: 2.4s| train loss: +3.585e+01 | test loss: +3.728e+01 | 
| 05-02 00:26:08 epoch: 112| train loss i: [9.6 	7.82	6.94	5.13	4.59	1.76] test loss i: [10.94	 8.29	 5.59	 5.43	 4.9 	 2.13] | 
| 05-02 00:26:10 epoch: 113| time: 2.5s| train loss: +3.436e+01 | test loss: +3.918e+01 | 
| 05-02 00:26:10 epoch: 113| train loss i: [8.88	7.59	6.59	5.61	3.88	1.81] test loss i: [11.95	 8.64	 6.6 	 5.47	 4.59	 1.93] | 
| 05-02 00:26:13 epoch: 114| time: 2.5s| train loss: +3.193e+01 | test loss: +3.379e+01 | 
| 05-02 00:26:13 epoch: 114| train loss i: [7.99	6.97	6.03	5.13	4.05	1.77] test loss i: [10.39	 7.01	 5.87	 4.22	 4.53	 1.78] | 
| 05-02 00:26:15 epoch: 115| time: 2.4s| train loss: +3.365e+01 | test loss: +4.391e+01 | 
| 05-02 00:26:15 epoch: 115| train loss i: [8.32	7.16	6.81	5.31	4.3 	1.74] test loss i: [10.8 	 9.63	 8.85	 7.75	 4.54	 2.35] | 
| 05-02 00:26:18 epoch: 116| time: 2.4s| train loss: +3.240e+01 | test loss: +3.210e+01 | 
| 05-02 00:26:18 epoch: 116| train loss i: [7.24	6.61	7.06	5.5 	4.24	1.75] test loss i: [8.09	6.95	6.88	4.43	4.06	1.67] | 
| 05-02 00:26:20 epoch: 117| time: 2.4s| train loss: +3.162e+01 | test loss: +3.629e+01 | 
| 05-02 00:26:20 epoch: 117| train loss i: [6.2 	6.97	6.92	5.43	4.3 	1.81] test loss i: [8.97	5.95	7.88	5.94	5.2 	2.34] | 
| 05-02 00:26:23 epoch: 118| time: 2.4s| train loss: +3.233e+01 | test loss: +3.033e+01 | 
| 05-02 00:26:23 epoch: 118| train loss i: [6.69	6.87	7.26	5.54	4.11	1.86] test loss i: [6.27	6.52	6.16	5.97	3.52	1.88] | 
| 05-02 00:26:25 epoch: 119| time: 2.4s| train loss: +3.127e+01 | test loss: +3.151e+01 | 
| 05-02 00:26:25 epoch: 119| train loss i: [6.27	6.49	7.01	5.52	4.06	1.92] test loss i: [4.92	6.12	6.25	6.37	5.37	2.46] | 
| 05-02 00:26:27 epoch: 120| time: 2.4s| train loss: +2.940e+01 | test loss: +3.567e+01 | 
| 05-02 00:26:27 epoch: 120| train loss i: [5.71	5.72	6.72	5.34	4.11	1.8 ] test loss i: [8.42	7.08	7.77	5.84	4.53	2.03] | 
| 05-02 00:26:30 epoch: 121| time: 2.5s| train loss: +2.958e+01 | test loss: +2.886e+01 | 
| 05-02 00:26:30 epoch: 121| train loss i: [5.15	6.23	6.88	5.44	4.14	1.74] test loss i: [7.12	6.04	6.33	4.09	3.53	1.75] | 
| 05-02 00:26:32 epoch: 122| time: 2.4s| train loss: +3.014e+01 | test loss: +3.935e+01 | 
| 05-02 00:26:32 epoch: 122| train loss i: [6.25	5.89	7.05	5.14	4.1 	1.71] test loss i: [10.94	 7.84	 7.82	 5.36	 5.33	 2.06] | 
| 05-02 00:26:35 epoch: 123| time: 2.5s| train loss: +2.909e+01 | test loss: +4.851e+01 | 
| 05-02 00:26:35 epoch: 123| train loss i: [6.15	5.43	6.5 	5.1 	4.19	1.72] test loss i: [13.92	10.45	 8.35	 7.46	 5.66	 2.67] | 
| 05-02 00:26:37 epoch: 124| time: 2.4s| train loss: +3.043e+01 | test loss: +3.119e+01 | 
| 05-02 00:26:37 epoch: 124| train loss i: [6.46	5.86	7.01	5.34	4.06	1.7 ] test loss i: [6.66	4.9 	7.96	5.75	4.16	1.75] | 
| 05-02 00:26:40 epoch: 125| time: 2.4s| train loss: +2.898e+01 | test loss: +3.270e+01 | 
| 05-02 00:26:40 epoch: 125| train loss i: [5.34	6.13	6.06	5.34	4.29	1.82] test loss i: [5.98	6.94	7.04	5.8 	5.02	1.92] | 
| 05-02 00:26:42 epoch: 126| time: 2.5s| train loss: +2.853e+01 | test loss: +3.202e+01 | 
| 05-02 00:26:42 epoch: 126| train loss i: [5.32	5.68	6.09	5.57	4.11	1.76] test loss i: [6.25	5.28	7.62	5.25	5.39	2.23] | 
| 05-02 00:26:44 epoch: 127| time: 2.4s| train loss: +2.819e+01 | test loss: +2.692e+01 | 
| 05-02 00:26:44 epoch: 127| train loss i: [4.92	5.64	6.54	5.46	3.97	1.67] test loss i: [4.39	4.95	6.95	5.56	3.28	1.79] | 
| 05-02 00:26:47 epoch: 128| time: 2.5s| train loss: +2.842e+01 | test loss: +2.647e+01 | 
| 05-02 00:26:47 epoch: 128| train loss i: [5.25	5.05	6.38	5.93	4.12	1.7 ] test loss i: [4.31	4.56	6.04	5.57	3.86	2.13] | 
| 05-02 00:26:49 epoch: 129| time: 2.4s| train loss: +2.698e+01 | test loss: +2.755e+01 | 
| 05-02 00:26:49 epoch: 129| train loss i: [5.02	4.98	6.35	4.92	3.96	1.74] test loss i: [5.15	5.26	6.23	4.76	4.07	2.07] | 
| 05-02 00:26:52 epoch: 130| time: 2.4s| train loss: +2.854e+01 | test loss: +3.597e+01 | 
| 05-02 00:26:52 epoch: 130| train loss i: [5.26	5.33	6.88	5.08	4.29	1.7 ] test loss i: [9.07	8.22	6.44	5.63	4.73	1.88] | 
| 05-02 00:26:54 epoch: 131| time: 2.5s| train loss: +2.829e+01 | test loss: +3.490e+01 | 
| 05-02 00:26:54 epoch: 131| train loss i: [5.27	5.62	6.31	5.08	4.1 	1.91] test loss i: [6.59	7.73	7.83	6.63	4.21	1.91] | 
| 05-02 00:26:57 epoch: 132| time: 2.5s| train loss: +2.832e+01 | test loss: +3.010e+01 | 
| 05-02 00:26:57 epoch: 132| train loss i: [4.94	5.5 	6.84	5.41	3.74	1.89] test loss i: [6.02	5.53	6.57	5.35	4.61	2.02] | 
| 05-02 00:26:59 epoch: 133| time: 2.4s| train loss: +2.669e+01 | test loss: +3.063e+01 | 
| 05-02 00:26:59 epoch: 133| train loss i: [4.82	5.33	5.96	5.08	3.89	1.61] test loss i: [6.45	5.2 	7.24	5.28	4.2 	2.27] | 
| 05-02 00:27:01 epoch: 134| time: 2.4s| train loss: +2.688e+01 | test loss: +3.435e+01 | 
| 05-02 00:27:01 epoch: 134| train loss i: [4.12	5.02	6.84	5.1 	4.08	1.72] test loss i: [7.49	7.99	7.26	5.2 	4.48	1.93] | 
| 05-02 00:27:04 epoch: 135| time: 2.4s| train loss: +2.620e+01 | test loss: +3.887e+01 | 
| 05-02 00:27:04 epoch: 135| train loss i: [4.4 	5.37	5.86	4.92	3.84	1.81] test loss i: [5.44	9.65	8.93	7.76	5.  	2.08] | 
| 05-02 00:27:06 epoch: 136| time: 2.5s| train loss: +2.623e+01 | test loss: +3.063e+01 | 
| 05-02 00:27:06 epoch: 136| train loss i: [4.3 	4.86	6.33	5.01	4.06	1.67] test loss i: [6.88	6.02	6.57	5.41	4.11	1.65] | 
| 05-02 00:27:09 epoch: 137| time: 2.5s| train loss: +2.560e+01 | test loss: +2.748e+01 | 
| 05-02 00:27:09 epoch: 137| train loss i: [4.23	5.31	5.68	4.66	3.91	1.81] test loss i: [5.44	5.83	5.3 	5.03	4.24	1.64] | 
| 05-02 00:27:11 epoch: 138| time: 2.4s| train loss: +2.649e+01 | test loss: +3.951e+01 | 
| 05-02 00:27:11 epoch: 138| train loss i: [4.6 	5.02	5.78	5.16	4.21	1.73] test loss i: [7.23	7.78	8.37	7.28	6.17	2.68] | 
| 05-02 00:27:14 epoch: 139| time: 2.4s| train loss: +2.547e+01 | test loss: +3.150e+01 | 
| 05-02 00:27:14 epoch: 139| train loss i: [4.21	4.8 	6.06	4.91	3.66	1.83] test loss i: [4.52	6.27	8.81	5.57	4.17	2.16] | 
| 05-02 00:27:16 epoch: 140| time: 2.4s| train loss: +2.707e+01 | test loss: +2.350e+01 | 
| 05-02 00:27:16 epoch: 140| train loss i: [4.77	4.79	6.4 	5.39	3.89	1.83] test loss i: [3.36	4.28	5.88	4.62	3.48	1.88] | 
| 05-02 00:27:19 epoch: 141| time: 2.5s| train loss: +2.568e+01 | test loss: +2.818e+01 | 
| 05-02 00:27:19 epoch: 141| train loss i: [4.33	4.27	6.  	5.1 	4.14	1.84] test loss i: [4.19	4.49	8.44	5.16	4.01	1.89] | 
| 05-02 00:27:21 epoch: 142| time: 2.5s| train loss: +2.685e+01 | test loss: +2.711e+01 | 
| 05-02 00:27:21 epoch: 142| train loss i: [4.34	4.99	6.46	5.21	4.12	1.74] test loss i: [5.57	5.42	5.59	4.87	3.86	1.8 ] | 
| 05-02 00:27:24 epoch: 143| time: 2.4s| train loss: +2.632e+01 | test loss: +2.402e+01 | 
| 05-02 00:27:24 epoch: 143| train loss i: [4.3 	4.49	6.52	5.03	4.29	1.69] test loss i: [3.31	3.57	5.88	5.58	3.92	1.77] | 
| 05-02 00:27:26 epoch: 144| time: 2.5s| train loss: +2.640e+01 | test loss: +2.889e+01 | 
| 05-02 00:27:26 epoch: 144| train loss i: [4.15	5.26	6.32	4.81	4.13	1.73] test loss i: [5.08	6.54	6.73	4.97	3.99	1.59] | 
| 05-02 00:27:28 epoch: 145| time: 2.4s| train loss: +2.644e+01 | test loss: +3.260e+01 | 
| 05-02 00:27:28 epoch: 145| train loss i: [4.48	4.86	6.28	5.35	3.76	1.71] test loss i: [6.44	5.44	8.24	5.99	4.72	1.78] | 
| 05-02 00:27:31 epoch: 146| time: 2.4s| train loss: +2.658e+01 | test loss: +3.093e+01 | 
| 05-02 00:27:31 epoch: 146| train loss i: [4.04	5.23	6.12	5.47	4.05	1.67] test loss i: [3.31	5.16	8.71	6.31	5.41	2.03] | 
| 05-02 00:27:33 epoch: 147| time: 2.4s| train loss: +2.586e+01 | test loss: +2.448e+01 | 
| 05-02 00:27:33 epoch: 147| train loss i: [3.84	4.66	6.39	4.98	4.33	1.66] test loss i: [4.39	4.47	5.01	4.88	4.  	1.72] | 
| 05-02 00:27:36 epoch: 148| time: 2.4s| train loss: +2.716e+01 | test loss: +4.189e+01 | 
| 05-02 00:27:36 epoch: 148| train loss i: [4.06	5.61	6.43	5.59	3.74	1.71] test loss i: [7.95	8.03	8.97	8.18	5.75	3.  ] | 
| 05-02 00:27:38 epoch: 149| time: 2.5s| train loss: +2.580e+01 | test loss: +3.006e+01 | 
| 05-02 00:27:38 epoch: 149| train loss i: [4.02	4.43	6.61	5.12	4.01	1.63] test loss i: [5.  	6.83	6.67	5.52	4.13	1.92] | 
| 05-02 00:27:41 epoch: 150| time: 2.4s| train loss: +2.613e+01 | test loss: +3.553e+01 | 
| 05-02 00:27:41 epoch: 150| train loss i: [4.03	4.69	6.08	5.67	3.94	1.73] test loss i: [5.49	5.46	9.03	6.35	6.61	2.58] | 
| 05-02 00:27:43 epoch: 151| time: 2.4s| train loss: +2.466e+01 | test loss: +2.825e+01 | 
| 05-02 00:27:43 epoch: 151| train loss i: [3.83	4.01	5.97	5.17	3.9 	1.78] test loss i: [6.03	3.58	6.67	6.3 	3.61	2.05] | 
| 05-02 00:27:45 epoch: 152| time: 2.4s| train loss: +2.527e+01 | test loss: +2.303e+01 | 
| 05-02 00:27:45 epoch: 152| train loss i: [4.  	4.43	6.01	5.04	4.01	1.78] test loss i: [3.63	4.36	5.27	4.11	3.82	1.85] | 
| 05-02 00:27:48 epoch: 153| time: 2.4s| train loss: +2.551e+01 | test loss: +4.047e+01 | 
| 05-02 00:27:48 epoch: 153| train loss i: [3.64	4.55	6.42	4.99	4.18	1.74] test loss i: [ 5.86	 7.76	11.6 	 7.07	 5.8 	 2.38] | 
| 05-02 00:27:50 epoch: 154| time: 2.5s| train loss: +2.547e+01 | test loss: +4.348e+01 | 
| 05-02 00:27:50 epoch: 154| train loss i: [3.99	4.39	6.44	4.87	4.16	1.61] test loss i: [ 9.16	 7.04	10.46	 8.6 	 5.78	 2.44] | 
| 05-02 00:27:53 epoch: 155| time: 2.4s| train loss: +2.443e+01 | test loss: +2.709e+01 | 
| 05-02 00:27:53 epoch: 155| train loss i: [3.77	3.88	6.16	4.87	4.01	1.72] test loss i: [3.92	5.5 	6.3 	5.17	4.39	1.8 ] | 
| 05-02 00:27:55 epoch: 156| time: 2.4s| train loss: +2.433e+01 | test loss: +2.592e+01 | 
| 05-02 00:27:55 epoch: 156| train loss i: [3.43	4.1 	5.8 	5.17	4.13	1.7 ] test loss i: [4.71	3.6 	6.87	5.26	3.61	1.88] | 
| 05-02 00:27:58 epoch: 157| time: 2.5s| train loss: +2.552e+01 | test loss: +3.874e+01 | 
| 05-02 00:27:58 epoch: 157| train loss i: [3.79	4.22	6.23	5.58	4.12	1.57] test loss i: [6.62	6.53	8.47	7.76	6.89	2.46] | 
| 05-02 00:28:00 epoch: 158| time: 2.4s| train loss: +2.603e+01 | test loss: +3.889e+01 | 
| 05-02 00:28:00 epoch: 158| train loss i: [4.26	4.64	6.06	5.05	4.38	1.63] test loss i: [7.98	7.96	8.58	6.64	5.5 	2.23] | 
| 05-02 00:28:03 epoch: 159| time: 2.5s| train loss: +2.642e+01 | test loss: +3.169e+01 | 
| 05-02 00:28:03 epoch: 159| train loss i: [4.32	4.64	6.24	5.6 	4.06	1.56] test loss i: [6.88	3.57	8.86	6.38	4.27	1.73] | 
| 05-02 00:28:05 epoch: 160| time: 2.5s| train loss: +2.475e+01 | test loss: +2.781e+01 | 
| 05-02 00:28:05 epoch: 160| train loss i: [4.01	3.96	5.65	5.49	3.96	1.69] test loss i: [4.71	3.17	7.3 	5.8 	4.67	2.15] | 
| 05-02 00:28:08 epoch: 161| time: 2.5s| train loss: +2.564e+01 | test loss: +3.186e+01 | 
| 05-02 00:28:08 epoch: 161| train loss i: [4.27	4.43	6.29	5.01	3.98	1.66] test loss i: [6.12	5.45	7.26	5.96	4.95	2.12] | 
| 05-02 00:28:10 epoch: 162| time: 2.5s| train loss: +2.722e+01 | test loss: +4.091e+01 | 
| 05-02 00:28:10 epoch: 162| train loss i: [5.06	4.52	6.59	5.33	4.12	1.6 ] test loss i: [ 7.07	 5.71	10.15	 7.93	 7.25	 2.8 ] | 
| 05-02 00:28:12 epoch: 163| time: 2.5s| train loss: +2.529e+01 | test loss: +2.928e+01 | 
| 05-02 00:28:12 epoch: 163| train loss i: [4.76	3.88	5.81	5.15	4.04	1.66] test loss i: [4.22	6.29	6.96	5.68	4.29	1.83] | 
| 05-02 00:28:15 epoch: 164| time: 2.5s| train loss: +2.481e+01 | test loss: +3.292e+01 | 
| 05-02 00:28:15 epoch: 164| train loss i: [4.04	4.41	5.86	5.12	3.74	1.63] test loss i: [7.44	5.72	7.61	5.55	4.62	1.98] | 
| 05-02 00:28:17 epoch: 165| time: 2.5s| train loss: +2.617e+01 | test loss: +3.790e+01 | 
| 05-02 00:28:17 epoch: 165| train loss i: [4.19	4.39	6.34	5.46	4.18	1.61] test loss i: [10.44	 5.34	 7.18	 7.73	 5.28	 1.93] | 
| 05-02 00:28:20 epoch: 166| time: 2.5s| train loss: +2.491e+01 | test loss: +3.026e+01 | 
| 05-02 00:28:20 epoch: 166| train loss i: [4.11	4.19	6.01	5.02	3.91	1.68] test loss i: [4.39	4.61	7.09	6.23	5.41	2.54] | 
| 05-02 00:28:22 epoch: 167| time: 2.5s| train loss: +2.408e+01 | test loss: +3.204e+01 | 
| 05-02 00:28:22 epoch: 167| train loss i: [3.89	3.61	6.16	5.06	3.7 	1.67] test loss i: [7.17	5.52	6.7 	6.07	4.89	1.68] | 
| 05-02 00:28:25 epoch: 168| time: 2.5s| train loss: +2.559e+01 | test loss: +2.765e+01 | 
| 05-02 00:28:25 epoch: 168| train loss i: [3.89	4.31	6.53	5.1 	4.  	1.74] test loss i: [5.7 	4.13	7.12	5.17	3.72	1.81] | 
| 05-02 00:28:27 epoch: 169| time: 2.4s| train loss: +2.625e+01 | test loss: +4.102e+01 | 
| 05-02 00:28:27 epoch: 169| train loss i: [4.22	4.5 	6.62	4.98	4.22	1.71] test loss i: [7.14	8.92	8.41	7.95	6.36	2.24] | 
| 05-02 00:28:30 epoch: 170| time: 2.5s| train loss: +2.446e+01 | test loss: +2.764e+01 | 
| 05-02 00:28:30 epoch: 170| train loss i: [4.08	4.24	5.78	4.95	3.74	1.66] test loss i: [3.97	5.37	6.82	5.53	4.12	1.84] | 
| 05-02 00:28:32 epoch: 171| time: 2.4s| train loss: +2.527e+01 | test loss: +2.558e+01 | 
| 05-02 00:28:32 epoch: 171| train loss i: [3.62	3.92	6.25	5.66	4.2 	1.62] test loss i: [4.31	4.26	5.53	5.46	4.3 	1.72] | 
| 05-02 00:28:35 epoch: 172| time: 2.4s| train loss: +2.362e+01 | test loss: +2.931e+01 | 
| 05-02 00:28:35 epoch: 172| train loss i: [3.55	3.7 	5.65	4.85	4.15	1.71] test loss i: [4.95	5.32	5.45	7.25	4.51	1.84] | 
| 05-02 00:28:37 epoch: 173| time: 2.5s| train loss: +2.296e+01 | test loss: +2.250e+01 | 
| 05-02 00:28:37 epoch: 173| train loss i: [3.09	3.77	5.4 	4.97	4.15	1.58] test loss i: [3.38	3.9 	5.19	4.32	4.06	1.64] | 
| 05-02 00:28:40 epoch: 174| time: 2.5s| train loss: +2.447e+01 | test loss: +2.513e+01 | 
| 05-02 00:28:40 epoch: 174| train loss i: [3.78	4.11	5.87	5.04	4.02	1.65] test loss i: [3.04	3.75	5.53	5.72	4.82	2.27] | 
| 05-02 00:28:42 epoch: 175| time: 2.5s| train loss: +2.429e+01 | test loss: +3.158e+01 | 
| 05-02 00:28:42 epoch: 175| train loss i: [3.56	3.99	5.79	5.22	3.95	1.77] test loss i: [4.21	5.11	8.85	6.6 	4.75	2.05] | 
| 05-02 00:28:45 epoch: 176| time: 2.5s| train loss: +2.291e+01 | test loss: +2.365e+01 | 
| 05-02 00:28:45 epoch: 176| train loss i: [3.26	3.44	5.38	4.99	4.19	1.66] test loss i: [4.21	3.49	5.65	5.32	3.45	1.53] | 
| 05-02 00:28:47 epoch: 177| time: 2.5s| train loss: +2.505e+01 | test loss: +2.891e+01 | 
| 05-02 00:28:47 epoch: 177| train loss i: [3.72	3.69	6.35	5.42	4.18	1.71] test loss i: [3.89	4.55	7.04	6.13	5.29	2.01] | 
| 05-02 00:28:50 epoch: 178| time: 2.5s| train loss: +2.520e+01 | test loss: +2.437e+01 | 
| 05-02 00:28:50 epoch: 178| train loss i: [3.29	5.32	6.09	4.89	3.97	1.65] test loss i: [2.75	2.66	6.19	6.15	4.95	1.68] | 
| 05-02 00:28:52 epoch: 179| time: 2.5s| train loss: +2.337e+01 | test loss: +2.337e+01 | 
| 05-02 00:28:52 epoch: 179| train loss i: [3.32	3.62	5.27	5.44	4.11	1.62] test loss i: [3.39	3.33	6.58	4.7 	3.58	1.78] | 
| 05-02 00:28:54 epoch: 180| time: 2.5s| train loss: +2.346e+01 | test loss: +2.239e+01 | 
| 05-02 00:28:54 epoch: 180| train loss i: [3.08	3.96	5.84	5.09	3.9 	1.58] test loss i: [3.28	3.39	5.26	4.7 	3.99	1.76] | 
| 05-02 00:28:57 epoch: 181| time: 2.5s| train loss: +2.412e+01 | test loss: +2.652e+01 | 
| 05-02 00:28:57 epoch: 181| train loss i: [3.58	4.07	5.48	5.26	4.04	1.68] test loss i: [3.92	3.25	7.5 	5.46	4.29	2.09] | 
| 05-02 00:28:59 epoch: 182| time: 2.4s| train loss: +2.441e+01 | test loss: +2.584e+01 | 
| 05-02 00:28:59 epoch: 182| train loss i: [3.25	4.1 	5.82	5.32	4.3 	1.63] test loss i: [5.32	3.55	5.21	5.05	4.82	1.9 ] | 
| 05-02 00:29:02 epoch: 183| time: 2.5s| train loss: +2.360e+01 | test loss: +2.279e+01 | 
| 05-02 00:29:02 epoch: 183| train loss i: [3.39	3.65	5.67	5.14	4.01	1.73] test loss i: [4.68	2.37	5.61	4.67	3.77	1.69] | 
| 05-02 00:29:04 epoch: 184| time: 2.5s| train loss: +2.447e+01 | test loss: +4.029e+01 | 
| 05-02 00:29:04 epoch: 184| train loss i: [3.19	3.49	6.52	5.25	4.13	1.88] test loss i: [ 6.42	 7.2 	12.07	 6.81	 5.69	 2.1 ] | 
| 05-02 00:29:07 epoch: 185| time: 2.4s| train loss: +2.426e+01 | test loss: +2.554e+01 | 
| 05-02 00:29:07 epoch: 185| train loss i: [3.39	4.24	5.93	5.19	3.87	1.64] test loss i: [4.28	4.31	5.82	5.05	4.3 	1.78] | 
| 05-02 00:29:09 epoch: 186| time: 2.5s| train loss: +2.320e+01 | test loss: +1.835e+01 | 
| 05-02 00:29:09 epoch: 186| train loss i: [3.44	3.33	6.  	4.7 	4.  	1.74] test loss i: [3.37	2.44	4.32	3.56	3.27	1.4 ] | 
| 05-02 00:29:12 epoch: 187| time: 2.5s| train loss: +2.343e+01 | test loss: +2.790e+01 | 
| 05-02 00:29:12 epoch: 187| train loss i: [3.27	3.11	6.43	5.06	3.83	1.72] test loss i: [4.56	3.08	7.73	5.15	5.  	2.39] | 
| 05-02 00:29:14 epoch: 188| time: 2.5s| train loss: +2.270e+01 | test loss: +2.337e+01 | 
| 05-02 00:29:14 epoch: 188| train loss i: [3.17	3.33	5.66	4.84	4.05	1.65] test loss i: [2.96	3.18	6.25	4.78	4.49	1.73] | 
| 05-02 00:29:17 epoch: 189| time: 2.5s| train loss: +2.311e+01 | test loss: +2.652e+01 | 
| 05-02 00:29:17 epoch: 189| train loss i: [3.28	3.47	5.49	5.23	3.98	1.66] test loss i: [4.69	3.49	6.37	6.02	3.97	1.98] | 
| 05-02 00:29:19 epoch: 190| time: 2.5s| train loss: +2.387e+01 | test loss: +3.573e+01 | 
| 05-02 00:29:19 epoch: 190| train loss i: [3.12	3.6 	5.74	5.6 	3.93	1.88] test loss i: [ 6.1 	 4.72	10.61	 6.75	 5.07	 2.48] | 
| 05-02 00:29:22 epoch: 191| time: 2.5s| train loss: +2.342e+01 | test loss: +2.734e+01 | 
| 05-02 00:29:22 epoch: 191| train loss i: [3.64	3.35	5.92	5.  	3.89	1.62] test loss i: [3.9 	3.97	7.59	5.42	4.88	1.58] | 
| 05-02 00:29:24 epoch: 192| time: 2.5s| train loss: +2.443e+01 | test loss: +3.086e+01 | 
| 05-02 00:29:24 epoch: 192| train loss i: [2.99	3.96	6.28	5.35	4.2 	1.65] test loss i: [ 3.79	 3.77	10.32	 7.49	 3.8 	 1.69] | 
| 05-02 00:29:26 epoch: 193| time: 2.4s| train loss: +2.289e+01 | test loss: +2.336e+01 | 
| 05-02 00:29:26 epoch: 193| train loss i: [3.34	2.74	5.72	5.2 	4.18	1.69] test loss i: [3.21	2.91	5.43	5.84	4.34	1.63] | 
| 05-02 00:29:29 epoch: 194| time: 2.4s| train loss: +2.333e+01 | test loss: +2.208e+01 | 
| 05-02 00:29:29 epoch: 194| train loss i: [3.31	3.12	6.09	4.92	4.2 	1.69] test loss i: [3.27	2.38	5.94	4.97	3.89	1.62] | 
| 05-02 00:29:31 epoch: 195| time: 2.5s| train loss: +2.221e+01 | test loss: +2.151e+01 | 
| 05-02 00:29:31 epoch: 195| train loss i: [3.1 	3.28	5.3 	4.91	3.93	1.69] test loss i: [2.62	2.16	6.38	4.96	3.82	1.58] | 
| 05-02 00:29:34 epoch: 196| time: 2.4s| train loss: +2.260e+01 | test loss: +2.201e+01 | 
| 05-02 00:29:34 epoch: 196| train loss i: [3.05	2.79	5.99	5.28	3.89	1.6 ] test loss i: [2.86	2.7 	4.87	5.29	4.21	2.08] | 
| 05-02 00:29:36 epoch: 197| time: 2.5s| train loss: +2.313e+01 | test loss: +2.828e+01 | 
| 05-02 00:29:36 epoch: 197| train loss i: [3.24	3.14	6.28	4.92	4.  	1.55] test loss i: [3.58	2.92	8.35	6.05	4.82	2.55] | 
| 05-02 00:29:39 epoch: 198| time: 2.5s| train loss: +2.291e+01 | test loss: +3.553e+01 | 
| 05-02 00:29:39 epoch: 198| train loss i: [3.09	3.23	5.88	5.09	3.97	1.65] test loss i: [5.83	5.47	8.02	8.08	5.98	2.14] | 
| 05-02 00:29:41 epoch: 199| time: 2.4s| train loss: +2.216e+01 | test loss: +2.354e+01 | 
| 05-02 00:29:41 epoch: 199| train loss i: [2.76	2.83	6.04	5.07	3.91	1.56] test loss i: [5.87	2.32	5.37	4.29	3.86	1.83] | 
| 05-02 00:29:44 epoch: 200| time: 2.5s| train loss: +2.230e+01 | test loss: +1.764e+01 | 
| 05-02 00:29:44 epoch: 200| train loss i: [2.9 	2.47	6.17	5.3 	3.75	1.7 ] test loss i: [2.08	2.06	4.57	4.45	2.94	1.54] | 
| 05-02 00:29:46 epoch: 201| time: 2.4s| train loss: +2.246e+01 | test loss: +2.426e+01 | 
| 05-02 00:29:46 epoch: 201| train loss i: [3.09	2.49	6.29	4.96	4.  	1.63] test loss i: [4.39	3.58	5.57	4.83	4.09	1.8 ] | 
| 05-02 00:29:49 epoch: 202| time: 2.4s| train loss: +2.311e+01 | test loss: +2.287e+01 | 
| 05-02 00:29:49 epoch: 202| train loss i: [3.06	2.99	6.07	5.31	4.01	1.66] test loss i: [2.16	3.43	5.39	5.53	4.44	1.91] | 
| 05-02 00:29:51 epoch: 203| time: 2.5s| train loss: +2.303e+01 | test loss: +2.447e+01 | 
| 05-02 00:29:51 epoch: 203| train loss i: [2.98	3.05	6.02	5.31	4.04	1.63] test loss i: [4.33	2.34	7.28	4.54	4.18	1.8 ] | 
| 05-02 00:29:54 epoch: 204| time: 2.5s| train loss: +2.283e+01 | test loss: +2.404e+01 | 
| 05-02 00:29:54 epoch: 204| train loss i: [2.96	2.81	5.55	5.6 	4.19	1.72] test loss i: [4.07	3.18	5.43	4.93	4.59	1.84] | 
| 05-02 00:29:56 epoch: 205| time: 2.5s| train loss: +2.246e+01 | test loss: +3.832e+01 | 
| 05-02 00:29:56 epoch: 205| train loss i: [2.96	3.07	5.53	5.12	4.12	1.66] test loss i: [5.24	7.68	7.58	9.48	5.89	2.44] | 
| 05-02 00:29:59 epoch: 206| time: 2.6s| train loss: +2.227e+01 | test loss: +3.068e+01 | 
| 05-02 00:29:59 epoch: 206| train loss i: [2.97	2.5 	6.2 	4.95	3.96	1.68] test loss i: [5.24	3.57	7.93	6.48	5.31	2.15] | 
| 05-02 00:30:01 epoch: 207| time: 2.5s| train loss: +2.304e+01 | test loss: +3.135e+01 | 
| 05-02 00:30:01 epoch: 207| train loss i: [3.19	2.99	5.96	4.93	4.25	1.72] test loss i: [7.23	3.59	7.67	5.42	5.21	2.23] | 
| 05-02 00:30:04 epoch: 208| time: 2.5s| train loss: +2.217e+01 | test loss: +3.103e+01 | 
| 05-02 00:30:04 epoch: 208| train loss i: [2.62	2.83	6.06	4.75	4.22	1.69] test loss i: [5.89	3.41	6.27	7.72	5.34	2.4 ] | 
| 05-02 00:30:06 epoch: 209| time: 2.6s| train loss: +2.233e+01 | test loss: +2.556e+01 | 
| 05-02 00:30:06 epoch: 209| train loss i: [2.97	2.99	5.5 	5.19	4.07	1.6 ] test loss i: [6.15	3.03	5.29	5.37	4.03	1.69] | 
| 05-02 00:30:09 epoch: 210| time: 2.5s| train loss: +2.285e+01 | test loss: +3.092e+01 | 
| 05-02 00:30:09 epoch: 210| train loss i: [3.72	2.84	5.68	5.07	3.84	1.69] test loss i: [5.13	4.72	8.91	6.04	4.02	2.09] | 
| 05-02 00:30:11 epoch: 211| time: 2.5s| train loss: +2.190e+01 | test loss: +2.376e+01 | 
| 05-02 00:30:11 epoch: 211| train loss i: [3.27	2.52	5.86	4.87	3.79	1.6 ] test loss i: [2.49	2.97	6.23	6.34	4.18	1.55] | 
| 05-02 00:30:14 epoch: 212| time: 2.6s| train loss: +2.177e+01 | test loss: +1.972e+01 | 
| 05-02 00:30:14 epoch: 212| train loss i: [2.65	2.61	5.56	5.28	3.94	1.73] test loss i: [3.27	2.11	5.09	3.87	3.87	1.51] | 
| 05-02 00:30:16 epoch: 213| time: 2.5s| train loss: +2.042e+01 | test loss: +2.249e+01 | 
| 05-02 00:30:16 epoch: 213| train loss i: [2.08	2.83	5.37	4.73	3.83	1.57] test loss i: [2.91	3.35	5.47	5.12	3.83	1.81] | 
| 05-02 00:30:19 epoch: 214| time: 2.5s| train loss: +2.018e+01 | test loss: +2.403e+01 | 
| 05-02 00:30:19 epoch: 214| train loss i: [2.56	2.15	5.05	4.91	3.93	1.58] test loss i: [3.59	3.44	6.06	5.36	4.01	1.58] | 
| 05-02 00:30:21 epoch: 215| time: 2.5s| train loss: +2.215e+01 | test loss: +2.286e+01 | 
| 05-02 00:30:21 epoch: 215| train loss i: [2.65	2.74	5.93	4.99	4.11	1.74] test loss i: [2.71	1.86	6.68	5.18	4.37	2.07] | 
| 05-02 00:30:24 epoch: 216| time: 2.4s| train loss: +2.207e+01 | test loss: +1.995e+01 | 
| 05-02 00:30:24 epoch: 216| train loss i: [2.28	2.62	6.21	5.25	4.04	1.66] test loss i: [1.32	1.93	5.94	4.64	4.12	2.02] | 
| 05-02 00:30:26 epoch: 217| time: 2.4s| train loss: +2.112e+01 | test loss: +2.260e+01 | 
| 05-02 00:30:26 epoch: 217| train loss i: [2.25	2.09	5.69	5.16	4.23	1.71] test loss i: [3.41	2.92	5.68	5.06	3.84	1.69] | 
| 05-02 00:30:29 epoch: 218| time: 2.5s| train loss: +2.187e+01 | test loss: +2.301e+01 | 
| 05-02 00:30:29 epoch: 218| train loss i: [2.22	2.75	6.03	5.05	4.13	1.71] test loss i: [2.59	2.09	7.19	4.52	4.78	1.83] | 
| 05-02 00:30:31 epoch: 219| time: 2.4s| train loss: +2.067e+01 | test loss: +3.322e+01 | 
| 05-02 00:30:31 epoch: 219| train loss i: [2.27	1.69	5.89	5.14	4.11	1.57] test loss i: [6.95	2.24	8.9 	7.67	5.11	2.35] | 
| 05-02 00:30:33 epoch: 220| time: 2.4s| train loss: +2.173e+01 | test loss: +3.118e+01 | 
| 05-02 00:30:33 epoch: 220| train loss i: [2.15	2.67	6.31	4.88	4.02	1.7 ] test loss i: [3.73	3.14	9.58	6.43	6.18	2.12] | 
| 05-02 00:30:36 epoch: 221| time: 2.4s| train loss: +2.077e+01 | test loss: +2.736e+01 | 
| 05-02 00:30:36 epoch: 221| train loss i: [1.82	2.45	5.58	5.  	4.31	1.61] test loss i: [5.05	3.  	6.5 	5.71	5.4 	1.7 ] | 
| 05-02 00:30:38 epoch: 222| time: 2.4s| train loss: +2.046e+01 | test loss: +2.768e+01 | 
| 05-02 00:30:38 epoch: 222| train loss i: [1.99	2.38	5.54	4.95	3.97	1.63] test loss i: [3.79	2.93	7.42	5.99	5.23	2.32] | 
| 05-02 00:30:41 epoch: 223| time: 2.5s| train loss: +2.095e+01 | test loss: +2.336e+01 | 
| 05-02 00:30:41 epoch: 223| train loss i: [1.92	2.64	5.77	5.14	3.84	1.65] test loss i: [3.23	2.51	5.99	5.09	4.79	1.75] | 
| 05-02 00:30:43 epoch: 224| time: 2.5s| train loss: +2.153e+01 | test loss: +2.481e+01 | 
| 05-02 00:30:43 epoch: 224| train loss i: [2.62	2.44	5.79	5.12	3.95	1.61] test loss i: [3.3 	3.75	6.13	5.27	4.49	1.87] | 
| 05-02 00:30:46 epoch: 225| time: 2.5s| train loss: +2.159e+01 | test loss: +2.196e+01 | 
| 05-02 00:30:46 epoch: 225| train loss i: [2.15	2.91	5.89	4.91	4.08	1.64] test loss i: [2.14	1.58	7.08	5.59	3.71	1.86] | 
| 05-02 00:30:48 epoch: 226| time: 2.4s| train loss: +2.038e+01 | test loss: +2.150e+01 | 
| 05-02 00:30:48 epoch: 226| train loss i: [2.06	2.15	5.78	4.77	3.98	1.65] test loss i: [2.48	1.53	4.96	5.49	5.12	1.92] | 
| 05-02 00:30:51 epoch: 227| time: 2.4s| train loss: +2.103e+01 | test loss: +2.179e+01 | 
| 05-02 00:30:51 epoch: 227| train loss i: [1.83	2.88	5.54	5.19	3.98	1.61] test loss i: [2.98	1.91	5.64	5.8 	3.61	1.85] | 
| 05-02 00:30:53 epoch: 228| time: 2.4s| train loss: +1.982e+01 | test loss: +2.840e+01 | 
| 05-02 00:30:53 epoch: 228| train loss i: [1.71	1.84	5.83	4.97	3.86	1.59] test loss i: [1.87	4.13	8.48	6.03	5.43	2.46] | 
| 05-02 00:30:55 epoch: 229| time: 2.5s| train loss: +2.056e+01 | test loss: +2.506e+01 | 
| 05-02 00:30:55 epoch: 229| train loss i: [1.75	2.12	5.94	5.25	3.92	1.58] test loss i: [2.17	2.25	8.01	6.05	4.71	1.86] | 
| 05-02 00:30:58 epoch: 230| time: 2.4s| train loss: +2.157e+01 | test loss: +2.472e+01 | 
| 05-02 00:30:58 epoch: 230| train loss i: [1.93	2.57	6.11	5.24	4.02	1.71] test loss i: [1.82	4.63	6.97	5.09	4.27	1.94] | 
| 05-02 00:31:00 epoch: 231| time: 2.4s| train loss: +1.935e+01 | test loss: +1.349e+01 | 
| 05-02 00:31:00 epoch: 231| train loss i: [1.61	1.96	5.2 	4.84	4.1 	1.64] test loss i: [1.41	0.81	3.15	3.76	2.93	1.42] | 
| 05-02 00:31:03 epoch: 232| time: 2.4s| train loss: +1.896e+01 | test loss: +1.831e+01 | 
| 05-02 00:31:03 epoch: 232| train loss i: [1.42	1.56	5.43	5.08	3.88	1.59] test loss i: [1.28	1.65	5.02	3.98	4.65	1.72] | 
| 05-02 00:31:05 epoch: 233| time: 2.5s| train loss: +2.005e+01 | test loss: +2.386e+01 | 
| 05-02 00:31:05 epoch: 233| train loss i: [1.82	2.45	5.2 	4.92	4.07	1.6 ] test loss i: [3.43	1.74	6.57	6.01	4.47	1.64] | 
| 05-02 00:31:08 epoch: 234| time: 2.5s| train loss: +2.080e+01 | test loss: +1.880e+01 | 
| 05-02 00:31:08 epoch: 234| train loss i: [1.71	2.4 	6.18	5.02	3.9 	1.59] test loss i: [3.11	1.77	4.54	4.54	3.21	1.63] | 
| 05-02 00:31:10 epoch: 235| time: 2.4s| train loss: +2.003e+01 | test loss: +1.701e+01 | 
| 05-02 00:31:10 epoch: 235| train loss i: [1.6 	1.41	6.21	5.  	4.13	1.68] test loss i: [1.18	1.3 	4.34	4.65	3.87	1.67] | 
| 05-02 00:31:13 epoch: 236| time: 2.4s| train loss: +1.997e+01 | test loss: +2.046e+01 | 
| 05-02 00:31:13 epoch: 236| train loss i: [1.26	1.98	6.02	5.01	4.06	1.63] test loss i: [1.11	2.14	5.36	4.87	4.97	2.  ] | 
| 05-02 00:31:15 epoch: 237| time: 2.4s| train loss: +1.990e+01 | test loss: +2.242e+01 | 
| 05-02 00:31:15 epoch: 237| train loss i: [1.49	2.33	5.69	5.02	3.72	1.64] test loss i: [1.11	0.96	8.07	5.52	5.06	1.69] | 
| 05-02 00:31:17 epoch: 238| time: 2.5s| train loss: +1.976e+01 | test loss: +2.586e+01 | 
| 05-02 00:31:17 epoch: 238| train loss i: [1.69	1.76	5.72	5.09	3.89	1.61] test loss i: [5.1 	2.25	7.78	4.84	4.11	1.78] | 
| 05-02 00:31:20 epoch: 239| time: 2.5s| train loss: +1.964e+01 | test loss: +2.741e+01 | 
| 05-02 00:31:20 epoch: 239| train loss i: [1.74	1.83	5.49	4.97	3.9 	1.71] test loss i: [2.21	2.98	7.35	7.26	5.54	2.08] | 
| 05-02 00:31:22 epoch: 240| time: 2.4s| train loss: +2.073e+01 | test loss: +2.297e+01 | 
| 05-02 00:31:22 epoch: 240| train loss i: [1.28	2.33	6.43	5.16	3.89	1.65] test loss i: [1.92	2.63	5.91	5.65	4.84	2.03] | 
| 05-02 00:31:25 epoch: 241| time: 2.4s| train loss: +1.955e+01 | test loss: +1.974e+01 | 
| 05-02 00:31:25 epoch: 241| train loss i: [1.68	2.14	5.39	5.01	3.69	1.63] test loss i: [1.11	1.55	6.99	4.51	3.88	1.69] | 
| 05-02 00:31:27 epoch: 242| time: 2.4s| train loss: +2.014e+01 | test loss: +1.986e+01 | 
| 05-02 00:31:27 epoch: 242| train loss i: [1.39	2.78	5.63	4.96	3.74	1.63] test loss i: [2.12	2.56	5.43	3.98	4.  	1.76] | 
| 05-02 00:31:30 epoch: 243| time: 2.5s| train loss: +1.947e+01 | test loss: +2.164e+01 | 
| 05-02 00:31:30 epoch: 243| train loss i: [1.41	1.84	5.78	5.14	3.77	1.53] test loss i: [2.33	2.48	5.28	5.4 	4.55	1.59] | 
| 05-02 00:31:32 epoch: 244| time: 2.5s| train loss: +2.078e+01 | test loss: +2.171e+01 | 
| 05-02 00:31:32 epoch: 244| train loss i: [1.7 	2.13	6.24	5.1 	4.  	1.61] test loss i: [2.35	1.6 	5.87	5.27	4.6 	2.02] | 
| 05-02 00:31:35 epoch: 245| time: 2.4s| train loss: +1.983e+01 | test loss: +2.183e+01 | 
| 05-02 00:31:35 epoch: 245| train loss i: [1.77	1.84	5.6 	4.91	3.84	1.88] test loss i: [1.57	2.03	5.54	5.4 	4.96	2.32] | 
| 05-02 00:31:37 epoch: 246| time: 2.4s| train loss: +1.990e+01 | test loss: +2.757e+01 | 
| 05-02 00:31:37 epoch: 246| train loss i: [1.98	1.68	5.59	4.89	4.02	1.74] test loss i: [2.94	3.48	7.61	5.92	5.49	2.13] | 
| 05-02 00:31:39 epoch: 247| time: 2.4s| train loss: +1.995e+01 | test loss: +2.337e+01 | 
| 05-02 00:31:39 epoch: 247| train loss i: [1.45	2.23	6.02	4.77	3.79	1.68] test loss i: [3.33	3.25	7.09	4.5 	3.53	1.67] | 
| 05-02 00:31:42 epoch: 248| time: 2.5s| train loss: +1.913e+01 | test loss: +1.822e+01 | 
| 05-02 00:31:42 epoch: 248| train loss i: [1.57	1.79	5.32	4.87	3.97	1.6 ] test loss i: [1.04	1.43	5.7 	4.93	3.46	1.67] | 
| 05-02 00:31:44 epoch: 249| time: 2.5s| train loss: +2.058e+01 | test loss: +2.187e+01 | 
| 05-02 00:31:44 epoch: 249| train loss i: [1.41	2.07	6.1 	5.21	4.13	1.66] test loss i: [1.92	3.26	6.05	4.95	3.64	2.03] | 
| 05-02 00:31:47 epoch: 250| time: 2.5s| train loss: +2.248e+01 | test loss: +2.417e+01 | 
| 05-02 00:31:47 epoch: 250| train loss i: [2.15	2.89	5.61	5.51	4.53	1.79] test loss i: [4.86	1.68	6.13	5.14	4.46	1.9 ] | 
| 05-02 00:31:49 epoch: 251| time: 2.5s| train loss: +1.996e+01 | test loss: +2.941e+01 | 
| 05-02 00:31:49 epoch: 251| train loss i: [1.5 	1.85	5.76	4.95	4.22	1.68] test loss i: [5.27	2.2 	7.76	6.11	5.98	2.08] | 
| 05-02 00:31:52 epoch: 252| time: 2.4s| train loss: +2.077e+01 | test loss: +2.257e+01 | 
| 05-02 00:31:52 epoch: 252| train loss i: [1.52	2.42	5.99	4.99	4.06	1.79] test loss i: [1.45	3.39	5.78	5.71	4.03	2.21] | 
| 05-02 00:31:54 epoch: 253| time: 2.5s| train loss: +1.916e+01 | test loss: +3.209e+01 | 
| 05-02 00:31:54 epoch: 253| train loss i: [1.41	1.79	5.2 	5.04	3.9 	1.83] test loss i: [1.87	5.27	9.  	7.72	5.82	2.4 ] | 
| 05-02 00:31:57 epoch: 254| time: 2.4s| train loss: +1.883e+01 | test loss: +1.809e+01 | 
| 05-02 00:31:57 epoch: 254| train loss i: [1.1 	1.59	5.48	4.96	4.  	1.69] test loss i: [1.11	2.55	4.69	4.9 	3.25	1.59] | 
| 05-02 00:31:59 epoch: 255| time: 2.4s| train loss: +2.019e+01 | test loss: +1.729e+01 | 
| 05-02 00:31:59 epoch: 255| train loss i: [1.42	2.16	5.81	4.91	4.21	1.67] test loss i: [1.69	0.96	4.97	4.4 	3.79	1.48] | 
| 05-02 00:32:01 epoch: 256| time: 2.5s| train loss: +1.907e+01 | test loss: +2.764e+01 | 
| 05-02 00:32:01 epoch: 256| train loss i: [1.66	1.88	5.17	5.02	3.68	1.65] test loss i: [1.01	5.61	7.09	6.38	5.12	2.42] | 
| 05-02 00:32:04 epoch: 257| time: 2.4s| train loss: +1.956e+01 | test loss: +1.991e+01 | 
| 05-02 00:32:04 epoch: 257| train loss i: [1.44	1.66	6.1 	4.73	3.93	1.69] test loss i: [1.94	1.17	5.87	4.74	4.25	1.94] | 
| 05-02 00:32:06 epoch: 258| time: 2.4s| train loss: +1.950e+01 | test loss: +2.443e+01 | 
| 05-02 00:32:06 epoch: 258| train loss i: [1.44	1.89	5.52	4.73	4.23	1.69] test loss i: [3.74	2.22	7.41	5.05	4.21	1.8 ] | 
| 05-02 00:32:09 epoch: 259| time: 2.4s| train loss: +2.001e+01 | test loss: +1.982e+01 | 
| 05-02 00:32:09 epoch: 259| train loss i: [1.36	1.68	6.25	4.88	4.12	1.72] test loss i: [1.58	1.49	6.25	4.83	4.01	1.66] | 
| 05-02 00:32:11 epoch: 260| time: 2.4s| train loss: +2.022e+01 | test loss: +2.131e+01 | 
| 05-02 00:32:11 epoch: 260| train loss i: [1.09	1.85	6.91	4.75	4.05	1.57] test loss i: [1.62	2.29	6.68	5.29	3.6 	1.82] | 
| 05-02 00:32:14 epoch: 261| time: 2.4s| train loss: +2.009e+01 | test loss: +1.590e+01 | 
| 05-02 00:32:14 epoch: 261| train loss i: [1.37	1.86	5.97	4.96	4.27	1.65] test loss i: [0.62	0.84	4.48	4.04	4.4 	1.52] | 
| 05-02 00:32:16 epoch: 262| time: 2.4s| train loss: +1.885e+01 | test loss: +2.192e+01 | 
| 05-02 00:32:16 epoch: 262| train loss i: [1.03	1.79	5.54	4.99	3.87	1.62] test loss i: [1.8 	2.05	5.75	5.73	4.64	1.94] | 
| 05-02 00:32:18 epoch: 263| time: 2.4s| train loss: +2.010e+01 | test loss: +1.810e+01 | 
| 05-02 00:32:18 epoch: 263| train loss i: [2.03	1.85	5.63	4.99	3.92	1.68] test loss i: [0.95	1.82	5.45	4.52	3.65	1.71] | 
| 05-02 00:32:21 epoch: 264| time: 2.5s| train loss: +1.949e+01 | test loss: +2.301e+01 | 
| 05-02 00:32:21 epoch: 264| train loss i: [1.12	1.73	5.65	5.15	4.28	1.57] test loss i: [2.78	3.65	6.17	5.06	3.62	1.74] | 
| 05-02 00:32:23 epoch: 265| time: 2.5s| train loss: +2.051e+01 | test loss: +3.348e+01 | 
| 05-02 00:32:23 epoch: 265| train loss i: [1.62	2.35	5.99	5.04	3.95	1.54] test loss i: [ 2.33	 5.93	10.17	 7.27	 5.6 	 2.18] | 
| 05-02 00:32:26 epoch: 266| time: 2.4s| train loss: +2.007e+01 | test loss: +2.402e+01 | 
| 05-02 00:32:26 epoch: 266| train loss i: [1.65	2.04	5.95	5.21	3.58	1.65] test loss i: [1.54	1.94	6.9 	6.13	5.39	2.12] | 
| 05-02 00:32:28 epoch: 267| time: 2.4s| train loss: +1.918e+01 | test loss: +2.009e+01 | 
| 05-02 00:32:28 epoch: 267| train loss i: [1.04	1.7 	5.63	4.8 	4.36	1.64] test loss i: [1.17	1.77	5.07	4.83	5.23	2.02] | 
| 05-02 00:32:31 epoch: 268| time: 2.5s| train loss: +1.910e+01 | test loss: +1.775e+01 | 
| 05-02 00:32:31 epoch: 268| train loss i: [0.96	2.01	5.37	5.13	3.95	1.68] test loss i: [1.54	0.7 	5.62	4.7 	3.51	1.68] | 
| 05-02 00:32:33 epoch: 269| time: 2.5s| train loss: +1.985e+01 | test loss: +2.137e+01 | 
| 05-02 00:32:33 epoch: 269| train loss i: [1.05	1.96	5.93	5.13	4.09	1.69] test loss i: [1.26	1.67	6.19	5.59	4.75	1.91] | 
| 05-02 00:32:36 epoch: 270| time: 2.4s| train loss: +1.839e+01 | test loss: +2.251e+01 | 
| 05-02 00:32:36 epoch: 270| train loss i: [0.82	1.65	5.55	4.96	3.82	1.6 ] test loss i: [1.32	1.64	7.33	6.36	3.92	1.94] | 
| 05-02 00:32:38 epoch: 271| time: 2.5s| train loss: +1.942e+01 | test loss: +2.211e+01 | 
| 05-02 00:32:38 epoch: 271| train loss i: [0.88	2.06	6.01	4.97	3.92	1.57] test loss i: [1.4 	1.81	5.73	5.94	5.1 	2.12] | 
| 05-02 00:32:41 epoch: 272| time: 2.5s| train loss: +1.866e+01 | test loss: +1.745e+01 | 
| 05-02 00:32:41 epoch: 272| train loss i: [0.59	1.91	5.76	4.93	3.84	1.63] test loss i: [0.38	1.41	5.19	4.74	4.07	1.65] | 
| 05-02 00:32:43 epoch: 273| time: 2.5s| train loss: +1.925e+01 | test loss: +1.953e+01 | 
| 05-02 00:32:43 epoch: 273| train loss i: [0.94	1.88	5.62	4.95	4.27	1.58] test loss i: [1.47	2.19	4.96	5.49	3.72	1.71] | 
| 05-02 00:32:46 epoch: 274| time: 2.5s| train loss: +1.905e+01 | test loss: +1.790e+01 | 
| 05-02 00:32:46 epoch: 274| train loss i: [0.88	1.87	5.52	5.03	4.08	1.67] test loss i: [0.46	2.  	5.21	5.11	3.55	1.57] | 
| 05-02 00:32:48 epoch: 275| time: 2.5s| train loss: +1.936e+01 | test loss: +2.005e+01 | 
| 05-02 00:32:48 epoch: 275| train loss i: [1.14	2.11	5.14	4.89	4.3 	1.78] test loss i: [1.21	2.18	5.6 	4.78	4.3 	1.98] | 
| 05-02 00:32:50 epoch: 276| time: 2.5s| train loss: +1.854e+01 | test loss: +1.695e+01 | 
| 05-02 00:32:50 epoch: 276| train loss i: [0.94	1.82	5.64	4.66	3.81	1.68] test loss i: [1.54	1.28	4.  	4.69	3.66	1.78] | 
| 05-02 00:32:53 epoch: 277| time: 2.5s| train loss: +1.980e+01 | test loss: +2.001e+01 | 
| 05-02 00:32:53 epoch: 277| train loss i: [1.39	1.86	5.99	5.16	3.69	1.71] test loss i: [1.3 	1.52	5.97	5.29	4.08	1.85] | 
| 05-02 00:32:55 epoch: 278| time: 2.4s| train loss: +2.051e+01 | test loss: +1.596e+01 | 
| 05-02 00:32:55 epoch: 278| train loss i: [1.18	2.51	6.41	4.69	4.07	1.65] test loss i: [0.84	0.75	5.16	3.85	3.62	1.75] | 
| 05-02 00:32:58 epoch: 279| time: 2.5s| train loss: +1.934e+01 | test loss: +2.034e+01 | 
| 05-02 00:32:58 epoch: 279| train loss i: [1.25	1.43	5.24	5.56	4.23	1.63] test loss i: [2.2 	1.54	5.56	4.81	4.39	1.85] | 
| 05-02 00:33:00 epoch: 280| time: 2.5s| train loss: +1.924e+01 | test loss: +2.018e+01 | 
| 05-02 00:33:00 epoch: 280| train loss i: [1.36	1.72	5.66	4.54	4.26	1.7 ] test loss i: [0.8 	1.61	5.22	4.53	6.06	1.96] | 
| 05-02 00:33:03 epoch: 281| time: 2.4s| train loss: +1.845e+01 | test loss: +1.978e+01 | 
| 05-02 00:33:03 epoch: 281| train loss i: [0.83	1.79	5.28	4.93	3.94	1.68] test loss i: [1.64	3.61	4.69	4.06	4.11	1.66] | 
| 05-02 00:33:05 epoch: 282| time: 2.5s| train loss: +2.035e+01 | test loss: +1.832e+01 | 
| 05-02 00:33:05 epoch: 282| train loss i: [1.38	2.56	5.36	5.16	4.22	1.67] test loss i: [2.36	1.35	4.75	4.39	3.55	1.91] | 
| 05-02 00:33:08 epoch: 283| time: 2.5s| train loss: +1.931e+01 | test loss: +2.710e+01 | 
| 05-02 00:33:08 epoch: 283| train loss i: [1.01	1.74	5.2 	5.59	4.17	1.61] test loss i: [1.49	2.71	8.75	6.17	5.54	2.43] | 
| 05-02 00:33:10 epoch: 284| time: 2.4s| train loss: +1.828e+01 | test loss: +2.763e+01 | 
| 05-02 00:33:10 epoch: 284| train loss i: [0.89	1.57	5.43	5.11	3.65	1.65] test loss i: [ 0.63	 3.97	10.22	 6.22	 4.16	 2.42] | 
| 05-02 00:33:13 epoch: 285| time: 2.5s| train loss: +1.952e+01 | test loss: +2.635e+01 | 
| 05-02 00:33:13 epoch: 285| train loss i: [1.05	1.65	5.82	4.83	4.27	1.9 ] test loss i: [2.75	1.33	8.53	6.39	5.24	2.11] | 
| 05-02 00:33:15 epoch: 286| time: 2.4s| train loss: +1.888e+01 | test loss: +2.013e+01 | 
| 05-02 00:33:15 epoch: 286| train loss i: [1.16	1.39	5.41	5.28	3.86	1.79] test loss i: [1.02	1.66	6.67	4.57	4.31	1.89] | 
| 05-02 00:33:18 epoch: 287| time: 2.5s| train loss: +2.045e+01 | test loss: +2.584e+01 | 
| 05-02 00:33:18 epoch: 287| train loss i: [0.96	2.59	5.83	5.26	3.86	1.96] test loss i: [3.19	5.46	5.23	5.29	4.77	1.9 ] | 
| 05-02 00:33:20 epoch: 288| time: 2.5s| train loss: +1.810e+01 | test loss: +1.959e+01 | 
| 05-02 00:33:20 epoch: 288| train loss i: [1.05	1.28	5.36	4.6 	4.07	1.74] test loss i: [1.09	1.84	5.63	5.  	4.12	1.92] | 
| 05-02 00:33:23 epoch: 289| time: 2.5s| train loss: +1.973e+01 | test loss: +1.937e+01 | 
| 05-02 00:33:23 epoch: 289| train loss i: [0.89	2.51	5.89	4.85	3.97	1.62] test loss i: [1.43	0.55	6.68	4.82	4.08	1.8 ] | 
| 05-02 00:33:25 epoch: 290| time: 2.4s| train loss: +2.021e+01 | test loss: +2.586e+01 | 
| 05-02 00:33:25 epoch: 290| train loss i: [1.36	1.92	5.94	5.37	3.87	1.75] test loss i: [4.11	3.39	6.59	4.83	4.26	2.67] | 
| 05-02 00:33:28 epoch: 291| time: 2.5s| train loss: +1.841e+01 | test loss: +2.127e+01 | 
| 05-02 00:33:28 epoch: 291| train loss i: [1.04	1.49	5.63	4.68	3.89	1.68] test loss i: [1.56	3.26	6.23	4.87	3.78	1.58] | 
| 05-02 00:33:30 epoch: 292| time: 2.5s| train loss: +1.886e+01 | test loss: +3.585e+01 | 
| 05-02 00:33:30 epoch: 292| train loss i: [1.33	1.16	5.74	4.83	4.15	1.65] test loss i: [6.16	4.38	7.6 	8.91	6.49	2.32] | 
| 05-02 00:33:32 epoch: 293| time: 2.5s| train loss: +2.052e+01 | test loss: +1.837e+01 | 
| 05-02 00:33:32 epoch: 293| train loss i: [1.31	1.85	6.65	5.02	4.  	1.7 ] test loss i: [1.81	1.49	4.44	4.48	4.45	1.71] | 
| 05-02 00:33:35 epoch: 294| time: 2.5s| train loss: +1.950e+01 | test loss: +2.695e+01 | 
| 05-02 00:33:35 epoch: 294| train loss i: [1.23	1.85	5.8 	4.97	4.04	1.61] test loss i: [2.66	2.54	7.24	7.68	4.71	2.12] | 
| 05-02 00:33:37 epoch: 295| time: 2.4s| train loss: +1.861e+01 | test loss: +2.100e+01 | 
| 05-02 00:33:37 epoch: 295| train loss i: [0.89	2.14	5.43	4.72	3.76	1.68] test loss i: [1.11	2.74	5.38	5.43	4.39	1.95] | 
| 05-02 00:33:40 epoch: 296| time: 2.5s| train loss: +1.862e+01 | test loss: +1.838e+01 | 
| 05-02 00:33:40 epoch: 296| train loss i: [0.79	1.46	5.71	4.94	4.03	1.69] test loss i: [0.69	1.23	6.23	4.62	3.99	1.61] | 
| 05-02 00:33:42 epoch: 297| time: 2.5s| train loss: +1.746e+01 | test loss: +2.667e+01 | 
| 05-02 00:33:42 epoch: 297| train loss i: [0.7 	1.54	5.39	4.57	3.73	1.52] test loss i: [3.17	3.52	7.54	5.57	4.67	2.21] | 
| 05-02 00:33:45 epoch: 298| time: 2.4s| train loss: +1.902e+01 | test loss: +1.820e+01 | 
| 05-02 00:33:45 epoch: 298| train loss i: [0.6 	1.81	6.26	4.8 	3.98	1.58] test loss i: [1.25	1.5 	5.62	4.12	4.05	1.66] | 
| 05-02 00:33:47 epoch: 299| time: 2.4s| train loss: +1.820e+01 | test loss: +1.676e+01 | 
| 05-02 00:33:47 epoch: 299| train loss i: [0.9 	1.23	5.05	5.55	3.92	1.55] test loss i: [0.65	0.75	5.54	4.54	3.78	1.5 ] | 
| 05-02 00:33:50 epoch: 300| time: 2.5s| train loss: +1.930e+01 | test loss: +1.652e+01 | 
| 05-02 00:33:50 epoch: 300| train loss i: [0.99	1.66	5.95	5.02	4.1 	1.59] test loss i: [1.5 	0.79	5.58	3.74	3.27	1.64] | 
| 05-02 00:33:52 epoch: 301| time: 2.5s| train loss: +1.863e+01 | test loss: +1.752e+01 | 
| 05-02 00:33:52 epoch: 301| train loss i: [0.64	1.44	5.66	5.03	4.19	1.66] test loss i: [0.8 	2.56	5.12	3.97	3.39	1.67] | 
| 05-02 00:33:55 epoch: 302| time: 2.5s| train loss: +1.990e+01 | test loss: +2.018e+01 | 
| 05-02 00:33:55 epoch: 302| train loss i: [0.9 	2.31	5.93	5.07	3.98	1.72] test loss i: [1.94	1.83	6.26	4.51	3.84	1.8 ] | 
| 05-02 00:33:57 epoch: 303| time: 2.5s| train loss: +1.941e+01 | test loss: +2.018e+01 | 
| 05-02 00:33:57 epoch: 303| train loss i: [1.  	1.71	5.64	5.25	4.11	1.7 ] test loss i: [1.6 	1.08	6.19	5.31	4.07	1.93] | 
| 05-02 00:34:00 epoch: 304| time: 2.5s| train loss: +1.912e+01 | test loss: +2.088e+01 | 
| 05-02 00:34:00 epoch: 304| train loss i: [0.88	1.92	5.87	5.23	3.56	1.66] test loss i: [1.39	1.67	7.77	4.5 	3.45	2.09] | 
| 05-02 00:34:02 epoch: 305| time: 2.5s| train loss: +1.907e+01 | test loss: +1.867e+01 | 
| 05-02 00:34:02 epoch: 305| train loss i: [0.96	1.91	5.69	4.74	4.14	1.65] test loss i: [1.26	2.54	5.02	4.67	3.51	1.67] | 
| 05-02 00:34:05 epoch: 306| time: 2.5s| train loss: +1.892e+01 | test loss: +2.657e+01 | 
| 05-02 00:34:05 epoch: 306| train loss i: [0.71	1.76	5.31	5.29	4.03	1.82] test loss i: [2.76	3.2 	7.11	6.28	5.25	1.97] | 
| 05-02 00:34:07 epoch: 307| time: 2.4s| train loss: +1.927e+01 | test loss: +1.853e+01 | 
| 05-02 00:34:07 epoch: 307| train loss i: [0.92	1.59	6.03	5.33	3.91	1.49] test loss i: [1.89	1.22	5.65	4.3 	4.12	1.36] | 
| 05-02 00:34:10 epoch: 308| time: 2.5s| train loss: +1.895e+01 | test loss: +2.092e+01 | 
| 05-02 00:34:10 epoch: 308| train loss i: [0.82	1.77	6.19	4.66	3.87	1.63] test loss i: [0.68	2.81	6.72	5.2 	3.82	1.69] | 
| 05-02 00:34:12 epoch: 309| time: 2.5s| train loss: +1.780e+01 | test loss: +2.015e+01 | 
| 05-02 00:34:12 epoch: 309| train loss i: [0.8 	1.18	5.38	4.83	3.9 	1.72] test loss i: [1.07	2.76	5.25	4.94	4.38	1.75] | 
| 05-02 00:34:14 epoch: 310| time: 2.5s| train loss: +2.011e+01 | test loss: +1.848e+01 | 
| 05-02 00:34:14 epoch: 310| train loss i: [1.01	2.31	6.15	4.93	4.12	1.59] test loss i: [0.84	1.58	5.77	5.41	3.34	1.53] | 
| 05-02 00:34:17 epoch: 311| time: 2.5s| train loss: +1.754e+01 | test loss: +1.690e+01 | 
| 05-02 00:34:17 epoch: 311| train loss i: [0.74	1.66	4.94	4.68	3.79	1.72] test loss i: [1.02	1.24	4.67	4.18	4.21	1.58] | 
| 05-02 00:34:19 epoch: 312| time: 2.5s| train loss: +1.830e+01 | test loss: +1.765e+01 | 
| 05-02 00:34:19 epoch: 312| train loss i: [0.63	1.72	5.8 	4.61	3.98	1.57] test loss i: [0.95	1.21	4.48	4.82	4.33	1.86] | 
| 05-02 00:34:22 epoch: 313| time: 2.5s| train loss: +1.845e+01 | test loss: +1.743e+01 | 
| 05-02 00:34:22 epoch: 313| train loss i: [0.64	1.95	5.88	4.73	3.73	1.52] test loss i: [0.41	2.35	4.11	5.23	3.67	1.66] | 
| 05-02 00:34:24 epoch: 314| time: 2.5s| train loss: +1.794e+01 | test loss: +2.677e+01 | 
| 05-02 00:34:24 epoch: 314| train loss i: [0.56	1.4 	5.59	4.88	3.86	1.66] test loss i: [0.99	3.48	7.76	7.22	5.09	2.22] | 
| 05-02 00:34:27 epoch: 315| time: 2.5s| train loss: +1.891e+01 | test loss: +2.091e+01 | 
| 05-02 00:34:27 epoch: 315| train loss i: [0.68	1.81	5.62	5.33	3.91	1.56] test loss i: [0.43	2.11	7.22	5.54	3.86	1.75] | 
| 05-02 00:34:29 epoch: 316| time: 2.5s| train loss: +1.736e+01 | test loss: +3.295e+01 | 
| 05-02 00:34:29 epoch: 316| train loss i: [0.48	0.78	5.57	5.03	3.98	1.52] test loss i: [ 0.97	 5.09	10.35	 8.1 	 5.9 	 2.56] | 
| 05-02 00:34:32 epoch: 317| time: 2.5s| train loss: +1.881e+01 | test loss: +2.018e+01 | 
| 05-02 00:34:32 epoch: 317| train loss i: [0.72	1.58	5.85	5.07	3.88	1.71] test loss i: [2.68	1.06	5.96	4.57	4.07	1.84] | 
| 05-02 00:34:34 epoch: 318| time: 2.4s| train loss: +1.867e+01 | test loss: +3.125e+01 | 
| 05-02 00:34:34 epoch: 318| train loss i: [0.92	1.5 	5.7 	4.95	3.94	1.66] test loss i: [5.05	1.17	8.92	7.8 	5.9 	2.4 ] | 
| 05-02 00:34:37 epoch: 319| time: 2.5s| train loss: +1.825e+01 | test loss: +2.933e+01 | 
| 05-02 00:34:37 epoch: 319| train loss i: [0.8 	1.55	5.59	4.85	3.79	1.67] test loss i: [2.7 	3.65	6.8 	7.52	6.18	2.47] | 
| 05-02 00:34:39 epoch: 320| time: 2.5s| train loss: +1.922e+01 | test loss: +2.077e+01 | 
| 05-02 00:34:39 epoch: 320| train loss i: [1.15	1.87	5.3 	5.3 	4.04	1.56] test loss i: [0.49	1.78	5.72	7.15	3.75	1.89] | 
| 05-02 00:34:42 epoch: 321| time: 2.5s| train loss: +1.966e+01 | test loss: +1.888e+01 | 
| 05-02 00:34:42 epoch: 321| train loss i: [0.98	2.36	5.61	4.74	4.25	1.72] test loss i: [0.69	1.31	6.38	5.48	3.34	1.68] | 
| 05-02 00:34:44 epoch: 322| time: 2.4s| train loss: +1.811e+01 | test loss: +1.801e+01 | 
| 05-02 00:34:44 epoch: 322| train loss i: [0.78	1.54	5.76	4.62	3.84	1.57] test loss i: [2.55	0.83	4.94	4.27	3.84	1.57] | 
| 05-02 00:34:47 epoch: 323| time: 2.5s| train loss: +1.951e+01 | test loss: +2.065e+01 | 
| 05-02 00:34:47 epoch: 323| train loss i: [1.03	1.97	6.24	5.  	3.63	1.64] test loss i: [0.6 	3.48	5.94	4.35	4.66	1.62] | 
| 05-02 00:34:49 epoch: 324| time: 2.4s| train loss: +1.816e+01 | test loss: +2.183e+01 | 
| 05-02 00:34:49 epoch: 324| train loss i: [0.76	1.36	5.9 	4.74	3.78	1.61] test loss i: [0.62	1.33	6.94	6.1 	4.82	2.02] | 
| 05-02 00:34:51 epoch: 325| time: 2.4s| train loss: +1.842e+01 | test loss: +2.189e+01 | 
| 05-02 00:34:51 epoch: 325| train loss i: [0.77	2.41	4.75	4.92	3.99	1.58] test loss i: [0.57	3.55	5.95	4.93	4.94	1.95] | 
| 05-02 00:34:54 epoch: 326| time: 2.5s| train loss: +1.874e+01 | test loss: +1.949e+01 | 
| 05-02 00:34:54 epoch: 326| train loss i: [0.58	1.66	5.59	5.27	4.06	1.59] test loss i: [0.62	1.33	5.61	5.77	4.21	1.96] | 
| 05-02 00:34:56 epoch: 327| time: 2.4s| train loss: +1.750e+01 | test loss: +1.834e+01 | 
| 05-02 00:34:56 epoch: 327| train loss i: [0.64	1.26	5.24	4.87	3.92	1.56] test loss i: [0.79	1.82	5.76	4.74	3.69	1.53] | 
| 05-02 00:34:59 epoch: 328| time: 2.4s| train loss: +1.838e+01 | test loss: +1.868e+01 | 
| 05-02 00:34:59 epoch: 328| train loss i: [0.42	1.49	5.91	5.21	3.76	1.59] test loss i: [0.98	1.93	4.83	5.22	3.86	1.86] | 
| 05-02 00:35:01 epoch: 329| time: 2.4s| train loss: +1.858e+01 | test loss: +2.116e+01 | 
| 05-02 00:35:01 epoch: 329| train loss i: [0.61	1.98	5.83	4.69	3.85	1.63] test loss i: [1.54	1.69	5.92	5.8 	4.49	1.72] | 
| 05-02 00:35:04 epoch: 330| time: 2.5s| train loss: +1.899e+01 | test loss: +2.475e+01 | 
| 05-02 00:35:04 epoch: 330| train loss i: [0.53	1.85	5.73	5.01	4.2 	1.67] test loss i: [1.87	1.15	6.95	6.46	5.96	2.35] | 
| 05-02 00:35:06 epoch: 331| time: 2.5s| train loss: +1.858e+01 | test loss: +2.404e+01 | 
| 05-02 00:35:06 epoch: 331| train loss i: [0.51	2.39	5.55	4.75	3.69	1.68] test loss i: [0.34	1.34	7.17	7.28	5.73	2.17] | 
| 05-02 00:35:09 epoch: 332| time: 2.5s| train loss: +1.858e+01 | test loss: +2.390e+01 | 
| 05-02 00:35:09 epoch: 332| train loss i: [0.5 	1.65	5.62	5.17	3.99	1.65] test loss i: [1.4 	4.61	5.78	5.94	4.45	1.72] | 
| 05-02 00:35:11 epoch: 333| time: 2.4s| train loss: +1.882e+01 | test loss: +1.939e+01 | 
| 05-02 00:35:11 epoch: 333| train loss i: [0.73	1.64	6.03	4.76	3.98	1.69] test loss i: [0.55	1.54	6.05	5.36	4.35	1.53] | 
| 05-02 00:35:13 epoch: 334| time: 2.4s| train loss: +1.721e+01 | test loss: +1.707e+01 | 
| 05-02 00:35:13 epoch: 334| train loss i: [0.49	1.36	5.35	4.39	4.01	1.61] test loss i: [0.3 	0.75	4.13	5.23	4.49	2.16] | 
| 05-02 00:35:16 epoch: 335| time: 2.5s| train loss: +1.817e+01 | test loss: +1.994e+01 | 
| 05-02 00:35:16 epoch: 335| train loss i: [0.53	2.01	5.81	4.45	3.72	1.65] test loss i: [0.81	3.81	5.8 	3.9 	3.85	1.77] | 
| 05-02 00:35:18 epoch: 336| time: 2.5s| train loss: +1.899e+01 | test loss: +1.929e+01 | 
| 05-02 00:35:18 epoch: 336| train loss i: [0.61	1.63	6.23	5.02	3.9 	1.59] test loss i: [0.55	1.73	4.91	6.02	4.07	2.01] | 
| 05-02 00:35:21 epoch: 337| time: 2.5s| train loss: +1.959e+01 | test loss: +1.785e+01 | 
| 05-02 00:35:21 epoch: 337| train loss i: [0.77	1.97	6.35	4.71	4.12	1.66] test loss i: [0.87	1.33	5.99	4.73	3.35	1.58] | 
| 05-02 00:35:23 epoch: 338| time: 2.5s| train loss: +1.854e+01 | test loss: +1.647e+01 | 
| 05-02 00:35:23 epoch: 338| train loss i: [1.07	1.87	5.11	5.02	3.81	1.67] test loss i: [1.07	0.86	5.3 	4.25	3.29	1.71] | 
| 05-02 00:35:26 epoch: 339| time: 2.6s| train loss: +1.845e+01 | test loss: +2.483e+01 | 
| 05-02 00:35:26 epoch: 339| train loss i: [0.68	1.37	5.8 	4.9 	4.15	1.55] test loss i: [1.81	1.64	8.5 	6.49	4.33	2.06] | 
| 05-02 00:35:29 epoch: 340| time: 2.6s| train loss: +1.927e+01 | test loss: +1.972e+01 | 
| 05-02 00:35:29 epoch: 340| train loss i: [0.76	1.76	6.07	5.28	3.81	1.6 ] test loss i: [1.52	3.86	4.05	4.9 	3.71	1.68] | 
| 05-02 00:35:31 epoch: 341| time: 2.6s| train loss: +1.844e+01 | test loss: +1.582e+01 | 
| 05-02 00:35:31 epoch: 341| train loss i: [0.86	1.34	5.45	5.15	3.98	1.65] test loss i: [0.32	0.91	5.2 	4.25	3.23	1.9 ] | 
| 05-02 00:35:34 epoch: 342| time: 2.5s| train loss: +1.810e+01 | test loss: +2.015e+01 | 
| 05-02 00:35:34 epoch: 342| train loss i: [0.64	1.24	5.7 	4.61	4.27	1.64] test loss i: [0.37	2.35	5.61	5.42	4.55	1.84] | 
| 05-02 00:35:36 epoch: 343| time: 2.5s| train loss: +1.813e+01 | test loss: +2.209e+01 | 
| 05-02 00:35:36 epoch: 343| train loss i: [0.52	1.49	5.58	5.  	3.91	1.65] test loss i: [1.65	2.47	6.23	5.68	4.  	2.05] | 
| 05-02 00:35:39 epoch: 344| time: 2.5s| train loss: +1.893e+01 | test loss: +1.967e+01 | 
| 05-02 00:35:39 epoch: 344| train loss i: [0.62	1.31	6.25	5.1 	3.94	1.71] test loss i: [0.88	1.92	5.63	5.26	4.18	1.8 ] | 
| 05-02 00:35:41 epoch: 345| time: 2.5s| train loss: +1.902e+01 | test loss: +1.989e+01 | 
| 05-02 00:35:41 epoch: 345| train loss i: [0.7 	2.06	5.85	4.76	4.02	1.62] test loss i: [2.06	1.74	5.17	4.72	4.43	1.77] | 
| 05-02 00:35:44 epoch: 346| time: 2.5s| train loss: +1.812e+01 | test loss: +2.649e+01 | 
| 05-02 00:35:44 epoch: 346| train loss i: [0.55	1.75	5.28	5.07	3.87	1.6 ] test loss i: [1.45	2.22	7.85	6.91	5.67	2.4 ] | 
| 05-02 00:35:46 epoch: 347| time: 2.6s| train loss: +1.849e+01 | test loss: +1.523e+01 | 
| 05-02 00:35:46 epoch: 347| train loss i: [0.53	1.44	5.38	5.63	3.89	1.62] test loss i: [0.35	0.92	4.31	4.31	3.63	1.71] | 
| 05-02 00:35:49 epoch: 348| time: 2.5s| train loss: +1.780e+01 | test loss: +1.616e+01 | 
| 05-02 00:35:49 epoch: 348| train loss i: [0.36	1.3 	5.56	4.99	3.97	1.64] test loss i: [0.3 	1.36	3.31	5.32	4.02	1.85] | 
| 05-02 00:35:51 epoch: 349| time: 2.5s| train loss: +1.778e+01 | test loss: +1.814e+01 | 
| 05-02 00:35:51 epoch: 349| train loss i: [0.47	1.32	5.43	5.06	3.85	1.65] test loss i: [0.38	2.84	5.3 	3.92	3.78	1.92] | 
| 05-02 00:35:54 epoch: 350| time: 2.5s| train loss: +1.865e+01 | test loss: +1.849e+01 | 
| 05-02 00:35:54 epoch: 350| train loss i: [0.45	1.23	6.27	5.19	3.89	1.63] test loss i: [0.47	1.18	5.6 	4.68	4.86	1.7 ] | 
| 05-02 00:35:56 epoch: 351| time: 2.5s| train loss: +1.852e+01 | test loss: +1.619e+01 | 
| 05-02 00:35:56 epoch: 351| train loss i: [0.48	2.04	5.35	5.26	3.75	1.64] test loss i: [0.62	0.85	4.27	5.19	3.67	1.59] | 
| 05-02 00:35:59 epoch: 352| time: 2.5s| train loss: +1.830e+01 | test loss: +1.739e+01 | 
| 05-02 00:35:59 epoch: 352| train loss i: [0.46	1.77	5.9 	4.89	3.73	1.56] test loss i: [0.65	1.22	4.76	5.48	3.6 	1.68] | 
| 05-02 00:36:01 epoch: 353| time: 2.5s| train loss: +1.810e+01 | test loss: +1.969e+01 | 
| 05-02 00:36:01 epoch: 353| train loss i: [0.81	1.39	5.52	4.93	3.83	1.61] test loss i: [0.92	2.17	6.16	5.02	3.53	1.89] | 
| 05-02 00:36:04 epoch: 354| time: 2.5s| train loss: +1.945e+01 | test loss: +1.813e+01 | 
| 05-02 00:36:04 epoch: 354| train loss i: [0.71	2.31	5.96	5.01	3.89	1.57] test loss i: [0.36	1.42	6.3 	4.47	3.85	1.72] | 
| 05-02 00:36:07 epoch: 355| time: 2.5s| train loss: +1.801e+01 | test loss: +1.706e+01 | 
| 05-02 00:36:07 epoch: 355| train loss i: [0.46	1.12	5.92	4.87	3.94	1.7 ] test loss i: [0.43	0.71	4.02	5.62	4.22	2.06] | 
| 05-02 00:36:09 epoch: 356| time: 2.5s| train loss: +1.834e+01 | test loss: +1.626e+01 | 
| 05-02 00:36:09 epoch: 356| train loss i: [0.46	1.66	6.23	4.75	3.62	1.63] test loss i: [0.48	1.27	5.82	3.95	3.31	1.42] | 
| 05-02 00:36:12 epoch: 357| time: 2.6s| train loss: +1.869e+01 | test loss: +1.857e+01 | 
| 05-02 00:36:12 epoch: 357| train loss i: [0.66	1.38	5.86	4.99	4.2 	1.59] test loss i: [0.88	1.03	6.37	5.23	3.41	1.65] | 
| 05-02 00:36:14 epoch: 358| time: 2.5s| train loss: +1.808e+01 | test loss: +2.435e+01 | 
| 05-02 00:36:14 epoch: 358| train loss i: [0.81	1.26	5.59	4.88	3.84	1.71] test loss i: [2.72	2.65	6.73	5.59	4.66	2.01] | 
| 05-02 00:36:17 epoch: 359| time: 2.5s| train loss: +1.900e+01 | test loss: +1.653e+01 | 
| 05-02 00:36:17 epoch: 359| train loss i: [0.55	1.71	5.58	5.17	4.29	1.7 ] test loss i: [0.48	0.96	5.25	4.36	4.01	1.47] | 
| 05-02 00:36:19 epoch: 360| time: 2.5s| train loss: +1.907e+01 | test loss: +1.696e+01 | 
| 05-02 00:36:19 epoch: 360| train loss i: [0.5 	1.84	5.9 	4.94	4.24	1.65] test loss i: [0.42	1.83	4.81	4.46	3.87	1.56] | 
| 05-02 00:36:22 epoch: 361| time: 2.5s| train loss: +1.879e+01 | test loss: +2.189e+01 | 
| 05-02 00:36:22 epoch: 361| train loss i: [0.64	1.84	5.73	4.87	4.02	1.68] test loss i: [1.88	3.09	6.81	4.96	3.57	1.58] | 
| 05-02 00:36:24 epoch: 362| time: 2.4s| train loss: +1.884e+01 | test loss: +2.708e+01 | 
| 05-02 00:36:24 epoch: 362| train loss i: [0.6 	1.44	5.96	5.4 	3.84	1.6 ] test loss i: [0.69	4.68	7.56	7.11	4.97	2.06] | 
| 05-02 00:36:27 epoch: 363| time: 2.4s| train loss: +1.756e+01 | test loss: +2.222e+01 | 
| 05-02 00:36:27 epoch: 363| train loss i: [0.46	1.04	5.73	4.75	4.07	1.52] test loss i: [1.91	3.73	6.59	4.79	3.55	1.65] | 
| 05-02 00:36:29 epoch: 364| time: 2.5s| train loss: +1.885e+01 | test loss: +3.059e+01 | 
| 05-02 00:36:29 epoch: 364| train loss i: [0.62	1.69	5.69	5.17	4.05	1.63] test loss i: [1.66	2.95	8.97	7.83	6.61	2.58] | 
| 05-02 00:36:31 epoch: 365| time: 2.5s| train loss: +1.964e+01 | test loss: +2.797e+01 | 
| 05-02 00:36:31 epoch: 365| train loss i: [1.02	1.62	6.46	4.74	4.12	1.67] test loss i: [1.63	2.67	9.82	6.38	5.36	2.11] | 
| 05-02 00:36:34 epoch: 366| time: 2.5s| train loss: +1.872e+01 | test loss: +2.558e+01 | 
| 05-02 00:36:34 epoch: 366| train loss i: [0.79	1.44	5.7 	5.17	4.01	1.61] test loss i: [1.81	5.42	5.93	5.69	4.79	1.94] | 
| 05-02 00:36:36 epoch: 367| time: 2.5s| train loss: +1.930e+01 | test loss: +2.120e+01 | 
| 05-02 00:36:36 epoch: 367| train loss i: [0.87	2.66	5.55	4.85	3.84	1.53] test loss i: [2.26	2.03	6.38	4.42	4.35	1.77] | 
| 05-02 00:36:39 epoch: 368| time: 2.5s| train loss: +1.868e+01 | test loss: +2.388e+01 | 
| 05-02 00:36:39 epoch: 368| train loss i: [0.84	1.78	5.35	5.09	4.03	1.59] test loss i: [0.4 	1.27	8.19	7.1 	5.05	1.88] | 
| 05-02 00:36:41 epoch: 369| time: 2.5s| train loss: +1.724e+01 | test loss: +2.073e+01 | 
| 05-02 00:36:41 epoch: 369| train loss i: [0.72	0.88	5.34	4.88	3.86	1.56] test loss i: [0.44	1.78	5.6 	6.35	4.42	2.13] | 
| 05-02 00:36:44 epoch: 370| time: 2.4s| train loss: +1.868e+01 | test loss: +1.692e+01 | 
| 05-02 00:36:44 epoch: 370| train loss i: [0.75	2.18	5.59	4.6 	4.03	1.54] test loss i: [1.08	1.42	4.92	4.28	3.28	1.94] | 
| 05-02 00:36:46 epoch: 371| time: 2.5s| train loss: +2.008e+01 | test loss: +2.609e+01 | 
| 05-02 00:36:46 epoch: 371| train loss i: [0.74	2.19	6.14	5.43	4.01	1.58] test loss i: [4.55	3.12	6.58	6.2 	3.81	1.84] | 
| 05-02 00:36:49 epoch: 372| time: 2.4s| train loss: +2.107e+01 | test loss: +1.775e+01 | 
| 05-02 00:36:49 epoch: 372| train loss i: [1.38	3.1 	5.67	5.16	4.05	1.72] test loss i: [1.53	0.7 	5.7 	4.63	3.59	1.6 ] | 
| 05-02 00:36:51 epoch: 373| time: 2.5s| train loss: +1.788e+01 | test loss: +1.801e+01 | 
| 05-02 00:36:51 epoch: 373| train loss i: [0.68	1.39	5.19	5.  	3.99	1.62] test loss i: [0.56	0.52	7.3 	4.72	3.31	1.61] | 
| 05-02 00:36:54 epoch: 374| time: 2.5s| train loss: +1.801e+01 | test loss: +1.584e+01 | 
| 05-02 00:36:54 epoch: 374| train loss i: [0.6 	1.44	5.67	4.75	3.91	1.64] test loss i: [1.03	0.61	4.62	4.81	3.45	1.33] | 
| 05-02 00:36:56 epoch: 375| time: 2.5s| train loss: +1.786e+01 | test loss: +2.015e+01 | 
| 05-02 00:36:56 epoch: 375| train loss i: [0.68	1.5 	5.32	4.96	3.81	1.6 ] test loss i: [0.36	2.34	5.46	6.1 	4.29	1.6 ] | 
| 05-02 00:36:59 epoch: 376| time: 2.5s| train loss: +1.843e+01 | test loss: +1.509e+01 | 
| 05-02 00:36:59 epoch: 376| train loss i: [0.47	1.68	5.96	4.86	3.84	1.62] test loss i: [0.39	0.58	5.17	3.67	3.74	1.54] | 
| 05-02 00:37:01 epoch: 377| time: 2.5s| train loss: +1.772e+01 | test loss: +1.791e+01 | 
| 05-02 00:37:01 epoch: 377| train loss i: [0.4 	1.48	5.67	4.76	3.74	1.67] test loss i: [0.61	1.31	4.77	5.34	4.18	1.69] | 
| 05-02 00:37:04 epoch: 378| time: 2.5s| train loss: +1.737e+01 | test loss: +1.896e+01 | 
| 05-02 00:37:04 epoch: 378| train loss i: [0.46	1.07	5.51	4.92	3.82	1.59] test loss i: [0.7 	1.24	5.12	5.42	4.2 	2.29] | 
| 05-02 00:37:06 epoch: 379| time: 2.4s| train loss: +1.726e+01 | test loss: +1.708e+01 | 
| 05-02 00:37:06 epoch: 379| train loss i: [0.3 	1.14	5.83	4.62	3.76	1.61] test loss i: [0.97	1.44	5.61	3.98	3.55	1.52] | 
| 05-02 00:37:09 epoch: 380| time: 2.5s| train loss: +1.722e+01 | test loss: +1.801e+01 | 
| 05-02 00:37:09 epoch: 380| train loss i: [0.41	1.43	5.24	4.8 	3.74	1.6 ] test loss i: [0.27	1.15	5.41	5.48	4.1 	1.61] | 
| 05-02 00:37:11 epoch: 381| time: 2.4s| train loss: +1.825e+01 | test loss: +1.618e+01 | 
| 05-02 00:37:11 epoch: 381| train loss i: [0.46	1.55	5.99	5.1 	3.53	1.61] test loss i: [0.57	1.3 	4.75	4.66	3.41	1.49] | 
| 05-02 00:37:13 epoch: 382| time: 2.5s| train loss: +1.765e+01 | test loss: +2.522e+01 | 
| 05-02 00:37:13 epoch: 382| train loss i: [0.44	1.81	5.38	4.59	3.84	1.59] test loss i: [0.96	2.2 	7.97	6.95	4.98	2.15] | 
| 05-02 00:37:16 epoch: 383| time: 2.5s| train loss: +1.753e+01 | test loss: +1.813e+01 | 
| 05-02 00:37:16 epoch: 383| train loss i: [0.36	1.23	5.24	4.9 	4.2 	1.61] test loss i: [0.69	1.9 	5.89	4.43	3.68	1.53] | 
| 05-02 00:37:18 epoch: 384| time: 2.4s| train loss: +1.807e+01 | test loss: +1.891e+01 | 
| 05-02 00:37:18 epoch: 384| train loss i: [0.53	1.9 	5.35	4.72	3.97	1.6 ] test loss i: [0.52	1.62	5.52	5.56	4.09	1.62] | 
| 05-02 00:37:21 epoch: 385| time: 2.5s| train loss: +1.777e+01 | test loss: +2.639e+01 | 
| 05-02 00:37:21 epoch: 385| train loss i: [0.41	1.91	4.95	4.73	4.12	1.64] test loss i: [1.84	2.17	8.63	6.93	4.83	1.99] | 
| 05-02 00:37:23 epoch: 386| time: 2.5s| train loss: +1.683e+01 | test loss: +2.260e+01 | 
| 05-02 00:37:23 epoch: 386| train loss i: [0.59	1.06	5.13	4.73	3.85	1.48] test loss i: [0.49	1.79	8.  	5.62	4.68	2.02] | 
| 05-02 00:37:26 epoch: 387| time: 2.5s| train loss: +1.696e+01 | test loss: +1.873e+01 | 
| 05-02 00:37:26 epoch: 387| train loss i: [0.33	1.22	5.1 	4.94	3.8 	1.57] test loss i: [0.56	1.25	5.09	5.13	4.94	1.75] | 
| 05-02 00:37:28 epoch: 388| time: 2.5s| train loss: +1.825e+01 | test loss: +1.626e+01 | 
| 05-02 00:37:28 epoch: 388| train loss i: [0.54	1.5 	5.61	4.72	4.28	1.6 ] test loss i: [0.46	1.79	5.  	3.81	3.69	1.51] | 
| 05-02 00:37:31 epoch: 389| time: 2.5s| train loss: +1.909e+01 | test loss: +1.610e+01 | 
| 05-02 00:37:31 epoch: 389| train loss i: [0.45	1.97	5.93	5.25	3.87	1.62] test loss i: [0.3 	1.24	5.82	4.23	3.06	1.44] | 
| 05-02 00:37:33 epoch: 390| time: 2.5s| train loss: +1.773e+01 | test loss: +2.113e+01 | 
| 05-02 00:37:33 epoch: 390| train loss i: [0.53	1.92	5.31	4.87	3.55	1.54] test loss i: [2.56	1.39	6.6 	4.84	3.99	1.74] | 
| 05-02 00:37:36 epoch: 391| time: 2.5s| train loss: +1.799e+01 | test loss: +2.149e+01 | 
| 05-02 00:37:36 epoch: 391| train loss i: [0.43	1.65	5.31	5.08	3.93	1.6 ] test loss i: [3.65	1.9 	5.62	4.75	3.69	1.87] | 
| 05-02 00:37:38 epoch: 392| time: 2.5s| train loss: +1.795e+01 | test loss: +2.156e+01 | 
| 05-02 00:37:38 epoch: 392| train loss i: [0.9 	1.36	5.63	4.54	3.82	1.69] test loss i: [0.89	3.06	6.45	6.06	3.63	1.47] | 
| 05-02 00:37:41 epoch: 393| time: 2.4s| train loss: +1.989e+01 | test loss: +2.022e+01 | 
| 05-02 00:37:41 epoch: 393| train loss i: [1.13	1.87	5.85	5.07	4.35	1.63] test loss i: [0.91	2.75	5.64	5.17	3.49	2.25] | 
| 05-02 00:37:43 epoch: 394| time: 2.4s| train loss: +1.913e+01 | test loss: +2.590e+01 | 
| 05-02 00:37:43 epoch: 394| train loss i: [0.49	1.62	6.48	4.84	4.07	1.63] test loss i: [0.54	1.71	7.3 	8.09	5.95	2.31] | 
| 05-02 00:37:46 epoch: 395| time: 2.5s| train loss: +1.915e+01 | test loss: +2.184e+01 | 
| 05-02 00:37:46 epoch: 395| train loss i: [0.7 	1.88	5.55	5.02	4.32	1.68] test loss i: [2.45	2.85	6.86	4.58	3.35	1.75] | 
| 05-02 00:37:48 epoch: 396| time: 2.5s| train loss: +1.753e+01 | test loss: +2.259e+01 | 
| 05-02 00:37:48 epoch: 396| train loss i: [0.51	1.61	5.32	4.62	3.83	1.64] test loss i: [3.94	1.52	5.69	4.93	5.  	1.52] | 
| 05-02 00:37:51 epoch: 397| time: 2.4s| train loss: +1.763e+01 | test loss: +1.792e+01 | 
| 05-02 00:37:51 epoch: 397| train loss i: [0.44	1.48	5.27	4.89	3.93	1.62] test loss i: [0.7 	2.4 	4.76	5.34	3.41	1.32] | 
| 05-02 00:37:53 epoch: 398| time: 2.5s| train loss: +1.861e+01 | test loss: +2.093e+01 | 
| 05-02 00:37:53 epoch: 398| train loss i: [0.51	1.69	5.85	5.  	4.01	1.56] test loss i: [1.36	1.75	5.89	5.98	4.13	1.82] | 
| 05-02 00:37:55 epoch: 399| time: 2.4s| train loss: +1.840e+01 | test loss: +2.112e+01 | 
| 05-02 00:37:55 epoch: 399| train loss i: [0.53	1.65	5.49	5.17	3.95	1.6 ] test loss i: [1.14	1.29	6.93	4.7 	5.04	2.01] | 
| 05-02 00:37:58 epoch: 400| time: 2.5s| train loss: +1.889e+01 | test loss: +1.740e+01 | 
| 05-02 00:37:58 epoch: 400| train loss i: [0.79	1.73	5.76	4.74	4.2 	1.67] test loss i: [0.67	1.1 	5.26	4.57	4.02	1.78] | 
| 05-02 00:38:00 epoch: 401| time: 2.5s| train loss: +1.987e+01 | test loss: +1.830e+01 | 
| 05-02 00:38:00 epoch: 401| train loss i: [1.23	1.93	5.88	5.  	4.17	1.67] test loss i: [1.83	2.04	4.83	4.23	3.76	1.62] | 
| 05-02 00:38:03 epoch: 402| time: 2.5s| train loss: +1.911e+01 | test loss: +2.006e+01 | 
| 05-02 00:38:03 epoch: 402| train loss i: [0.86	2.2 	5.67	4.75	3.94	1.7 ] test loss i: [1.55	2.25	5.94	5.19	3.69	1.45] | 
| 05-02 00:38:05 epoch: 403| time: 2.5s| train loss: +1.892e+01 | test loss: +1.857e+01 | 
| 05-02 00:38:05 epoch: 403| train loss i: [0.8 	1.4 	6.02	4.93	4.02	1.74] test loss i: [0.6 	1.46	6.01	4.7 	4.08	1.73] | 
| 05-02 00:38:08 epoch: 404| time: 2.5s| train loss: +1.861e+01 | test loss: +2.045e+01 | 
| 05-02 00:38:08 epoch: 404| train loss i: [0.56	1.67	6.06	4.91	3.74	1.67] test loss i: [1.  	0.9 	6.51	5.91	4.22	1.91] | 
| 05-02 00:38:10 epoch: 405| time: 2.5s| train loss: +1.902e+01 | test loss: +2.295e+01 | 
| 05-02 00:38:10 epoch: 405| train loss i: [0.54	2.  	6.04	5.04	3.78	1.61] test loss i: [0.8 	3.22	6.24	6.12	4.79	1.77] | 
| 05-02 00:38:13 epoch: 406| time: 2.5s| train loss: +1.793e+01 | test loss: +2.115e+01 | 
| 05-02 00:38:13 epoch: 406| train loss i: [0.64	1.26	5.63	4.95	3.86	1.58] test loss i: [0.74	1.02	7.55	6.03	4.08	1.72] | 
| 05-02 00:38:15 epoch: 407| time: 2.5s| train loss: +1.845e+01 | test loss: +2.531e+01 | 
| 05-02 00:38:15 epoch: 407| train loss i: [0.51	0.99	6.24	5.02	4.05	1.63] test loss i: [0.77	1.21	8.15	7.89	4.92	2.37] | 
| 05-02 00:38:18 epoch: 408| time: 2.5s| train loss: +1.871e+01 | test loss: +2.123e+01 | 
| 05-02 00:38:18 epoch: 408| train loss i: [0.56	2.11	5.99	4.68	3.84	1.53] test loss i: [0.32	1.29	7.3 	5.45	5.04	1.82] | 
| 05-02 00:38:20 epoch: 409| time: 2.4s| train loss: +1.807e+01 | test loss: +2.024e+01 | 
| 05-02 00:38:20 epoch: 409| train loss i: [0.43	1.72	5.69	4.89	3.71	1.62] test loss i: [0.66	1.72	5.92	5.71	4.19	2.04] | 
| 05-02 00:38:23 epoch: 410| time: 2.5s| train loss: +1.878e+01 | test loss: +2.062e+01 | 
| 05-02 00:38:23 epoch: 410| train loss i: [0.29	2.22	5.87	4.88	3.87	1.65] test loss i: [0.43	0.85	7.88	5.63	3.6 	2.22] | 
| 05-02 00:38:25 epoch: 411| time: 2.4s| train loss: +1.809e+01 | test loss: +1.942e+01 | 
| 05-02 00:38:25 epoch: 411| train loss i: [0.39	1.52	5.95	4.99	3.66	1.58] test loss i: [0.4 	1.48	5.65	5.56	4.72	1.62] | 
| 05-02 00:38:28 epoch: 412| time: 2.4s| train loss: +1.887e+01 | test loss: +2.020e+01 | 
| 05-02 00:38:28 epoch: 412| train loss i: [0.43	2.01	5.63	5.07	3.99	1.73] test loss i: [1.01	2.41	4.42	5.74	4.68	1.93] | 
| 05-02 00:38:30 epoch: 413| time: 2.5s| train loss: +1.768e+01 | test loss: +1.701e+01 | 
| 05-02 00:38:30 epoch: 413| train loss i: [0.37	1.43	5.73	5.  	3.57	1.58] test loss i: [1.  	1.44	5.05	3.65	4.26	1.61] | 
| 05-02 00:38:33 epoch: 414| time: 2.5s| train loss: +1.825e+01 | test loss: +2.334e+01 | 
| 05-02 00:38:33 epoch: 414| train loss i: [0.31	1.16	5.97	5.29	3.84	1.66] test loss i: [0.49	4.59	6.08	5.44	4.83	1.91] | 
| 05-02 00:38:35 epoch: 415| time: 2.4s| train loss: +1.719e+01 | test loss: +2.336e+01 | 
| 05-02 00:38:35 epoch: 415| train loss i: [0.35	1.18	5.49	4.65	3.89	1.63] test loss i: [1.34	3.75	6.61	5.34	4.6 	1.72] | 
| 05-02 00:38:38 epoch: 416| time: 2.5s| train loss: +1.876e+01 | test loss: +1.529e+01 | 
| 05-02 00:38:38 epoch: 416| train loss i: [0.38	1.27	6.27	5.15	4.04	1.63] test loss i: [0.34	1.15	3.75	4.85	3.6 	1.6 ] | 
| 05-02 00:38:40 epoch: 417| time: 2.4s| train loss: +1.876e+01 | test loss: +2.329e+01 | 
| 05-02 00:38:40 epoch: 417| train loss i: [0.38	1.83	6.05	5.  	3.91	1.6 ] test loss i: [0.97	1.03	7.92	6.94	4.38	2.06] | 
| 05-02 00:38:42 epoch: 418| time: 2.5s| train loss: +1.773e+01 | test loss: +1.504e+01 | 
| 05-02 00:38:42 epoch: 418| train loss i: [0.38	1.55	5.38	5.03	3.82	1.57] test loss i: [0.36	1.26	4.  	4.07	3.85	1.5 ] | 
| 05-02 00:38:45 epoch: 419| time: 2.5s| train loss: +1.669e+01 | test loss: +1.886e+01 | 
| 05-02 00:38:45 epoch: 419| train loss i: [0.43	1.22	4.99	4.68	3.77	1.61] test loss i: [0.73	0.95	5.57	4.6 	5.09	1.91] | 
| 05-02 00:38:47 epoch: 420| time: 2.5s| train loss: +1.799e+01 | test loss: +1.800e+01 | 
| 05-02 00:38:47 epoch: 420| train loss i: [0.37	1.2 	5.71	5.  	4.07	1.65] test loss i: [0.2 	0.2 	6.26	4.83	4.74	1.76] | 
| 05-02 00:38:50 epoch: 421| time: 2.4s| train loss: +1.684e+01 | test loss: +1.694e+01 | 
| 05-02 00:38:50 epoch: 421| train loss i: [0.23	1.41	5.21	4.66	3.78	1.55] test loss i: [0.25	1.04	5.64	4.63	3.84	1.54] | 
| 05-02 00:38:52 epoch: 422| time: 2.5s| train loss: +1.696e+01 | test loss: +1.789e+01 | 
| 05-02 00:38:52 epoch: 422| train loss i: [0.26	0.86	5.59	4.81	3.83	1.61] test loss i: [0.28	0.96	6.43	4.62	3.83	1.77] | 
| 05-02 00:38:55 epoch: 423| time: 2.4s| train loss: +1.797e+01 | test loss: +2.212e+01 | 
| 05-02 00:38:55 epoch: 423| train loss i: [0.34	1.48	5.76	4.66	4.21	1.52] test loss i: [0.46	2.11	7.01	5.5 	4.95	2.08] | 
| 05-02 00:38:57 epoch: 424| time: 2.5s| train loss: +1.857e+01 | test loss: +1.924e+01 | 
| 05-02 00:38:57 epoch: 424| train loss i: [0.28	1.81	5.47	5.35	3.96	1.69] test loss i: [0.24	3.34	5.9 	4.15	3.79	1.82] | 
| 05-02 00:39:00 epoch: 425| time: 2.5s| train loss: +1.745e+01 | test loss: +2.091e+01 | 
| 05-02 00:39:00 epoch: 425| train loss i: [0.39	1.59	5.3 	4.79	3.8 	1.58] test loss i: [1.31	1.35	6.34	6.01	4.14	1.77] | 
| 05-02 00:39:02 epoch: 426| time: 2.4s| train loss: +1.868e+01 | test loss: +2.012e+01 | 
| 05-02 00:39:02 epoch: 426| train loss i: [0.36	2.12	5.82	4.8 	3.97	1.61] test loss i: [0.6 	2.09	6.73	4.78	3.91	2.02] | 
| 05-02 00:39:05 epoch: 427| time: 2.5s| train loss: +1.819e+01 | test loss: +2.214e+01 | 
| 05-02 00:39:05 epoch: 427| train loss i: [0.41	1.87	5.55	4.83	3.94	1.59] test loss i: [0.3 	3.68	6.11	5.6 	4.6 	1.85] | 
| 05-02 00:39:07 epoch: 428| time: 2.5s| train loss: +1.682e+01 | test loss: +2.638e+01 | 
| 05-02 00:39:07 epoch: 428| train loss i: [0.33	0.92	5.44	4.61	3.95	1.57] test loss i: [1.24	5.15	7.66	6.04	4.02	2.27] | 
| 05-02 00:39:10 epoch: 429| time: 2.4s| train loss: +1.933e+01 | test loss: +2.879e+01 | 
| 05-02 00:39:10 epoch: 429| train loss i: [0.74	1.64	6.14	5.28	3.92	1.61] test loss i: [1.7 	3.73	9.26	6.76	5.39	1.95] | 
| 05-02 00:39:12 epoch: 430| time: 2.5s| train loss: +1.753e+01 | test loss: +2.079e+01 | 
| 05-02 00:39:12 epoch: 430| train loss i: [0.69	1.3 	5.42	4.73	3.84	1.55] test loss i: [1.74	2.56	5.07	4.61	4.97	1.84] | 
| 05-02 00:39:14 epoch: 431| time: 2.4s| train loss: +1.812e+01 | test loss: +1.851e+01 | 
| 05-02 00:39:14 epoch: 431| train loss i: [0.73	1.4 	5.43	5.24	3.74	1.59] test loss i: [1.15	2.92	4.29	4.79	3.69	1.68] | 
| 05-02 00:39:17 epoch: 432| time: 2.5s| train loss: +1.872e+01 | test loss: +1.720e+01 | 
| 05-02 00:39:17 epoch: 432| train loss i: [0.44	2.17	5.63	5.01	3.87	1.61] test loss i: [0.86	1.19	4.98	4.81	3.8 	1.55] | 
| 05-02 00:39:19 epoch: 433| time: 2.5s| train loss: +1.806e+01 | test loss: +2.754e+01 | 
| 05-02 00:39:19 epoch: 433| train loss i: [0.65	1.64	5.48	4.67	3.98	1.64] test loss i: [0.7 	2.87	7.92	7.81	6.01	2.23] | 
| 05-02 00:39:22 epoch: 434| time: 2.5s| train loss: +1.887e+01 | test loss: +1.891e+01 | 
| 05-02 00:39:22 epoch: 434| train loss i: [0.49	2.21	5.4 	5.23	3.88	1.67] test loss i: [0.29	2.83	6.14	4.53	3.48	1.64] | 
| 05-02 00:39:24 epoch: 435| time: 2.5s| train loss: +1.784e+01 | test loss: +1.471e+01 | 
| 05-02 00:39:24 epoch: 435| train loss i: [0.61	1.44	6.1 	4.39	3.71	1.6 ] test loss i: [0.51	1.39	4.88	3.7 	2.81	1.42] | 
| 05-02 00:39:27 epoch: 436| time: 2.5s| train loss: +1.849e+01 | test loss: +1.898e+01 | 
| 05-02 00:39:27 epoch: 436| train loss i: [0.37	1.4 	5.69	5.09	4.38	1.57] test loss i: [0.63	0.77	5.79	5.14	5.  	1.65] | 
| 05-02 00:39:29 epoch: 437| time: 2.4s| train loss: +1.736e+01 | test loss: +1.714e+01 | 
| 05-02 00:39:29 epoch: 437| train loss i: [0.33	1.56	4.96	4.93	4.  	1.59] test loss i: [0.36	2.18	5.01	4.57	3.45	1.57] | 
| 05-02 00:39:32 epoch: 438| time: 2.5s| train loss: +1.792e+01 | test loss: +2.207e+01 | 
| 05-02 00:39:32 epoch: 438| train loss i: [0.33	1.59	5.28	5.18	3.93	1.61] test loss i: [0.89	0.81	7.22	5.66	5.23	2.25] | 
| 05-02 00:39:34 epoch: 439| time: 2.5s| train loss: +1.890e+01 | test loss: +1.984e+01 | 
| 05-02 00:39:34 epoch: 439| train loss i: [0.4 	1.64	6.02	5.26	3.96	1.61] test loss i: [1.05	1.57	5.31	5.  	4.93	1.97] | 
| 05-02 00:39:37 epoch: 440| time: 2.5s| train loss: +1.837e+01 | test loss: +1.899e+01 | 
| 05-02 00:39:37 epoch: 440| train loss i: [0.51	1.43	5.7 	5.  	4.11	1.62] test loss i: [0.26	1.65	6.5 	4.95	4.  	1.63] | 
| 05-02 00:39:39 epoch: 441| time: 2.5s| train loss: +1.860e+01 | test loss: +2.501e+01 | 
| 05-02 00:39:39 epoch: 441| train loss i: [0.41	1.51	5.81	5.09	4.04	1.72] test loss i: [0.89	3.28	8.05	6.  	4.81	1.98] | 
| 05-02 00:39:42 epoch: 442| time: 2.5s| train loss: +1.738e+01 | test loss: +1.779e+01 | 
| 05-02 00:39:42 epoch: 442| train loss i: [0.37	1.17	5.45	4.75	3.88	1.75] test loss i: [0.4 	0.54	6.06	5.35	3.7 	1.74] | 
| 05-02 00:39:44 epoch: 443| time: 2.5s| train loss: +1.777e+01 | test loss: +2.353e+01 | 
| 05-02 00:39:44 epoch: 443| train loss i: [0.23	0.96	5.77	5.14	4.09	1.59] test loss i: [0.3 	1.9 	8.59	5.95	4.59	2.19] | 
| 05-02 00:39:47 epoch: 444| time: 2.5s| train loss: +1.793e+01 | test loss: +2.501e+01 | 
| 05-02 00:39:47 epoch: 444| train loss i: [0.33	1.43	5.82	4.74	4.03	1.58] test loss i: [0.38	1.67	8.66	6.98	5.25	2.07] | 
| 05-02 00:39:49 epoch: 445| time: 2.5s| train loss: +1.759e+01 | test loss: +1.609e+01 | 
| 05-02 00:39:49 epoch: 445| train loss i: [0.34	1.58	5.2 	5.11	3.67	1.7 ] test loss i: [0.26	1.85	4.53	4.13	3.76	1.57] | 
| 05-02 00:39:52 epoch: 446| time: 2.4s| train loss: +1.708e+01 | test loss: +1.854e+01 | 
| 05-02 00:39:52 epoch: 446| train loss i: [0.36	0.95	5.12	4.8 	4.18	1.67] test loss i: [0.33	3.21	4.74	5.98	2.81	1.46] | 
| 05-02 00:39:54 epoch: 447| time: 2.5s| train loss: +1.761e+01 | test loss: +1.617e+01 | 
| 05-02 00:39:54 epoch: 447| train loss i: [0.35	1.08	5.65	4.87	4.02	1.63] test loss i: [0.18	0.46	5.33	4.39	4.03	1.78] | 
| 05-02 00:39:56 epoch: 448| time: 2.5s| train loss: +1.797e+01 | test loss: +1.989e+01 | 
| 05-02 00:39:56 epoch: 448| train loss i: [0.4 	1.88	5.65	4.75	3.67	1.61] test loss i: [1.62	1.46	5.99	5.5 	3.66	1.65] | 
| 05-02 00:39:59 epoch: 449| time: 2.4s| train loss: +1.721e+01 | test loss: +1.745e+01 | 
| 05-02 00:39:59 epoch: 449| train loss i: [0.41	1.06	5.42	5.04	3.68	1.59] test loss i: [0.3 	0.67	4.47	5.52	4.6 	1.89] | 
| 05-02 00:40:01 epoch: 450| time: 2.5s| train loss: +1.737e+01 | test loss: +1.910e+01 | 
| 05-02 00:40:01 epoch: 450| train loss i: [0.31	1.3 	5.28	4.94	3.95	1.58] test loss i: [1.52	0.87	6.67	3.98	4.37	1.69] | 
| 05-02 00:40:04 epoch: 451| time: 2.5s| train loss: +1.770e+01 | test loss: +1.890e+01 | 
| 05-02 00:40:04 epoch: 451| train loss i: [0.35	1.59	5.35	4.82	4.04	1.55] test loss i: [0.56	0.79	6.4 	5.01	4.43	1.72] | 
| 05-02 00:40:06 epoch: 452| time: 2.5s| train loss: +1.766e+01 | test loss: +2.009e+01 | 
| 05-02 00:40:06 epoch: 452| train loss i: [0.32	1.03	5.61	4.84	4.28	1.58] test loss i: [0.18	1.76	6.33	5.61	4.12	2.08] | 
| 05-02 00:40:09 epoch: 453| time: 2.5s| train loss: +1.762e+01 | test loss: +1.735e+01 | 
| 05-02 00:40:09 epoch: 453| train loss i: [0.46	1.5 	5.03	4.96	4.02	1.65] test loss i: [0.8 	0.48	5.86	5.05	3.56	1.61] | 
| 05-02 00:40:11 epoch: 454| time: 2.5s| train loss: +1.767e+01 | test loss: +2.123e+01 | 
| 05-02 00:40:11 epoch: 454| train loss i: [0.43	1.78	5.24	4.87	3.81	1.55] test loss i: [0.47	3.09	6.  	5.14	4.61	1.92] | 
| 05-02 00:40:14 epoch: 455| time: 2.5s| train loss: +1.744e+01 | test loss: +2.528e+01 | 
| 05-02 00:40:14 epoch: 455| train loss i: [0.35	1.18	5.58	4.79	3.97	1.57] test loss i: [0.6 	2.32	8.17	7.41	4.69	2.1 ] | 
| 05-02 00:40:16 epoch: 456| time: 2.5s| train loss: +1.878e+01 | test loss: +2.172e+01 | 
| 05-02 00:40:16 epoch: 456| train loss i: [0.45	2.06	5.87	4.71	4.09	1.61] test loss i: [0.9 	0.6 	7.63	6.22	4.44	1.94] | 
| 05-02 00:40:19 epoch: 457| time: 2.5s| train loss: +1.825e+01 | test loss: +1.814e+01 | 
| 05-02 00:40:19 epoch: 457| train loss i: [0.35	1.4 	5.73	4.99	4.14	1.63] test loss i: [0.83	2.42	4.88	4.96	3.35	1.71] | 
| 05-02 00:40:21 epoch: 458| time: 2.5s| train loss: +1.867e+01 | test loss: +1.855e+01 | 
| 05-02 00:40:21 epoch: 458| train loss i: [0.44	1.73	5.81	5.25	3.72	1.72] test loss i: [0.54	1.81	5.87	5.36	3.43	1.54] | 
| 05-02 00:40:24 epoch: 459| time: 2.5s| train loss: +1.829e+01 | test loss: +2.189e+01 | 
| 05-02 00:40:24 epoch: 459| train loss i: [0.3 	1.36	6.11	4.98	3.82	1.71] test loss i: [0.99	1.05	7.39	5.51	4.72	2.22] | 
| 05-02 00:40:26 epoch: 460| time: 2.5s| train loss: +1.773e+01 | test loss: +1.553e+01 | 
| 05-02 00:40:26 epoch: 460| train loss i: [0.33	1.49	5.38	5.02	3.69	1.81] test loss i: [0.38	1.  	4.85	4.57	3.09	1.64] | 
| 05-02 00:40:29 epoch: 461| time: 2.5s| train loss: +1.816e+01 | test loss: +2.402e+01 | 
| 05-02 00:40:29 epoch: 461| train loss i: [0.27	1.87	5.36	5.18	3.8 	1.68] test loss i: [2.42	1.92	6.31	6.65	4.88	1.85] | 
| 05-02 00:40:31 epoch: 462| time: 2.4s| train loss: +1.843e+01 | test loss: +1.818e+01 | 
| 05-02 00:40:31 epoch: 462| train loss i: [0.46	2.14	5.45	4.85	3.97	1.55] test loss i: [0.22	3.11	4.84	4.22	3.99	1.8 ] | 
| 05-02 00:40:34 epoch: 463| time: 2.4s| train loss: +1.831e+01 | test loss: +3.223e+01 | 
| 05-02 00:40:34 epoch: 463| train loss i: [0.3 	1.09	5.78	5.6 	3.95	1.58] test loss i: [ 0.95	 4.96	10.01	 6.96	 6.86	 2.49] | 
| 05-02 00:40:36 epoch: 464| time: 2.5s| train loss: +1.684e+01 | test loss: +2.968e+01 | 
| 05-02 00:40:36 epoch: 464| train loss i: [0.29	1.43	5.27	4.57	3.72	1.55] test loss i: [0.4 	3.52	9.37	7.92	6.17	2.3 ] | 
| 05-02 00:40:39 epoch: 465| time: 2.5s| train loss: +1.821e+01 | test loss: +1.613e+01 | 
| 05-02 00:40:39 epoch: 465| train loss i: [0.26	2.24	5.51	4.7 	3.9 	1.59] test loss i: [0.26	0.45	4.94	4.73	4.05	1.7 ] | 
| 05-02 00:40:41 epoch: 466| time: 2.4s| train loss: +1.782e+01 | test loss: +2.212e+01 | 
| 05-02 00:40:41 epoch: 466| train loss i: [0.24	1.22	6.15	4.53	4.15	1.52] test loss i: [0.44	1.1 	7.69	6.49	4.66	1.74] | 
| 05-02 00:40:43 epoch: 467| time: 2.5s| train loss: +1.804e+01 | test loss: +2.313e+01 | 
| 05-02 00:40:43 epoch: 467| train loss i: [0.39	1.67	5.69	4.84	3.87	1.58] test loss i: [0.19	1.58	8.09	5.82	5.37	2.09] | 
| 05-02 00:40:46 epoch: 468| time: 2.5s| train loss: +1.857e+01 | test loss: +2.118e+01 | 
| 05-02 00:40:46 epoch: 468| train loss i: [0.47	2.39	5.35	4.87	3.8 	1.69] test loss i: [1.04	1.49	5.68	6.91	4.09	1.97] | 
| 05-02 00:40:48 epoch: 469| time: 2.5s| train loss: +1.775e+01 | test loss: +2.202e+01 | 
| 05-02 00:40:48 epoch: 469| train loss i: [0.46	1.62	5.55	5.09	3.45	1.57] test loss i: [0.63	1.54	7.28	5.59	5.12	1.86] | 
| 05-02 00:40:51 epoch: 470| time: 2.5s| train loss: +1.789e+01 | test loss: +2.084e+01 | 
| 05-02 00:40:51 epoch: 470| train loss i: [0.36	1.6 	5.68	4.94	3.78	1.53] test loss i: [0.45	0.86	7.3 	5.78	4.37	2.07] | 
| 05-02 00:40:53 epoch: 471| time: 2.4s| train loss: +1.750e+01 | test loss: +1.871e+01 | 
| 05-02 00:40:53 epoch: 471| train loss i: [0.32	1.41	5.45	4.88	3.78	1.66] test loss i: [0.42	0.21	5.52	5.66	4.85	2.06] | 
| 05-02 00:40:56 epoch: 472| time: 2.5s| train loss: +1.758e+01 | test loss: +2.270e+01 | 
| 05-02 00:40:56 epoch: 472| train loss i: [0.42	0.98	5.82	4.88	3.82	1.67] test loss i: [1.51	2.25	7.3 	5.24	4.56	1.84] | 
| 05-02 00:40:58 epoch: 473| time: 2.5s| train loss: +1.736e+01 | test loss: +1.515e+01 | 
| 05-02 00:40:58 epoch: 473| train loss i: [0.45	1.09	5.25	5.02	3.91	1.63] test loss i: [0.26	0.62	4.91	4.29	3.53	1.54] | 
| 05-02 00:41:01 epoch: 474| time: 2.5s| train loss: +1.672e+01 | test loss: +1.884e+01 | 
| 05-02 00:41:01 epoch: 474| train loss i: [0.23	0.98	5.57	4.45	3.84	1.65] test loss i: [0.57	0.83	6.66	4.99	4.02	1.78] | 
| 05-02 00:41:03 epoch: 475| time: 2.5s| train loss: +1.777e+01 | test loss: +1.831e+01 | 
| 05-02 00:41:03 epoch: 475| train loss i: [0.41	1.72	5.75	4.49	3.72	1.68] test loss i: [0.63	2.6 	5.56	4.69	3.21	1.61] | 
| 05-02 00:41:06 epoch: 476| time: 2.5s| train loss: +1.762e+01 | test loss: +3.271e+01 | 
| 05-02 00:41:06 epoch: 476| train loss i: [0.63	1.34	5.3 	4.97	3.74	1.64] test loss i: [5.06	3.97	8.89	6.61	5.94	2.23] | 
| 05-02 00:41:08 epoch: 477| time: 2.5s| train loss: +1.807e+01 | test loss: +2.729e+01 | 
| 05-02 00:41:08 epoch: 477| train loss i: [0.71	1.56	5.21	5.24	3.79	1.56] test loss i: [4.13	3.12	6.31	6.88	4.78	2.08] | 
| 05-02 00:41:11 epoch: 478| time: 2.5s| train loss: +1.980e+01 | test loss: +2.145e+01 | 
| 05-02 00:41:11 epoch: 478| train loss i: [0.58	2.  	5.89	5.76	3.97	1.6 ] test loss i: [1.76	0.56	7.59	5.44	4.24	1.86] | 
| 05-02 00:41:13 epoch: 479| time: 2.5s| train loss: +1.863e+01 | test loss: +1.946e+01 | 
| 05-02 00:41:13 epoch: 479| train loss i: [0.64	2.01	5.6 	5.07	3.73	1.58] test loss i: [0.84	1.63	5.01	5.67	4.52	1.78] | 
| 05-02 00:41:16 epoch: 480| time: 2.4s| train loss: +1.876e+01 | test loss: +1.642e+01 | 
| 05-02 00:41:16 epoch: 480| train loss i: [0.45	1.55	5.87	5.08	4.14	1.68] test loss i: [0.58	1.5 	4.78	4.32	3.73	1.51] | 
| 05-02 00:41:18 epoch: 481| time: 2.5s| train loss: +1.700e+01 | test loss: +1.857e+01 | 
| 05-02 00:41:18 epoch: 481| train loss i: [0.4 	1.34	5.45	4.45	3.74	1.62] test loss i: [0.47	1.04	5.07	6.16	3.96	1.87] | 
| 05-02 00:41:21 epoch: 482| time: 2.4s| train loss: +1.852e+01 | test loss: +1.617e+01 | 
| 05-02 00:41:21 epoch: 482| train loss i: [0.42	2.21	5.3 	5.11	3.86	1.62] test loss i: [0.39	1.77	4.03	4.94	3.41	1.64] | 
| 05-02 00:41:23 epoch: 483| time: 2.4s| train loss: +1.751e+01 | test loss: +1.710e+01 | 
| 05-02 00:41:23 epoch: 483| train loss i: [0.32	1.28	5.31	5.  	4.  	1.61] test loss i: [0.4 	1.76	4.49	4.99	3.77	1.68] | 
| 05-02 00:41:25 epoch: 484| time: 2.5s| train loss: +1.805e+01 | test loss: +1.893e+01 | 
| 05-02 00:41:25 epoch: 484| train loss i: [0.44	1.32	6.03	4.9 	3.75	1.61] test loss i: [0.6 	1.17	6.09	5.25	3.4 	2.42] | 
| 05-02 00:41:28 epoch: 485| time: 2.5s| train loss: +1.745e+01 | test loss: +2.388e+01 | 
| 05-02 00:41:28 epoch: 485| train loss i: [0.49	1.7 	5.17	4.6 	3.84	1.65] test loss i: [0.5 	2.93	6.54	6.86	5.09	1.95] | 
| 05-02 00:41:30 epoch: 486| time: 2.5s| train loss: +1.760e+01 | test loss: +1.851e+01 | 
| 05-02 00:41:30 epoch: 486| train loss i: [0.31	1.63	5.44	4.97	3.71	1.55] test loss i: [0.3 	1.58	6.07	4.94	3.77	1.85] | 
| 05-02 00:41:33 epoch: 487| time: 2.5s| train loss: +1.811e+01 | test loss: +1.423e+01 | 
| 05-02 00:41:33 epoch: 487| train loss i: [0.38	1.27	6.14	4.98	3.76	1.58] test loss i: [0.34	0.58	4.29	4.25	3.3 	1.47] | 
| 05-02 00:41:35 epoch: 488| time: 2.5s| train loss: +1.741e+01 | test loss: +1.808e+01 | 
| 05-02 00:41:35 epoch: 488| train loss i: [0.45	0.96	5.6 	4.96	3.85	1.58] test loss i: [0.32	2.3 	5.47	4.46	3.71	1.83] | 
| 05-02 00:41:38 epoch: 489| time: 2.4s| train loss: +1.829e+01 | test loss: +2.362e+01 | 
| 05-02 00:41:38 epoch: 489| train loss i: [0.33	1.64	5.77	4.87	4.11	1.58] test loss i: [0.23	1.45	7.82	6.92	5.29	1.91] | 
| 05-02 00:41:40 epoch: 490| time: 2.5s| train loss: +1.812e+01 | test loss: +2.280e+01 | 
| 05-02 00:41:40 epoch: 490| train loss i: [0.3 	1.72	5.72	4.93	3.9 	1.54] test loss i: [2.24	2.21	5.79	6.3 	4.47	1.79] | 
| 05-02 00:41:43 epoch: 491| time: 2.5s| train loss: +1.812e+01 | test loss: +2.091e+01 | 
| 05-02 00:41:43 epoch: 491| train loss i: [0.42	1.47	5.76	4.91	3.94	1.62] test loss i: [0.35	3.02	6.15	5.45	3.85	2.1 ] | 
| 05-02 00:41:45 epoch: 492| time: 2.5s| train loss: +1.831e+01 | test loss: +2.055e+01 | 
| 05-02 00:41:45 epoch: 492| train loss i: [0.38	1.88	5.26	5.34	3.83	1.62] test loss i: [1.43	2.08	5.98	4.42	4.55	2.09] | 
| 05-02 00:41:48 epoch: 493| time: 2.5s| train loss: +1.791e+01 | test loss: +1.896e+01 | 
| 05-02 00:41:48 epoch: 493| train loss i: [0.45	1.5 	5.45	4.91	3.91	1.69] test loss i: [1.65	1.33	6.2 	3.93	4.2 	1.66] | 
| 05-02 00:41:50 epoch: 494| time: 2.4s| train loss: +1.766e+01 | test loss: +1.636e+01 | 
| 05-02 00:41:50 epoch: 494| train loss i: [0.42	1.41	5.47	4.61	4.18	1.57] test loss i: [0.31	1.16	5.11	4.31	3.71	1.76] | 
| 05-02 00:41:53 epoch: 495| time: 2.5s| train loss: +1.711e+01 | test loss: +1.789e+01 | 
| 05-02 00:41:53 epoch: 495| train loss i: [0.42	1.62	5.03	4.76	3.66	1.62] test loss i: [0.86	1.63	4.82	4.38	4.3 	1.91] | 
| 05-02 00:41:55 epoch: 496| time: 2.5s| train loss: +1.688e+01 | test loss: +1.918e+01 | 
| 05-02 00:41:55 epoch: 496| train loss i: [0.37	0.99	5.32	4.69	3.96	1.56] test loss i: [0.89	2.61	4.76	5.39	3.71	1.82] | 
| 05-02 00:41:58 epoch: 497| time: 2.6s| train loss: +1.831e+01 | test loss: +1.952e+01 | 
| 05-02 00:41:58 epoch: 497| train loss i: [0.49	1.61	5.72	4.87	4.04	1.57] test loss i: [0.38	2.33	6.03	4.65	4.34	1.79] | 
| 05-02 00:42:00 epoch: 498| time: 2.5s| train loss: +1.840e+01 | test loss: +1.735e+01 | 
| 05-02 00:42:00 epoch: 498| train loss i: [0.59	2.  	5.53	4.52	4.01	1.74] test loss i: [0.21	2.68	5.58	4.05	3.33	1.5 ] | 
| 05-02 00:42:03 epoch: 499| time: 2.5s| train loss: +1.886e+01 | test loss: +1.731e+01 | 
| 05-02 00:42:03 epoch: 499| train loss i: [0.42	1.82	5.99	5.14	3.86	1.64] test loss i: [0.32	2.25	4.6 	4.09	4.41	1.64] | 
| 05-02 00:42:05 epoch: 500| time: 2.4s| train loss: +1.809e+01 | test loss: +1.774e+01 | 
| 05-02 00:42:05 epoch: 500| train loss i: [0.3 	1.69	5.36	5.05	4.15	1.54] test loss i: [0.36	1.36	5.48	5.13	3.52	1.89] | 
| 05-02 00:42:08 epoch: 501| time: 2.4s| train loss: +1.765e+01 | test loss: +1.686e+01 | 
| 05-02 00:42:08 epoch: 501| train loss i: [0.35	2.06	4.77	4.67	4.25	1.55] test loss i: [0.23	0.68	5.13	3.86	5.33	1.62] | 
| 05-02 00:42:10 epoch: 502| time: 2.5s| train loss: +1.810e+01 | test loss: +1.814e+01 | 
| 05-02 00:42:10 epoch: 502| train loss i: [0.3 	2.18	5.19	5.  	3.85	1.57] test loss i: [0.36	2.61	4.9 	4.69	4.  	1.58] | 
| 05-02 00:42:13 epoch: 503| time: 2.4s| train loss: +1.672e+01 | test loss: +1.913e+01 | 
| 05-02 00:42:13 epoch: 503| train loss i: [0.29	0.94	5.18	4.87	3.86	1.59] test loss i: [0.35	2.24	5.63	5.47	3.84	1.6 ] | 
| 05-02 00:42:15 epoch: 504| time: 2.5s| train loss: +1.743e+01 | test loss: +1.888e+01 | 
| 05-02 00:42:15 epoch: 504| train loss i: [0.23	1.65	5.34	4.77	3.79	1.65] test loss i: [0.28	1.97	6.06	4.78	4.15	1.65] | 
| 05-02 00:42:18 epoch: 505| time: 2.5s| train loss: +1.724e+01 | test loss: +2.307e+01 | 
| 05-02 00:42:18 epoch: 505| train loss i: [0.25	1.59	5.15	4.92	3.81	1.52] test loss i: [0.42	3.05	8.03	5.31	4.24	2.03] | 
| 05-02 00:42:20 epoch: 506| time: 2.5s| train loss: +1.858e+01 | test loss: +2.448e+01 | 
| 05-02 00:42:20 epoch: 506| train loss i: [0.25	1.55	6.03	5.14	4.  	1.62] test loss i: [0.38	0.67	7.61	7.46	5.69	2.67] | 
| 05-02 00:42:23 epoch: 507| time: 2.5s| train loss: +1.835e+01 | test loss: +1.767e+01 | 
| 05-02 00:42:23 epoch: 507| train loss i: [0.21	1.48	6.14	5.16	3.77	1.59] test loss i: [0.21	1.41	5.11	5.24	3.96	1.74] | 
| 05-02 00:42:25 epoch: 508| time: 2.4s| train loss: +1.724e+01 | test loss: +1.472e+01 | 
| 05-02 00:42:25 epoch: 508| train loss i: [0.25	1.47	4.95	5.26	3.78	1.54] test loss i: [0.34	0.85	4.43	4.12	3.23	1.76] | 
| 05-02 00:42:27 epoch: 509| time: 2.4s| train loss: +1.880e+01 | test loss: +1.627e+01 | 
| 05-02 00:42:27 epoch: 509| train loss i: [0.28	2.21	5.37	5.22	4.1 	1.62] test loss i: [0.27	0.99	5.46	4.41	3.61	1.53] | 
| 05-02 00:42:30 epoch: 510| time: 2.5s| train loss: +1.772e+01 | test loss: +2.314e+01 | 
| 05-02 00:42:30 epoch: 510| train loss i: [0.41	1.16	5.34	4.89	4.25	1.67] test loss i: [1.83	1.93	7.41	5.35	4.42	2.21] | 
| 05-02 00:42:32 epoch: 511| time: 2.5s| train loss: +1.826e+01 | test loss: +1.891e+01 | 
| 05-02 00:42:32 epoch: 511| train loss i: [0.38	2.04	5.76	4.69	3.84	1.55] test loss i: [0.61	1.88	5.13	4.26	5.23	1.79] | 
| 05-02 00:42:35 epoch: 512| time: 2.5s| train loss: +1.789e+01 | test loss: +2.982e+01 | 
| 05-02 00:42:35 epoch: 512| train loss i: [0.27	1.14	6.13	4.78	3.81	1.76] test loss i: [ 0.46	 3.04	10.41	 7.59	 5.96	 2.36] | 
| 05-02 00:42:37 epoch: 513| time: 2.5s| train loss: +1.869e+01 | test loss: +1.838e+01 | 
| 05-02 00:42:37 epoch: 513| train loss i: [0.35	1.48	5.75	5.46	4.09	1.56] test loss i: [0.4 	1.52	6.17	5.18	3.52	1.6 ] | 
| 05-02 00:42:40 epoch: 514| time: 2.5s| train loss: +1.805e+01 | test loss: +2.613e+01 | 
| 05-02 00:42:40 epoch: 514| train loss i: [0.37	1.2 	5.56	5.15	4.1 	1.66] test loss i: [ 0.68	 1.4 	10.  	 6.96	 4.95	 2.13] | 
| 05-02 00:42:42 epoch: 515| time: 2.5s| train loss: +1.741e+01 | test loss: +1.922e+01 | 
| 05-02 00:42:42 epoch: 515| train loss i: [0.43	1.32	5.38	4.76	3.82	1.7 ] test loss i: [0.88	1.37	5.89	4.6 	4.64	1.84] | 
| 05-02 00:42:45 epoch: 516| time: 2.5s| train loss: +1.764e+01 | test loss: +2.338e+01 | 
| 05-02 00:42:45 epoch: 516| train loss i: [0.65	1.52	5.46	4.69	3.7 	1.63] test loss i: [0.86	1.45	7.78	5.95	5.3 	2.03] | 
| 05-02 00:42:47 epoch: 517| time: 2.6s| train loss: +1.840e+01 | test loss: +2.107e+01 | 
| 05-02 00:42:47 epoch: 517| train loss i: [0.86	1.79	5.18	4.8 	4.1 	1.67] test loss i: [2.99	3.19	4.73	4.86	3.59	1.71] | 
| 05-02 00:42:50 epoch: 518| time: 2.5s| train loss: +1.870e+01 | test loss: +1.795e+01 | 
| 05-02 00:42:50 epoch: 518| train loss i: [0.69	2.02	5.48	4.78	4.12	1.6 ] test loss i: [0.82	0.99	5.24	5.16	4.07	1.67] | 
| 05-02 00:42:53 epoch: 519| time: 2.5s| train loss: +1.794e+01 | test loss: +1.917e+01 | 
| 05-02 00:42:53 epoch: 519| train loss i: [0.77	1.23	5.5 	4.94	3.91	1.59] test loss i: [2.1 	2.12	5.12	4.88	3.31	1.64] | 
| 05-02 00:42:55 epoch: 520| time: 2.6s| train loss: +1.872e+01 | test loss: +2.564e+01 | 
| 05-02 00:42:55 epoch: 520| train loss i: [0.65	1.52	5.96	5.32	3.69	1.58] test loss i: [0.77	2.22	7.88	6.62	5.84	2.31] | 
| 05-02 00:42:58 epoch: 521| time: 2.5s| train loss: +1.931e+01 | test loss: +2.969e+01 | 
| 05-02 00:42:58 epoch: 521| train loss i: [0.95	1.96	5.86	5.02	3.89	1.63] test loss i: [2.66	3.82	8.26	7.45	5.46	2.05] | 
| 05-02 00:43:00 epoch: 522| time: 2.5s| train loss: +1.855e+01 | test loss: +2.330e+01 | 
| 05-02 00:43:00 epoch: 522| train loss i: [0.93	1.98	5.42	4.97	3.65	1.6 ] test loss i: [2.54	1.99	6.36	5.79	4.83	1.79] | 
| 05-02 00:43:03 epoch: 523| time: 2.6s| train loss: +1.865e+01 | test loss: +1.669e+01 | 
| 05-02 00:43:03 epoch: 523| train loss i: [0.76	2.18	5.34	4.8 	4.02	1.56] test loss i: [0.46	0.93	5.2 	4.96	3.67	1.48] | 
| 05-02 00:43:05 epoch: 524| time: 2.5s| train loss: +1.782e+01 | test loss: +2.003e+01 | 
| 05-02 00:43:05 epoch: 524| train loss i: [0.55	1.25	5.71	4.86	3.89	1.57] test loss i: [0.34	1.36	6.12	5.94	4.14	2.13] | 
| 05-02 00:43:08 epoch: 525| time: 2.5s| train loss: +1.856e+01 | test loss: +1.993e+01 | 
| 05-02 00:43:08 epoch: 525| train loss i: [0.46	1.94	5.79	4.77	4.05	1.54] test loss i: [0.49	0.53	6.06	6.34	4.5 	2.02] | 
| 05-02 00:43:10 epoch: 526| time: 2.4s| train loss: +1.757e+01 | test loss: +1.730e+01 | 
| 05-02 00:43:10 epoch: 526| train loss i: [0.52	1.05	5.21	5.14	3.99	1.66] test loss i: [0.78	1.98	4.91	4.31	3.51	1.81] | 
| 05-02 00:43:12 epoch: 527| time: 2.4s| train loss: +1.829e+01 | test loss: +1.639e+01 | 
| 05-02 00:43:12 epoch: 527| train loss i: [0.35	2.12	5.29	4.8 	4.15	1.59] test loss i: [1.63	1.07	4.79	4.29	3.12	1.48] | 
| 05-02 00:43:15 epoch: 528| time: 2.5s| train loss: +1.733e+01 | test loss: +2.011e+01 | 
| 05-02 00:43:15 epoch: 528| train loss i: [0.44	1.48	5.66	4.43	3.74	1.58] test loss i: [0.29	2.64	5.64	5.08	4.54	1.93] | 
| 05-02 00:43:17 epoch: 529| time: 2.5s| train loss: +1.821e+01 | test loss: +2.452e+01 | 
| 05-02 00:43:17 epoch: 529| train loss i: [0.61	1.53	5.32	5.07	4.03	1.64] test loss i: [0.51	1.33	6.89	7.15	6.2 	2.44] | 
| 05-02 00:43:20 epoch: 530| time: 2.5s| train loss: +1.860e+01 | test loss: +1.646e+01 | 
| 05-02 00:43:20 epoch: 530| train loss i: [0.46	2.16	5.62	4.94	3.82	1.61] test loss i: [0.65	1.37	5.27	3.96	3.65	1.56] | 
| 05-02 00:43:22 epoch: 531| time: 2.5s| train loss: +1.699e+01 | test loss: +2.378e+01 | 
| 05-02 00:43:22 epoch: 531| train loss i: [0.43	1.29	5.3 	4.59	3.84	1.55] test loss i: [0.86	1.98	6.28	6.74	5.75	2.18] | 
| 05-02 00:43:25 epoch: 532| time: 2.4s| train loss: +1.799e+01 | test loss: +1.501e+01 | 
| 05-02 00:43:25 epoch: 532| train loss i: [0.31	1.34	6.03	4.9 	3.83	1.58] test loss i: [0.28	0.25	5.9 	4.34	2.81	1.43] | 
| 05-02 00:43:27 epoch: 533| time: 2.4s| train loss: +1.732e+01 | test loss: +1.556e+01 | 
| 05-02 00:43:27 epoch: 533| train loss i: [0.35	1.7 	5.07	4.98	3.66	1.57] test loss i: [0.16	0.6 	5.22	4.31	3.61	1.66] | 
| 05-02 00:43:30 epoch: 534| time: 2.4s| train loss: +1.794e+01 | test loss: +1.562e+01 | 
| 05-02 00:43:30 epoch: 534| train loss i: [0.28	1.45	5.85	4.61	4.15	1.6 ] test loss i: [0.17	1.12	5.2 	4.76	2.89	1.48] | 
| 05-02 00:43:32 epoch: 535| time: 2.4s| train loss: +1.818e+01 | test loss: +1.558e+01 | 
| 05-02 00:43:32 epoch: 535| train loss i: [0.26	1.79	5.47	5.06	3.99	1.61] test loss i: [0.29	1.24	5.09	4.02	3.58	1.35] | 
| 05-02 00:43:35 epoch: 536| time: 2.5s| train loss: +1.734e+01 | test loss: +2.097e+01 | 
| 05-02 00:43:35 epoch: 536| train loss i: [0.27	1.29	5.26	5.11	3.86	1.54] test loss i: [0.24	1.71	6.45	6.1 	4.49	1.99] | 
| 05-02 00:43:37 epoch: 537| time: 2.4s| train loss: +1.821e+01 | test loss: +1.840e+01 | 
| 05-02 00:43:37 epoch: 537| train loss i: [0.26	1.65	5.89	5.03	3.81	1.58] test loss i: [0.57	0.51	6.99	4.76	3.62	1.96] | 
| 05-02 00:43:39 epoch: 538| time: 2.5s| train loss: +1.743e+01 | test loss: +2.662e+01 | 
| 05-02 00:43:39 epoch: 538| train loss i: [0.3 	1.7 	5.25	4.81	3.86	1.52] test loss i: [0.44	2.49	8.46	7.27	5.82	2.13] | 
| 05-02 00:43:42 epoch: 539| time: 2.4s| train loss: +1.842e+01 | test loss: +2.179e+01 | 
| 05-02 00:43:42 epoch: 539| train loss i: [0.28	2.12	5.44	5.27	3.72	1.59] test loss i: [0.39	1.42	6.94	5.27	5.63	2.14] | 
| 05-02 00:43:44 epoch: 540| time: 2.4s| train loss: +1.793e+01 | test loss: +1.724e+01 | 
| 05-02 00:43:44 epoch: 540| train loss i: [0.19	1.83	5.35	5.23	3.84	1.49] test loss i: [0.4 	1.36	5.41	4.86	3.62	1.59] | 
| 05-02 00:43:47 epoch: 541| time: 2.5s| train loss: +1.822e+01 | test loss: +2.688e+01 | 
| 05-02 00:43:47 epoch: 541| train loss i: [0.18	1.64	5.93	4.91	3.96	1.61] test loss i: [1.01	3.79	7.31	7.12	5.41	2.24] | 
| 05-02 00:43:49 epoch: 542| time: 2.4s| train loss: +1.710e+01 | test loss: +1.886e+01 | 
| 05-02 00:43:49 epoch: 542| train loss i: [0.24	1.41	5.41	4.7 	3.79	1.55] test loss i: [0.19	1.23	6.  	5.63	4.  	1.81] | 
| 05-02 00:43:52 epoch: 543| time: 2.4s| train loss: +1.682e+01 | test loss: +1.617e+01 | 
| 05-02 00:43:52 epoch: 543| train loss i: [0.31	0.82	5.71	4.67	3.75	1.55] test loss i: [1.16	0.87	4.39	4.4 	3.89	1.45] | 
| 05-02 00:43:54 epoch: 544| time: 2.4s| train loss: +1.736e+01 | test loss: +2.632e+01 | 
| 05-02 00:43:54 epoch: 544| train loss i: [0.27	1.34	6.04	4.52	3.62	1.58] test loss i: [0.21	2.51	8.57	6.4 	5.97	2.67] | 
| 05-02 00:43:56 epoch: 545| time: 2.4s| train loss: +1.849e+01 | test loss: +2.023e+01 | 
| 05-02 00:43:56 epoch: 545| train loss i: [0.31	1.4 	5.83	5.3 	4.07	1.59] test loss i: [0.21	3.91	5.25	4.96	4.11	1.79] | 
| 05-02 00:43:59 epoch: 546| time: 2.5s| train loss: +1.842e+01 | test loss: +1.706e+01 | 
| 05-02 00:43:59 epoch: 546| train loss i: [0.35	1.83	5.72	4.9 	4.01	1.61] test loss i: [0.26	0.54	5.62	4.77	3.81	2.06] | 
| 05-02 00:44:01 epoch: 547| time: 2.5s| train loss: +1.727e+01 | test loss: +1.298e+01 | 
| 05-02 00:44:01 epoch: 547| train loss i: [0.28	1.2 	5.25	5.04	3.85	1.65] test loss i: [0.8 	0.74	3.4 	3.38	3.07	1.59] | 
| 05-02 00:44:04 epoch: 548| time: 2.4s| train loss: +1.765e+01 | test loss: +1.789e+01 | 
| 05-02 00:44:04 epoch: 548| train loss i: [0.29	1.33	5.29	5.  	4.05	1.69] test loss i: [0.7 	0.63	6.26	5.08	3.6 	1.62] | 
| 05-02 00:44:06 epoch: 549| time: 2.4s| train loss: +1.709e+01 | test loss: +1.716e+01 | 
| 05-02 00:44:06 epoch: 549| train loss i: [0.27	1.32	5.39	4.92	3.58	1.61] test loss i: [0.19	0.76	5.31	5.64	3.57	1.7 ] | 
| 05-02 00:44:09 epoch: 550| time: 2.4s| train loss: +1.726e+01 | test loss: +2.079e+01 | 
| 05-02 00:44:09 epoch: 550| train loss i: [0.2 	0.91	5.6 	5.09	3.88	1.58] test loss i: [0.24	2.52	6.81	4.88	4.42	1.93] | 
| 05-02 00:44:11 epoch: 551| time: 2.5s| train loss: +1.715e+01 | test loss: +2.127e+01 | 
| 05-02 00:44:11 epoch: 551| train loss i: [0.32	1.48	5.45	4.46	3.89	1.56] test loss i: [0.34	2.27	5.54	6.2 	4.84	2.08] | 
| 05-02 00:44:14 epoch: 552| time: 2.4s| train loss: +1.780e+01 | test loss: +1.625e+01 | 
| 05-02 00:44:14 epoch: 552| train loss i: [0.26	1.33	5.89	4.87	3.92	1.53] test loss i: [0.18	0.28	5.39	4.8 	4.02	1.58] | 
| 05-02 00:44:16 epoch: 553| time: 2.5s| train loss: +1.773e+01 | test loss: +1.951e+01 | 
| 05-02 00:44:16 epoch: 553| train loss i: [0.43	1.61	5.82	4.49	3.81	1.58] test loss i: [1.32	1.6 	5.77	4.78	4.17	1.85] | 
| 05-02 00:44:18 epoch: 554| time: 2.5s| train loss: +1.820e+01 | test loss: +2.385e+01 | 
| 05-02 00:44:18 epoch: 554| train loss i: [0.51	1.51	5.77	4.82	3.96	1.62] test loss i: [1.12	0.94	8.04	6.24	5.4 	2.1 ] | 
| 05-02 00:44:21 epoch: 555| time: 2.4s| train loss: +1.806e+01 | test loss: +2.083e+01 | 
| 05-02 00:44:21 epoch: 555| train loss i: [0.39	1.05	6.15	4.93	3.91	1.62] test loss i: [1.91	0.76	6.56	5.47	4.38	1.75] | 
| 05-02 00:44:23 epoch: 556| time: 2.4s| train loss: +1.891e+01 | test loss: +1.463e+01 | 
| 05-02 00:44:23 epoch: 556| train loss i: [0.52	1.95	6.09	4.88	3.81	1.66] test loss i: [0.15	1.61	4.51	3.55	3.29	1.53] | 
| 05-02 00:44:26 epoch: 557| time: 2.4s| train loss: +1.862e+01 | test loss: +1.920e+01 | 
| 05-02 00:44:26 epoch: 557| train loss i: [0.35	2.27	5.6 	4.74	3.9 	1.75] test loss i: [0.64	2.02	5.47	5.44	3.56	2.07] | 
| 05-02 00:44:28 epoch: 558| time: 2.4s| train loss: +1.794e+01 | test loss: +2.078e+01 | 
| 05-02 00:44:28 epoch: 558| train loss i: [0.4 	1.71	5.31	5.02	3.8 	1.69] test loss i: [0.97	2.08	6.23	5.54	4.41	1.54] | 
| 05-02 00:44:31 epoch: 559| time: 2.4s| train loss: +1.713e+01 | test loss: +2.151e+01 | 
| 05-02 00:44:31 epoch: 559| train loss i: [0.49	1.58	5.1 	4.64	3.74	1.6 ] test loss i: [1.18	1.37	6.84	4.62	5.52	1.98] | 
| 05-02 00:44:33 epoch: 560| time: 2.4s| train loss: +1.839e+01 | test loss: +1.797e+01 | 
| 05-02 00:44:33 epoch: 560| train loss i: [0.43	1.93	5.42	5.01	3.92	1.67] test loss i: [0.21	1.49	5.66	5.04	3.65	1.92] | 
| 05-02 00:44:36 epoch: 561| time: 2.5s| train loss: +1.734e+01 | test loss: +1.847e+01 | 
| 05-02 00:44:36 epoch: 561| train loss i: [0.26	1.24	5.55	4.82	3.78	1.69] test loss i: [1.89	1.49	5.49	4.11	3.59	1.91] | 
| 05-02 00:44:38 epoch: 562| time: 2.5s| train loss: +1.923e+01 | test loss: +1.807e+01 | 
| 05-02 00:44:38 epoch: 562| train loss i: [0.37	1.98	6.23	5.02	3.92	1.72] test loss i: [0.25	3.33	4.09	4.83	3.88	1.69] | 
| 05-02 00:44:40 epoch: 563| time: 2.4s| train loss: +1.805e+01 | test loss: +2.802e+01 | 
| 05-02 00:44:40 epoch: 563| train loss i: [0.32	1.9 	5.51	4.57	4.07	1.67] test loss i: [0.92	4.17	8.3 	7.3 	4.7 	2.63] | 
| 05-02 00:44:43 epoch: 564| time: 2.4s| train loss: +1.829e+01 | test loss: +1.926e+01 | 
| 05-02 00:44:43 epoch: 564| train loss i: [0.37	1.38	5.91	4.97	4.08	1.58] test loss i: [0.68	0.4 	6.17	5.62	4.45	1.94] | 
| 05-02 00:44:45 epoch: 565| time: 2.4s| train loss: +1.747e+01 | test loss: +1.891e+01 | 
| 05-02 00:44:45 epoch: 565| train loss i: [0.22	1.54	5.54	4.76	3.87	1.55] test loss i: [0.66	2.5 	5.49	4.71	3.92	1.61] | 
| 05-02 00:44:48 epoch: 566| time: 2.5s| train loss: +1.708e+01 | test loss: +1.933e+01 | 
| 05-02 00:44:48 epoch: 566| train loss i: [0.21	1.11	6.17	4.38	3.6 	1.62] test loss i: [0.78	3.3 	5.11	4.21	4.24	1.7 ] | 
| 05-02 00:44:50 epoch: 567| time: 2.5s| train loss: +1.811e+01 | test loss: +1.792e+01 | 
| 05-02 00:44:50 epoch: 567| train loss i: [0.36	1.27	5.76	4.9 	4.16	1.66] test loss i: [0.29	1.35	4.82	5.66	4.07	1.74] | 
| 05-02 00:44:53 epoch: 568| time: 2.5s| train loss: +1.841e+01 | test loss: +2.033e+01 | 
| 05-02 00:44:53 epoch: 568| train loss i: [0.29	1.24	6.16	5.09	3.96	1.67] test loss i: [0.31	2.65	6.07	5.17	4.58	1.55] | 
| 05-02 00:44:55 epoch: 569| time: 2.4s| train loss: +1.699e+01 | test loss: +2.342e+01 | 
| 05-02 00:44:55 epoch: 569| train loss i: [0.26	1.18	5.49	4.9 	3.53	1.63] test loss i: [0.6 	4.44	6.95	5.32	4.07	2.04] | 
| 05-02 00:44:57 epoch: 570| time: 2.4s| train loss: +1.784e+01 | test loss: +2.148e+01 | 
| 05-02 00:44:57 epoch: 570| train loss i: [0.25	2.05	5.23	4.92	3.68	1.71] test loss i: [0.4 	1.5 	6.84	6.2 	4.42	2.13] | 
| 05-02 00:45:00 epoch: 571| time: 2.5s| train loss: +1.825e+01 | test loss: +1.898e+01 | 
| 05-02 00:45:00 epoch: 571| train loss i: [0.67	2.  	5.57	4.54	3.8 	1.66] test loss i: [0.85	0.78	6.8 	4.96	4.  	1.6 ] | 
| 05-02 00:45:02 epoch: 572| time: 2.5s| train loss: +1.861e+01 | test loss: +1.401e+01 | 
| 05-02 00:45:02 epoch: 572| train loss i: [0.23	2.12	5.94	4.91	3.79	1.61] test loss i: [0.17	0.94	4.71	3.7 	2.94	1.55] | 
| 05-02 00:45:05 epoch: 573| time: 2.4s| train loss: +1.794e+01 | test loss: +1.787e+01 | 
| 05-02 00:45:05 epoch: 573| train loss i: [0.27	1.28	6.03	5.18	3.53	1.66] test loss i: [0.25	1.4 	5.53	4.67	4.35	1.66] | 
| 05-02 00:45:07 epoch: 574| time: 2.5s| train loss: +1.744e+01 | test loss: +1.776e+01 | 
| 05-02 00:45:07 epoch: 574| train loss i: [0.24	1.5 	5.22	4.94	4.  	1.54] test loss i: [1.64	0.57	4.9 	4.87	3.77	2.  ] | 
| 05-02 00:45:10 epoch: 575| time: 2.4s| train loss: +1.684e+01 | test loss: +2.702e+01 | 
| 05-02 00:45:10 epoch: 575| train loss i: [0.34	0.93	5.45	4.99	3.57	1.56] test loss i: [0.56	3.02	7.75	7.36	5.97	2.35] | 
| 05-02 00:45:12 epoch: 576| time: 2.5s| train loss: +1.823e+01 | test loss: +1.768e+01 | 
| 05-02 00:45:12 epoch: 576| train loss i: [0.31	1.8 	5.67	4.87	3.93	1.65] test loss i: [0.25	2.28	4.41	5.  	3.93	1.81] | 
| 05-02 00:45:15 epoch: 577| time: 2.5s| train loss: +1.672e+01 | test loss: +2.175e+01 | 
| 05-02 00:45:15 epoch: 577| train loss i: [0.22	0.99	5.41	4.76	3.78	1.55] test loss i: [0.22	1.78	7.03	6.28	4.62	1.81] | 
| 05-02 00:45:17 epoch: 578| time: 2.5s| train loss: +1.886e+01 | test loss: +1.521e+01 | 
| 05-02 00:45:17 epoch: 578| train loss i: [0.2 	2.55	5.49	4.95	4.04	1.63] test loss i: [0.52	0.38	4.48	4.23	3.9 	1.69] | 
| 05-02 00:45:20 epoch: 579| time: 2.5s| train loss: +1.815e+01 | test loss: +2.003e+01 | 
| 05-02 00:45:20 epoch: 579| train loss i: [0.28	1.82	5.68	5.09	3.69	1.6 ] test loss i: [0.76	1.01	5.88	5.97	4.4 	2.01] | 
| 05-02 00:45:22 epoch: 580| time: 2.5s| train loss: +1.761e+01 | test loss: +1.656e+01 | 
| 05-02 00:45:22 epoch: 580| train loss i: [0.25	1.28	5.87	4.87	3.83	1.51] test loss i: [0.39	1.22	5.44	4.09	3.81	1.61] | 
| 05-02 00:45:25 epoch: 581| time: 2.5s| train loss: +1.786e+01 | test loss: +2.280e+01 | 
| 05-02 00:45:25 epoch: 581| train loss i: [0.21	1.2 	6.05	4.74	4.06	1.6 ] test loss i: [0.89	0.92	8.42	6.12	4.46	1.98] | 
| 05-02 00:45:27 epoch: 582| time: 2.5s| train loss: +1.920e+01 | test loss: +1.910e+01 | 
| 05-02 00:45:27 epoch: 582| train loss i: [0.34	2.75	5.94	5.05	3.62	1.51] test loss i: [0.9 	0.29	6.51	5.44	3.96	2.  ] | 
| 05-02 00:45:30 epoch: 583| time: 2.4s| train loss: +1.825e+01 | test loss: +2.125e+01 | 
| 05-02 00:45:30 epoch: 583| train loss i: [0.52	1.76	5.47	5.08	3.88	1.54] test loss i: [0.54	1.39	7.22	5.56	4.5 	2.04] | 
| 05-02 00:45:32 epoch: 584| time: 2.4s| train loss: +1.720e+01 | test loss: +1.510e+01 | 
| 05-02 00:45:32 epoch: 584| train loss i: [0.48	1.25	5.4 	4.81	3.69	1.56] test loss i: [0.77	1.05	4.42	3.64	3.65	1.56] | 
| 05-02 00:45:34 epoch: 585| time: 2.5s| train loss: +1.828e+01 | test loss: +2.562e+01 | 
| 05-02 00:45:34 epoch: 585| train loss i: [0.41	1.67	5.86	4.73	3.95	1.66] test loss i: [1.46	2.72	8.9 	6.02	4.46	2.06] | 
| 05-02 00:45:37 epoch: 586| time: 2.4s| train loss: +1.789e+01 | test loss: +1.994e+01 | 
| 05-02 00:45:37 epoch: 586| train loss i: [0.42	1.54	5.47	5.13	3.8 	1.54] test loss i: [1.05	2.54	6.5 	4.84	3.45	1.56] | 
| 05-02 00:45:39 epoch: 587| time: 2.5s| train loss: +1.724e+01 | test loss: +1.792e+01 | 
| 05-02 00:45:39 epoch: 587| train loss i: [0.41	1.29	5.41	4.81	3.75	1.57] test loss i: [0.98	1.79	4.47	4.97	3.96	1.75] | 
| 05-02 00:45:42 epoch: 588| time: 2.5s| train loss: +1.637e+01 | test loss: +2.550e+01 | 
| 05-02 00:45:42 epoch: 588| train loss i: [0.32	0.84	5.17	4.6 	3.88	1.55] test loss i: [0.48	1.34	8.53	6.89	5.48	2.78] | 
| 05-02 00:45:44 epoch: 589| time: 2.5s| train loss: +1.769e+01 | test loss: +1.818e+01 | 
| 05-02 00:45:44 epoch: 589| train loss i: [0.34	1.73	5.27	4.81	4.04	1.51] test loss i: [0.5 	2.01	5.21	4.93	3.98	1.54] | 
| 05-02 00:45:47 epoch: 590| time: 2.5s| train loss: +1.773e+01 | test loss: +1.811e+01 | 
| 05-02 00:45:47 epoch: 590| train loss i: [0.32	1.41	5.69	4.66	4.03	1.62] test loss i: [0.44	0.64	5.75	5.36	3.91	2.  ] | 
| 05-02 00:45:49 epoch: 591| time: 2.5s| train loss: +1.792e+01 | test loss: +1.734e+01 | 
| 05-02 00:45:49 epoch: 591| train loss i: [0.4 	1.18	5.94	5.17	3.63	1.59] test loss i: [0.38	1.15	5.84	5.24	3.2 	1.52] | 
| 05-02 00:45:52 epoch: 592| time: 2.5s| train loss: +1.830e+01 | test loss: +1.769e+01 | 
| 05-02 00:45:52 epoch: 592| train loss i: [0.33	1.47	6.13	4.82	3.94	1.61] test loss i: [0.44	1.02	6.96	4.18	3.41	1.7 ] | 
| 05-02 00:45:54 epoch: 593| time: 2.5s| train loss: +1.751e+01 | test loss: +1.882e+01 | 
| 05-02 00:45:54 epoch: 593| train loss i: [0.55	1.41	5.61	4.79	3.59	1.57] test loss i: [0.32	2.05	5.89	5.19	3.83	1.54] | 
| 05-02 00:45:57 epoch: 594| time: 2.5s| train loss: +1.844e+01 | test loss: +1.820e+01 | 
| 05-02 00:45:57 epoch: 594| train loss i: [0.47	2.11	5.44	5.04	3.81	1.57] test loss i: [0.72	1.4 	5.4 	4.7 	4.1 	1.86] | 
| 05-02 00:45:59 epoch: 595| time: 2.5s| train loss: +1.844e+01 | test loss: +1.391e+01 | 
| 05-02 00:45:59 epoch: 595| train loss i: [0.32	1.36	6.3 	4.85	4.02	1.59] test loss i: [0.59	0.72	3.85	3.83	3.39	1.53] | 
| 05-02 00:46:02 epoch: 596| time: 2.5s| train loss: +1.846e+01 | test loss: +1.855e+01 | 
| 05-02 00:46:02 epoch: 596| train loss i: [0.52	0.86	5.64	5.31	4.6 	1.53] test loss i: [0.73	1.22	5.49	5.73	3.59	1.79] | 
| 05-02 00:46:04 epoch: 597| time: 2.5s| train loss: +1.783e+01 | test loss: +2.231e+01 | 
| 05-02 00:46:04 epoch: 597| train loss i: [0.37	1.4 	5.67	4.87	3.93	1.6 ] test loss i: [0.97	4.79	5.65	4.78	4.36	1.76] | 
| 05-02 00:46:07 epoch: 598| time: 2.5s| train loss: +1.792e+01 | test loss: +2.264e+01 | 
| 05-02 00:46:07 epoch: 598| train loss i: [0.44	1.91	5.2 	5.06	3.74	1.57] test loss i: [0.62	3.67	7.6 	4.77	4.12	1.84] | 
| 05-02 00:46:09 epoch: 599| time: 2.5s| train loss: +1.855e+01 | test loss: +2.056e+01 | 
| 05-02 00:46:09 epoch: 599| train loss i: [0.29	2.39	5.61	4.96	3.66	1.64] test loss i: [0.75	1.31	7.04	5.2 	4.27	1.99] | 
| 05-02 00:46:12 epoch: 600| time: 2.5s| train loss: +1.776e+01 | test loss: +2.018e+01 | 
| 05-02 00:46:12 epoch: 600| train loss i: [0.3 	1.4 	5.65	4.77	4.05	1.59] test loss i: [0.8 	1.3 	6.26	5.22	4.77	1.82] | 
| 05-02 00:46:14 epoch: 601| time: 2.5s| train loss: +1.780e+01 | test loss: +2.613e+01 | 
| 05-02 00:46:14 epoch: 601| train loss i: [0.33	0.7 	6.17	4.88	4.17	1.54] test loss i: [0.67	3.29	7.76	7.09	4.98	2.35] | 
| 05-02 00:46:17 epoch: 602| time: 2.5s| train loss: +1.881e+01 | test loss: +2.301e+01 | 
| 05-02 00:46:17 epoch: 602| train loss i: [0.26	2.62	5.71	4.9 	3.69	1.63] test loss i: [0.46	2.59	7.18	5.83	5.14	1.81] | 
| 05-02 00:46:19 epoch: 603| time: 2.5s| train loss: +1.741e+01 | test loss: +1.411e+01 | 
| 05-02 00:46:19 epoch: 603| train loss i: [0.22	1.57	5.7 	4.68	3.71	1.53] test loss i: [0.28	1.31	3.66	4.37	2.88	1.62] | 
| 05-02 00:46:22 epoch: 604| time: 2.5s| train loss: +1.811e+01 | test loss: +1.692e+01 | 
| 05-02 00:46:22 epoch: 604| train loss i: [0.2 	1.49	5.87	4.89	4.01	1.65] test loss i: [0.21	1.25	4.99	4.76	3.94	1.77] | 
| 05-02 00:46:24 epoch: 605| time: 2.5s| train loss: +1.769e+01 | test loss: +1.650e+01 | 
| 05-02 00:46:24 epoch: 605| train loss i: [0.25	1.75	5.45	4.64	3.99	1.62] test loss i: [0.48	2.26	3.98	4.13	3.91	1.75] | 
| 05-02 00:46:27 epoch: 606| time: 2.5s| train loss: +1.783e+01 | test loss: +1.673e+01 | 
| 05-02 00:46:27 epoch: 606| train loss i: [0.22	1.47	5.63	4.72	4.18	1.61] test loss i: [0.19	1.26	5.14	4.69	3.86	1.59] | 
| 05-02 00:46:29 epoch: 607| time: 2.5s| train loss: +1.807e+01 | test loss: +1.741e+01 | 
| 05-02 00:46:29 epoch: 607| train loss i: [0.26	1.71	5.55	5.05	3.98	1.51] test loss i: [1.23	1.96	4.65	4.96	2.99	1.61] | 
| 05-02 00:46:32 epoch: 608| time: 2.5s| train loss: +1.822e+01 | test loss: +2.331e+01 | 
| 05-02 00:46:32 epoch: 608| train loss i: [0.35	1.91	5.33	5.04	4.02	1.57] test loss i: [0.53	1.69	8.53	5.92	4.82	1.83] | 
| 05-02 00:46:34 epoch: 609| time: 2.5s| train loss: +1.794e+01 | test loss: +1.823e+01 | 
| 05-02 00:46:34 epoch: 609| train loss i: [0.34	1.32	5.76	5.1 	3.73	1.68] test loss i: [0.62	1.43	5.41	5.24	3.84	1.7 ] | 
| 05-02 00:46:37 epoch: 610| time: 2.5s| train loss: +1.853e+01 | test loss: +1.923e+01 | 
| 05-02 00:46:37 epoch: 610| train loss i: [0.45	1.69	5.85	5.05	3.87	1.61] test loss i: [0.98	2.35	6.13	3.84	4.05	1.87] | 
| 05-02 00:46:39 epoch: 611| time: 2.5s| train loss: +1.822e+01 | test loss: +2.372e+01 | 
| 05-02 00:46:39 epoch: 611| train loss i: [0.53	1.78	5.48	5.08	3.77	1.58] test loss i: [0.8 	4.72	6.84	5.38	4.05	1.94] | 
| 05-02 00:46:42 epoch: 612| time: 2.5s| train loss: +1.841e+01 | test loss: +1.813e+01 | 
| 05-02 00:46:42 epoch: 612| train loss i: [0.4 	1.11	6.26	5.  	3.99	1.66] test loss i: [0.38	0.4 	6.75	4.98	3.87	1.75] | 
| 05-02 00:46:44 epoch: 613| time: 2.5s| train loss: +1.798e+01 | test loss: +2.022e+01 | 
| 05-02 00:46:44 epoch: 613| train loss i: [0.44	1.79	5.56	4.85	3.75	1.6 ] test loss i: [1.07	0.54	7.73	5.12	3.88	1.87] | 
| 05-02 00:46:46 epoch: 614| time: 2.4s| train loss: +1.813e+01 | test loss: +1.959e+01 | 
| 05-02 00:46:46 epoch: 614| train loss i: [0.4 	1.67	5.63	5.16	3.7 	1.58] test loss i: [0.6 	1.9 	5.88	5.45	4.2 	1.55] | 
| 05-02 00:46:49 epoch: 615| time: 2.5s| train loss: +1.814e+01 | test loss: +2.211e+01 | 
| 05-02 00:46:49 epoch: 615| train loss i: [0.51	1.34	5.77	5.1 	3.83	1.6 ] test loss i: [2.  	1.36	5.6 	6.6 	4.81	1.74] | 
| 05-02 00:46:51 epoch: 616| time: 2.4s| train loss: +1.745e+01 | test loss: +2.101e+01 | 
| 05-02 00:46:51 epoch: 616| train loss i: [0.46	1.25	5.59	4.6 	3.93	1.62] test loss i: [0.32	2.18	5.84	6.5 	4.01	2.15] | 
| 05-02 00:46:54 epoch: 617| time: 2.5s| train loss: +1.810e+01 | test loss: +2.259e+01 | 
| 05-02 00:46:54 epoch: 617| train loss i: [0.23	1.41	5.39	5.31	4.17	1.59] test loss i: [0.58	1.74	7.03	6.59	4.77	1.87] | 
| 05-02 00:46:56 epoch: 618| time: 2.5s| train loss: +1.805e+01 | test loss: +1.605e+01 | 
| 05-02 00:46:56 epoch: 618| train loss i: [0.24	1.78	5.74	4.92	3.75	1.63] test loss i: [0.8 	1.14	4.57	4.22	3.76	1.55] | 
| 05-02 00:46:59 epoch: 619| time: 2.5s| train loss: +1.779e+01 | test loss: +1.709e+01 | 
| 05-02 00:46:59 epoch: 619| train loss i: [0.28	1.2 	5.55	5.26	3.93	1.57] test loss i: [0.44	0.92	5.77	4.01	4.24	1.71] | 
| 05-02 00:47:01 epoch: 620| time: 2.4s| train loss: +1.705e+01 | test loss: +1.570e+01 | 
| 05-02 00:47:01 epoch: 620| train loss i: [0.27	1.13	5.25	4.95	3.87	1.59] test loss i: [0.38	0.77	5.19	3.84	3.94	1.58] | 
| 05-02 00:47:04 epoch: 621| time: 2.5s| train loss: +1.739e+01 | test loss: +2.008e+01 | 
| 05-02 00:47:04 epoch: 621| train loss i: [0.25	1.05	5.78	5.04	3.75	1.52] test loss i: [0.75	3.  	5.93	5.26	3.42	1.73] | 
| 05-02 00:47:06 epoch: 622| time: 2.5s| train loss: +1.692e+01 | test loss: +2.277e+01 | 
| 05-02 00:47:06 epoch: 622| train loss i: [0.23	1.21	5.32	4.71	3.85	1.6 ] test loss i: [1.76	3.72	5.21	5.96	4.28	1.84] | 
| 05-02 00:47:09 epoch: 623| time: 2.5s| train loss: +1.763e+01 | test loss: +2.163e+01 | 
| 05-02 00:47:09 epoch: 623| train loss i: [0.23	1.04	5.85	5.23	3.63	1.64] test loss i: [0.2 	1.09	7.42	6.24	4.67	2.02] | 
| 05-02 00:47:11 epoch: 624| time: 2.5s| train loss: +1.740e+01 | test loss: +2.019e+01 | 
| 05-02 00:47:11 epoch: 624| train loss i: [0.21	1.47	5.48	4.92	3.65	1.67] test loss i: [0.62	2.75	4.51	5.81	4.38	2.12] | 
| 05-02 00:47:14 epoch: 625| time: 2.4s| train loss: +1.710e+01 | test loss: +1.498e+01 | 
| 05-02 00:47:14 epoch: 625| train loss i: [0.23	0.91	5.48	4.94	3.86	1.67] test loss i: [0.16	1.36	4.12	3.52	4.23	1.58] | 
| 05-02 00:47:16 epoch: 626| time: 2.5s| train loss: +1.710e+01 | test loss: +2.271e+01 | 
| 05-02 00:47:16 epoch: 626| train loss i: [0.21	1.83	5.32	4.39	3.79	1.56] test loss i: [0.41	0.67	7.05	6.78	5.51	2.31] | 
| 05-02 00:47:19 epoch: 627| time: 2.5s| train loss: +1.746e+01 | test loss: +1.985e+01 | 
| 05-02 00:47:19 epoch: 627| train loss i: [0.33	1.33	5.6 	4.73	3.85	1.62] test loss i: [1.19	1.81	5.46	5.43	4.18	1.78] | 
| 05-02 00:47:21 epoch: 628| time: 2.4s| train loss: +1.761e+01 | test loss: +1.658e+01 | 
| 05-02 00:47:21 epoch: 628| train loss i: [0.41	1.73	5.35	4.9 	3.65	1.57] test loss i: [0.43	1.45	4.94	4.25	3.7 	1.81] | 
| 05-02 00:47:23 epoch: 629| time: 2.5s| train loss: +1.707e+01 | test loss: +1.885e+01 | 
| 05-02 00:47:23 epoch: 629| train loss i: [0.43	1.21	5.31	4.86	3.67	1.59] test loss i: [0.42	1.31	6.54	4.63	4.13	1.82] | 
| 05-02 00:47:26 epoch: 630| time: 2.5s| train loss: +1.729e+01 | test loss: +2.474e+01 | 
| 05-02 00:47:26 epoch: 630| train loss i: [0.34	1.48	5.32	4.77	3.73	1.65] test loss i: [1.01	0.63	8.91	6.84	5.15	2.21] | 
| 05-02 00:47:28 epoch: 631| time: 2.5s| train loss: +1.809e+01 | test loss: +2.165e+01 | 
| 05-02 00:47:28 epoch: 631| train loss i: [0.37	1.88	5.72	4.9 	3.54	1.68] test loss i: [0.5 	0.54	7.33	5.94	5.2 	2.15] | 
| 05-02 00:47:31 epoch: 632| time: 2.4s| train loss: +1.792e+01 | test loss: +2.218e+01 | 
| 05-02 00:47:31 epoch: 632| train loss i: [0.3 	1.5 	5.13	5.16	4.11	1.72] test loss i: [0.73	3.89	6.15	4.63	4.78	2.  ] | 
| 05-02 00:47:33 epoch: 633| time: 2.5s| train loss: +1.734e+01 | test loss: +1.661e+01 | 
| 05-02 00:47:33 epoch: 633| train loss i: [0.37	1.58	5.17	4.9 	3.77	1.56] test loss i: [0.35	1.04	6.07	3.97	3.61	1.57] | 
| 05-02 00:47:36 epoch: 634| time: 2.5s| train loss: +1.932e+01 | test loss: +1.793e+01 | 
| 05-02 00:47:36 epoch: 634| train loss i: [0.46	1.62	6.47	5.31	3.84	1.62] test loss i: [0.18	1.04	5.44	5.34	4.46	1.47] | 
| 05-02 00:47:38 epoch: 635| time: 2.5s| train loss: +1.745e+01 | test loss: +1.768e+01 | 
| 05-02 00:47:38 epoch: 635| train loss i: [0.28	1.8 	5.07	5.14	3.62	1.53] test loss i: [0.45	1.21	5.19	4.8 	4.21	1.8 ] | 
| 05-02 00:47:41 epoch: 636| time: 2.5s| train loss: +1.853e+01 | test loss: +1.793e+01 | 
| 05-02 00:47:41 epoch: 636| train loss i: [0.2 	2.61	5.65	4.91	3.65	1.51] test loss i: [0.36	1.44	6.25	4.55	3.37	1.96] | 
| 05-02 00:47:43 epoch: 637| time: 2.5s| train loss: +1.801e+01 | test loss: +1.925e+01 | 
| 05-02 00:47:43 epoch: 637| train loss i: [0.16	1.83	5.51	5.01	3.93	1.57] test loss i: [0.19	2.39	6.81	4.72	3.45	1.69] | 
| 05-02 00:47:46 epoch: 638| time: 2.5s| train loss: +1.644e+01 | test loss: +1.367e+01 | 
| 05-02 00:47:46 epoch: 638| train loss i: [0.19	1.38	5.04	4.55	3.66	1.63] test loss i: [0.26	0.57	3.75	4.25	3.28	1.57] | 
| 05-02 00:47:48 epoch: 639| time: 2.5s| train loss: +1.654e+01 | test loss: +2.072e+01 | 
| 05-02 00:47:48 epoch: 639| train loss i: [0.25	0.94	5.3 	4.56	3.9 	1.59] test loss i: [1.53	2.34	5.64	4.77	4.86	1.58] | 
| 05-02 00:47:51 epoch: 640| time: 2.5s| train loss: +1.857e+01 | test loss: +2.399e+01 | 
| 05-02 00:47:51 epoch: 640| train loss i: [0.52	1.78	5.65	4.98	3.95	1.7 ] test loss i: [1.28	3.54	6.91	6.27	3.92	2.07] | 
| 05-02 00:47:53 epoch: 641| time: 2.5s| train loss: +1.831e+01 | test loss: +2.853e+01 | 
| 05-02 00:47:53 epoch: 641| train loss i: [0.59	1.97	5.12	5.14	3.89	1.6 ] test loss i: [1.34	2.8 	8.82	7.46	5.97	2.15] | 
| 05-02 00:47:56 epoch: 642| time: 2.5s| train loss: +1.790e+01 | test loss: +1.669e+01 | 
| 05-02 00:47:56 epoch: 642| train loss i: [0.49	1.23	5.78	5.16	3.67	1.56] test loss i: [0.7 	1.63	5.23	3.72	3.73	1.68] | 
| 05-02 00:47:58 epoch: 643| time: 2.4s| train loss: +1.831e+01 | test loss: +2.105e+01 | 
| 05-02 00:47:58 epoch: 643| train loss i: [0.46	1.58	6.15	4.9 	3.63	1.6 ] test loss i: [1.54	2.29	6.91	4.39	4.15	1.77] | 
| 05-02 00:48:01 epoch: 644| time: 2.5s| train loss: +1.817e+01 | test loss: +2.225e+01 | 
| 05-02 00:48:01 epoch: 644| train loss i: [0.41	1.92	5.76	4.6 	3.84	1.65] test loss i: [1.12	1.31	6.1 	6.4 	5.13	2.2 ] | 
| 05-02 00:48:03 epoch: 645| time: 2.5s| train loss: +1.690e+01 | test loss: +1.875e+01 | 
| 05-02 00:48:03 epoch: 645| train loss i: [0.35	1.06	5.27	4.82	3.82	1.57] test loss i: [0.26	0.83	6.41	4.99	4.16	2.1 ] | 
| 05-02 00:48:06 epoch: 646| time: 2.5s| train loss: +1.719e+01 | test loss: +2.554e+01 | 
| 05-02 00:48:06 epoch: 646| train loss i: [0.28	1.06	5.53	4.82	3.92	1.58] test loss i: [0.58	0.96	9.43	6.2 	6.11	2.26] | 
| 05-02 00:48:08 epoch: 647| time: 2.5s| train loss: +1.755e+01 | test loss: +1.739e+01 | 
| 05-02 00:48:08 epoch: 647| train loss i: [0.26	1.72	5.63	4.65	3.73	1.56] test loss i: [0.86	2.17	4.73	4.1 	3.64	1.89] | 
| 05-02 00:48:11 epoch: 648| time: 2.5s| train loss: +1.737e+01 | test loss: +2.629e+01 | 
| 05-02 00:48:11 epoch: 648| train loss i: [0.27	1.68	4.95	5.06	3.85	1.56] test loss i: [0.48	1.99	8.65	7.17	4.79	3.22] | 
| 05-02 00:48:13 epoch: 649| time: 2.4s| train loss: +1.748e+01 | test loss: +1.708e+01 | 
| 05-02 00:48:13 epoch: 649| train loss i: [0.34	1.04	5.66	4.9 	3.85	1.68] test loss i: [0.23	2.67	5.42	3.58	3.76	1.43] | 
| 05-02 00:48:15 epoch: 650| time: 2.5s| train loss: +1.719e+01 | test loss: +1.732e+01 | 
| 05-02 00:48:15 epoch: 650| train loss i: [0.23	1.66	4.91	4.93	3.85	1.61] test loss i: [0.29	0.89	5.69	4.72	4.11	1.62] | 
| 05-02 00:48:18 epoch: 651| time: 2.5s| train loss: +1.820e+01 | test loss: +1.618e+01 | 
| 05-02 00:48:18 epoch: 651| train loss i: [0.32	1.47	5.68	5.18	3.86	1.69] test loss i: [0.49	2.05	3.97	3.82	4.04	1.81] | 
| 05-02 00:48:20 epoch: 652| time: 2.5s| train loss: +1.787e+01 | test loss: +3.031e+01 | 
| 05-02 00:48:20 epoch: 652| train loss i: [0.4 	1.37	5.73	4.9 	3.93	1.54] test loss i: [0.88	3.5 	9.26	7.55	6.54	2.59] | 
| 05-02 00:48:23 epoch: 653| time: 2.5s| train loss: +1.892e+01 | test loss: +1.706e+01 | 
| 05-02 00:48:23 epoch: 653| train loss i: [0.52	1.62	6.06	5.25	3.86	1.61] test loss i: [0.42	1.19	4.94	4.91	3.76	1.83] | 
| 05-02 00:48:25 epoch: 654| time: 2.4s| train loss: +1.813e+01 | test loss: +2.014e+01 | 
| 05-02 00:48:25 epoch: 654| train loss i: [0.57	1.19	5.78	4.93	3.99	1.66] test loss i: [1.52	0.74	6.15	5.15	4.89	1.7 ] | 
| 05-02 00:48:28 epoch: 655| time: 2.5s| train loss: +1.780e+01 | test loss: +1.854e+01 | 
| 05-02 00:48:28 epoch: 655| train loss i: [0.57	1.01	5.44	5.18	3.89	1.7 ] test loss i: [1.05	2.21	5.13	4.72	3.6 	1.83] | 
| 05-02 00:48:30 epoch: 656| time: 2.5s| train loss: +1.758e+01 | test loss: +2.030e+01 | 
| 05-02 00:48:30 epoch: 656| train loss i: [0.63	1.18	5.73	4.64	3.69	1.71] test loss i: [0.24	2.63	5.85	5.65	4.4 	1.52] | 
| 05-02 00:48:33 epoch: 657| time: 2.5s| train loss: +1.848e+01 | test loss: +2.541e+01 | 
| 05-02 00:48:33 epoch: 657| train loss i: [0.65	1.68	5.67	4.87	3.98	1.63] test loss i: [0.58	2.86	7.18	7.19	5.58	2.01] | 
| 05-02 00:48:35 epoch: 658| time: 2.4s| train loss: +1.768e+01 | test loss: +1.754e+01 | 
| 05-02 00:48:35 epoch: 658| train loss i: [0.46	2.02	4.9 	5.01	3.75	1.54] test loss i: [0.98	2.26	4.24	5.19	3.32	1.55] | 
| 05-02 00:48:38 epoch: 659| time: 2.5s| train loss: +1.769e+01 | test loss: +1.868e+01 | 
| 05-02 00:48:38 epoch: 659| train loss i: [0.41	1.48	5.6 	4.69	3.9 	1.61] test loss i: [0.53	2.41	5.82	4.18	3.95	1.8 ] | 
| 05-02 00:48:40 epoch: 660| time: 2.5s| train loss: +1.806e+01 | test loss: +1.802e+01 | 
| 05-02 00:48:40 epoch: 660| train loss i: [0.44	1.77	5.66	4.98	3.61	1.61] test loss i: [0.39	1.16	6.42	4.32	4.18	1.54] | 
| 05-02 00:48:43 epoch: 661| time: 2.5s| train loss: +1.744e+01 | test loss: +2.307e+01 | 
| 05-02 00:48:43 epoch: 661| train loss i: [0.41	1.49	5.27	5.05	3.61	1.62] test loss i: [0.87	2.  	6.52	6.86	4.69	2.14] | 
| 05-02 00:48:45 epoch: 662| time: 2.5s| train loss: +1.767e+01 | test loss: +1.792e+01 | 
| 05-02 00:48:45 epoch: 662| train loss i: [0.25	1.59	5.56	4.73	3.93	1.61] test loss i: [0.33	1.64	6.55	4.16	3.31	1.93] | 
| 05-02 00:48:48 epoch: 663| time: 2.4s| train loss: +1.818e+01 | test loss: +2.423e+01 | 
| 05-02 00:48:48 epoch: 663| train loss i: [0.38	2.15	5.14	4.89	4.07	1.56] test loss i: [0.51	1.7 	7.25	6.59	5.89	2.29] | 
| 05-02 00:48:50 epoch: 664| time: 2.4s| train loss: +1.651e+01 | test loss: +1.778e+01 | 
| 05-02 00:48:50 epoch: 664| train loss i: [0.21	1.05	4.96	4.84	3.85	1.6 ] test loss i: [0.4 	1.25	5.61	4.42	4.58	1.52] | 
| 05-02 00:48:52 epoch: 665| time: 2.5s| train loss: +1.790e+01 | test loss: +1.655e+01 | 
| 05-02 00:48:52 epoch: 665| train loss i: [0.25	1.42	5.88	4.8 	3.99	1.56] test loss i: [0.3 	1.4 	5.52	4.17	3.5 	1.67] | 
| 05-02 00:48:55 epoch: 666| time: 2.5s| train loss: +1.655e+01 | test loss: +1.830e+01 | 
| 05-02 00:48:55 epoch: 666| train loss i: [0.2 	1.34	4.96	4.51	3.98	1.56] test loss i: [0.49	1.03	6.18	4.59	4.51	1.5 ] | 
| 05-02 00:48:57 epoch: 667| time: 2.5s| train loss: +1.721e+01 | test loss: +1.659e+01 | 
| 05-02 00:48:57 epoch: 667| train loss i: [0.21	1.77	5.36	4.69	3.55	1.63] test loss i: [0.78	0.72	4.71	4.14	4.38	1.87] | 
| 05-02 00:49:00 epoch: 668| time: 2.5s| train loss: +1.709e+01 | test loss: +1.627e+01 | 
| 05-02 00:49:00 epoch: 668| train loss i: [0.28	0.94	5.44	4.72	4.14	1.57] test loss i: [0.17	0.69	6.17	4.22	3.5 	1.51] | 
| 05-02 00:49:02 epoch: 669| time: 2.5s| train loss: +1.838e+01 | test loss: +2.011e+01 | 
| 05-02 00:49:02 epoch: 669| train loss i: [0.2 	1.74	5.72	4.98	4.13	1.61] test loss i: [0.29	3.45	5.96	5.4 	3.33	1.67] | 
| 05-02 00:49:05 epoch: 670| time: 2.4s| train loss: +1.801e+01 | test loss: +1.866e+01 | 
| 05-02 00:49:05 epoch: 670| train loss i: [0.22	1.8 	5.89	4.85	3.7 	1.57] test loss i: [0.17	2.23	6.4 	4.78	3.41	1.68] | 
| 05-02 00:49:07 epoch: 671| time: 2.5s| train loss: +1.745e+01 | test loss: +1.610e+01 | 
| 05-02 00:49:07 epoch: 671| train loss i: [0.2 	1.5 	5.71	4.87	3.55	1.62] test loss i: [0.53	1.25	4.13	5.29	3.22	1.67] | 
| 05-02 00:49:10 epoch: 672| time: 2.4s| train loss: +1.785e+01 | test loss: +2.273e+01 | 
| 05-02 00:49:10 epoch: 672| train loss i: [0.36	1.26	5.88	4.95	3.84	1.58] test loss i: [1.2 	0.88	7.86	5.85	4.94	2.  ] | 
| 05-02 00:49:12 epoch: 673| time: 2.4s| train loss: +1.715e+01 | test loss: +1.598e+01 | 
| 05-02 00:49:12 epoch: 673| train loss i: [0.31	1.47	5.56	4.37	3.8 	1.64] test loss i: [0.49	0.69	5.5 	4.31	3.48	1.51] | 
| 05-02 00:49:15 epoch: 674| time: 2.4s| train loss: +1.669e+01 | test loss: +1.601e+01 | 
| 05-02 00:49:15 epoch: 674| train loss i: [0.22	1.05	5.17	4.91	3.72	1.62] test loss i: [0.23	0.98	5.  	3.56	4.33	1.92] | 
| 05-02 00:49:17 epoch: 675| time: 2.4s| train loss: +1.788e+01 | test loss: +1.471e+01 | 
| 05-02 00:49:17 epoch: 675| train loss i: [0.2 	1.86	5.61	4.86	3.75	1.59] test loss i: [0.42	1.03	4.03	4.06	3.55	1.61] | 
| 05-02 00:49:19 epoch: 676| time: 2.5s| train loss: +1.796e+01 | test loss: +2.133e+01 | 
| 05-02 00:49:19 epoch: 676| train loss i: [0.3 	1.34	5.89	4.84	4.03	1.55] test loss i: [0.22	2.94	5.34	5.84	4.68	2.31] | 
| 05-02 00:49:22 epoch: 677| time: 2.5s| train loss: +1.725e+01 | test loss: +1.821e+01 | 
| 05-02 00:49:22 epoch: 677| train loss i: [0.23	1.39	5.36	4.74	3.9 	1.63] test loss i: [0.24	1.23	6.18	4.49	4.25	1.81] | 
| 05-02 00:49:24 epoch: 678| time: 2.5s| train loss: +1.760e+01 | test loss: +1.801e+01 | 
| 05-02 00:49:24 epoch: 678| train loss i: [0.17	1.18	5.6 	5.06	4.04	1.56] test loss i: [0.13	1.87	5.53	4.9 	4.05	1.53] | 
| 05-02 00:49:27 epoch: 679| time: 2.4s| train loss: +1.623e+01 | test loss: +1.767e+01 | 
| 05-02 00:49:27 epoch: 679| train loss i: [0.17	1.3 	5.1 	4.63	3.5 	1.53] test loss i: [0.31	1.96	5.56	4.5 	3.9 	1.44] | 
| 05-02 00:49:29 epoch: 680| time: 2.4s| train loss: +1.660e+01 | test loss: +2.362e+01 | 
| 05-02 00:49:29 epoch: 680| train loss i: [0.13	1.25	5.26	4.72	3.67	1.58] test loss i: [0.27	1.66	7.71	6.17	5.73	2.08] | 
| 05-02 00:49:32 epoch: 681| time: 2.5s| train loss: +1.718e+01 | test loss: +2.836e+01 | 
| 05-02 00:49:32 epoch: 681| train loss i: [0.21	1.51	5.43	4.71	3.82	1.52] test loss i: [0.27	3.77	8.48	8.15	5.65	2.04] | 
| 05-02 00:49:34 epoch: 682| time: 2.4s| train loss: +1.831e+01 | test loss: +2.688e+01 | 
| 05-02 00:49:34 epoch: 682| train loss i: [0.24	1.73	5.86	5.07	3.76	1.65] test loss i: [0.43	3.57	6.91	7.79	5.84	2.35] | 
| 05-02 00:49:37 epoch: 683| time: 2.4s| train loss: +1.759e+01 | test loss: +1.924e+01 | 
| 05-02 00:49:37 epoch: 683| train loss i: [0.25	1.  	5.9 	5.02	3.84	1.58] test loss i: [0.5 	1.16	5.6 	4.91	5.  	2.07] | 
| 05-02 00:49:39 epoch: 684| time: 2.4s| train loss: +1.677e+01 | test loss: +2.248e+01 | 
| 05-02 00:49:39 epoch: 684| train loss i: [0.24	1.42	5.23	4.69	3.58	1.6 ] test loss i: [0.22	2.34	7.03	6.64	4.41	1.85] | 
| 05-02 00:49:41 epoch: 685| time: 2.4s| train loss: +1.795e+01 | test loss: +1.652e+01 | 
| 05-02 00:49:41 epoch: 685| train loss i: [0.25	1.32	5.61	5.2 	3.94	1.64] test loss i: [0.36	0.92	4.39	5.02	3.93	1.9 ] | 
| 05-02 00:49:44 epoch: 686| time: 2.5s| train loss: +1.706e+01 | test loss: +1.822e+01 | 
| 05-02 00:49:44 epoch: 686| train loss i: [0.39	1.46	5.35	4.73	3.58	1.56] test loss i: [0.43	1.37	4.93	5.21	4.53	1.76] | 
| 05-02 00:49:46 epoch: 687| time: 2.5s| train loss: +1.663e+01 | test loss: +1.972e+01 | 
| 05-02 00:49:46 epoch: 687| train loss i: [0.25	0.62	5.5 	4.73	3.95	1.58] test loss i: [0.52	1.79	5.32	6.08	3.98	2.02] | 
| 05-02 00:49:49 epoch: 688| time: 2.4s| train loss: +1.803e+01 | test loss: +1.532e+01 | 
| 05-02 00:49:49 epoch: 688| train loss i: [0.19	1.75	5.68	4.91	3.84	1.66] test loss i: [0.68	0.67	4.52	3.56	4.19	1.71] | 
| 05-02 00:49:51 epoch: 689| time: 2.4s| train loss: +1.711e+01 | test loss: +1.891e+01 | 
| 05-02 00:49:51 epoch: 689| train loss i: [0.17	1.09	5.7 	5.02	3.54	1.6 ] test loss i: [0.19	0.45	5.92	5.66	4.71	1.98] | 
| 05-02 00:49:54 epoch: 690| time: 2.4s| train loss: +1.788e+01 | test loss: +1.862e+01 | 
| 05-02 00:49:54 epoch: 690| train loss i: [0.21	1.76	5.56	4.98	3.66	1.71] test loss i: [0.43	0.78	5.92	5.43	4.4 	1.66] | 
| 05-02 00:49:56 epoch: 691| time: 2.5s| train loss: +1.674e+01 | test loss: +1.462e+01 | 
| 05-02 00:49:56 epoch: 691| train loss i: [0.19	1.45	5.26	4.5 	3.76	1.59] test loss i: [0.27	0.47	4.98	4.41	3.  	1.5 ] | 
| 05-02 00:49:59 epoch: 692| time: 2.5s| train loss: +1.668e+01 | test loss: +2.027e+01 | 
| 05-02 00:49:59 epoch: 692| train loss i: [0.21	0.99	5.52	4.57	3.85	1.54] test loss i: [0.25	2.05	6.96	5.22	4.09	1.69] | 
| 05-02 00:50:01 epoch: 693| time: 2.4s| train loss: +1.754e+01 | test loss: +1.630e+01 | 
| 05-02 00:50:01 epoch: 693| train loss i: [0.21	1.46	5.81	4.82	3.63	1.6 ] test loss i: [0.23	2.12	5.01	3.92	3.24	1.78] | 
| 05-02 00:50:03 epoch: 694| time: 2.5s| train loss: +1.676e+01 | test loss: +1.766e+01 | 
| 05-02 00:50:03 epoch: 694| train loss i: [0.15	1.11	5.47	4.58	3.82	1.62] test loss i: [0.12	2.63	5.38	4.52	3.39	1.63] | 
| 05-02 00:50:06 epoch: 695| time: 2.5s| train loss: +1.766e+01 | test loss: +2.003e+01 | 
| 05-02 00:50:06 epoch: 695| train loss i: [0.15	1.36	5.9 	5.03	3.63	1.58] test loss i: [0.17	0.96	5.52	6.21	5.  	2.17] | 
| 05-02 00:50:08 epoch: 696| time: 2.4s| train loss: +1.851e+01 | test loss: +1.768e+01 | 
| 05-02 00:50:08 epoch: 696| train loss i: [0.19	2.13	5.5 	5.02	4.07	1.6 ] test loss i: [0.22	2.69	5.32	3.97	4.03	1.45] | 
| 05-02 00:50:11 epoch: 697| time: 2.4s| train loss: +1.789e+01 | test loss: +2.276e+01 | 
| 05-02 00:50:11 epoch: 697| train loss i: [0.27	1.23	5.85	4.88	4.08	1.57] test loss i: [0.69	2.47	8.79	4.92	4.3 	1.58] | 
| 05-02 00:50:13 epoch: 698| time: 2.4s| train loss: +1.744e+01 | test loss: +1.836e+01 | 
| 05-02 00:50:13 epoch: 698| train loss i: [0.25	1.55	5.3 	4.95	3.84	1.56] test loss i: [0.33	1.51	5.32	5.17	4.16	1.85] | 
| 05-02 00:50:16 epoch: 699| time: 2.5s| train loss: +1.827e+01 | test loss: +1.553e+01 | 
| 05-02 00:50:16 epoch: 699| train loss i: [0.23	1.93	5.63	4.78	4.12	1.59] test loss i: [0.34	2.39	3.87	4.02	3.37	1.54] | 
| 05-02 00:50:18 epoch: 700| time: 2.5s| train loss: +1.815e+01 | test loss: +1.840e+01 | 
| 05-02 00:50:18 epoch: 700| train loss i: [0.35	1.31	5.8 	5.11	3.95	1.63] test loss i: [1.16	3.09	4.49	4.97	3.04	1.65] | 
| 05-02 00:50:21 epoch: 701| time: 2.5s| train loss: +1.683e+01 | test loss: +1.912e+01 | 
| 05-02 00:50:21 epoch: 701| train loss i: [0.27	0.96	5.75	4.37	3.85	1.62] test loss i: [0.72	0.9 	4.45	7.4 	3.88	1.78] | 
| 05-02 00:50:23 epoch: 702| time: 2.5s| train loss: +1.725e+01 | test loss: +1.676e+01 | 
| 05-02 00:50:23 epoch: 702| train loss i: [0.32	1.15	5.4 	4.93	3.86	1.59] test loss i: [0.14	1.45	4.98	4.95	3.72	1.53] | 
| 05-02 00:50:26 epoch: 703| time: 2.5s| train loss: +1.787e+01 | test loss: +1.765e+01 | 
| 05-02 00:50:26 epoch: 703| train loss i: [0.22	1.25	5.59	5.08	4.16	1.57] test loss i: [0.75	0.86	6.45	4.6 	3.5 	1.49] | 
| 05-02 00:50:28 epoch: 704| time: 2.4s| train loss: +1.806e+01 | test loss: +1.567e+01 | 
| 05-02 00:50:28 epoch: 704| train loss i: [0.24	1.73	5.88	4.85	3.78	1.58] test loss i: [0.09	0.8 	5.38	4.64	3.11	1.65] | 
| 05-02 00:50:30 epoch: 705| time: 2.4s| train loss: +1.798e+01 | test loss: +1.902e+01 | 
| 05-02 00:50:30 epoch: 705| train loss i: [0.35	1.57	5.46	5.15	3.83	1.61] test loss i: [0.36	1.82	6.05	4.98	4.18	1.63] | 
| 05-02 00:50:33 epoch: 706| time: 2.4s| train loss: +1.837e+01 | test loss: +2.445e+01 | 
| 05-02 00:50:33 epoch: 706| train loss i: [0.32	1.52	5.71	5.28	3.94	1.61] test loss i: [0.71	0.73	7.24	7.78	5.45	2.54] | 
| 05-02 00:50:35 epoch: 707| time: 2.4s| train loss: +1.878e+01 | test loss: +2.133e+01 | 
| 05-02 00:50:35 epoch: 707| train loss i: [0.37	1.77	5.92	5.09	4.02	1.61] test loss i: [0.83	3.97	6.39	5.02	3.47	1.66] | 
| 05-02 00:50:38 epoch: 708| time: 2.4s| train loss: +1.796e+01 | test loss: +1.795e+01 | 
| 05-02 00:50:38 epoch: 708| train loss i: [0.37	1.5 	5.22	5.09	4.17	1.61] test loss i: [0.15	0.61	5.22	5.43	4.71	1.83] | 
| 05-02 00:50:40 epoch: 709| time: 2.5s| train loss: +1.846e+01 | test loss: +1.431e+01 | 
| 05-02 00:50:40 epoch: 709| train loss i: [0.22	1.45	6.39	4.93	3.81	1.65] test loss i: [0.35	1.5 	3.43	4.22	3.22	1.59] | 
| 05-02 00:50:43 epoch: 710| time: 2.5s| train loss: +1.741e+01 | test loss: +1.681e+01 | 
| 05-02 00:50:43 epoch: 710| train loss i: [0.24	1.09	6.09	4.81	3.54	1.64] test loss i: [0.93	1.53	5.11	4.14	3.46	1.64] | 
| 05-02 00:50:45 epoch: 711| time: 2.4s| train loss: +1.691e+01 | test loss: +2.077e+01 | 
| 05-02 00:50:45 epoch: 711| train loss i: [0.18	0.88	5.63	4.91	3.79	1.53] test loss i: [0.52	1.14	5.43	6.52	5.22	1.94] | 
| 05-02 00:50:48 epoch: 712| time: 2.5s| train loss: +1.783e+01 | test loss: +1.832e+01 | 
| 05-02 00:50:48 epoch: 712| train loss i: [0.29	1.76	5.65	4.91	3.69	1.53] test loss i: [0.26	0.65	5.55	5.34	4.51	2.01] | 
| 05-02 00:50:50 epoch: 713| time: 2.4s| train loss: +1.664e+01 | test loss: +1.628e+01 | 
| 05-02 00:50:50 epoch: 713| train loss i: [0.17	1.49	5.05	4.61	3.72	1.59] test loss i: [0.32	1.15	5.4 	4.3 	3.33	1.79] | 
| 05-02 00:50:53 epoch: 714| time: 2.4s| train loss: +1.888e+01 | test loss: +1.693e+01 | 
| 05-02 00:50:53 epoch: 714| train loss i: [0.16	1.8 	6.01	5.19	4.11	1.61] test loss i: [0.37	1.44	4.98	3.88	4.55	1.7 ] | 
| 05-02 00:50:55 epoch: 715| time: 2.5s| train loss: +1.810e+01 | test loss: +2.819e+01 | 
| 05-02 00:50:55 epoch: 715| train loss i: [0.3 	1.65	5.49	4.9 	4.1 	1.67] test loss i: [ 0.31	 3.09	10.51	 6.47	 5.06	 2.75] | 
| 05-02 00:50:57 epoch: 716| time: 2.4s| train loss: +1.768e+01 | test loss: +2.218e+01 | 
| 05-02 00:50:57 epoch: 716| train loss i: [0.21	1.84	5.27	4.99	3.75	1.63] test loss i: [0.98	2.07	5.95	6.29	4.68	2.21] | 
| 05-02 00:51:00 epoch: 717| time: 2.4s| train loss: +1.857e+01 | test loss: +2.186e+01 | 
| 05-02 00:51:00 epoch: 717| train loss i: [0.21	1.89	6.  	5.07	3.9 	1.51] test loss i: [0.24	2.91	7.18	5.51	4.25	1.77] | 
| 05-02 00:51:02 epoch: 718| time: 2.5s| train loss: +1.799e+01 | test loss: +1.568e+01 | 
| 05-02 00:51:02 epoch: 718| train loss i: [0.2 	0.99	6.2 	4.87	4.16	1.57] test loss i: [0.17	0.48	5.56	5.  	2.92	1.55] | 
| 05-02 00:51:05 epoch: 719| time: 2.5s| train loss: +1.657e+01 | test loss: +2.310e+01 | 
| 05-02 00:51:05 epoch: 719| train loss i: [0.2 	0.94	5.39	4.66	3.71	1.66] test loss i: [0.2 	3.25	7.1 	6.5 	3.85	2.2 ] | 
| 05-02 00:51:07 epoch: 720| time: 2.5s| train loss: +1.714e+01 | test loss: +2.473e+01 | 
| 05-02 00:51:07 epoch: 720| train loss i: [0.17	1.36	5.56	4.82	3.68	1.55] test loss i: [0.52	3.07	7.06	6.26	5.67	2.16] | 
| 05-02 00:51:10 epoch: 721| time: 2.5s| train loss: +1.730e+01 | test loss: +2.342e+01 | 
| 05-02 00:51:10 epoch: 721| train loss i: [0.21	1.51	4.89	4.96	4.09	1.62] test loss i: [0.94	1.04	7.44	6.55	5.45	2.  ] | 
| 05-02 00:51:12 epoch: 722| time: 2.5s| train loss: +1.807e+01 | test loss: +1.964e+01 | 
| 05-02 00:51:12 epoch: 722| train loss i: [0.18	1.57	6.02	4.78	3.92	1.6 ] test loss i: [0.81	3.04	4.9 	4.99	4.05	1.85] | 
| 05-02 00:51:15 epoch: 723| time: 2.5s| train loss: +1.831e+01 | test loss: +1.760e+01 | 
| 05-02 00:51:15 epoch: 723| train loss i: [0.16	1.7 	5.77	5.05	4.04	1.58] test loss i: [0.17	2.18	5.15	4.49	3.8 	1.81] | 
| 05-02 00:51:17 epoch: 724| time: 2.5s| train loss: +1.660e+01 | test loss: +2.162e+01 | 
| 05-02 00:51:17 epoch: 724| train loss i: [0.21	1.59	4.91	4.58	3.75	1.55] test loss i: [0.64	2.15	5.73	7.09	3.94	2.08] | 
| 05-02 00:51:20 epoch: 725| time: 2.4s| train loss: +1.712e+01 | test loss: +2.143e+01 | 
| 05-02 00:51:20 epoch: 725| train loss i: [0.22	0.9 	5.57	4.78	4.08	1.57] test loss i: [0.9 	5.35	4.87	4.71	3.59	2.  ] | 
| 05-02 00:51:22 epoch: 726| time: 2.5s| train loss: +1.846e+01 | test loss: +2.521e+01 | 
| 05-02 00:51:22 epoch: 726| train loss i: [0.28	2.32	5.43	4.76	4.01	1.66] test loss i: [0.97	2.28	6.96	7.75	5.02	2.24] | 
| 05-02 00:51:25 epoch: 727| time: 2.4s| train loss: +1.826e+01 | test loss: +1.976e+01 | 
| 05-02 00:51:25 epoch: 727| train loss i: [0.29	1.91	5.8 	5.  	3.7 	1.56] test loss i: [0.23	1.52	6.11	5.47	4.33	2.1 ] | 
| 05-02 00:51:27 epoch: 728| time: 2.4s| train loss: +1.734e+01 | test loss: +2.146e+01 | 
| 05-02 00:51:27 epoch: 728| train loss i: [0.25	1.5 	5.62	4.51	3.9 	1.57] test loss i: [0.59	1.23	7.4 	5.7 	4.43	2.1 ] | 
| 05-02 00:51:30 epoch: 729| time: 2.5s| train loss: +1.648e+01 | test loss: +1.744e+01 | 
| 05-02 00:51:30 epoch: 729| train loss i: [0.24	1.37	4.83	4.64	3.83	1.57] test loss i: [0.26	3.68	4.77	3.59	3.27	1.86] | 
| 05-02 00:51:32 epoch: 730| time: 2.5s| train loss: +1.711e+01 | test loss: +1.825e+01 | 
| 05-02 00:51:32 epoch: 730| train loss i: [0.26	1.68	5.11	4.57	3.83	1.65] test loss i: [0.27	0.61	5.92	5.11	4.73	1.61] | 
| 05-02 00:51:34 epoch: 731| time: 2.5s| train loss: +1.739e+01 | test loss: +1.737e+01 | 
| 05-02 00:51:34 epoch: 731| train loss i: [0.28	1.3 	5.3 	4.88	4.01	1.62] test loss i: [0.61	0.78	4.88	5.34	4.08	1.67] | 
| 05-02 00:51:37 epoch: 732| time: 2.5s| train loss: +1.727e+01 | test loss: +2.511e+01 | 
| 05-02 00:51:37 epoch: 732| train loss i: [0.29	1.73	4.82	5.14	3.72	1.57] test loss i: [0.35	2.04	7.5 	8.21	5.17	1.84] | 
| 05-02 00:51:39 epoch: 733| time: 2.5s| train loss: +1.670e+01 | test loss: +2.449e+01 | 
| 05-02 00:51:39 epoch: 733| train loss i: [0.3 	1.08	5.39	4.64	3.65	1.64] test loss i: [2.97	1.77	7.25	5.61	4.91	1.98] | 
| 05-02 00:51:42 epoch: 734| time: 2.5s| train loss: +1.731e+01 | test loss: +2.380e+01 | 
| 05-02 00:51:42 epoch: 734| train loss i: [0.33	0.89	5.81	4.88	3.79	1.6 ] test loss i: [1.4 	1.41	6.81	5.68	6.44	2.05] | 
| 05-02 00:51:44 epoch: 735| time: 2.4s| train loss: +1.810e+01 | test loss: +2.739e+01 | 
| 05-02 00:51:44 epoch: 735| train loss i: [0.33	1.84	5.49	5.05	3.74	1.64] test loss i: [1.07	3.  	9.35	6.74	5.07	2.17] | 
| 05-02 00:51:47 epoch: 736| time: 2.4s| train loss: +1.690e+01 | test loss: +2.594e+01 | 
| 05-02 00:51:47 epoch: 736| train loss i: [0.31	1.08	5.18	5.  	3.79	1.54] test loss i: [1.93	2.97	7.98	6.34	4.81	1.91] | 
| 05-02 00:51:49 epoch: 737| time: 2.5s| train loss: +1.757e+01 | test loss: +1.663e+01 | 
| 05-02 00:51:49 epoch: 737| train loss i: [0.33	1.81	5.24	4.72	3.85	1.62] test loss i: [0.15	0.8 	5.71	4.73	3.45	1.78] | 
| 05-02 00:51:52 epoch: 738| time: 2.5s| train loss: +1.818e+01 | test loss: +2.439e+01 | 
| 05-02 00:51:52 epoch: 738| train loss i: [0.44	1.52	5.52	5.19	3.92	1.6 ] test loss i: [1.45	2.37	7.33	6.64	4.86	1.73] | 
| 05-02 00:51:54 epoch: 739| time: 2.5s| train loss: +1.787e+01 | test loss: +1.624e+01 | 
| 05-02 00:51:54 epoch: 739| train loss i: [0.31	1.98	5.62	4.52	3.87	1.57] test loss i: [0.16	0.63	5.4 	4.33	4.05	1.67] | 
| 05-02 00:51:57 epoch: 740| time: 2.6s| train loss: +1.775e+01 | test loss: +1.789e+01 | 
| 05-02 00:51:57 epoch: 740| train loss i: [0.4 	1.5 	5.14	5.41	3.76	1.53] test loss i: [1.28	1.7 	3.96	4.68	4.73	1.54] | 
| 05-02 00:51:59 epoch: 741| time: 2.4s| train loss: +1.857e+01 | test loss: +2.004e+01 | 
| 05-02 00:51:59 epoch: 741| train loss i: [0.6 	1.55	5.77	4.96	4.09	1.62] test loss i: [1.85	2.44	5.77	4.43	3.83	1.72] | 
| 05-02 00:52:02 epoch: 742| time: 2.5s| train loss: +1.893e+01 | test loss: +1.910e+01 | 
| 05-02 00:52:02 epoch: 742| train loss i: [0.64	2.15	5.53	5.33	3.71	1.56] test loss i: [2.57	1.25	5.51	4.51	3.4 	1.85] | 
| 05-02 00:52:04 epoch: 743| time: 2.5s| train loss: +1.683e+01 | test loss: +2.166e+01 | 
| 05-02 00:52:04 epoch: 743| train loss i: [0.36	1.26	5.28	4.65	3.73	1.55] test loss i: [0.35	1.17	6.75	6.32	5.1 	1.97] | 
| 05-02 00:52:06 epoch: 744| time: 2.4s| train loss: +1.777e+01 | test loss: +3.145e+01 | 
| 05-02 00:52:06 epoch: 744| train loss i: [0.4 	1.47	5.3 	4.87	4.15	1.57] test loss i: [1.7 	4.38	9.17	7.2 	6.2 	2.8 ] | 
| 05-02 00:52:09 epoch: 745| time: 2.5s| train loss: +1.843e+01 | test loss: +2.125e+01 | 
| 05-02 00:52:09 epoch: 745| train loss i: [0.42	2.5 	5.33	4.93	3.74	1.52] test loss i: [0.96	1.82	6.12	7.03	3.55	1.79] | 
| 05-02 00:52:11 epoch: 746| time: 2.5s| train loss: +1.741e+01 | test loss: +2.082e+01 | 
| 05-02 00:52:11 epoch: 746| train loss i: [0.38	1.42	5.27	4.78	3.99	1.57] test loss i: [0.86	2.52	5.45	6.04	3.89	2.06] | 
| 05-02 00:52:14 epoch: 747| time: 2.5s| train loss: +1.746e+01 | test loss: +2.358e+01 | 
| 05-02 00:52:14 epoch: 747| train loss i: [0.19	1.76	5.18	4.82	3.72	1.79] test loss i: [0.56	1.12	7.46	6.59	5.49	2.37] | 
| 05-02 00:52:16 epoch: 748| time: 2.5s| train loss: +1.769e+01 | test loss: +2.481e+01 | 
| 05-02 00:52:16 epoch: 748| train loss i: [0.17	1.98	5.69	4.43	3.78	1.64] test loss i: [0.25	2.58	8.48	6.45	4.92	2.14] | 
| 05-02 00:52:19 epoch: 749| time: 2.5s| train loss: +1.726e+01 | test loss: +2.491e+01 | 
| 05-02 00:52:19 epoch: 749| train loss i: [0.24	1.21	5.12	5.12	3.91	1.67] test loss i: [0.48	0.39	9.55	7.15	4.91	2.44] | 
| 05-02 00:52:22 epoch: 750| time: 2.5s| train loss: +1.728e+01 | test loss: +2.506e+01 | 
| 05-02 00:52:22 epoch: 750| train loss i: [0.21	1.01	5.79	4.77	3.9 	1.6 ] test loss i: [0.65	1.95	8.01	7.05	4.99	2.4 ] | 
| 05-02 00:52:24 epoch: 751| time: 2.5s| train loss: +1.712e+01 | test loss: +1.569e+01 | 
| 05-02 00:52:24 epoch: 751| train loss i: [0.21	1.39	5.03	4.8 	4.06	1.63] test loss i: [0.58	0.92	3.85	4.48	4.33	1.53] | 
| 05-02 00:52:27 epoch: 752| time: 2.6s| train loss: +1.755e+01 | test loss: +2.114e+01 | 
| 05-02 00:52:27 epoch: 752| train loss i: [0.23	1.46	5.58	4.82	3.93	1.54] test loss i: [0.59	1.63	6.46	5.94	4.84	1.67] | 
| 05-02 00:52:29 epoch: 753| time: 2.6s| train loss: +1.770e+01 | test loss: +1.500e+01 | 
| 05-02 00:52:29 epoch: 753| train loss i: [0.27	1.53	5.54	4.65	4.09	1.62] test loss i: [0.13	0.95	4.38	4.34	3.5 	1.71] | 
| 05-02 00:52:32 epoch: 754| time: 2.5s| train loss: +1.703e+01 | test loss: +1.820e+01 | 
| 05-02 00:52:32 epoch: 754| train loss i: [0.17	0.88	5.83	4.63	3.91	1.62] test loss i: [0.28	1.8 	5.46	4.53	4.35	1.78] | 
| 05-02 00:52:34 epoch: 755| time: 2.5s| train loss: +1.720e+01 | test loss: +1.687e+01 | 
| 05-02 00:52:34 epoch: 755| train loss i: [0.17	1.4 	5.47	4.87	3.73	1.56] test loss i: [0.13	0.79	5.63	4.91	3.79	1.61] | 
| 05-02 00:52:37 epoch: 756| time: 2.6s| train loss: +1.717e+01 | test loss: +1.759e+01 | 
| 05-02 00:52:37 epoch: 756| train loss i: [0.17	1.44	5.19	5.05	3.74	1.57] test loss i: [0.24	1.52	4.93	4.86	4.4 	1.65] | 
| 05-02 00:52:39 epoch: 757| time: 2.5s| train loss: +1.766e+01 | test loss: +1.732e+01 | 
| 05-02 00:52:39 epoch: 757| train loss i: [0.19	1.8 	5.26	5.09	3.79	1.54] test loss i: [0.4 	0.76	5.35	4.68	4.46	1.66] | 
| 05-02 00:52:42 epoch: 758| time: 2.5s| train loss: +1.780e+01 | test loss: +2.500e+01 | 
| 05-02 00:52:42 epoch: 758| train loss i: [0.19	1.4 	6.06	4.7 	3.88	1.56] test loss i: [0.2 	2.39	8.01	7.45	5.06	1.9 ] | 
| 05-02 00:52:44 epoch: 759| time: 2.4s| train loss: +1.747e+01 | test loss: +2.489e+01 | 
| 05-02 00:52:44 epoch: 759| train loss i: [0.18	1.1 	5.72	5.19	3.72	1.56] test loss i: [ 1.39	 1.8 	10.06	 5.14	 4.23	 2.27] | 
| 05-02 00:52:47 epoch: 760| time: 2.4s| train loss: +1.710e+01 | test loss: +1.861e+01 | 
| 05-02 00:52:47 epoch: 760| train loss i: [0.25	1.09	5.65	4.67	3.84	1.6 ] test loss i: [0.21	1.3 	6.68	5.4 	3.27	1.75] | 
| 05-02 00:52:49 epoch: 761| time: 2.5s| train loss: +1.705e+01 | test loss: +1.818e+01 | 
| 05-02 00:52:49 epoch: 761| train loss i: [0.18	1.76	5.3 	4.78	3.5 	1.54] test loss i: [0.16	0.78	5.72	5.44	4.25	1.82] | 
| 05-02 00:52:52 epoch: 762| time: 2.4s| train loss: +1.770e+01 | test loss: +1.628e+01 | 
| 05-02 00:52:52 epoch: 762| train loss i: [0.19	1.13	5.84	5.08	3.88	1.59] test loss i: [0.16	0.76	5.26	4.64	3.78	1.67] | 
| 05-02 00:52:54 epoch: 763| time: 2.5s| train loss: +1.782e+01 | test loss: +2.006e+01 | 
| 05-02 00:52:54 epoch: 763| train loss i: [0.18	0.99	6.14	5.05	3.89	1.56] test loss i: [0.69	1.51	6.15	4.71	4.78	2.21] | 
| 05-02 00:52:56 epoch: 764| time: 2.5s| train loss: +1.755e+01 | test loss: +1.812e+01 | 
| 05-02 00:52:56 epoch: 764| train loss i: [0.2 	0.86	5.87	5.19	3.88	1.56] test loss i: [0.24	0.59	6.04	4.98	4.01	2.25] | 
| 05-02 00:52:59 epoch: 765| time: 2.5s| train loss: +1.710e+01 | test loss: +1.657e+01 | 
| 05-02 00:52:59 epoch: 765| train loss i: [0.2 	1.62	5.52	4.7 	3.4 	1.66] test loss i: [0.2 	1.68	5.42	4.17	3.64	1.45] | 
| 05-02 00:53:01 epoch: 766| time: 2.5s| train loss: +1.739e+01 | test loss: +2.043e+01 | 
| 05-02 00:53:01 epoch: 766| train loss i: [0.17	1.52	5.6 	5.09	3.43	1.58] test loss i: [0.32	1.86	7.4 	5.51	3.82	1.52] | 
| 05-02 00:53:04 epoch: 767| time: 2.4s| train loss: +1.744e+01 | test loss: +2.102e+01 | 
| 05-02 00:53:04 epoch: 767| train loss i: [0.26	0.92	5.26	5.26	4.13	1.62] test loss i: [0.32	2.58	5.41	5.85	4.97	1.88] | 
| 05-02 00:53:06 epoch: 768| time: 2.5s| train loss: +1.885e+01 | test loss: +2.237e+01 | 
| 05-02 00:53:06 epoch: 768| train loss i: [0.38	1.85	5.75	5.32	3.87	1.68] test loss i: [0.13	2.41	6.3 	6.7 	4.54	2.29] | 
| 05-02 00:53:09 epoch: 769| time: 2.5s| train loss: +1.806e+01 | test loss: +2.528e+01 | 
| 05-02 00:53:09 epoch: 769| train loss i: [0.37	2.12	5.32	4.84	3.82	1.59] test loss i: [0.53	2.13	7.67	7.09	5.86	2.  ] | 
| 05-02 00:53:11 epoch: 770| time: 2.4s| train loss: +1.859e+01 | test loss: +1.762e+01 | 
| 05-02 00:53:11 epoch: 770| train loss i: [0.31	1.78	6.06	4.98	3.81	1.64] test loss i: [0.62	1.68	4.65	4.5 	4.58	1.58] | 
| 05-02 00:53:14 epoch: 771| time: 2.5s| train loss: +1.741e+01 | test loss: +1.635e+01 | 
| 05-02 00:53:14 epoch: 771| train loss i: [0.29	1.43	5.27	4.96	3.85	1.61] test loss i: [0.21	0.41	6.21	4.23	3.59	1.7 ] | 
| 05-02 00:53:16 epoch: 772| time: 2.5s| train loss: +1.712e+01 | test loss: +1.937e+01 | 
| 05-02 00:53:16 epoch: 772| train loss i: [0.21	1.19	5.67	4.63	3.85	1.58] test loss i: [0.36	1.9 	6.06	5.93	3.42	1.7 ] | 
| 05-02 00:53:19 epoch: 773| time: 2.5s| train loss: +1.781e+01 | test loss: +1.811e+01 | 
| 05-02 00:53:19 epoch: 773| train loss i: [0.25	1.86	5.36	4.86	3.95	1.53] test loss i: [0.82	1.33	5.55	5.46	3.47	1.49] | 
| 05-02 00:53:21 epoch: 774| time: 2.5s| train loss: +1.822e+01 | test loss: +2.116e+01 | 
| 05-02 00:53:21 epoch: 774| train loss i: [0.35	1.83	5.61	5.08	3.8 	1.56] test loss i: [0.86	1.02	6.55	6.58	4.52	1.64] | 
| 05-02 00:53:24 epoch: 775| time: 2.5s| train loss: +1.801e+01 | test loss: +2.402e+01 | 
| 05-02 00:53:24 epoch: 775| train loss i: [0.35	1.25	5.79	5.24	3.8 	1.58] test loss i: [0.39	4.17	5.94	6.22	5.23	2.07] | 
| 05-02 00:53:26 epoch: 776| time: 2.5s| train loss: +1.721e+01 | test loss: +2.015e+01 | 
| 05-02 00:53:26 epoch: 776| train loss i: [0.34	1.36	5.18	4.86	3.84	1.62] test loss i: [0.93	1.63	6.74	5.2 	3.62	2.02] | 
| 05-02 00:53:29 epoch: 777| time: 2.5s| train loss: +1.756e+01 | test loss: +1.861e+01 | 
| 05-02 00:53:29 epoch: 777| train loss i: [0.24	1.48	5.57	4.82	3.84	1.6 ] test loss i: [0.5 	0.88	6.7 	4.64	4.42	1.46] | 
| 05-02 00:53:31 epoch: 778| time: 2.5s| train loss: +1.914e+01 | test loss: +2.077e+01 | 
| 05-02 00:53:31 epoch: 778| train loss i: [0.41	1.88	6.14	5.  	4.11	1.6 ] test loss i: [1.01	1.42	5.98	6.08	4.08	2.2 ] | 
| 05-02 00:53:33 epoch: 779| time: 2.5s| train loss: +1.773e+01 | test loss: +1.756e+01 | 
| 05-02 00:53:33 epoch: 779| train loss i: [0.37	1.28	5.65	4.61	4.26	1.54] test loss i: [1.6 	0.53	4.32	6.19	3.47	1.45] | 
| 05-02 00:53:36 epoch: 780| time: 2.5s| train loss: +1.830e+01 | test loss: +2.412e+01 | 
| 05-02 00:53:36 epoch: 780| train loss i: [0.52	2.04	5.23	5.17	3.82	1.51] test loss i: [0.54	1.83	6.96	6.8 	6.  	2.01] | 
| 05-02 00:53:38 epoch: 781| time: 2.4s| train loss: +1.772e+01 | test loss: +2.023e+01 | 
| 05-02 00:53:38 epoch: 781| train loss i: [0.26	1.46	5.74	4.86	3.83	1.58] test loss i: [0.95	3.39	5.42	3.99	4.71	1.77] | 
| 05-02 00:53:41 epoch: 782| time: 2.4s| train loss: +1.700e+01 | test loss: +1.924e+01 | 
| 05-02 00:53:41 epoch: 782| train loss i: [0.33	0.96	5.51	4.82	3.81	1.57] test loss i: [0.11	2.42	5.86	5.03	4.32	1.49] | 
| 05-02 00:53:43 epoch: 783| time: 2.5s| train loss: +1.723e+01 | test loss: +1.648e+01 | 
| 05-02 00:53:43 epoch: 783| train loss i: [0.22	1.71	5.17	4.69	3.87	1.56] test loss i: [0.38	0.8 	5.31	4.77	3.55	1.66] | 
| 05-02 00:53:46 epoch: 784| time: 2.5s| train loss: +1.717e+01 | test loss: +1.761e+01 | 
| 05-02 00:53:46 epoch: 784| train loss i: [0.19	1.09	5.5 	4.98	3.89	1.52] test loss i: [0.14	1.7 	6.05	4.28	3.78	1.68] | 
| 05-02 00:53:48 epoch: 785| time: 2.5s| train loss: +1.776e+01 | test loss: +1.824e+01 | 
| 05-02 00:53:48 epoch: 785| train loss i: [0.19	0.92	5.59	5.28	4.23	1.54] test loss i: [0.66	0.92	5.19	5.16	4.67	1.63] | 
| 05-02 00:53:51 epoch: 786| time: 2.5s| train loss: +1.738e+01 | test loss: +1.921e+01 | 
| 05-02 00:53:51 epoch: 786| train loss i: [0.19	1.67	5.08	4.92	3.91	1.61] test loss i: [0.12	1.76	6.61	4.7 	4.22	1.78] | 
| 05-02 00:53:53 epoch: 787| time: 2.5s| train loss: +1.688e+01 | test loss: +2.639e+01 | 
| 05-02 00:53:53 epoch: 787| train loss i: [0.18	0.89	5.72	4.84	3.65	1.6 ] test loss i: [0.15	6.39	6.91	6.21	4.63	2.09] | 
| 05-02 00:53:56 epoch: 788| time: 2.5s| train loss: +1.664e+01 | test loss: +2.350e+01 | 
| 05-02 00:53:56 epoch: 788| train loss i: [0.13	1.01	5.24	4.94	3.66	1.66] test loss i: [0.19	0.65	8.71	6.74	5.21	1.99] | 
| 05-02 00:53:58 epoch: 789| time: 2.5s| train loss: +1.701e+01 | test loss: +1.721e+01 | 
| 05-02 00:53:58 epoch: 789| train loss i: [0.14	1.37	5.44	4.89	3.52	1.66] test loss i: [0.19	1.25	5.73	4.44	3.78	1.83] | 
| 05-02 00:54:01 epoch: 790| time: 2.5s| train loss: +1.776e+01 | test loss: +1.369e+01 | 
| 05-02 00:54:01 epoch: 790| train loss i: [0.19	1.95	5.17	4.81	4.03	1.61] test loss i: [0.12	1.13	3.76	3.73	3.4 	1.55] | 
| 05-02 00:54:03 epoch: 791| time: 2.5s| train loss: +1.723e+01 | test loss: +1.719e+01 | 
| 05-02 00:54:03 epoch: 791| train loss i: [0.35	1.07	5.73	4.68	3.79	1.6 ] test loss i: [0.11	1.84	4.73	4.71	4.17	1.62] | 
| 05-02 00:54:06 epoch: 792| time: 2.4s| train loss: +1.840e+01 | test loss: +1.574e+01 | 
| 05-02 00:54:06 epoch: 792| train loss i: [0.4 	1.5 	5.7 	5.27	3.93	1.6 ] test loss i: [0.65	1.18	4.31	4.75	3.21	1.64] | 
| 05-02 00:54:08 epoch: 793| time: 2.4s| train loss: +1.719e+01 | test loss: +1.814e+01 | 
| 05-02 00:54:08 epoch: 793| train loss i: [0.41	1.68	5.11	4.81	3.59	1.6 ] test loss i: [0.7 	0.85	5.89	4.93	4.  	1.78] | 
| 05-02 00:54:10 epoch: 794| time: 2.5s| train loss: +1.745e+01 | test loss: +2.292e+01 | 
| 05-02 00:54:10 epoch: 794| train loss i: [0.25	1.58	5.06	4.91	4.08	1.57] test loss i: [0.47	0.82	8.38	6.67	4.79	1.79] | 
| 05-02 00:54:13 epoch: 795| time: 2.5s| train loss: +1.692e+01 | test loss: +2.718e+01 | 
| 05-02 00:54:13 epoch: 795| train loss i: [0.18	1.71	4.99	4.8 	3.6 	1.65] test loss i: [0.26	4.2 	7.2 	8.18	5.33	2.02] | 
| 05-02 00:54:15 epoch: 796| time: 2.5s| train loss: +1.685e+01 | test loss: +1.460e+01 | 
| 05-02 00:54:15 epoch: 796| train loss i: [0.12	1.46	5.22	4.78	3.68	1.61] test loss i: [0.15	0.86	4.38	4.67	3.14	1.39] | 
| 05-02 00:54:18 epoch: 797| time: 2.5s| train loss: +1.694e+01 | test loss: +1.816e+01 | 
| 05-02 00:54:18 epoch: 797| train loss i: [0.15	1.31	5.17	4.62	4.09	1.61] test loss i: [0.59	1.76	5.83	4.94	3.22	1.82] | 
| 05-02 00:54:20 epoch: 798| time: 2.5s| train loss: +1.766e+01 | test loss: +1.905e+01 | 
| 05-02 00:54:20 epoch: 798| train loss i: [0.17	1.41	5.22	5.27	4.  	1.59] test loss i: [0.14	0.71	6.71	4.73	4.91	1.85] | 
| 05-02 00:54:23 epoch: 799| time: 2.5s| train loss: +1.679e+01 | test loss: +2.829e+01 | 
| 05-02 00:54:23 epoch: 799| train loss i: [0.17	1.77	4.9 	4.72	3.66	1.58] test loss i: [ 0.4 	 0.38	10.38	 7.68	 7.15	 2.31] | 
| 05-02 00:54:25 epoch: 800| time: 2.5s| train loss: +1.711e+01 | test loss: +1.757e+01 | 
| 05-02 00:54:25 epoch: 800| train loss i: [0.15	1.57	4.99	5.  	3.82	1.58] test loss i: [0.17	0.3 	7.2 	4.85	3.5 	1.55] | 
| 05-02 00:54:28 epoch: 801| time: 2.5s| train loss: +1.723e+01 | test loss: +1.530e+01 | 
| 05-02 00:54:28 epoch: 801| train loss i: [0.16	1.  	5.78	5.01	3.81	1.47] test loss i: [0.14	0.15	4.54	5.23	3.61	1.62] | 
| 05-02 00:54:30 epoch: 802| time: 2.5s| train loss: +1.818e+01 | test loss: +2.048e+01 | 
| 05-02 00:54:30 epoch: 802| train loss i: [0.22	1.47	5.88	4.93	4.1 	1.58] test loss i: [0.23	2.57	7.09	4.64	3.86	2.08] | 
| 05-02 00:54:33 epoch: 803| time: 2.5s| train loss: +1.792e+01 | test loss: +1.690e+01 | 
| 05-02 00:54:33 epoch: 803| train loss i: [0.25	1.6 	5.58	4.88	4.06	1.55] test loss i: [0.87	0.75	5.06	5.19	3.62	1.42] | 
| 05-02 00:54:35 epoch: 804| time: 2.5s| train loss: +1.787e+01 | test loss: +1.747e+01 | 
| 05-02 00:54:35 epoch: 804| train loss i: [0.18	1.49	5.97	4.74	3.85	1.63] test loss i: [0.62	1.23	5.03	4.51	4.14	1.94] | 
| 05-02 00:54:38 epoch: 805| time: 2.5s| train loss: +1.743e+01 | test loss: +2.124e+01 | 
| 05-02 00:54:38 epoch: 805| train loss i: [0.25	1.52	5.39	4.77	3.83	1.67] test loss i: [0.43	2.34	7.46	4.86	4.3 	1.84] | 
| 05-02 00:54:40 epoch: 806| time: 2.4s| train loss: +1.669e+01 | test loss: +1.634e+01 | 
| 05-02 00:54:40 epoch: 806| train loss i: [0.19	1.03	5.31	5.  	3.65	1.51] test loss i: [0.42	2.17	4.41	4.12	3.76	1.46] | 
| 05-02 00:54:43 epoch: 807| time: 2.4s| train loss: +1.849e+01 | test loss: +1.821e+01 | 
| 05-02 00:54:43 epoch: 807| train loss i: [0.24	1.85	5.54	5.34	3.93	1.59] test loss i: [0.11	2.4 	4.85	4.91	4.32	1.63] | 
| 05-02 00:54:45 epoch: 808| time: 2.5s| train loss: +1.611e+01 | test loss: +1.948e+01 | 
| 05-02 00:54:45 epoch: 808| train loss i: [0.15	1.3 	4.69	4.81	3.61	1.55] test loss i: [0.21	0.97	7.35	5.66	3.55	1.75] | 
| 05-02 00:54:47 epoch: 809| time: 2.5s| train loss: +1.731e+01 | test loss: +1.897e+01 | 
| 05-02 00:54:47 epoch: 809| train loss i: [0.23	1.31	5.5 	4.93	3.7 	1.64] test loss i: [0.32	2.03	6.45	4.73	3.69	1.75] | 
| 05-02 00:54:50 epoch: 810| time: 2.5s| train loss: +1.817e+01 | test loss: +1.376e+01 | 
| 05-02 00:54:50 epoch: 810| train loss i: [0.13	1.81	6.  	4.66	3.99	1.57] test loss i: [0.18	0.74	3.92	4.2 	3.17	1.55] | 
| 05-02 00:54:52 epoch: 811| time: 2.5s| train loss: +1.715e+01 | test loss: +2.186e+01 | 
| 05-02 00:54:52 epoch: 811| train loss i: [0.23	1.33	5.02	5.16	3.81	1.6 ] test loss i: [0.65	2.56	6.8 	5.44	4.35	2.07] | 
| 05-02 00:54:55 epoch: 812| time: 2.5s| train loss: +1.893e+01 | test loss: +1.759e+01 | 
| 05-02 00:54:55 epoch: 812| train loss i: [0.37	1.57	6.46	5.15	3.72	1.67] test loss i: [0.18	0.55	6.6 	4.64	3.89	1.73] | 
| 05-02 00:54:57 epoch: 813| time: 2.5s| train loss: +1.743e+01 | test loss: +2.480e+01 | 
| 05-02 00:54:57 epoch: 813| train loss i: [0.34	1.2 	5.76	4.87	3.73	1.54] test loss i: [1.04	1.51	8.97	6.44	4.91	1.93] | 
| 05-02 00:55:00 epoch: 814| time: 2.5s| train loss: +1.736e+01 | test loss: +2.032e+01 | 
| 05-02 00:55:00 epoch: 814| train loss i: [0.27	1.13	5.55	4.73	4.  	1.68] test loss i: [0.49	1.24	6.4 	5.57	4.75	1.87] | 
| 05-02 00:55:02 epoch: 815| time: 2.4s| train loss: +1.698e+01 | test loss: +2.481e+01 | 
| 05-02 00:55:02 epoch: 815| train loss i: [0.23	1.44	5.34	4.63	3.72	1.62] test loss i: [0.38	2.01	7.85	6.97	5.37	2.22] | 
| 05-02 00:55:05 epoch: 816| time: 2.5s| train loss: +1.768e+01 | test loss: +2.433e+01 | 
| 05-02 00:55:05 epoch: 816| train loss i: [0.27	1.26	5.81	4.68	4.1 	1.55] test loss i: [0.21	2.14	7.18	6.74	5.84	2.22] | 
| 05-02 00:55:07 epoch: 817| time: 2.5s| train loss: +1.690e+01 | test loss: +1.550e+01 | 
| 05-02 00:55:07 epoch: 817| train loss i: [0.21	1.05	5.46	4.97	3.64	1.58] test loss i: [0.18	1.45	5.47	3.82	3.16	1.42] | 
| 05-02 00:55:10 epoch: 818| time: 2.4s| train loss: +1.675e+01 | test loss: +1.812e+01 | 
| 05-02 00:55:10 epoch: 818| train loss i: [0.18	0.62	5.53	5.16	3.64	1.62] test loss i: [0.68	2.49	4.65	4.99	3.53	1.77] | 
| 05-02 00:55:12 epoch: 819| time: 2.5s| train loss: +1.752e+01 | test loss: +1.921e+01 | 
| 05-02 00:55:12 epoch: 819| train loss i: [0.32	1.07	5.91	4.94	3.72	1.57] test loss i: [0.21	1.4 	5.37	5.57	4.94	1.72] | 
| 05-02 00:55:15 epoch: 820| time: 2.4s| train loss: +1.842e+01 | test loss: +2.132e+01 | 
| 05-02 00:55:15 epoch: 820| train loss i: [0.29	1.59	6.17	4.82	3.9 	1.66] test loss i: [0.95	2.04	6.24	5.36	4.68	2.05] | 
| 05-02 00:55:17 epoch: 821| time: 2.4s| train loss: +1.718e+01 | test loss: +2.505e+01 | 
| 05-02 00:55:17 epoch: 821| train loss i: [0.38	0.94	5.65	4.83	3.84	1.55] test loss i: [1.44	1.2 	7.99	6.71	5.82	1.9 ] | 
| 05-02 00:55:20 epoch: 822| time: 2.5s| train loss: +1.752e+01 | test loss: +2.825e+01 | 
| 05-02 00:55:20 epoch: 822| train loss i: [0.37	1.34	5.72	4.63	3.98	1.49] test loss i: [0.87	6.67	9.85	5.17	3.67	2.02] | 
| 05-02 00:55:22 epoch: 823| time: 2.5s| train loss: +1.818e+01 | test loss: +2.166e+01 | 
| 05-02 00:55:22 epoch: 823| train loss i: [0.35	1.29	6.07	4.72	4.17	1.59] test loss i: [0.34	1.73	6.62	5.97	4.84	2.16] | 
| 05-02 00:55:24 epoch: 824| time: 2.5s| train loss: +1.658e+01 | test loss: +1.692e+01 | 
| 05-02 00:55:24 epoch: 824| train loss i: [0.32	1.24	5.13	4.72	3.59	1.58] test loss i: [0.2 	1.96	5.29	4.43	3.33	1.72] | 
| 05-02 00:55:27 epoch: 825| time: 2.5s| train loss: +1.758e+01 | test loss: +1.656e+01 | 
| 05-02 00:55:27 epoch: 825| train loss i: [0.36	1.69	5.66	4.69	3.7 	1.47] test loss i: [0.48	1.39	4.84	5.05	3.31	1.48] | 
| 05-02 00:55:29 epoch: 826| time: 2.4s| train loss: +1.728e+01 | test loss: +1.857e+01 | 
| 05-02 00:55:29 epoch: 826| train loss i: [0.41	1.52	5.34	4.64	3.72	1.64] test loss i: [0.46	2.08	6.33	4.15	3.56	1.98] | 
| 05-02 00:55:32 epoch: 827| time: 2.5s| train loss: +1.821e+01 | test loss: +1.869e+01 | 
| 05-02 00:55:32 epoch: 827| train loss i: [0.45	1.74	5.89	4.7 	3.91	1.52] test loss i: [0.5 	1.14	5.83	5.15	4.18	1.89] | 
| 05-02 00:55:34 epoch: 828| time: 2.4s| train loss: +1.756e+01 | test loss: +1.975e+01 | 
| 05-02 00:55:34 epoch: 828| train loss i: [0.39	1.43	5.58	4.78	3.8 	1.59] test loss i: [0.28	0.93	6.87	5.68	4.32	1.68] | 
| 05-02 00:55:37 epoch: 829| time: 2.4s| train loss: +1.788e+01 | test loss: +2.892e+01 | 
| 05-02 00:55:37 epoch: 829| train loss i: [0.36	1.56	5.31	5.19	3.87	1.59] test loss i: [1.25	2.86	9.04	7.87	5.59	2.3 ] | 
| 05-02 00:55:39 epoch: 830| time: 2.5s| train loss: +1.735e+01 | test loss: +2.506e+01 | 
| 05-02 00:55:39 epoch: 830| train loss i: [0.34	1.63	5.31	4.76	3.81	1.5 ] test loss i: [0.36	1.61	8.89	6.28	5.99	1.92] | 
| 05-02 00:55:42 epoch: 831| time: 2.4s| train loss: +1.748e+01 | test loss: +1.706e+01 | 
| 05-02 00:55:42 epoch: 831| train loss i: [0.28	1.29	5.47	4.97	3.9 	1.56] test loss i: [0.29	0.79	5.11	5.  	4.04	1.84] | 
| 05-02 00:55:44 epoch: 832| time: 2.4s| train loss: +1.792e+01 | test loss: +1.830e+01 | 
| 05-02 00:55:44 epoch: 832| train loss i: [0.23	1.61	5.95	4.74	3.89	1.5 ] test loss i: [0.28	0.9 	5.6 	6.06	3.76	1.7 ] | 
| 05-02 00:55:47 epoch: 833| time: 2.5s| train loss: +1.701e+01 | test loss: +1.775e+01 | 
| 05-02 00:55:47 epoch: 833| train loss i: [0.2 	1.65	5.02	4.86	3.76	1.52] test loss i: [0.51	2.21	4.26	4.44	4.27	2.06] | 
| 05-02 00:55:49 epoch: 834| time: 2.5s| train loss: +1.797e+01 | test loss: +1.753e+01 | 
| 05-02 00:55:49 epoch: 834| train loss i: [0.32	1.47	5.67	5.3 	3.65	1.56] test loss i: [0.14	0.46	5.98	4.8 	4.61	1.54] | 
| 05-02 00:55:52 epoch: 835| time: 2.5s| train loss: +1.805e+01 | test loss: +2.407e+01 | 
| 05-02 00:55:52 epoch: 835| train loss i: [0.25	1.95	5.51	5.1 	3.65	1.6 ] test loss i: [0.65	1.51	7.87	6.17	5.56	2.31] | 
| 05-02 00:55:54 epoch: 836| time: 2.5s| train loss: +1.666e+01 | test loss: +2.236e+01 | 
| 05-02 00:55:54 epoch: 836| train loss i: [0.24	1.27	5.2 	4.69	3.75	1.51] test loss i: [0.33	3.71	5.87	5.46	4.99	1.99] | 
| 05-02 00:55:56 epoch: 837| time: 2.4s| train loss: +1.709e+01 | test loss: +1.885e+01 | 
| 05-02 00:55:56 epoch: 837| train loss i: [0.16	1.32	5.33	4.64	4.07	1.56] test loss i: [0.3 	1.19	7.46	4.55	3.6 	1.75] | 
| 05-02 00:55:59 epoch: 838| time: 2.5s| train loss: +1.742e+01 | test loss: +2.058e+01 | 
| 05-02 00:55:59 epoch: 838| train loss i: [0.09	1.44	5.87	4.7 	3.73	1.59] test loss i: [0.32	1.53	6.76	5.56	4.52	1.89] | 
| 05-02 00:56:01 epoch: 839| time: 2.5s| train loss: +1.647e+01 | test loss: +1.440e+01 | 
| 05-02 00:56:01 epoch: 839| train loss i: [0.16	0.89	5.58	4.56	3.69	1.6 ] test loss i: [0.18	0.45	4.47	4.31	3.58	1.41] | 
| 05-02 00:56:04 epoch: 840| time: 2.5s| train loss: +1.743e+01 | test loss: +1.825e+01 | 
| 05-02 00:56:04 epoch: 840| train loss i: [0.33	1.29	5.67	4.73	3.9 	1.51] test loss i: [0.27	1.09	6.92	5.25	3.18	1.54] | 
| 05-02 00:56:06 epoch: 841| time: 2.5s| train loss: +1.668e+01 | test loss: +1.357e+01 | 
| 05-02 00:56:06 epoch: 841| train loss i: [0.29	0.69	5.7 	4.64	3.72	1.64] test loss i: [0.25	0.35	4.32	3.99	3.17	1.49] | 
| 05-02 00:56:09 epoch: 842| time: 2.4s| train loss: +1.810e+01 | test loss: +1.745e+01 | 
| 05-02 00:56:09 epoch: 842| train loss i: [0.22	1.91	5.78	4.76	3.88	1.55] test loss i: [0.44	2.71	4.77	4.67	3.25	1.61] | 
| 05-02 00:56:11 epoch: 843| time: 2.4s| train loss: +1.789e+01 | test loss: +1.802e+01 | 
| 05-02 00:56:11 epoch: 843| train loss i: [0.27	1.7 	5.52	4.87	3.93	1.61] test loss i: [0.33	0.82	6.26	5.03	3.65	1.93] | 
| 05-02 00:56:14 epoch: 844| time: 2.4s| train loss: +1.731e+01 | test loss: +1.910e+01 | 
| 05-02 00:56:14 epoch: 844| train loss i: [0.2 	0.95	5.43	5.23	3.93	1.57] test loss i: [0.34	1.95	5.64	5.33	3.97	1.88] | 
| 05-02 00:56:16 epoch: 845| time: 2.5s| train loss: +1.701e+01 | test loss: +1.910e+01 | 
| 05-02 00:56:16 epoch: 845| train loss i: [0.35	1.25	5.17	4.79	3.86	1.6 ] test loss i: [0.32	2.28	5.62	4.82	4.12	1.95] | 
| 05-02 00:56:19 epoch: 846| time: 2.5s| train loss: +1.791e+01 | test loss: +1.960e+01 | 
| 05-02 00:56:19 epoch: 846| train loss i: [0.18	1.56	5.41	4.99	4.09	1.66] test loss i: [0.21	2.61	5.49	5.76	3.77	1.77] | 
| 05-02 00:56:21 epoch: 847| time: 2.4s| train loss: +1.700e+01 | test loss: +2.194e+01 | 
| 05-02 00:56:21 epoch: 847| train loss i: [0.18	1.25	5.35	4.8 	3.82	1.61] test loss i: [0.17	2.92	6.47	5.87	4.56	1.94] | 
| 05-02 00:56:23 epoch: 848| time: 2.5s| train loss: +1.754e+01 | test loss: +2.022e+01 | 
| 05-02 00:56:23 epoch: 848| train loss i: [0.19	2.2 	5.47	4.43	3.62	1.63] test loss i: [0.28	2.06	5.25	6.02	4.43	2.19] | 
| 05-02 00:56:26 epoch: 849| time: 2.4s| train loss: +1.784e+01 | test loss: +1.642e+01 | 
| 05-02 00:56:26 epoch: 849| train loss i: [0.19	1.09	5.92	4.83	4.21	1.6 ] test loss i: [0.35	1.1 	4.88	4.31	4.17	1.61] | 
| 05-02 00:56:28 epoch: 850| time: 2.4s| train loss: +1.798e+01 | test loss: +1.910e+01 | 
| 05-02 00:56:28 epoch: 850| train loss i: [0.2 	1.38	6.04	4.79	3.98	1.59] test loss i: [0.14	0.54	7.57	4.69	4.5 	1.67] | 
| 05-02 00:56:31 epoch: 851| time: 2.5s| train loss: +1.770e+01 | test loss: +1.548e+01 | 
| 05-02 00:56:31 epoch: 851| train loss i: [0.16	1.87	5.65	4.64	3.81	1.57] test loss i: [0.22	1.15	3.82	4.79	3.86	1.66] | 
| 05-02 00:56:33 epoch: 852| time: 2.5s| train loss: +1.734e+01 | test loss: +1.905e+01 | 
| 05-02 00:56:33 epoch: 852| train loss i: [0.2 	1.37	5.89	4.61	3.62	1.65] test loss i: [0.14	1.12	7.13	5.15	3.99	1.52] | 
| 05-02 00:56:36 epoch: 853| time: 2.5s| train loss: +1.714e+01 | test loss: +1.869e+01 | 
| 05-02 00:56:36 epoch: 853| train loss i: [0.12	1.3 	5.66	4.73	3.63	1.69] test loss i: [0.28	0.69	7.08	4.55	4.27	1.83] | 
| 05-02 00:56:38 epoch: 854| time: 2.5s| train loss: +1.723e+01 | test loss: +1.805e+01 | 
| 05-02 00:56:38 epoch: 854| train loss i: [0.16	1.39	5.63	4.78	3.76	1.51] test loss i: [0.17	0.7 	5.93	5.06	4.29	1.89] | 
| 05-02 00:56:41 epoch: 855| time: 2.4s| train loss: +1.754e+01 | test loss: +1.933e+01 | 
| 05-02 00:56:41 epoch: 855| train loss i: [0.17	1.65	5.88	4.82	3.5 	1.52] test loss i: [0.32	1.37	5.99	5.53	3.97	2.15] | 
| 05-02 00:56:43 epoch: 856| time: 2.5s| train loss: +1.764e+01 | test loss: +2.170e+01 | 
| 05-02 00:56:43 epoch: 856| train loss i: [0.13	1.56	5.61	4.81	3.93	1.6 ] test loss i: [0.33	1.22	6.96	6.27	5.09	1.82] | 
| 05-02 00:56:46 epoch: 857| time: 2.4s| train loss: +1.666e+01 | test loss: +2.003e+01 | 
| 05-02 00:56:46 epoch: 857| train loss i: [0.14	1.36	5.4 	4.56	3.59	1.61] test loss i: [0.39	2.13	5.61	4.9 	4.66	2.35] | 
| 05-02 00:56:48 epoch: 858| time: 2.4s| train loss: +1.716e+01 | test loss: +1.855e+01 | 
| 05-02 00:56:48 epoch: 858| train loss i: [0.12	1.44	5.58	4.86	3.56	1.6 ] test loss i: [0.1 	1.19	6.76	4.86	3.57	2.07] | 
| 05-02 00:56:50 epoch: 859| time: 2.5s| train loss: +1.679e+01 | test loss: +1.615e+01 | 
| 05-02 00:56:50 epoch: 859| train loss i: [0.18	1.12	5.72	4.44	3.7 	1.63] test loss i: [0.16	1.07	4.46	4.33	4.53	1.61] | 
| 05-02 00:56:53 epoch: 860| time: 2.4s| train loss: +1.734e+01 | test loss: +1.679e+01 | 
| 05-02 00:56:53 epoch: 860| train loss i: [0.11	1.26	5.26	5.  	4.19	1.5 ] test loss i: [0.1 	1.02	5.03	5.17	3.68	1.78] | 
| 05-02 00:56:55 epoch: 861| time: 2.4s| train loss: +1.758e+01 | test loss: +2.203e+01 | 
| 05-02 00:56:55 epoch: 861| train loss i: [0.2 	1.31	5.27	5.09	4.19	1.52] test loss i: [0.25	2.14	7.13	6.35	4.48	1.68] | 
| 05-02 00:56:58 epoch: 862| time: 2.4s| train loss: +1.736e+01 | test loss: +1.613e+01 | 
| 05-02 00:56:58 epoch: 862| train loss i: [0.25	1.67	5.29	4.6 	3.95	1.6 ] test loss i: [0.28	0.73	5.14	4.53	3.7 	1.75] | 
| 05-02 00:57:00 epoch: 863| time: 2.4s| train loss: +1.800e+01 | test loss: +1.467e+01 | 
| 05-02 00:57:00 epoch: 863| train loss i: [0.42	1.57	5.54	4.85	4.1 	1.52] test loss i: [0.34	1.54	3.48	4.12	3.58	1.61] | 
| 05-02 00:57:03 epoch: 864| time: 2.5s| train loss: +1.761e+01 | test loss: +1.962e+01 | 
| 05-02 00:57:03 epoch: 864| train loss i: [0.43	1.38	5.79	4.84	3.68	1.49] test loss i: [0.47	1.83	7.16	4.62	4.  	1.53] | 
| 05-02 00:57:05 epoch: 865| time: 2.5s| train loss: +1.787e+01 | test loss: +1.763e+01 | 
| 05-02 00:57:05 epoch: 865| train loss i: [0.44	1.89	5.64	4.53	3.81	1.57] test loss i: [0.6 	1.04	5.82	5.15	3.38	1.64] | 
| 05-02 00:57:08 epoch: 866| time: 2.4s| train loss: +1.702e+01 | test loss: +1.755e+01 | 
| 05-02 00:57:08 epoch: 866| train loss i: [0.44	1.34	5.05	4.66	4.  	1.52] test loss i: [0.46	0.59	6.46	4.3 	3.71	2.03] | 
| 05-02 00:57:10 epoch: 867| time: 2.4s| train loss: +1.823e+01 | test loss: +2.530e+01 | 
| 05-02 00:57:10 epoch: 867| train loss i: [0.29	1.56	5.8 	4.91	4.03	1.63] test loss i: [0.64	1.77	8.16	7.17	5.43	2.13] | 
| 05-02 00:57:12 epoch: 868| time: 2.4s| train loss: +1.775e+01 | test loss: +1.898e+01 | 
| 05-02 00:57:12 epoch: 868| train loss i: [0.28	1.64	5.21	4.99	4.08	1.55] test loss i: [0.36	3.29	5.22	3.91	4.58	1.64] | 
| 05-02 00:57:15 epoch: 869| time: 2.4s| train loss: +1.753e+01 | test loss: +2.797e+01 | 
| 05-02 00:57:15 epoch: 869| train loss i: [0.31	1.69	5.15	4.97	3.88	1.52] test loss i: [2.33	4.91	6.49	6.58	5.58	2.08] | 
| 05-02 00:57:17 epoch: 870| time: 2.4s| train loss: +1.754e+01 | test loss: +1.640e+01 | 
| 05-02 00:57:17 epoch: 870| train loss i: [0.32	1.63	5.29	4.6 	4.07	1.63] test loss i: [0.19	1.21	5.51	4.75	3.26	1.49] | 
| 05-02 00:57:20 epoch: 871| time: 2.4s| train loss: +1.724e+01 | test loss: +1.913e+01 | 
| 05-02 00:57:20 epoch: 871| train loss i: [0.18	1.03	5.43	4.95	4.08	1.57] test loss i: [1.07	0.68	6.76	5.3 	3.76	1.56] | 
| 05-02 00:57:22 epoch: 872| time: 2.4s| train loss: +1.767e+01 | test loss: +1.558e+01 | 
| 05-02 00:57:22 epoch: 872| train loss i: [0.33	1.69	5.45	4.95	3.6 	1.64] test loss i: [0.62	1.06	4.3 	4.89	3.15	1.56] | 
| 05-02 00:57:25 epoch: 873| time: 2.4s| train loss: +1.770e+01 | test loss: +2.176e+01 | 
| 05-02 00:57:25 epoch: 873| train loss i: [0.2 	1.45	5.84	4.58	3.99	1.64] test loss i: [0.21	1.22	8.11	5.72	4.5 	2.  ] | 
| 05-02 00:57:27 epoch: 874| time: 2.5s| train loss: +1.716e+01 | test loss: +1.929e+01 | 
| 05-02 00:57:27 epoch: 874| train loss i: [0.26	1.24	5.02	4.86	4.1 	1.67] test loss i: [0.62	1.77	6.28	4.95	3.86	1.79] | 
| 05-02 00:57:29 epoch: 875| time: 2.4s| train loss: +1.743e+01 | test loss: +1.706e+01 | 
| 05-02 00:57:29 epoch: 875| train loss i: [0.18	1.29	5.6 	4.74	3.98	1.64] test loss i: [0.32	1.04	5.71	5.01	3.33	1.66] | 
| 05-02 00:57:32 epoch: 876| time: 2.4s| train loss: +1.726e+01 | test loss: +2.271e+01 | 
| 05-02 00:57:32 epoch: 876| train loss i: [0.2 	1.44	5.35	4.84	3.91	1.52] test loss i: [0.4 	1.43	6.49	6.36	5.18	2.85] | 
| 05-02 00:57:34 epoch: 877| time: 2.4s| train loss: +1.794e+01 | test loss: +1.788e+01 | 
| 05-02 00:57:34 epoch: 877| train loss i: [0.2 	1.69	5.73	4.84	3.89	1.6 ] test loss i: [0.17	1.1 	5.87	5.62	3.01	2.11] | 
| 05-02 00:57:37 epoch: 878| time: 2.4s| train loss: +1.778e+01 | test loss: +2.112e+01 | 
| 05-02 00:57:37 epoch: 878| train loss i: [0.15	1.59	5.84	4.79	3.83	1.58] test loss i: [0.51	0.62	7.74	5.5 	4.46	2.29] | 
| 05-02 00:57:39 epoch: 879| time: 2.4s| train loss: +1.598e+01 | test loss: +1.931e+01 | 
| 05-02 00:57:39 epoch: 879| train loss i: [0.14	1.21	4.96	4.48	3.59	1.61] test loss i: [0.16	3.35	5.27	5.04	3.9 	1.58] | 
| 05-02 00:57:42 epoch: 880| time: 2.5s| train loss: +1.692e+01 | test loss: +1.806e+01 | 
| 05-02 00:57:42 epoch: 880| train loss i: [0.21	1.18	5.38	4.78	3.83	1.54] test loss i: [0.31	1.34	5.51	4.89	4.17	1.83] | 
| 05-02 00:57:44 epoch: 881| time: 2.4s| train loss: +1.839e+01 | test loss: +1.831e+01 | 
| 05-02 00:57:44 epoch: 881| train loss i: [0.16	1.62	5.87	5.09	4.  	1.64] test loss i: [0.17	0.93	5.73	5.35	4.07	2.06] | 
| 05-02 00:57:46 epoch: 882| time: 2.4s| train loss: +1.761e+01 | test loss: +2.313e+01 | 
| 05-02 00:57:46 epoch: 882| train loss i: [0.15	1.71	5.5 	4.86	3.87	1.52] test loss i: [0.15	1.68	8.21	6.  	5.2 	1.89] | 
| 05-02 00:57:49 epoch: 883| time: 2.4s| train loss: +1.668e+01 | test loss: +1.509e+01 | 
| 05-02 00:57:49 epoch: 883| train loss i: [0.19	1.22	4.9 	4.84	3.95	1.57] test loss i: [0.2 	1.91	4.05	4.58	2.85	1.49] | 
| 05-02 00:57:51 epoch: 884| time: 2.5s| train loss: +1.787e+01 | test loss: +1.913e+01 | 
| 05-02 00:57:51 epoch: 884| train loss i: [0.14	1.78	5.27	5.  	4.13	1.55] test loss i: [0.23	1.24	6.06	5.23	4.68	1.69] | 
| 05-02 00:57:54 epoch: 885| time: 2.4s| train loss: +1.670e+01 | test loss: +1.944e+01 | 
| 05-02 00:57:54 epoch: 885| train loss i: [0.21	1.32	5.14	4.79	3.62	1.62] test loss i: [0.32	1.61	6.32	5.29	4.24	1.66] | 
| 05-02 00:57:56 epoch: 886| time: 2.5s| train loss: +1.881e+01 | test loss: +1.797e+01 | 
| 05-02 00:57:56 epoch: 886| train loss i: [0.15	1.81	6.49	4.63	4.1 	1.63] test loss i: [0.16	0.83	5.61	5.12	4.49	1.76] | 
| 05-02 00:57:59 epoch: 887| time: 2.5s| train loss: +1.689e+01 | test loss: +1.694e+01 | 
| 05-02 00:57:59 epoch: 887| train loss i: [0.15	1.08	5.34	4.95	3.9 	1.48] test loss i: [0.18	1.63	5.3 	4.77	3.53	1.53] | 
| 05-02 00:58:01 epoch: 888| time: 2.4s| train loss: +1.725e+01 | test loss: +1.724e+01 | 
| 05-02 00:58:01 epoch: 888| train loss i: [0.21	1.34	5.56	5.12	3.57	1.44] test loss i: [0.5 	0.44	5.47	5.45	3.66	1.73] | 
| 05-02 00:58:04 epoch: 889| time: 2.4s| train loss: +1.634e+01 | test loss: +1.731e+01 | 
| 05-02 00:58:04 epoch: 889| train loss i: [0.24	1.34	4.96	4.36	3.85	1.59] test loss i: [0.43	2.05	5.46	3.89	3.68	1.81] | 
| 05-02 00:58:06 epoch: 890| time: 2.4s| train loss: +1.721e+01 | test loss: +2.023e+01 | 
| 05-02 00:58:06 epoch: 890| train loss i: [0.22	0.91	5.51	5.03	4.03	1.51] test loss i: [0.2 	0.56	8.08	5.34	4.18	1.87] | 
| 05-02 00:58:09 epoch: 891| time: 2.5s| train loss: +1.789e+01 | test loss: +1.541e+01 | 
| 05-02 00:58:09 epoch: 891| train loss i: [0.14	1.67	5.78	4.9 	3.74	1.66] test loss i: [0.11	1.6 	4.34	3.98	3.78	1.61] | 
| 05-02 00:58:11 epoch: 892| time: 2.4s| train loss: +1.782e+01 | test loss: +2.223e+01 | 
| 05-02 00:58:11 epoch: 892| train loss i: [0.23	1.6 	5.25	5.21	3.98	1.56] test loss i: [0.3 	2.72	6.82	5.73	4.59	2.07] | 
| 05-02 00:58:13 epoch: 893| time: 2.4s| train loss: +1.821e+01 | test loss: +1.772e+01 | 
| 05-02 00:58:13 epoch: 893| train loss i: [0.17	2.11	5.55	5.04	3.77	1.58] test loss i: [0.84	1.12	4.86	5.13	4.18	1.58] | 
| 05-02 00:58:16 epoch: 894| time: 2.4s| train loss: +1.734e+01 | test loss: +1.888e+01 | 
| 05-02 00:58:16 epoch: 894| train loss i: [0.17	1.02	5.31	5.16	4.06	1.62] test loss i: [0.32	1.73	5.77	5.37	4.03	1.67] | 
| 05-02 00:58:18 epoch: 895| time: 2.4s| train loss: +1.673e+01 | test loss: +2.157e+01 | 
| 05-02 00:58:18 epoch: 895| train loss i: [0.09	1.23	5.27	4.69	3.81	1.64] test loss i: [0.17	2.18	6.2 	6.22	4.72	2.07] | 
| 05-02 00:58:21 epoch: 896| time: 2.4s| train loss: +1.666e+01 | test loss: +2.072e+01 | 
| 05-02 00:58:21 epoch: 896| train loss i: [0.13	1.01	5.51	4.75	3.65	1.61] test loss i: [0.26	0.53	6.87	6.4 	4.68	1.97] | 
| 05-02 00:58:23 epoch: 897| time: 2.4s| train loss: +1.721e+01 | test loss: +1.731e+01 | 
| 05-02 00:58:23 epoch: 897| train loss i: [0.15	1.28	5.45	4.85	3.89	1.6 ] test loss i: [0.3 	1.6 	4.73	5.38	3.55	1.75] | 
| 05-02 00:58:26 epoch: 898| time: 2.4s| train loss: +1.846e+01 | test loss: +1.827e+01 | 
| 05-02 00:58:26 epoch: 898| train loss i: [0.13	2.41	5.8 	4.9 	3.66	1.56] test loss i: [0.2 	0.83	5.87	4.44	5.02	1.92] | 
| 05-02 00:58:28 epoch: 899| time: 2.4s| train loss: +1.806e+01 | test loss: +1.775e+01 | 
| 05-02 00:58:28 epoch: 899| train loss i: [0.14	2.17	5.62	4.63	3.85	1.64] test loss i: [0.19	0.99	5.51	5.42	3.97	1.68] | 
| 05-02 00:58:30 epoch: 900| time: 2.5s| train loss: +1.769e+01 | test loss: +1.812e+01 | 
| 05-02 00:58:30 epoch: 900| train loss i: [0.14	1.57	5.79	4.69	3.93	1.57] test loss i: [0.16	1.48	5.29	5.64	3.63	1.91] | 
| 05-02 00:58:33 epoch: 901| time: 2.5s| train loss: +1.865e+01 | test loss: +1.511e+01 | 
| 05-02 00:58:33 epoch: 901| train loss i: [0.16	1.8 	5.57	5.58	4.  	1.55] test loss i: [0.18	0.91	4.85	3.87	3.73	1.57] | 
| 05-02 00:58:35 epoch: 902| time: 2.4s| train loss: +1.762e+01 | test loss: +1.788e+01 | 
| 05-02 00:58:35 epoch: 902| train loss i: [0.19	1.07	5.66	5.08	4.  	1.61] test loss i: [0.09	0.54	6.39	5.36	3.79	1.72] | 
| 05-02 00:58:38 epoch: 903| time: 2.4s| train loss: +1.636e+01 | test loss: +1.689e+01 | 
| 05-02 00:58:38 epoch: 903| train loss i: [0.22	1.06	5.09	4.66	3.78	1.55] test loss i: [0.17	2.27	4.97	4.74	3.14	1.6 ] | 
| 05-02 00:58:40 epoch: 904| time: 2.5s| train loss: +1.733e+01 | test loss: +1.651e+01 | 
| 05-02 00:58:40 epoch: 904| train loss i: [0.18	1.48	5.1 	4.98	4.04	1.55] test loss i: [1.05	0.3 	5.34	4.75	3.26	1.81] | 
| 05-02 00:58:43 epoch: 905| time: 2.4s| train loss: +1.766e+01 | test loss: +1.820e+01 | 
| 05-02 00:58:43 epoch: 905| train loss i: [0.22	1.8 	5.48	4.92	3.66	1.58] test loss i: [0.34	1.03	6.09	4.83	4.19	1.72] | 
| 05-02 00:58:45 epoch: 906| time: 2.5s| train loss: +1.786e+01 | test loss: +1.757e+01 | 
| 05-02 00:58:45 epoch: 906| train loss i: [0.15	1.42	5.67	5.08	3.96	1.58] test loss i: [0.17	0.87	4.98	4.98	4.36	2.19] | 
| 05-02 00:58:48 epoch: 907| time: 2.5s| train loss: +1.757e+01 | test loss: +1.635e+01 | 
| 05-02 00:58:48 epoch: 907| train loss i: [0.11	1.55	5.45	4.93	3.92	1.61] test loss i: [0.38	2.  	4.48	4.44	3.56	1.49] | 
| 05-02 00:58:50 epoch: 908| time: 2.5s| train loss: +1.737e+01 | test loss: +1.798e+01 | 
| 05-02 00:58:50 epoch: 908| train loss i: [0.18	1.8 	5.14	4.71	4.05	1.5 ] test loss i: [0.76	1.14	5.48	5.07	3.89	1.64] | 
| 05-02 00:58:53 epoch: 909| time: 2.5s| train loss: +1.698e+01 | test loss: +1.583e+01 | 
| 05-02 00:58:53 epoch: 909| train loss i: [0.23	1.35	5.24	4.63	3.87	1.66] test loss i: [0.15	0.45	4.83	5.49	3.44	1.47] | 
| 05-02 00:58:55 epoch: 910| time: 2.4s| train loss: +1.712e+01 | test loss: +2.386e+01 | 
| 05-02 00:58:55 epoch: 910| train loss i: [0.18	1.22	5.6 	4.83	3.7 	1.6 ] test loss i: [0.55	1.86	6.74	6.94	5.44	2.33] | 
| 05-02 00:58:57 epoch: 911| time: 2.4s| train loss: +1.754e+01 | test loss: +1.610e+01 | 
| 05-02 00:58:57 epoch: 911| train loss i: [0.18	1.61	6.06	4.71	3.47	1.51] test loss i: [1.05	0.77	4.5 	4.48	3.69	1.61] | 
| 05-02 00:59:00 epoch: 912| time: 2.5s| train loss: +1.720e+01 | test loss: +2.332e+01 | 
| 05-02 00:59:00 epoch: 912| train loss i: [0.19	1.46	5.24	4.8 	4.  	1.51] test loss i: [0.28	2.33	7.54	6.53	4.51	2.13] | 
| 05-02 00:59:02 epoch: 913| time: 2.5s| train loss: +1.785e+01 | test loss: +2.223e+01 | 
| 05-02 00:59:02 epoch: 913| train loss i: [0.15	1.73	5.33	5.13	3.91	1.62] test loss i: [0.58	1.59	6.71	5.82	5.66	1.87] | 
| 05-02 00:59:05 epoch: 914| time: 2.4s| train loss: +1.675e+01 | test loss: +2.193e+01 | 
| 05-02 00:59:05 epoch: 914| train loss i: [0.22	1.19	5.34	4.68	3.78	1.54] test loss i: [0.2 	3.41	7.13	4.98	4.36	1.85] | 
| 05-02 00:59:07 epoch: 915| time: 2.4s| train loss: +1.720e+01 | test loss: +1.586e+01 | 
| 05-02 00:59:07 epoch: 915| train loss i: [0.13	1.04	5.22	5.14	4.05	1.63] test loss i: [0.46	1.42	5.28	4.24	2.89	1.56] | 
| 05-02 00:59:10 epoch: 916| time: 2.4s| train loss: +1.801e+01 | test loss: +1.660e+01 | 
| 05-02 00:59:10 epoch: 916| train loss i: [0.25	2.16	5.31	4.82	3.82	1.64] test loss i: [0.37	0.56	5.65	4.69	3.71	1.62] | 
| 05-02 00:59:12 epoch: 917| time: 2.5s| train loss: +1.666e+01 | test loss: +2.027e+01 | 
| 05-02 00:59:12 epoch: 917| train loss i: [0.12	0.93	5.14	4.95	3.98	1.53] test loss i: [0.1 	2.44	6.45	4.99	4.23	2.06] | 
| 05-02 00:59:15 epoch: 918| time: 2.4s| train loss: +1.746e+01 | test loss: +1.852e+01 | 
| 05-02 00:59:15 epoch: 918| train loss i: [0.19	1.06	5.68	5.05	3.91	1.58] test loss i: [0.21	3.42	5.08	4.3 	4.  	1.52] | 
| 05-02 00:59:17 epoch: 919| time: 2.4s| train loss: +1.780e+01 | test loss: +2.079e+01 | 
| 05-02 00:59:17 epoch: 919| train loss i: [0.2 	1.72	5.69	4.75	3.87	1.57] test loss i: [0.15	0.41	7.96	5.85	4.4 	2.03] | 
| 05-02 00:59:19 epoch: 920| time: 2.4s| train loss: +1.811e+01 | test loss: +2.046e+01 | 
| 05-02 00:59:19 epoch: 920| train loss i: [0.13	1.79	5.9 	4.9 	3.84	1.55] test loss i: [0.35	1.59	6.62	4.94	5.07	1.88] | 
| 05-02 00:59:22 epoch: 921| time: 2.4s| train loss: +1.714e+01 | test loss: +2.661e+01 | 
| 05-02 00:59:22 epoch: 921| train loss i: [0.29	1.23	5.31	4.88	3.84	1.59] test loss i: [1.16	2.47	9.55	6.51	4.75	2.19] | 
| 05-02 00:59:24 epoch: 922| time: 2.5s| train loss: +1.754e+01 | test loss: +2.180e+01 | 
| 05-02 00:59:24 epoch: 922| train loss i: [0.23	1.  	5.82	5.14	3.73	1.62] test loss i: [0.78	0.87	7.09	6.28	4.58	2.21] | 
| 05-02 00:59:27 epoch: 923| time: 2.4s| train loss: +1.773e+01 | test loss: +1.824e+01 | 
| 05-02 00:59:27 epoch: 923| train loss i: [0.16	1.58	5.98	4.49	3.96	1.56] test loss i: [0.26	2.11	6.52	3.99	3.55	1.81] | 
| 05-02 00:59:29 epoch: 924| time: 2.4s| train loss: +1.767e+01 | test loss: +2.374e+01 | 
| 05-02 00:59:29 epoch: 924| train loss i: [0.12	1.47	5.58	4.88	4.01	1.61] test loss i: [0.64	3.93	7.35	5.44	4.8 	1.59] | 
| 05-02 00:59:32 epoch: 925| time: 2.3s| train loss: +1.752e+01 | test loss: +1.982e+01 | 
| 05-02 00:59:32 epoch: 925| train loss i: [0.14	1.33	5.29	5.05	4.12	1.6 ] test loss i: [0.21	3.15	5.58	5.25	3.82	1.81] | 
| 05-02 00:59:34 epoch: 926| time: 2.4s| train loss: +1.635e+01 | test loss: +2.511e+01 | 
| 05-02 00:59:34 epoch: 926| train loss i: [0.17	1.01	5.1 	4.67	3.8 	1.6 ] test loss i: [0.38	2.37	6.86	7.18	5.98	2.35] | 
| 05-02 00:59:36 epoch: 927| time: 2.4s| train loss: +1.732e+01 | test loss: +1.563e+01 | 
| 05-02 00:59:36 epoch: 927| train loss i: [0.11	1.53	5.36	4.78	3.94	1.6 ] test loss i: [0.09	1.61	4.69	3.44	4.14	1.66] | 
| 05-02 00:59:39 epoch: 928| time: 2.4s| train loss: +1.721e+01 | test loss: +2.272e+01 | 
| 05-02 00:59:39 epoch: 928| train loss i: [0.14	1.3 	5.78	4.67	3.69	1.63] test loss i: [0.3 	2.78	5.99	7.22	4.44	1.99] | 
| 05-02 00:59:41 epoch: 929| time: 2.5s| train loss: +1.704e+01 | test loss: +1.876e+01 | 
| 05-02 00:59:41 epoch: 929| train loss i: [0.15	1.34	5.3 	4.92	3.71	1.62] test loss i: [0.7 	1.99	4.8 	5.41	4.23	1.64] | 
| 05-02 00:59:44 epoch: 930| time: 2.4s| train loss: +1.725e+01 | test loss: +1.923e+01 | 
| 05-02 00:59:44 epoch: 930| train loss i: [0.14	1.87	5.26	4.63	3.87	1.48] test loss i: [0.15	1.13	6.45	5.87	3.91	1.72] | 
| 05-02 00:59:46 epoch: 931| time: 2.4s| train loss: +1.750e+01 | test loss: +1.931e+01 | 
| 05-02 00:59:46 epoch: 931| train loss i: [0.08	1.46	6.05	4.48	3.88	1.55] test loss i: [0.22	1.13	7.27	5.19	3.91	1.59] | 
| 05-02 00:59:49 epoch: 932| time: 2.4s| train loss: +1.657e+01 | test loss: +1.729e+01 | 
| 05-02 00:59:49 epoch: 932| train loss i: [0.14	1.32	5.16	4.72	3.69	1.54] test loss i: [0.24	1.14	4.39	5.42	4.23	1.87] | 
| 05-02 00:59:51 epoch: 933| time: 2.4s| train loss: +1.743e+01 | test loss: +2.143e+01 | 
| 05-02 00:59:51 epoch: 933| train loss i: [0.11	1.21	5.51	4.8 	4.18	1.63] test loss i: [3.01	0.98	6.07	4.8 	4.54	2.03] | 
| 05-02 00:59:53 epoch: 934| time: 2.5s| train loss: +1.695e+01 | test loss: +1.674e+01 | 
| 05-02 00:59:53 epoch: 934| train loss i: [0.14	1.47	5.14	4.83	3.84	1.54] test loss i: [0.36	1.53	5.46	4.05	3.72	1.62] | 
| 05-02 00:59:56 epoch: 935| time: 2.4s| train loss: +1.759e+01 | test loss: +1.784e+01 | 
| 05-02 00:59:56 epoch: 935| train loss i: [0.18	1.3 	5.74	4.95	3.87	1.56] test loss i: [0.2 	1.18	5.13	5.69	3.89	1.74] | 
| 05-02 00:59:58 epoch: 936| time: 2.4s| train loss: +1.720e+01 | test loss: +2.423e+01 | 
| 05-02 00:59:58 epoch: 936| train loss i: [0.21	1.79	5.63	4.35	3.56	1.66] test loss i: [0.24	3.38	7.62	6.53	4.53	1.93] | 
| 05-02 01:00:01 epoch: 937| time: 2.4s| train loss: +1.781e+01 | test loss: +2.347e+01 | 
| 05-02 01:00:01 epoch: 937| train loss i: [0.2 	2.09	5.72	4.57	3.59	1.64] test loss i: [0.29	1.72	9.6 	5.56	4.31	1.99] | 
| 05-02 01:00:03 epoch: 938| time: 2.4s| train loss: +1.724e+01 | test loss: +2.203e+01 | 
| 05-02 01:00:03 epoch: 938| train loss i: [0.12	1.6 	5.19	5.05	3.76	1.53] test loss i: [0.42	1.61	7.11	6.19	4.71	1.99] | 
| 05-02 01:00:06 epoch: 939| time: 2.5s| train loss: +1.743e+01 | test loss: +1.804e+01 | 
| 05-02 01:00:06 epoch: 939| train loss i: [0.22	1.46	5.29	5.29	3.63	1.53] test loss i: [0.58	1.86	5.57	4.68	3.88	1.48] | 
| 05-02 01:00:08 epoch: 940| time: 2.4s| train loss: +1.770e+01 | test loss: +1.773e+01 | 
| 05-02 01:00:08 epoch: 940| train loss i: [0.31	1.7 	5.68	4.84	3.65	1.51] test loss i: [0.58	1.68	5.34	5.3 	3.42	1.41] | 
| 05-02 01:00:10 epoch: 941| time: 2.4s| train loss: +1.739e+01 | test loss: +1.623e+01 | 
| 05-02 01:00:10 epoch: 941| train loss i: [0.2 	1.16	5.65	5.03	3.73	1.62] test loss i: [0.18	0.66	4.99	4.65	4.09	1.65] | 
| 05-02 01:00:13 epoch: 942| time: 2.4s| train loss: +1.670e+01 | test loss: +2.441e+01 | 
| 05-02 01:00:13 epoch: 942| train loss i: [0.24	0.73	5.44	4.75	3.92	1.62] test loss i: [0.18	1.2 	9.01	7.12	4.86	2.04] | 
| 05-02 01:00:15 epoch: 943| time: 2.4s| train loss: +1.723e+01 | test loss: +2.430e+01 | 
| 05-02 01:00:15 epoch: 943| train loss i: [0.32	1.51	5.37	4.86	3.61	1.55] test loss i: [0.45	1.67	7.9 	7.25	5.04	1.99] | 
| 05-02 01:00:18 epoch: 944| time: 2.4s| train loss: +1.675e+01 | test loss: +1.839e+01 | 
| 05-02 01:00:18 epoch: 944| train loss i: [0.22	1.64	4.93	4.56	3.86	1.54] test loss i: [0.4 	1.87	4.62	5.67	4.01	1.82] | 
| 05-02 01:00:20 epoch: 945| time: 2.4s| train loss: +1.786e+01 | test loss: +1.736e+01 | 
| 05-02 01:00:20 epoch: 945| train loss i: [0.16	1.24	6.02	4.94	3.89	1.61] test loss i: [0.28	0.92	5.65	5.08	3.58	1.86] | 
| 05-02 01:00:22 epoch: 946| time: 2.4s| train loss: +1.820e+01 | test loss: +2.231e+01 | 
| 05-02 01:00:22 epoch: 946| train loss i: [0.16	1.74	5.19	5.44	4.04	1.62] test loss i: [0.14	3.05	7.36	5.34	4.31	2.11] | 
| 05-02 01:00:25 epoch: 947| time: 2.5s| train loss: +1.725e+01 | test loss: +2.075e+01 | 
| 05-02 01:00:25 epoch: 947| train loss i: [0.19	1.55	5.65	4.57	3.71	1.58] test loss i: [0.6 	2.07	6.81	5.05	4.24	1.98] | 
| 05-02 01:00:27 epoch: 948| time: 2.5s| train loss: +1.780e+01 | test loss: +1.810e+01 | 
| 05-02 01:00:27 epoch: 948| train loss i: [0.23	1.26	5.49	4.96	4.14	1.72] test loss i: [0.24	2.43	5.71	4.6 	3.42	1.7 ] | 
| 05-02 01:00:30 epoch: 949| time: 2.5s| train loss: +1.682e+01 | test loss: +1.687e+01 | 
| 05-02 01:00:30 epoch: 949| train loss i: [0.23	0.97	5.66	4.75	3.72	1.49] test loss i: [0.58	1.19	5.18	4.44	3.76	1.71] | 
| 05-02 01:00:32 epoch: 950| time: 2.5s| train loss: +1.670e+01 | test loss: +2.016e+01 | 
| 05-02 01:00:32 epoch: 950| train loss i: [0.25	0.73	5.12	4.91	4.06	1.64] test loss i: [1.17	3.68	4.87	4.42	4.33	1.69] | 
| 05-02 01:00:35 epoch: 951| time: 2.5s| train loss: +1.779e+01 | test loss: +1.892e+01 | 
| 05-02 01:00:35 epoch: 951| train loss i: [0.18	2.1 	5.53	4.76	3.66	1.54] test loss i: [0.24	2.  	5.73	5.79	3.5 	1.65] | 
| 05-02 01:00:37 epoch: 952| time: 2.4s| train loss: +1.779e+01 | test loss: +1.882e+01 | 
| 05-02 01:00:37 epoch: 952| train loss i: [0.16	1.46	5.95	5.13	3.55	1.54] test loss i: [0.43	2.09	4.42	6.12	3.97	1.8 ] | 
| 05-02 01:00:40 epoch: 953| time: 2.5s| train loss: +1.669e+01 | test loss: +1.619e+01 | 
| 05-02 01:00:40 epoch: 953| train loss i: [0.2 	1.36	5.07	4.57	3.84	1.64] test loss i: [0.14	1.56	5.37	4.33	3.37	1.42] | 
| 05-02 01:00:42 epoch: 954| time: 2.4s| train loss: +1.727e+01 | test loss: +1.620e+01 | 
| 05-02 01:00:42 epoch: 954| train loss i: [0.12	1.65	5.09	4.93	3.91	1.57] test loss i: [0.17	1.03	5.11	4.92	3.23	1.73] | 
| 05-02 01:00:44 epoch: 955| time: 2.4s| train loss: +1.718e+01 | test loss: +2.521e+01 | 
| 05-02 01:00:44 epoch: 955| train loss i: [0.13	1.2 	5.29	5.03	3.98	1.54] test loss i: [0.22	3.22	7.45	6.98	5.27	2.06] | 
| 05-02 01:00:47 epoch: 956| time: 2.5s| train loss: +1.738e+01 | test loss: +1.804e+01 | 
| 05-02 01:00:47 epoch: 956| train loss i: [0.14	1.73	5.7 	4.65	3.55	1.61] test loss i: [0.11	2.4 	6.43	4.03	3.65	1.43] | 
| 05-02 01:00:49 epoch: 957| time: 2.5s| train loss: +1.656e+01 | test loss: +2.369e+01 | 
| 05-02 01:00:49 epoch: 957| train loss i: [0.18	1.22	4.6 	4.97	3.93	1.66] test loss i: [1.19	1.09	7.15	6.78	4.9 	2.59] | 
| 05-02 01:00:52 epoch: 958| time: 2.5s| train loss: +1.798e+01 | test loss: +1.994e+01 | 
| 05-02 01:00:52 epoch: 958| train loss i: [0.2 	1.49	5.88	5.07	3.79	1.56] test loss i: [0.39	0.33	6.01	6.7 	4.47	2.04] | 
| 05-02 01:00:54 epoch: 959| time: 2.4s| train loss: +1.786e+01 | test loss: +1.670e+01 | 
| 05-02 01:00:54 epoch: 959| train loss i: [0.16	1.74	5.48	5.33	3.59	1.56] test loss i: [0.13	1.25	4.62	4.64	4.12	1.95] | 
| 05-02 01:00:57 epoch: 960| time: 2.4s| train loss: +1.785e+01 | test loss: +1.804e+01 | 
| 05-02 01:00:57 epoch: 960| train loss i: [0.23	1.81	5.73	4.78	3.8 	1.5 ] test loss i: [0.62	1.2 	5.37	4.98	4.06	1.8 ] | 
| 05-02 01:00:59 epoch: 961| time: 2.5s| train loss: +1.716e+01 | test loss: +1.656e+01 | 
| 05-02 01:00:59 epoch: 961| train loss i: [0.23	1.51	4.98	4.99	3.9 	1.55] test loss i: [0.33	1.63	4.31	5.11	3.36	1.82] | 
| 05-02 01:01:02 epoch: 962| time: 2.4s| train loss: +1.775e+01 | test loss: +1.607e+01 | 
| 05-02 01:01:02 epoch: 962| train loss i: [0.38	1.27	5.46	4.95	4.01	1.68] test loss i: [0.24	0.62	5.53	4.28	3.6 	1.81] | 
| 05-02 01:01:04 epoch: 963| time: 2.4s| train loss: +1.886e+01 | test loss: +2.287e+01 | 
| 05-02 01:01:04 epoch: 963| train loss i: [0.28	1.72	6.11	4.99	4.23	1.54] test loss i: [0.99	1.2 	7.17	6.67	4.65	2.18] | 
| 05-02 01:01:07 epoch: 964| time: 2.5s| train loss: +1.787e+01 | test loss: +1.673e+01 | 
| 05-02 01:01:07 epoch: 964| train loss i: [0.21	1.71	5.76	4.67	3.93	1.59] test loss i: [0.23	1.73	4.47	5.76	3.03	1.51] | 
| 05-02 01:01:09 epoch: 965| time: 2.5s| train loss: +1.788e+01 | test loss: +1.611e+01 | 
| 05-02 01:01:09 epoch: 965| train loss i: [0.16	0.81	6.1 	5.06	4.14	1.63] test loss i: [0.26	1.51	4.51	4.25	4.14	1.45] | 
| 05-02 01:01:12 epoch: 966| time: 2.5s| train loss: +1.745e+01 | test loss: +1.772e+01 | 
| 05-02 01:01:12 epoch: 966| train loss i: [0.17	1.51	5.17	5.09	3.86	1.64] test loss i: [0.23	1.27	5.39	4.76	4.24	1.83] | 
| 05-02 01:01:14 epoch: 967| time: 2.5s| train loss: +1.666e+01 | test loss: +1.677e+01 | 
| 05-02 01:01:14 epoch: 967| train loss i: [0.22	1.28	4.88	4.73	3.93	1.62] test loss i: [0.2 	2.84	5.08	4.04	2.88	1.73] | 
| 05-02 01:01:17 epoch: 968| time: 2.5s| train loss: +1.800e+01 | test loss: +1.774e+01 | 
| 05-02 01:01:17 epoch: 968| train loss i: [0.31	1.85	5.55	4.97	3.76	1.55] test loss i: [0.25	0.69	5.52	5.24	4.41	1.62] | 
| 05-02 01:01:19 epoch: 969| time: 2.5s| train loss: +1.802e+01 | test loss: +1.763e+01 | 
| 05-02 01:01:19 epoch: 969| train loss i: [0.31	1.32	5.82	5.29	3.75	1.54] test loss i: [0.55	1.31	4.55	5.78	3.86	1.58] | 
| 05-02 01:01:21 epoch: 970| time: 2.4s| train loss: +1.676e+01 | test loss: +1.526e+01 | 
| 05-02 01:01:21 epoch: 970| train loss i: [0.18	1.33	5.35	4.4 	3.9 	1.59] test loss i: [0.3 	1.31	4.99	3.97	3.31	1.39] | 
| 05-02 01:01:24 epoch: 971| time: 2.5s| train loss: +1.737e+01 | test loss: +1.595e+01 | 
| 05-02 01:01:24 epoch: 971| train loss i: [0.25	1.36	5.71	4.86	3.66	1.54] test loss i: [0.4 	1.59	4.78	4.04	3.42	1.71] | 
| 05-02 01:01:26 epoch: 972| time: 2.5s| train loss: +1.645e+01 | test loss: +1.862e+01 | 
| 05-02 01:01:26 epoch: 972| train loss i: [0.19	1.17	4.82	4.73	3.98	1.56] test loss i: [0.28	1.63	5.18	5.96	3.88	1.68] | 
| 05-02 01:01:29 epoch: 973| time: 2.5s| train loss: +1.790e+01 | test loss: +2.008e+01 | 
| 05-02 01:01:29 epoch: 973| train loss i: [0.24	1.75	5.41	5.2 	3.83	1.47] test loss i: [0.43	1.88	6.46	6.14	3.53	1.64] | 
| 05-02 01:01:31 epoch: 974| time: 2.5s| train loss: +1.762e+01 | test loss: +1.976e+01 | 
| 05-02 01:01:31 epoch: 974| train loss i: [0.15	1.54	5.73	5.06	3.66	1.48] test loss i: [0.55	2.39	6.49	4.92	3.51	1.9 ] | 
| 05-02 01:01:34 epoch: 975| time: 2.5s| train loss: +1.757e+01 | test loss: +1.749e+01 | 
| 05-02 01:01:34 epoch: 975| train loss i: [0.2 	1.21	5.42	5.08	4.09	1.57] test loss i: [0.13	0.6 	5.62	5.59	3.85	1.7 ] | 
| 05-02 01:01:36 epoch: 976| time: 2.4s| train loss: +1.750e+01 | test loss: +1.823e+01 | 
| 05-02 01:01:36 epoch: 976| train loss i: [0.2 	1.62	5.58	4.73	3.78	1.58] test loss i: [0.22	1.27	6.07	5.12	3.91	1.64] | 
| 05-02 01:01:39 epoch: 977| time: 2.5s| train loss: +1.718e+01 | test loss: +2.211e+01 | 
| 05-02 01:01:39 epoch: 977| train loss i: [0.19	1.64	5.15	5.06	3.6 	1.54] test loss i: [0.89	3.67	5.82	5.76	4.24	1.73] | 
| 05-02 01:01:41 epoch: 978| time: 2.4s| train loss: +1.706e+01 | test loss: +2.039e+01 | 
| 05-02 01:01:41 epoch: 978| train loss i: [0.18	1.35	5.39	4.85	3.75	1.54] test loss i: [0.7 	1.64	7.29	4.68	4.4 	1.7 ] | 
| 05-02 01:01:44 epoch: 979| time: 2.4s| train loss: +1.767e+01 | test loss: +2.183e+01 | 
| 05-02 01:01:44 epoch: 979| train loss i: [0.31	1.31	5.47	5.06	3.92	1.6 ] test loss i: [0.45	1.37	7.99	5.49	4.45	2.07] | 
| 05-02 01:01:46 epoch: 980| time: 2.5s| train loss: +1.723e+01 | test loss: +2.309e+01 | 
| 05-02 01:01:46 epoch: 980| train loss i: [0.2 	1.41	5.69	4.69	3.77	1.47] test loss i: [0.33	2.62	6.82	6.68	4.42	2.21] | 
| 05-02 01:01:48 epoch: 981| time: 2.4s| train loss: +1.820e+01 | test loss: +1.985e+01 | 
| 05-02 01:01:48 epoch: 981| train loss i: [0.18	1.66	5.8 	5.13	3.85	1.58] test loss i: [0.14	2.14	5.59	4.98	4.88	2.12] | 
| 05-02 01:01:51 epoch: 982| time: 2.4s| train loss: +1.805e+01 | test loss: +2.573e+01 | 
| 05-02 01:01:51 epoch: 982| train loss i: [0.37	1.58	6.09	4.68	3.71	1.62] test loss i: [0.72	3.31	7.9 	6.77	4.77	2.25] | 
| 05-02 01:01:53 epoch: 983| time: 2.4s| train loss: +1.857e+01 | test loss: +1.517e+01 | 
| 05-02 01:01:53 epoch: 983| train loss i: [0.2 	1.62	6.19	4.97	3.93	1.65] test loss i: [0.26	2.06	4.48	3.72	3.08	1.57] | 
| 05-02 01:01:56 epoch: 984| time: 2.5s| train loss: +1.711e+01 | test loss: +1.764e+01 | 
| 05-02 01:01:56 epoch: 984| train loss i: [0.2 	1.33	5.44	4.69	3.87	1.57] test loss i: [0.66	0.84	6.27	4.42	3.63	1.82] | 
| 05-02 01:01:58 epoch: 985| time: 2.5s| train loss: +1.724e+01 | test loss: +2.110e+01 | 
| 05-02 01:01:58 epoch: 985| train loss i: [0.15	0.82	5.42	5.33	3.89	1.63] test loss i: [0.27	1.77	7.52	5.7 	3.88	1.95] | 
| 05-02 01:02:01 epoch: 986| time: 2.4s| train loss: +1.722e+01 | test loss: +1.898e+01 | 
| 05-02 01:02:01 epoch: 986| train loss i: [0.15	1.11	5.59	5.02	3.84	1.51] test loss i: [0.14	0.7 	6.03	6.12	3.93	2.06] | 
| 05-02 01:02:03 epoch: 987| time: 2.5s| train loss: +1.694e+01 | test loss: +2.702e+01 | 
| 05-02 01:02:03 epoch: 987| train loss i: [0.14	0.87	5.93	4.74	3.62	1.65] test loss i: [0.4 	2.26	8.49	7.35	6.13	2.39] | 
| 05-02 01:02:06 epoch: 988| time: 2.4s| train loss: +1.806e+01 | test loss: +1.939e+01 | 
| 05-02 01:02:06 epoch: 988| train loss i: [0.11	1.33	5.86	5.09	4.05	1.62] test loss i: [0.34	1.53	6.28	5.06	4.2 	1.99] | 
| 05-02 01:02:08 epoch: 989| time: 2.4s| train loss: +1.607e+01 | test loss: +2.251e+01 | 
| 05-02 01:02:08 epoch: 989| train loss i: [0.11	1.1 	5.14	4.49	3.74	1.5 ] test loss i: [0.25	1.81	7.86	5.72	4.92	1.95] | 
| 05-02 01:02:10 epoch: 990| time: 2.5s| train loss: +1.699e+01 | test loss: +1.821e+01 | 
| 05-02 01:02:10 epoch: 990| train loss i: [0.11	1.4 	5.32	4.79	3.74	1.63] test loss i: [0.08	0.73	6.8 	5.18	3.58	1.84] | 
| 05-02 01:02:13 epoch: 991| time: 2.5s| train loss: +1.681e+01 | test loss: +1.681e+01 | 
| 05-02 01:02:13 epoch: 991| train loss i: [0.33	1.13	5.17	4.73	3.89	1.55] test loss i: [0.36	0.43	5.32	5.57	3.37	1.76] | 
| 05-02 01:02:15 epoch: 992| time: 2.5s| train loss: +1.731e+01 | test loss: +1.985e+01 | 
| 05-02 01:02:15 epoch: 992| train loss i: [0.28	1.23	5.6 	4.94	3.68	1.58] test loss i: [0.62	0.83	6.71	5.54	4.03	2.12] | 
| 05-02 01:02:18 epoch: 993| time: 2.4s| train loss: +1.753e+01 | test loss: +1.771e+01 | 
| 05-02 01:02:18 epoch: 993| train loss i: [0.14	0.92	6.12	4.91	3.84	1.61] test loss i: [0.39	2.34	4.64	4.56	4.15	1.63] | 
| 05-02 01:02:20 epoch: 994| time: 2.4s| train loss: +1.773e+01 | test loss: +1.841e+01 | 
| 05-02 01:02:20 epoch: 994| train loss i: [0.13	1.6 	5.94	4.78	3.72	1.56] test loss i: [0.39	0.47	6.26	5.59	3.78	1.92] | 
| 05-02 01:02:23 epoch: 995| time: 2.5s| train loss: +1.683e+01 | test loss: +2.038e+01 | 
| 05-02 01:02:23 epoch: 995| train loss i: [0.17	1.02	5.37	5.08	3.69	1.51] test loss i: [0.13	1.31	6.35	6.27	4.22	2.11] | 
| 05-02 01:02:25 epoch: 996| time: 2.4s| train loss: +1.719e+01 | test loss: +1.694e+01 | 
| 05-02 01:02:25 epoch: 996| train loss i: [0.17	0.99	5.62	5.01	3.82	1.58] test loss i: [0.22	1.48	4.61	4.92	4.19	1.52] | 
| 05-02 01:02:28 epoch: 997| time: 2.5s| train loss: +1.794e+01 | test loss: +2.313e+01 | 
| 05-02 01:02:28 epoch: 997| train loss i: [0.24	1.81	5.49	4.92	3.93	1.56] test loss i: [0.38	3.24	7.56	5.77	4.36	1.82] | 
| 05-02 01:02:30 epoch: 998| time: 2.5s| train loss: +1.721e+01 | test loss: +2.371e+01 | 
| 05-02 01:02:30 epoch: 998| train loss i: [0.34	1.58	5.11	4.83	3.79	1.57] test loss i: [0.74	2.49	7.33	6.26	4.67	2.22] | 
| 05-02 01:02:33 epoch: 999| time: 2.4s| train loss: +1.798e+01 | test loss: +1.875e+01 | 
| 05-02 01:02:33 epoch: 999| train loss i: [0.21	1.59	5.69	5.11	3.69	1.69] test loss i: [0.39	1.74	5.43	5.65	3.81	1.72] | 
| 05-02 01:02:35 epoch: 1000| time: 2.5s| train loss: +1.767e+01 | test loss: +2.085e+01 | 
| 05-02 01:02:35 epoch: 1000| train loss i: [0.23	1.36	5.65	5.03	3.81	1.58] test loss i: [0.3 	1.91	6.34	6.09	4.25	1.96] | 
| 05-02 01:02:37 epoch: 1001| time: 2.4s| train loss: +1.770e+01 | test loss: +2.045e+01 | 
| 05-02 01:02:37 epoch: 1001| train loss i: [0.2 	1.52	5.31	5.05	3.98	1.62] test loss i: [0.57	1.35	7.25	5.36	4.09	1.83] | 
| 05-02 01:02:40 epoch: 1002| time: 2.5s| train loss: +1.824e+01 | test loss: +1.694e+01 | 
| 05-02 01:02:40 epoch: 1002| train loss i: [0.18	1.37	5.86	5.23	4.01	1.6 ] test loss i: [0.32	1.52	5.09	5.03	3.27	1.7 ] | 
| 05-02 01:02:42 epoch: 1003| time: 2.5s| train loss: +1.704e+01 | test loss: +1.534e+01 | 
| 05-02 01:02:42 epoch: 1003| train loss i: [0.26	1.54	5.47	4.57	3.63	1.56] test loss i: [0.21	1.8 	4.1 	3.63	3.81	1.79] | 
| 05-02 01:02:45 epoch: 1004| time: 2.4s| train loss: +1.665e+01 | test loss: +2.053e+01 | 
| 05-02 01:02:45 epoch: 1004| train loss i: [0.21	1.24	5.2 	4.74	3.64	1.62] test loss i: [0.25	1.14	7.42	5.3 	4.28	2.13] | 
| 05-02 01:02:47 epoch: 1005| time: 2.5s| train loss: +1.902e+01 | test loss: +2.506e+01 | 
| 05-02 01:02:47 epoch: 1005| train loss i: [0.15	1.69	5.89	5.61	4.04	1.64] test loss i: [1.04	2.05	8.2 	6.56	4.94	2.27] | 
| 05-02 01:02:50 epoch: 1006| time: 2.4s| train loss: +1.747e+01 | test loss: +1.588e+01 | 
| 05-02 01:02:50 epoch: 1006| train loss i: [0.2 	1.19	5.7 	5.07	3.71	1.61] test loss i: [0.16	0.92	5.56	4.06	3.66	1.52] | 
| 05-02 01:02:52 epoch: 1007| time: 2.4s| train loss: +1.799e+01 | test loss: +1.929e+01 | 
| 05-02 01:02:52 epoch: 1007| train loss i: [0.26	1.61	5.7 	4.82	4.02	1.59] test loss i: [0.18	1.78	5.62	5.62	4.25	1.83] | 
| 05-02 01:02:55 epoch: 1008| time: 2.5s| train loss: +1.776e+01 | test loss: +2.387e+01 | 
| 05-02 01:02:55 epoch: 1008| train loss i: [0.19	1.59	5.75	4.91	3.78	1.54] test loss i: [0.17	0.76	8.19	6.82	5.5 	2.42] | 
| 05-02 01:02:57 epoch: 1009| time: 2.4s| train loss: +1.842e+01 | test loss: +2.215e+01 | 
| 05-02 01:02:57 epoch: 1009| train loss i: [0.16	2.37	5.88	4.74	3.65	1.63] test loss i: [0.21	2.08	5.39	7.41	4.98	2.08] | 
| 05-02 01:02:59 epoch: 1010| time: 2.4s| train loss: +1.800e+01 | test loss: +2.812e+01 | 
| 05-02 01:02:59 epoch: 1010| train loss i: [0.23	2.13	5.35	4.84	3.83	1.62] test loss i: [0.52	4.62	8.69	6.85	5.26	2.18] | 
| 05-02 01:03:02 epoch: 1011| time: 2.5s| train loss: +1.741e+01 | test loss: +1.794e+01 | 
| 05-02 01:03:02 epoch: 1011| train loss i: [0.19	1.97	5.24	4.79	3.7 	1.52] test loss i: [0.33	3.04	4.36	4.87	3.92	1.41] | 
| 05-02 01:03:04 epoch: 1012| time: 2.4s| train loss: +1.813e+01 | test loss: +2.390e+01 | 
| 05-02 01:03:04 epoch: 1012| train loss i: [0.13	1.98	6.03	4.84	3.6 	1.55] test loss i: [0.24	2.84	8.61	6.1 	3.99	2.12] | 
| 05-02 01:03:07 epoch: 1013| time: 2.5s| train loss: +1.741e+01 | test loss: +2.177e+01 | 
| 05-02 01:03:07 epoch: 1013| train loss i: [0.17	1.66	5.24	4.95	3.79	1.6 ] test loss i: [0.29	0.65	8.26	5.59	5.01	1.96] | 
| 05-02 01:03:09 epoch: 1014| time: 2.4s| train loss: +1.781e+01 | test loss: +2.200e+01 | 
| 05-02 01:03:09 epoch: 1014| train loss i: [0.14	1.5 	5.82	4.82	3.91	1.61] test loss i: [0.16	3.18	6.85	5.6 	4.03	2.19] | 
| 05-02 01:03:12 epoch: 1015| time: 2.4s| train loss: +1.763e+01 | test loss: +1.941e+01 | 
| 05-02 01:03:12 epoch: 1015| train loss i: [0.13	2.11	5.75	4.62	3.47	1.54] test loss i: [0.13	0.83	7.29	5.42	4.31	1.43] | 
| 05-02 01:03:14 epoch: 1016| time: 2.5s| train loss: +1.794e+01 | test loss: +1.838e+01 | 
| 05-02 01:03:14 epoch: 1016| train loss i: [0.11	1.5 	6.27	4.75	3.73	1.58] test loss i: [0.23	0.62	6.46	4.53	4.84	1.7 ] | 
| 05-02 01:03:17 epoch: 1017| time: 2.5s| train loss: +1.709e+01 | test loss: +1.547e+01 | 
| 05-02 01:03:17 epoch: 1017| train loss i: [0.12	1.32	5.59	4.72	3.8 	1.55] test loss i: [0.12	0.52	5.95	4.1 	3.29	1.5 ] | 
| 05-02 01:03:19 epoch: 1018| time: 2.5s| train loss: +1.688e+01 | test loss: +1.754e+01 | 
| 05-02 01:03:19 epoch: 1018| train loss i: [0.2 	1.53	4.73	5.05	3.78	1.6 ] test loss i: [0.16	1.04	5.56	4.87	3.73	2.18] | 
| 05-02 01:03:22 epoch: 1019| time: 2.5s| train loss: +1.836e+01 | test loss: +1.873e+01 | 
| 05-02 01:03:22 epoch: 1019| train loss i: [0.17	1.47	6.14	5.01	3.95	1.61] test loss i: [0.4 	1.44	6.3 	4.97	4.07	1.53] | 
| 05-02 01:03:24 epoch: 1020| time: 2.4s| train loss: +1.728e+01 | test loss: +1.430e+01 | 
| 05-02 01:03:24 epoch: 1020| train loss i: [0.21	1.27	4.99	5.12	4.21	1.49] test loss i: [0.54	0.43	4.07	4.51	3.32	1.44] | 
| 05-02 01:03:27 epoch: 1021| time: 2.5s| train loss: +1.756e+01 | test loss: +1.641e+01 | 
| 05-02 01:03:27 epoch: 1021| train loss i: [0.17	1.43	5.47	5.06	3.89	1.54] test loss i: [0.24	0.57	5.2 	5.07	3.68	1.65] | 
| 05-02 01:03:29 epoch: 1022| time: 2.4s| train loss: +1.709e+01 | test loss: +1.996e+01 | 
| 05-02 01:03:29 epoch: 1022| train loss i: [0.22	1.5 	5.23	4.92	3.64	1.58] test loss i: [0.36	1.82	5.92	5.16	4.94	1.76] | 
| 05-02 01:03:31 epoch: 1023| time: 2.4s| train loss: +1.674e+01 | test loss: +1.648e+01 | 
| 05-02 01:03:31 epoch: 1023| train loss i: [0.13	1.26	5.26	4.82	3.74	1.53] test loss i: [0.33	0.74	5.08	4.29	4.32	1.71] | 
| 05-02 01:03:34 epoch: 1024| time: 2.5s| train loss: +1.660e+01 | test loss: +1.602e+01 | 
| 05-02 01:03:34 epoch: 1024| train loss i: [0.16	0.98	5.58	4.54	3.83	1.5 ] test loss i: [0.1 	0.35	5.8 	4.27	4.04	1.47] | 
| 05-02 01:03:36 epoch: 1025| time: 2.5s| train loss: +1.757e+01 | test loss: +2.210e+01 | 
| 05-02 01:03:36 epoch: 1025| train loss i: [0.19	1.94	5.15	4.74	3.96	1.59] test loss i: [0.19	0.88	7.3 	6.69	4.82	2.21] | 
| 05-02 01:03:39 epoch: 1026| time: 2.5s| train loss: +1.697e+01 | test loss: +1.389e+01 | 
| 05-02 01:03:39 epoch: 1026| train loss i: [0.3 	0.97	5.49	4.78	3.81	1.62] test loss i: [0.25	0.4 	4.72	3.76	3.29	1.46] | 
| 05-02 01:03:41 epoch: 1027| time: 2.4s| train loss: +1.757e+01 | test loss: +1.721e+01 | 
| 05-02 01:03:41 epoch: 1027| train loss i: [0.23	2.06	5.33	4.57	3.81	1.57] test loss i: [0.21	3.18	4.79	4.33	3.26	1.44] | 
| 05-02 01:03:44 epoch: 1028| time: 2.4s| train loss: +1.741e+01 | test loss: +1.742e+01 | 
| 05-02 01:03:44 epoch: 1028| train loss i: [0.16	1.55	5.31	5.14	3.77	1.48] test loss i: [0.43	0.6 	5.69	4.82	4.16	1.74] | 
| 05-02 01:03:46 epoch: 1029| time: 2.5s| train loss: +1.683e+01 | test loss: +2.241e+01 | 
| 05-02 01:03:46 epoch: 1029| train loss i: [0.15	1.27	5.33	4.8 	3.69	1.59] test loss i: [0.21	1.03	8.01	6.36	5.15	1.64] | 
| 05-02 01:03:49 epoch: 1030| time: 2.5s| train loss: +1.713e+01 | test loss: +1.792e+01 | 
| 05-02 01:03:49 epoch: 1030| train loss i: [0.15	1.52	5.54	4.47	3.95	1.5 ] test loss i: [0.31	2.23	5.32	4.25	4.28	1.52] | 
| 05-02 01:03:51 epoch: 1031| time: 2.5s| train loss: +1.859e+01 | test loss: +1.782e+01 | 
| 05-02 01:03:51 epoch: 1031| train loss i: [0.15	1.99	5.84	5.19	3.79	1.63] test loss i: [0.22	2.18	4.87	5.  	4.01	1.55] | 
| 05-02 01:03:53 epoch: 1032| time: 2.4s| train loss: +1.686e+01 | test loss: +1.671e+01 | 
| 05-02 01:03:53 epoch: 1032| train loss i: [0.13	1.57	5.09	4.58	4.  	1.51] test loss i: [0.37	1.9 	4.96	4.1 	3.79	1.6 ] | 
| 05-02 01:03:56 epoch: 1033| time: 2.4s| train loss: +1.671e+01 | test loss: +2.042e+01 | 
| 05-02 01:03:56 epoch: 1033| train loss i: [0.13	1.42	5.12	4.87	3.65	1.53] test loss i: [1.12	2.16	5.94	5.25	4.05	1.89] | 
| 05-02 01:03:58 epoch: 1034| time: 2.5s| train loss: +1.750e+01 | test loss: +1.733e+01 | 
| 05-02 01:03:58 epoch: 1034| train loss i: [0.13	1.79	5.21	4.9 	3.93	1.53] test loss i: [0.7 	1.11	5.67	5.08	3.05	1.71] | 
| 05-02 01:04:01 epoch: 1035| time: 2.5s| train loss: +1.687e+01 | test loss: +1.750e+01 | 
| 05-02 01:04:01 epoch: 1035| train loss i: [0.19	1.47	5.12	4.66	3.86	1.56] test loss i: [0.1 	1.67	5.68	4.71	3.7 	1.64] | 
| 05-02 01:04:03 epoch: 1036| time: 2.4s| train loss: +1.748e+01 | test loss: +2.244e+01 | 
| 05-02 01:04:03 epoch: 1036| train loss i: [0.17	1.43	5.35	5.1 	3.85	1.59] test loss i: [0.62	1.7 	7.87	5.85	4.62	1.78] | 
| 05-02 01:04:06 epoch: 1037| time: 2.4s| train loss: +1.798e+01 | test loss: +1.504e+01 | 
| 05-02 01:04:06 epoch: 1037| train loss i: [0.13	1.62	5.45	5.18	4.07	1.53] test loss i: [0.13	0.7 	4.17	4.94	3.53	1.57] | 
| 05-02 01:04:08 epoch: 1038| time: 2.4s| train loss: +1.777e+01 | test loss: +1.951e+01 | 
| 05-02 01:04:08 epoch: 1038| train loss i: [0.13	1.56	5.9 	4.86	3.76	1.56] test loss i: [0.22	1.2 	6.09	6.13	4.11	1.77] | 
| 05-02 01:04:10 epoch: 1039| time: 2.5s| train loss: +1.586e+01 | test loss: +2.186e+01 | 
| 05-02 01:04:10 epoch: 1039| train loss i: [0.14	1.  	4.69	4.77	3.66	1.59] test loss i: [0.2 	0.92	7.69	6.19	4.53	2.31] | 
| 05-02 01:04:13 epoch: 1040| time: 2.4s| train loss: +1.746e+01 | test loss: +1.667e+01 | 
| 05-02 01:04:13 epoch: 1040| train loss i: [0.13	1.48	5.49	4.96	3.91	1.49] test loss i: [0.51	1.79	5.46	3.97	3.32	1.62] | 
| 05-02 01:04:15 epoch: 1041| time: 2.4s| train loss: +1.652e+01 | test loss: +2.170e+01 | 
| 05-02 01:04:15 epoch: 1041| train loss i: [0.21	1.28	5.23	4.72	3.55	1.51] test loss i: [0.15	4.52	5.98	5.12	4.15	1.77] | 
| 05-02 01:04:18 epoch: 1042| time: 2.4s| train loss: +1.657e+01 | test loss: +1.740e+01 | 
| 05-02 01:04:18 epoch: 1042| train loss i: [0.16	1.57	5.08	4.41	3.7 	1.65] test loss i: [0.31	0.52	6.35	4.37	4.29	1.57] | 
| 05-02 01:04:20 epoch: 1043| time: 2.4s| train loss: +1.804e+01 | test loss: +2.048e+01 | 
| 05-02 01:04:20 epoch: 1043| train loss i: [0.21	1.45	5.65	5.07	4.04	1.63] test loss i: [0.19	1.89	6.89	5.02	4.33	2.16] | 
| 05-02 01:04:22 epoch: 1044| time: 2.4s| train loss: +1.725e+01 | test loss: +1.875e+01 | 
| 05-02 01:04:22 epoch: 1044| train loss i: [0.29	1.29	5.44	4.85	3.83	1.55] test loss i: [0.12	1.  	5.89	4.35	5.5 	1.89] | 
| 05-02 01:04:25 epoch: 1045| time: 2.4s| train loss: +1.742e+01 | test loss: +1.789e+01 | 
| 05-02 01:04:25 epoch: 1045| train loss i: [0.18	1.79	5.  	5.08	3.88	1.5 ] test loss i: [0.17	2.09	5.05	5.22	3.89	1.47] | 
| 05-02 01:04:27 epoch: 1046| time: 2.4s| train loss: +1.704e+01 | test loss: +2.221e+01 | 
| 05-02 01:04:27 epoch: 1046| train loss i: [0.19	1.09	5.55	4.83	3.81	1.58] test loss i: [0.47	0.5 	7.56	6.49	5.02	2.19] | 
| 05-02 01:04:30 epoch: 1047| time: 2.4s| train loss: +1.777e+01 | test loss: +1.790e+01 | 
| 05-02 01:04:30 epoch: 1047| train loss i: [0.17	1.91	5.32	4.89	3.88	1.61] test loss i: [0.23	0.59	5.57	5.38	4.05	2.08] | 
| 05-02 01:04:32 epoch: 1048| time: 2.5s| train loss: +1.699e+01 | test loss: +2.492e+01 | 
| 05-02 01:04:32 epoch: 1048| train loss i: [0.28	1.6 	5.46	4.38	3.77	1.5 ] test loss i: [0.5 	0.28	8.92	7.16	5.9 	2.15] | 
| 05-02 01:04:34 epoch: 1049| time: 2.4s| train loss: +1.658e+01 | test loss: +1.904e+01 | 
| 05-02 01:04:34 epoch: 1049| train loss i: [0.19	1.09	5.36	4.7 	3.64	1.6 ] test loss i: [0.3 	0.82	6.26	5.33	4.58	1.76] | 
| 05-02 01:04:37 epoch: 1050| time: 2.5s| train loss: +1.713e+01 | test loss: +2.558e+01 | 
| 05-02 01:04:37 epoch: 1050| train loss i: [0.19	1.34	5.24	4.9 	3.9 	1.55] test loss i: [0.76	1.45	8.92	6.51	5.64	2.31] | 
| 05-02 01:04:39 epoch: 1051| time: 2.4s| train loss: +1.664e+01 | test loss: +1.873e+01 | 
| 05-02 01:04:39 epoch: 1051| train loss i: [0.18	1.17	5.74	4.52	3.47	1.56] test loss i: [0.21	1.74	6.57	4.77	3.82	1.62] | 
| 05-02 01:04:42 epoch: 1052| time: 2.4s| train loss: +1.704e+01 | test loss: +2.457e+01 | 
| 05-02 01:04:42 epoch: 1052| train loss i: [0.09	1.4 	5.49	4.71	3.8 	1.55] test loss i: [0.15	2.37	8.04	6.91	5.06	2.04] | 
| 05-02 01:04:44 epoch: 1053| time: 2.4s| train loss: +1.797e+01 | test loss: +1.562e+01 | 
| 05-02 01:04:44 epoch: 1053| train loss i: [0.14	1.33	5.78	4.96	4.22	1.53] test loss i: [0.18	0.8 	5.08	4.61	3.39	1.56] | 
| 05-02 01:04:47 epoch: 1054| time: 2.4s| train loss: +1.755e+01 | test loss: +1.428e+01 | 
| 05-02 01:04:47 epoch: 1054| train loss i: [0.14	1.05	5.9 	5.21	3.74	1.51] test loss i: [0.17	0.34	4.29	4.76	3.17	1.55] | 
| 05-02 01:04:49 epoch: 1055| time: 2.4s| train loss: +1.833e+01 | test loss: +1.895e+01 | 
| 05-02 01:04:49 epoch: 1055| train loss i: [0.16	2.52	5.69	4.8 	3.64	1.52] test loss i: [0.18	2.59	5.46	5.45	3.55	1.72] | 
| 05-02 01:04:51 epoch: 1056| time: 2.4s| train loss: +1.763e+01 | test loss: +1.865e+01 | 
| 05-02 01:04:51 epoch: 1056| train loss i: [0.16	1.27	5.35	4.98	4.25	1.61] test loss i: [0.56	2.92	4.86	4.18	4.48	1.64] | 
| 05-02 01:04:54 epoch: 1057| time: 2.4s| train loss: +1.777e+01 | test loss: +2.301e+01 | 
| 05-02 01:04:54 epoch: 1057| train loss i: [0.14	1.75	5.57	4.98	3.7 	1.63] test loss i: [0.19	1.22	6.92	7.68	4.94	2.05] | 
| 05-02 01:04:56 epoch: 1058| time: 2.4s| train loss: +1.654e+01 | test loss: +1.566e+01 | 
| 05-02 01:04:56 epoch: 1058| train loss i: [0.13	0.92	5.13	4.91	3.87	1.59] test loss i: [0.15	1.78	4.33	4.25	3.37	1.79] | 
| 05-02 01:04:59 epoch: 1059| time: 2.5s| train loss: +1.679e+01 | test loss: +1.832e+01 | 
| 05-02 01:04:59 epoch: 1059| train loss i: [0.11	1.14	5.36	4.67	3.91	1.6 ] test loss i: [0.16	1.5 	6.09	5.37	3.37	1.85] | 
| 05-02 01:05:01 epoch: 1060| time: 2.5s| train loss: +1.736e+01 | test loss: +1.838e+01 | 
| 05-02 01:05:01 epoch: 1060| train loss i: [0.17	1.18	5.65	5.11	3.62	1.63] test loss i: [0.12	1.19	6.65	4.43	4.4 	1.59] | 
| 05-02 01:05:04 epoch: 1061| time: 2.6s| train loss: +1.779e+01 | test loss: +2.283e+01 | 
| 05-02 01:05:04 epoch: 1061| train loss i: [0.21	1.96	5.45	4.92	3.67	1.59] test loss i: [0.25	0.86	8.01	6.4 	5.03	2.28] | 
| 05-02 01:05:06 epoch: 1062| time: 2.5s| train loss: +1.748e+01 | test loss: +1.534e+01 | 
| 05-02 01:05:06 epoch: 1062| train loss i: [0.17	1.39	5.72	4.67	3.95	1.58] test loss i: [0.38	1.16	4.41	4.11	3.67	1.61] | 
| 05-02 01:05:09 epoch: 1063| time: 2.5s| train loss: +1.800e+01 | test loss: +1.565e+01 | 
| 05-02 01:05:09 epoch: 1063| train loss i: [0.23	1.27	5.93	4.94	4.1 	1.53] test loss i: [0.19	1.05	5.07	4.32	3.45	1.57] | 
| 05-02 01:05:11 epoch: 1064| time: 2.5s| train loss: +1.735e+01 | test loss: +1.747e+01 | 
| 05-02 01:05:11 epoch: 1064| train loss i: [0.13	1.43	5.69	4.71	3.78	1.62] test loss i: [0.15	2.14	5.51	4.52	3.5 	1.65] | 
| 05-02 01:05:14 epoch: 1065| time: 2.5s| train loss: +1.861e+01 | test loss: +2.056e+01 | 
| 05-02 01:05:14 epoch: 1065| train loss i: [0.15	1.79	6.16	5.11	3.8 	1.61] test loss i: [0.36	1.97	5.96	5.57	4.92	1.78] | 
| 05-02 01:05:16 epoch: 1066| time: 2.5s| train loss: +1.725e+01 | test loss: +1.588e+01 | 
| 05-02 01:05:16 epoch: 1066| train loss i: [0.18	1.2 	5.18	5.19	3.9 	1.59] test loss i: [0.1 	0.95	4.33	4.75	4.05	1.71] | 
| 05-02 01:05:19 epoch: 1067| time: 2.4s| train loss: +1.663e+01 | test loss: +1.990e+01 | 
| 05-02 01:05:19 epoch: 1067| train loss i: [0.11	1.13	5.33	4.57	3.91	1.57] test loss i: [0.41	1.08	6.86	4.7 	4.92	1.92] | 
| 05-02 01:05:21 epoch: 1068| time: 2.5s| train loss: +1.726e+01 | test loss: +2.183e+01 | 
| 05-02 01:05:21 epoch: 1068| train loss i: [0.11	1.32	5.64	4.77	3.82	1.61] test loss i: [0.26	0.96	6.73	5.5 	6.  	2.38] | 
| 05-02 01:05:24 epoch: 1069| time: 2.4s| train loss: +1.639e+01 | test loss: +2.251e+01 | 
| 05-02 01:05:24 epoch: 1069| train loss i: [0.17	1.44	4.9 	4.73	3.62	1.54] test loss i: [0.18	2.1 	7.38	6.26	4.73	1.86] | 
| 05-02 01:05:26 epoch: 1070| time: 2.5s| train loss: +1.768e+01 | test loss: +1.834e+01 | 
| 05-02 01:05:26 epoch: 1070| train loss i: [0.13	1.93	5.01	4.86	4.15	1.59] test loss i: [0.12	2.33	6.27	4.57	3.38	1.66] | 
| 05-02 01:05:29 epoch: 1071| time: 2.5s| train loss: +1.677e+01 | test loss: +2.189e+01 | 
| 05-02 01:05:29 epoch: 1071| train loss i: [0.11	1.05	5.3 	5.02	3.8 	1.49] test loss i: [0.22	1.74	7.23	5.71	4.89	2.1 ] | 
| 05-02 01:05:31 epoch: 1072| time: 2.4s| train loss: +1.716e+01 | test loss: +2.522e+01 | 
| 05-02 01:05:31 epoch: 1072| train loss i: [0.15	1.1 	5.74	4.99	3.65	1.53] test loss i: [0.18	1.37	9.91	6.5 	5.34	1.91] | 
| 05-02 01:05:33 epoch: 1073| time: 2.5s| train loss: +1.715e+01 | test loss: +1.673e+01 | 
| 05-02 01:05:33 epoch: 1073| train loss i: [0.16	1.3 	6.11	4.44	3.56	1.58] test loss i: [0.37	0.34	5.76	4.79	3.73	1.73] | 
| 05-02 01:05:36 epoch: 1074| time: 2.5s| train loss: +1.675e+01 | test loss: +1.684e+01 | 
| 05-02 01:05:36 epoch: 1074| train loss i: [0.21	1.32	5.12	4.69	3.82	1.59] test loss i: [0.24	1.12	5.25	4.56	3.79	1.86] | 
| 05-02 01:05:38 epoch: 1075| time: 2.5s| train loss: +1.781e+01 | test loss: +2.016e+01 | 
| 05-02 01:05:38 epoch: 1075| train loss i: [0.22	1.45	5.86	4.88	3.76	1.64] test loss i: [0.23	3.37	6.24	4.53	4.  	1.8 ] | 
| 05-02 01:05:41 epoch: 1076| time: 2.5s| train loss: +1.610e+01 | test loss: +2.086e+01 | 
| 05-02 01:05:41 epoch: 1076| train loss i: [0.24	0.98	5.04	4.54	3.76	1.53] test loss i: [0.48	2.73	5.69	5.83	4.33	1.81] | 
| 05-02 01:05:43 epoch: 1077| time: 2.4s| train loss: +1.869e+01 | test loss: +2.024e+01 | 
| 05-02 01:05:43 epoch: 1077| train loss i: [0.2 	2.36	5.39	5.27	3.89	1.58] test loss i: [0.39	1.48	5.82	5.95	4.67	1.93] | 
| 05-02 01:05:46 epoch: 1078| time: 2.4s| train loss: +1.792e+01 | test loss: +1.770e+01 | 
| 05-02 01:05:46 epoch: 1078| train loss i: [0.35	1.66	6.  	4.73	3.58	1.6 ] test loss i: [1.07	1.21	4.95	5.25	3.31	1.91] | 
| 05-02 01:05:48 epoch: 1079| time: 2.5s| train loss: +1.691e+01 | test loss: +1.964e+01 | 
| 05-02 01:05:48 epoch: 1079| train loss i: [0.23	1.34	5.1 	5.  	3.76	1.49] test loss i: [0.45	2.31	6.46	5.12	3.63	1.67] | 
| 05-02 01:05:51 epoch: 1080| time: 2.5s| train loss: +1.758e+01 | test loss: +2.482e+01 | 
| 05-02 01:05:51 epoch: 1080| train loss i: [0.19	1.22	5.56	5.11	3.86	1.64] test loss i: [0.42	1.69	8.63	6.99	4.84	2.25] | 
| 05-02 01:05:53 epoch: 1081| time: 2.4s| train loss: +1.644e+01 | test loss: +2.615e+01 | 
| 05-02 01:05:53 epoch: 1081| train loss i: [0.24	0.6 	5.19	5.04	3.85	1.51] test loss i: [0.48	2.1 	7.28	7.71	6.  	2.58] | 
| 05-02 01:05:56 epoch: 1082| time: 2.5s| train loss: +1.701e+01 | test loss: +1.889e+01 | 
| 05-02 01:05:56 epoch: 1082| train loss i: [0.17	1.29	5.61	4.76	3.6 	1.58] test loss i: [0.15	1.9 	5.94	4.87	4.14	1.88] | 
| 05-02 01:05:58 epoch: 1083| time: 2.5s| train loss: +1.748e+01 | test loss: +2.290e+01 | 
| 05-02 01:05:58 epoch: 1083| train loss i: [0.18	1.84	5.24	4.92	3.78	1.52] test loss i: [0.13	2.95	7.53	5.68	4.51	2.09] | 
| 05-02 01:06:01 epoch: 1084| time: 2.5s| train loss: +1.753e+01 | test loss: +1.958e+01 | 
| 05-02 01:06:01 epoch: 1084| train loss i: [0.2 	1.73	5.5 	4.81	3.77	1.52] test loss i: [0.32	1.55	6.04	5.3 	4.53	1.84] | 
| 05-02 01:06:03 epoch: 1085| time: 2.5s| train loss: +1.658e+01 | test loss: +2.060e+01 | 
| 05-02 01:06:03 epoch: 1085| train loss i: [0.15	1.37	5.13	4.52	3.86	1.55] test loss i: [0.3 	1.91	6.02	5.39	4.79	2.2 ] | 
| 05-02 01:06:06 epoch: 1086| time: 2.5s| train loss: +1.741e+01 | test loss: +1.983e+01 | 
| 05-02 01:06:06 epoch: 1086| train loss i: [0.2 	1.83	5.12	4.75	3.92	1.59] test loss i: [0.17	1.03	6.29	5.12	5.07	2.15] | 
| 05-02 01:06:08 epoch: 1087| time: 2.5s| train loss: +1.801e+01 | test loss: +1.651e+01 | 
| 05-02 01:06:08 epoch: 1087| train loss i: [0.14	1.71	5.49	5.29	3.8 	1.57] test loss i: [0.38	0.74	5.79	3.6 	4.27	1.73] | 
| 05-02 01:06:11 epoch: 1088| time: 2.5s| train loss: +1.775e+01 | test loss: +1.558e+01 | 
| 05-02 01:06:11 epoch: 1088| train loss i: [0.11	2.07	5.34	4.88	3.72	1.63] test loss i: [0.15	0.74	5.58	4.23	3.32	1.57] | 
| 05-02 01:06:13 epoch: 1089| time: 2.5s| train loss: +1.870e+01 | test loss: +1.991e+01 | 
| 05-02 01:06:13 epoch: 1089| train loss i: [0.11	1.92	6.19	4.53	4.3 	1.65] test loss i: [0.19	1.28	6.6 	5.99	3.84	2.01] | 
| 05-02 01:06:16 epoch: 1090| time: 2.5s| train loss: +1.695e+01 | test loss: +1.937e+01 | 
| 05-02 01:06:16 epoch: 1090| train loss i: [0.09	1.42	5.33	4.66	3.83	1.61] test loss i: [0.17	2.16	6.07	5.73	3.42	1.82] | 
| 05-02 01:06:18 epoch: 1091| time: 2.5s| train loss: +1.743e+01 | test loss: +1.776e+01 | 
| 05-02 01:06:18 epoch: 1091| train loss i: [0.11	1.2 	5.59	5.04	3.86	1.62] test loss i: [0.1 	0.63	6.36	4.83	4.29	1.55] | 
| 05-02 01:06:20 epoch: 1092| time: 2.4s| train loss: +1.716e+01 | test loss: +2.216e+01 | 
| 05-02 01:06:20 epoch: 1092| train loss i: [0.17	1.32	5.72	4.89	3.49	1.57] test loss i: [0.76	0.77	7.94	6.11	4.62	1.96] | 
| 05-02 01:06:23 epoch: 1093| time: 2.5s| train loss: +1.677e+01 | test loss: +2.383e+01 | 
| 05-02 01:06:23 epoch: 1093| train loss i: [0.21	1.1 	5.39	4.74	3.76	1.58] test loss i: [0.59	1.64	8.04	6.08	5.5 	1.98] | 
| 05-02 01:06:25 epoch: 1094| time: 2.5s| train loss: +1.751e+01 | test loss: +1.637e+01 | 
| 05-02 01:06:25 epoch: 1094| train loss i: [0.2 	1.24	5.72	4.96	3.74	1.64] test loss i: [0.14	1.11	5.34	4.84	3.33	1.61] | 
| 05-02 01:06:28 epoch: 1095| time: 2.4s| train loss: +1.721e+01 | test loss: +1.949e+01 | 
| 05-02 01:06:28 epoch: 1095| train loss i: [0.14	1.14	5.51	4.76	4.01	1.64] test loss i: [0.26	2.61	6.59	4.99	3.43	1.61] | 
| 05-02 01:06:30 epoch: 1096| time: 2.5s| train loss: +1.752e+01 | test loss: +1.721e+01 | 
| 05-02 01:06:30 epoch: 1096| train loss i: [0.19	1.79	5.39	4.87	3.71	1.57] test loss i: [0.11	3.66	3.77	4.43	3.83	1.42] | 
| 05-02 01:06:33 epoch: 1097| time: 2.5s| train loss: +1.775e+01 | test loss: +1.724e+01 | 
| 05-02 01:06:33 epoch: 1097| train loss i: [0.2 	1.23	6.59	4.67	3.52	1.55] test loss i: [0.65	2.2 	4.45	4.42	3.69	1.83] | 
| 05-02 01:06:35 epoch: 1098| time: 2.5s| train loss: +1.799e+01 | test loss: +1.439e+01 | 
| 05-02 01:06:35 epoch: 1098| train loss i: [0.16	1.45	5.83	5.01	3.93	1.6 ] test loss i: [0.2 	0.42	4.78	4.28	3.21	1.51] | 
| 05-02 01:06:38 epoch: 1099| time: 2.6s| train loss: +1.786e+01 | test loss: +2.242e+01 | 
| 05-02 01:06:38 epoch: 1099| train loss i: [0.16	1.65	5.89	4.72	3.87	1.57] test loss i: [0.43	4.08	5.64	5.84	4.68	1.75] | 
| 05-02 01:06:40 epoch: 1100| time: 2.5s| train loss: +1.664e+01 | test loss: +1.917e+01 | 
| 05-02 01:06:40 epoch: 1100| train loss i: [0.2 	0.85	5.05	5.09	3.94	1.52] test loss i: [0.1 	1.46	5.76	4.99	4.77	2.08] | 
| 05-02 01:06:43 epoch: 1101| time: 2.5s| train loss: +1.703e+01 | test loss: +1.670e+01 | 
| 05-02 01:06:43 epoch: 1101| train loss i: [0.14	1.53	4.91	4.82	4.14	1.5 ] test loss i: [0.24	0.14	6.83	4.24	3.38	1.86] | 
| 05-02 01:06:45 epoch: 1102| time: 2.5s| train loss: +1.820e+01 | test loss: +1.941e+01 | 
| 05-02 01:06:45 epoch: 1102| train loss i: [0.18	1.74	5.72	5.16	3.84	1.57] test loss i: [0.21	1.06	5.76	6.3 	4.35	1.73] | 
| 05-02 01:06:48 epoch: 1103| time: 2.5s| train loss: +1.820e+01 | test loss: +2.679e+01 | 
| 05-02 01:06:48 epoch: 1103| train loss i: [0.17	1.41	5.98	4.95	4.1 	1.59] test loss i: [1.03	4.57	7.92	6.3 	4.79	2.18] | 
| 05-02 01:06:50 epoch: 1104| time: 2.5s| train loss: +1.699e+01 | test loss: +1.590e+01 | 
| 05-02 01:06:50 epoch: 1104| train loss i: [0.18	1.11	5.14	4.9 	4.04	1.62] test loss i: [0.07	1.68	4.56	4.81	3.2 	1.58] | 
| 05-02 01:06:53 epoch: 1105| time: 2.4s| train loss: +1.754e+01 | test loss: +1.525e+01 | 
| 05-02 01:06:53 epoch: 1105| train loss i: [0.15	1.35	5.69	5.  	3.8 	1.54] test loss i: [0.51	1.53	4.11	4.48	3.13	1.49] | 
| 05-02 01:06:55 epoch: 1106| time: 2.4s| train loss: +1.807e+01 | test loss: +1.812e+01 | 
| 05-02 01:06:55 epoch: 1106| train loss i: [0.17	1.8 	6.  	4.88	3.64	1.59] test loss i: [0.16	2.37	6.46	4.13	3.57	1.43] | 
| 05-02 01:06:57 epoch: 1107| time: 2.5s| train loss: +1.755e+01 | test loss: +1.712e+01 | 
| 05-02 01:06:57 epoch: 1107| train loss i: [0.16	1.88	5.74	4.55	3.68	1.55] test loss i: [0.44	1.04	5.63	4.63	3.76	1.61] | 
| 05-02 01:07:00 epoch: 1108| time: 2.4s| train loss: +1.658e+01 | test loss: +1.907e+01 | 
| 05-02 01:07:00 epoch: 1108| train loss i: [0.15	1.34	5.01	4.65	3.83	1.6 ] test loss i: [0.2 	1.27	6.49	4.99	4.43	1.69] | 
| 05-02 01:07:02 epoch: 1109| time: 2.5s| train loss: +1.775e+01 | test loss: +1.593e+01 | 
| 05-02 01:07:02 epoch: 1109| train loss i: [0.15	1.46	5.6 	5.16	3.8 	1.58] test loss i: [0.07	0.52	4.81	5.18	3.84	1.5 ] | 
| 05-02 01:07:05 epoch: 1110| time: 2.5s| train loss: +1.844e+01 | test loss: +1.912e+01 | 
| 05-02 01:07:05 epoch: 1110| train loss i: [0.16	1.73	6.03	4.93	3.97	1.62] test loss i: [0.64	0.65	6.72	5.11	4.13	1.86] | 
| 05-02 01:07:07 epoch: 1111| time: 2.5s| train loss: +1.799e+01 | test loss: +2.746e+01 | 
| 05-02 01:07:07 epoch: 1111| train loss i: [0.12	1.87	5.58	4.89	3.98	1.55] test loss i: [ 0.34	 2.1 	10.35	 7.01	 5.41	 2.24] | 
| 05-02 01:07:10 epoch: 1112| time: 2.5s| train loss: +1.678e+01 | test loss: +1.551e+01 | 
| 05-02 01:07:10 epoch: 1112| train loss i: [0.17	0.57	5.22	5.21	4.09	1.52] test loss i: [0.54	0.79	5.  	4.27	3.34	1.57] | 
| 05-02 01:07:12 epoch: 1113| time: 2.4s| train loss: +1.742e+01 | test loss: +2.320e+01 | 
| 05-02 01:07:12 epoch: 1113| train loss i: [0.14	1.37	5.99	4.7 	3.64	1.58] test loss i: [0.19	0.7 	8.13	6.9 	5.23	2.04] | 
| 05-02 01:07:15 epoch: 1114| time: 2.4s| train loss: +1.759e+01 | test loss: +1.658e+01 | 
| 05-02 01:07:15 epoch: 1114| train loss i: [0.1 	2.16	5.44	4.52	3.81	1.55] test loss i: [0.14	1.6 	4.46	5.01	3.85	1.53] | 
| 05-02 01:07:17 epoch: 1115| time: 2.5s| train loss: +1.699e+01 | test loss: +1.649e+01 | 
| 05-02 01:07:17 epoch: 1115| train loss i: [0.16	1.54	5.11	4.77	3.9 	1.51] test loss i: [0.15	0.82	5.21	4.63	3.84	1.83] | 
| 05-02 01:07:20 epoch: 1116| time: 2.5s| train loss: +1.711e+01 | test loss: +1.937e+01 | 
| 05-02 01:07:20 epoch: 1116| train loss i: [0.08	1.27	5.32	4.98	3.91	1.54] test loss i: [0.22	0.97	6.55	5.3 	4.38	1.95] | 
| 05-02 01:07:22 epoch: 1117| time: 2.4s| train loss: +1.765e+01 | test loss: +2.607e+01 | 
| 05-02 01:07:22 epoch: 1117| train loss i: [0.08	1.85	5.31	5.29	3.57	1.55] test loss i: [0.21	3.5 	7.42	7.59	5.38	1.97] | 
| 05-02 01:07:25 epoch: 1118| time: 2.5s| train loss: +1.733e+01 | test loss: +1.458e+01 | 
| 05-02 01:07:25 epoch: 1118| train loss i: [0.08	1.42	5.58	5.06	3.67	1.53] test loss i: [0.09	0.63	5.21	4.  	3.09	1.55] | 
| 05-02 01:07:27 epoch: 1119| time: 2.5s| train loss: +1.581e+01 | test loss: +1.800e+01 | 
| 05-02 01:07:27 epoch: 1119| train loss i: [0.1 	1.04	5.06	4.4 	3.69	1.52] test loss i: [0.12	2.07	4.93	5.04	4.26	1.57] | 
| 05-02 01:07:29 epoch: 1120| time: 2.5s| train loss: +1.676e+01 | test loss: +1.469e+01 | 
| 05-02 01:07:29 epoch: 1120| train loss i: [0.11	1.3 	5.48	4.63	3.71	1.52] test loss i: [0.16	0.7 	4.3 	4.38	3.67	1.47] | 
| 05-02 01:07:32 epoch: 1121| time: 2.5s| train loss: +1.727e+01 | test loss: +2.134e+01 | 
| 05-02 01:07:32 epoch: 1121| train loss i: [0.13	1.38	5.33	5.05	3.85	1.53] test loss i: [0.13	0.9 	7.7 	5.98	4.88	1.75] | 
| 05-02 01:07:34 epoch: 1122| time: 2.5s| train loss: +1.715e+01 | test loss: +2.174e+01 | 
| 05-02 01:07:34 epoch: 1122| train loss i: [0.09	1.65	5.14	4.9 	3.81	1.56] test loss i: [0.11	3.4 	5.75	5.32	5.56	1.61] | 
| 05-02 01:07:37 epoch: 1123| time: 2.5s| train loss: +1.710e+01 | test loss: +1.503e+01 | 
| 05-02 01:07:37 epoch: 1123| train loss i: [0.21	1.11	5.44	4.83	3.91	1.6 ] test loss i: [0.18	1.47	4.21	4.1 	3.75	1.32] | 
| 05-02 01:07:39 epoch: 1124| time: 2.5s| train loss: +1.692e+01 | test loss: +2.960e+01 | 
| 05-02 01:07:39 epoch: 1124| train loss i: [0.28	1.36	5.36	4.47	3.83	1.62] test loss i: [1.03	3.2 	9.21	8.45	5.59	2.12] | 
| 05-02 01:07:42 epoch: 1125| time: 2.4s| train loss: +1.760e+01 | test loss: +1.598e+01 | 
| 05-02 01:07:42 epoch: 1125| train loss i: [0.22	1.37	5.8 	4.75	3.8 	1.66] test loss i: [0.1 	1.51	5.25	4.29	3.35	1.47] | 
| 05-02 01:07:44 epoch: 1126| time: 2.5s| train loss: +1.693e+01 | test loss: +1.968e+01 | 
| 05-02 01:07:44 epoch: 1126| train loss i: [0.18	1.44	4.77	4.98	3.95	1.6 ] test loss i: [0.95	0.81	6.92	4.62	4.22	2.16] | 
| 05-02 01:07:47 epoch: 1127| time: 2.5s| train loss: +1.718e+01 | test loss: +1.687e+01 | 
| 05-02 01:07:47 epoch: 1127| train loss i: [0.19	1.02	5.41	5.04	3.98	1.54] test loss i: [0.11	1.02	4.96	4.67	4.35	1.75] | 
| 05-02 01:07:49 epoch: 1128| time: 2.4s| train loss: +1.808e+01 | test loss: +1.901e+01 | 
| 05-02 01:07:49 epoch: 1128| train loss i: [0.16	2.08	5.68	4.68	3.88	1.6 ] test loss i: [0.22	2.09	6.07	5.09	3.4 	2.14] | 
| 05-02 01:07:52 epoch: 1129| time: 2.5s| train loss: +1.732e+01 | test loss: +1.588e+01 | 
| 05-02 01:07:52 epoch: 1129| train loss i: [0.37	1.04	5.3 	5.15	3.91	1.55] test loss i: [0.19	0.8 	5.04	4.56	3.67	1.62] | 
| 05-02 01:07:54 epoch: 1130| time: 2.4s| train loss: +1.743e+01 | test loss: +2.314e+01 | 
| 05-02 01:07:54 epoch: 1130| train loss i: [0.17	1.63	5.64	4.78	3.65	1.55] test loss i: [0.34	2.99	6.81	6.22	4.78	2.  ] | 
| 05-02 01:07:57 epoch: 1131| time: 2.5s| train loss: +1.720e+01 | test loss: +2.008e+01 | 
| 05-02 01:07:57 epoch: 1131| train loss i: [0.19	1.36	5.44	4.69	3.9 	1.61] test loss i: [0.61	3.32	5.93	4.69	3.82	1.71] | 
| 05-02 01:07:59 epoch: 1132| time: 2.5s| train loss: +1.670e+01 | test loss: +1.797e+01 | 
| 05-02 01:07:59 epoch: 1132| train loss i: [0.19	1.03	5.38	4.74	3.83	1.54] test loss i: [0.11	2.92	5.08	4.76	3.59	1.51] | 
| 05-02 01:08:01 epoch: 1133| time: 2.5s| train loss: +1.675e+01 | test loss: +1.638e+01 | 
| 05-02 01:08:01 epoch: 1133| train loss i: [0.17	1.04	5.42	4.95	3.61	1.57] test loss i: [0.26	0.99	4.82	4.59	4.27	1.45] | 
| 05-02 01:08:04 epoch: 1134| time: 2.5s| train loss: +1.722e+01 | test loss: +2.030e+01 | 
| 05-02 01:08:04 epoch: 1134| train loss i: [0.3 	1.68	5.41	4.69	3.59	1.55] test loss i: [1.25	0.6 	6.59	5.22	4.41	2.23] | 
| 05-02 01:08:06 epoch: 1135| time: 2.5s| train loss: +1.766e+01 | test loss: +2.893e+01 | 
| 05-02 01:08:06 epoch: 1135| train loss i: [0.18	1.31	6.09	4.81	3.72	1.56] test loss i: [0.13	5.33	8.75	6.78	5.39	2.54] | 
| 05-02 01:08:09 epoch: 1136| time: 2.5s| train loss: +1.686e+01 | test loss: +1.773e+01 | 
| 05-02 01:08:09 epoch: 1136| train loss i: [0.17	1.59	5.37	4.63	3.52	1.57] test loss i: [0.42	1.38	4.31	5.52	4.22	1.88] | 
| 05-02 01:08:11 epoch: 1137| time: 2.5s| train loss: +1.707e+01 | test loss: +1.439e+01 | 
| 05-02 01:08:11 epoch: 1137| train loss i: [0.15	1.28	5.22	4.91	3.93	1.58] test loss i: [0.07	2.27	3.7 	3.61	3.28	1.45] | 
| 05-02 01:08:14 epoch: 1138| time: 2.5s| train loss: +1.841e+01 | test loss: +1.544e+01 | 
| 05-02 01:08:14 epoch: 1138| train loss i: [0.16	2.01	5.73	5.26	3.65	1.61] test loss i: [0.07	1.07	4.37	4.36	3.92	1.65] | 
| 05-02 01:08:16 epoch: 1139| time: 2.5s| train loss: +1.762e+01 | test loss: +1.593e+01 | 
| 05-02 01:08:16 epoch: 1139| train loss i: [0.14	1.4 	5.81	4.84	3.88	1.55] test loss i: [0.48	1.9 	5.42	3.64	3.13	1.36] | 
| 05-02 01:08:19 epoch: 1140| time: 2.5s| train loss: +1.674e+01 | test loss: +1.515e+01 | 
| 05-02 01:08:19 epoch: 1140| train loss i: [0.16	1.22	5.65	4.5 	3.66	1.55] test loss i: [0.23	0.85	4.91	4.13	3.63	1.4 ] | 
| 05-02 01:08:21 epoch: 1141| time: 2.5s| train loss: +1.633e+01 | test loss: +1.417e+01 | 
| 05-02 01:08:21 epoch: 1141| train loss i: [0.12	0.94	5.39	4.66	3.69	1.55] test loss i: [0.09	0.6 	3.9 	4.28	3.58	1.72] | 
| 05-02 01:08:24 epoch: 1142| time: 2.5s| train loss: +1.717e+01 | test loss: +2.180e+01 | 
| 05-02 01:08:24 epoch: 1142| train loss i: [0.15	1.64	5.61	4.68	3.61	1.48] test loss i: [0.15	2.25	6.44	6.26	4.72	1.98] | 
| 05-02 01:08:26 epoch: 1143| time: 2.5s| train loss: +1.790e+01 | test loss: +1.974e+01 | 
| 05-02 01:08:26 epoch: 1143| train loss i: [0.17	2.07	5.16	4.96	3.95	1.59] test loss i: [1.02	1.68	7.21	4.35	3.78	1.7 ] | 
| 05-02 01:08:29 epoch: 1144| time: 2.5s| train loss: +1.708e+01 | test loss: +1.495e+01 | 
| 05-02 01:08:29 epoch: 1144| train loss i: [0.14	1.42	5.64	4.62	3.71	1.54] test loss i: [0.09	0.96	5.36	3.93	3.23	1.38] | 
| 05-02 01:08:31 epoch: 1145| time: 2.5s| train loss: +1.675e+01 | test loss: +1.816e+01 | 
| 05-02 01:08:31 epoch: 1145| train loss i: [0.18	1.06	5.34	4.78	3.89	1.51] test loss i: [0.21	2.34	5.11	4.94	3.87	1.68] | 
| 05-02 01:08:34 epoch: 1146| time: 2.5s| train loss: +1.730e+01 | test loss: +1.477e+01 | 
| 05-02 01:08:34 epoch: 1146| train loss i: [0.14	1.65	5.67	4.49	3.76	1.59] test loss i: [0.11	0.22	4.71	4.31	3.97	1.45] | 
| 05-02 01:08:36 epoch: 1147| time: 2.5s| train loss: +1.743e+01 | test loss: +1.626e+01 | 
| 05-02 01:08:36 epoch: 1147| train loss i: [0.17	1.68	4.94	5.26	3.79	1.6 ] test loss i: [0.24	0.51	5.13	4.6 	4.22	1.57] | 
| 05-02 01:08:38 epoch: 1148| time: 2.5s| train loss: +1.706e+01 | test loss: +1.660e+01 | 
| 05-02 01:08:38 epoch: 1148| train loss i: [0.14	1.21	5.63	4.77	3.75	1.56] test loss i: [0.34	0.2 	5.14	5.42	3.91	1.59] | 
| 05-02 01:08:41 epoch: 1149| time: 2.5s| train loss: +1.730e+01 | test loss: +1.704e+01 | 
| 05-02 01:08:41 epoch: 1149| train loss i: [0.17	1.52	5.7 	4.61	3.72	1.57] test loss i: [0.08	2.13	4.69	4.74	3.9 	1.5 ] | 
| 05-02 01:08:43 epoch: 1150| time: 2.5s| train loss: +1.702e+01 | test loss: +2.354e+01 | 
| 05-02 01:08:43 epoch: 1150| train loss i: [0.15	0.67	5.72	4.87	4.08	1.54] test loss i: [0.26	1.05	7.17	6.8 	6.01	2.25] | 
| 05-02 01:08:46 epoch: 1151| time: 2.5s| train loss: +1.682e+01 | test loss: +2.976e+01 | 
| 05-02 01:08:46 epoch: 1151| train loss i: [0.14	1.07	5.52	4.66	3.82	1.6 ] test loss i: [0.5 	5.29	6.67	8.55	6.06	2.68] | 
| 05-02 01:08:49 epoch: 1152| time: 2.6s| train loss: +1.695e+01 | test loss: +1.634e+01 | 
| 05-02 01:08:49 epoch: 1152| train loss i: [0.13	1.39	5.36	4.53	3.93	1.61] test loss i: [0.27	1.78	4.64	3.78	4.47	1.4 ] | 
| 05-02 01:08:51 epoch: 1153| time: 2.5s| train loss: +1.777e+01 | test loss: +1.536e+01 | 
| 05-02 01:08:51 epoch: 1153| train loss i: [0.12	1.84	5.47	4.76	4.02	1.55] test loss i: [0.08	1.1 	4.83	4.65	2.96	1.74] | 
| 05-02 01:08:54 epoch: 1154| time: 2.5s| train loss: +1.735e+01 | test loss: +1.676e+01 | 
| 05-02 01:08:54 epoch: 1154| train loss i: [0.08	1.47	5.56	4.86	3.78	1.6 ] test loss i: [0.08	1.15	5.89	3.73	4.11	1.8 ] | 
| 05-02 01:08:56 epoch: 1155| time: 2.6s| train loss: +1.664e+01 | test loss: +2.028e+01 | 
| 05-02 01:08:56 epoch: 1155| train loss i: [0.12	1.32	4.9 	4.84	3.94	1.52] test loss i: [0.2 	0.78	6.54	6.1 	4.48	2.19] | 
| 05-02 01:08:59 epoch: 1156| time: 2.5s| train loss: +1.656e+01 | test loss: +1.720e+01 | 
| 05-02 01:08:59 epoch: 1156| train loss i: [0.13	0.87	5.56	4.68	3.8 	1.52] test loss i: [0.05	2.02	4.11	5.34	4.15	1.52] | 
| 05-02 01:09:01 epoch: 1157| time: 2.5s| train loss: +1.737e+01 | test loss: +1.652e+01 | 
| 05-02 01:09:01 epoch: 1157| train loss i: [0.21	1.4 	5.5 	4.82	3.9 	1.53] test loss i: [0.1 	0.78	5.05	5.18	3.65	1.75] | 
| 05-02 01:09:04 epoch: 1158| time: 2.5s| train loss: +1.668e+01 | test loss: +1.713e+01 | 
| 05-02 01:09:04 epoch: 1158| train loss i: [0.16	1.4 	5.08	4.89	3.56	1.59] test loss i: [0.12	2.04	5.5 	4.48	3.31	1.68] | 
| 05-02 01:09:06 epoch: 1159| time: 2.6s| train loss: +1.772e+01 | test loss: +1.593e+01 | 
| 05-02 01:09:06 epoch: 1159| train loss i: [0.11	1.57	5.53	4.75	4.21	1.55] test loss i: [0.25	0.59	5.97	4.2 	3.14	1.79] | 
| 05-02 01:09:09 epoch: 1160| time: 2.5s| train loss: +1.761e+01 | test loss: +1.631e+01 | 
| 05-02 01:09:09 epoch: 1160| train loss i: [0.13	1.64	5.59	4.89	3.76	1.6 ] test loss i: [0.17	0.55	4.82	5.82	3.24	1.71] | 
| 05-02 01:09:11 epoch: 1161| time: 2.5s| train loss: +1.799e+01 | test loss: +1.714e+01 | 
| 05-02 01:09:11 epoch: 1161| train loss i: [0.16	2.6 	5.45	4.47	3.77	1.54] test loss i: [0.17	0.84	4.98	5.19	4.23	1.74] | 
| 05-02 01:09:14 epoch: 1162| time: 2.6s| train loss: +1.680e+01 | test loss: +1.945e+01 | 
| 05-02 01:09:14 epoch: 1162| train loss i: [0.13	1.27	5.58	4.53	3.73	1.55] test loss i: [0.72	1.07	5.77	5.64	4.66	1.6 ] | 
| 05-02 01:09:16 epoch: 1163| time: 2.5s| train loss: +1.672e+01 | test loss: +1.966e+01 | 
| 05-02 01:09:16 epoch: 1163| train loss i: [0.14	1.38	5.25	4.78	3.66	1.51] test loss i: [0.3 	2.38	6.93	4.92	3.65	1.48] | 
| 05-02 01:09:19 epoch: 1164| time: 2.5s| train loss: +1.634e+01 | test loss: +1.939e+01 | 
| 05-02 01:09:19 epoch: 1164| train loss i: [0.14	1.14	5.33	4.41	3.77	1.55] test loss i: [0.19	1.88	6.51	4.37	4.4 	2.04] | 
| 05-02 01:09:21 epoch: 1165| time: 2.5s| train loss: +1.727e+01 | test loss: +1.550e+01 | 
| 05-02 01:09:21 epoch: 1165| train loss i: [0.15	1.08	5.58	5.12	3.76	1.58] test loss i: [0.13	0.94	4.81	4.81	3.24	1.57] | 
| 05-02 01:09:24 epoch: 1166| time: 2.5s| train loss: +1.705e+01 | test loss: +2.764e+01 | 
| 05-02 01:09:24 epoch: 1166| train loss i: [0.11	1.19	5.74	4.78	3.63	1.6 ] test loss i: [0.13	4.93	7.49	6.99	5.67	2.44] | 
| 05-02 01:09:27 epoch: 1167| time: 2.6s| train loss: +1.727e+01 | test loss: +1.821e+01 | 
| 05-02 01:09:27 epoch: 1167| train loss i: [0.17	1.75	5.15	4.92	3.78	1.5 ] test loss i: [0.14	1.86	5.63	4.38	4.72	1.48] | 
| 05-02 01:09:29 epoch: 1168| time: 2.5s| train loss: +1.648e+01 | test loss: +1.907e+01 | 
| 05-02 01:09:29 epoch: 1168| train loss i: [0.08	1.39	4.69	4.83	3.87	1.62] test loss i: [0.16	2.3 	5.56	5.43	3.75	1.87] | 
| 05-02 01:09:32 epoch: 1169| time: 2.6s| train loss: +1.661e+01 | test loss: +1.863e+01 | 
| 05-02 01:09:32 epoch: 1169| train loss i: [0.11	1.09	5.16	4.83	3.81	1.61] test loss i: [0.18	0.9 	6.41	4.98	4.22	1.94] | 
| 05-02 01:09:34 epoch: 1170| time: 2.5s| train loss: +1.764e+01 | test loss: +2.230e+01 | 
| 05-02 01:09:34 epoch: 1170| train loss i: [0.12	1.88	5.53	4.68	3.96	1.48] test loss i: [0.13	2.95	5.96	6.74	4.57	1.96] | 
| 05-02 01:09:37 epoch: 1171| time: 2.6s| train loss: +1.779e+01 | test loss: +1.727e+01 | 
| 05-02 01:09:37 epoch: 1171| train loss i: [0.21	1.61	5.95	4.79	3.65	1.57] test loss i: [0.66	0.65	5.5 	4.49	4.08	1.89] | 
| 05-02 01:09:39 epoch: 1172| time: 2.5s| train loss: +1.865e+01 | test loss: +2.299e+01 | 
| 05-02 01:09:39 epoch: 1172| train loss i: [0.22	1.84	5.74	5.3 	3.98	1.57] test loss i: [0.19	2.62	6.63	6.45	4.9 	2.2 ] | 
| 05-02 01:09:42 epoch: 1173| time: 2.5s| train loss: +1.683e+01 | test loss: +2.216e+01 | 
| 05-02 01:09:42 epoch: 1173| train loss i: [0.17	1.19	5.19	4.87	3.94	1.47] test loss i: [0.47	0.94	7.22	7.04	4.46	2.05] | 
| 05-02 01:09:44 epoch: 1174| time: 2.5s| train loss: +1.645e+01 | test loss: +2.623e+01 | 
| 05-02 01:09:44 epoch: 1174| train loss i: [0.17	1.47	4.68	4.91	3.71	1.52] test loss i: [0.19	2.97	8.95	6.68	5.04	2.4 ] | 
| 05-02 01:09:47 epoch: 1175| time: 2.5s| train loss: +1.715e+01 | test loss: +1.628e+01 | 
| 05-02 01:09:47 epoch: 1175| train loss i: [0.15	1.29	5.2 	5.05	3.9 	1.57] test loss i: [0.22	0.75	5.11	4.48	4.1 	1.63] | 
| 05-02 01:09:49 epoch: 1176| time: 2.6s| train loss: +1.699e+01 | test loss: +2.329e+01 | 
| 05-02 01:09:49 epoch: 1176| train loss i: [0.15	1.03	5.82	4.73	3.74	1.53] test loss i: [0.98	2.33	5.35	6.93	5.49	2.2 ] | 
| 05-02 01:09:52 epoch: 1177| time: 2.5s| train loss: +1.750e+01 | test loss: +1.519e+01 | 
| 05-02 01:09:52 epoch: 1177| train loss i: [0.12	2.32	5.16	4.51	3.79	1.61] test loss i: [0.15	1.1 	4.43	3.8 	4.3 	1.41] | 
| 05-02 01:09:54 epoch: 1178| time: 2.5s| train loss: +1.720e+01 | test loss: +1.924e+01 | 
| 05-02 01:09:54 epoch: 1178| train loss i: [0.14	1.29	5.1 	5.03	4.13	1.52] test loss i: [0.15	3.99	6.41	4.04	2.97	1.68] | 
| 05-02 01:09:57 epoch: 1179| time: 2.6s| train loss: +1.839e+01 | test loss: +1.791e+01 | 
| 05-02 01:09:57 epoch: 1179| train loss i: [0.14	1.82	5.76	5.2 	3.88	1.59] test loss i: [0.27	1.63	5.44	5.06	3.78	1.73] | 
| 05-02 01:10:00 epoch: 1180| time: 2.5s| train loss: +1.718e+01 | test loss: +2.144e+01 | 
| 05-02 01:10:00 epoch: 1180| train loss i: [0.16	1.75	5.11	4.89	3.73	1.53] test loss i: [0.17	4.51	5.94	5.53	3.59	1.7 ] | 
| 05-02 01:10:02 epoch: 1181| time: 2.5s| train loss: +1.777e+01 | test loss: +2.156e+01 | 
| 05-02 01:10:02 epoch: 1181| train loss i: [0.15	1.47	5.6 	4.95	4.03	1.58] test loss i: [0.29	1.48	6.9 	5.86	5.15	1.88] | 
| 05-02 01:10:04 epoch: 1182| time: 2.5s| train loss: +1.666e+01 | test loss: +1.782e+01 | 
| 05-02 01:10:04 epoch: 1182| train loss i: [0.13	1.71	4.97	4.58	3.73	1.54] test loss i: [0.11	0.41	6.41	5.26	3.88	1.75] | 
| 05-02 01:10:07 epoch: 1183| time: 2.4s| train loss: +1.708e+01 | test loss: +1.796e+01 | 
| 05-02 01:10:07 epoch: 1183| train loss i: [0.1 	0.99	5.32	5.04	4.1 	1.52] test loss i: [0.45	1.35	5.82	4.47	4.25	1.62] | 
| 05-02 01:10:09 epoch: 1184| time: 2.4s| train loss: +1.792e+01 | test loss: +1.889e+01 | 
| 05-02 01:10:09 epoch: 1184| train loss i: [0.11	1.52	6.1 	4.73	3.9 	1.56] test loss i: [0.12	0.43	5.46	6.32	4.62	1.94] | 
| 05-02 01:10:12 epoch: 1185| time: 2.5s| train loss: +1.702e+01 | test loss: +2.192e+01 | 
| 05-02 01:10:12 epoch: 1185| train loss i: [0.11	1.22	5.31	5.02	3.74	1.62] test loss i: [0.27	2.5 	6.99	5.52	4.42	2.22] | 
| 05-02 01:10:14 epoch: 1186| time: 2.5s| train loss: +1.791e+01 | test loss: +1.819e+01 | 
| 05-02 01:10:14 epoch: 1186| train loss i: [0.1 	1.68	5.39	5.06	4.04	1.64] test loss i: [0.28	1.82	5.46	4.95	4.12	1.56] | 
| 05-02 01:10:17 epoch: 1187| time: 2.5s| train loss: +1.675e+01 | test loss: +1.819e+01 | 
| 05-02 01:10:17 epoch: 1187| train loss i: [0.11	0.98	5.3 	5.13	3.71	1.53] test loss i: [0.17	0.75	6.23	5.38	4.14	1.52] | 
| 05-02 01:10:19 epoch: 1188| time: 2.5s| train loss: +1.663e+01 | test loss: +1.709e+01 | 
| 05-02 01:10:19 epoch: 1188| train loss i: [0.12	1.14	5.28	4.58	3.95	1.56] test loss i: [0.23	1.42	5.06	4.77	4.  	1.61] | 
| 05-02 01:10:22 epoch: 1189| time: 2.4s| train loss: +1.809e+01 | test loss: +1.956e+01 | 
| 05-02 01:10:22 epoch: 1189| train loss i: [0.17	2.02	5.53	4.98	3.86	1.54] test loss i: [0.69	1.32	6.81	5.12	3.86	1.76] | 
| 05-02 01:10:24 epoch: 1190| time: 2.5s| train loss: +1.711e+01 | test loss: +2.059e+01 | 
| 05-02 01:10:24 epoch: 1190| train loss i: [0.17	1.21	5.23	4.99	3.9 	1.6 ] test loss i: [0.48	3.39	5.49	4.92	4.5 	1.81] | 
| 05-02 01:10:27 epoch: 1191| time: 2.4s| train loss: +1.700e+01 | test loss: +1.931e+01 | 
| 05-02 01:10:27 epoch: 1191| train loss i: [0.1 	1.62	5.17	4.66	3.84	1.61] test loss i: [0.12	2.08	5.75	5.21	4.56	1.59] | 
| 05-02 01:10:29 epoch: 1192| time: 2.4s| train loss: +1.760e+01 | test loss: +1.968e+01 | 
| 05-02 01:10:29 epoch: 1192| train loss i: [0.13	1.48	5.74	4.99	3.74	1.51] test loss i: [0.15	1.42	5.76	6.23	4.13	1.98] | 
| 05-02 01:10:31 epoch: 1193| time: 2.5s| train loss: +1.698e+01 | test loss: +2.338e+01 | 
| 05-02 01:10:31 epoch: 1193| train loss i: [0.11	1.14	5.26	4.94	4.03	1.49] test loss i: [0.15	0.64	7.92	6.99	5.5 	2.18] | 
| 05-02 01:10:34 epoch: 1194| time: 2.5s| train loss: +1.722e+01 | test loss: +1.882e+01 | 
| 05-02 01:10:34 epoch: 1194| train loss i: [0.11	1.26	5.4 	5.05	3.8 	1.6 ] test loss i: [0.1 	1.88	5.25	4.99	4.91	1.69] | 
| 05-02 01:10:36 epoch: 1195| time: 2.5s| train loss: +1.614e+01 | test loss: +1.828e+01 | 
| 05-02 01:10:36 epoch: 1195| train loss i: [0.1 	0.96	5.03	4.71	3.82	1.52] test loss i: [0.42	1.37	5.75	4.54	4.36	1.85] | 
| 05-02 01:10:39 epoch: 1196| time: 2.5s| train loss: +1.724e+01 | test loss: +2.497e+01 | 
| 05-02 01:10:39 epoch: 1196| train loss i: [0.11	1.29	5.74	4.9 	3.62	1.58] test loss i: [0.15	0.21	8.18	8.84	5.05	2.54] | 
| 05-02 01:10:41 epoch: 1197| time: 2.4s| train loss: +1.673e+01 | test loss: +1.755e+01 | 
| 05-02 01:10:41 epoch: 1197| train loss i: [0.14	0.93	5.71	4.68	3.8 	1.46] test loss i: [0.07	1.85	6.24	4.46	3.29	1.65] | 
| 05-02 01:10:44 epoch: 1198| time: 2.4s| train loss: +1.711e+01 | test loss: +2.093e+01 | 
| 05-02 01:10:44 epoch: 1198| train loss i: [0.16	1.6 	5.39	4.63	3.78	1.55] test loss i: [0.53	0.93	6.9 	6.05	4.81	1.71] | 
| 05-02 01:10:46 epoch: 1199| time: 2.4s| train loss: +1.735e+01 | test loss: +1.825e+01 | 
| 05-02 01:10:46 epoch: 1199| train loss i: [0.16	1.62	5.51	4.81	3.66	1.58] test loss i: [0.11	1.26	5.15	6.15	3.85	1.74] | 
| 05-02 01:10:49 epoch: 1200| time: 2.4s| train loss: +1.765e+01 | test loss: +2.557e+01 | 
| 05-02 01:10:49 epoch: 1200| train loss i: [0.14	1.65	5.28	5.11	3.97	1.49] test loss i: [0.44	2.97	7.18	7.18	5.47	2.33] | 
| 05-02 01:10:51 epoch: 1201| time: 2.5s| train loss: +1.638e+01 | test loss: +1.926e+01 | 
| 05-02 01:10:51 epoch: 1201| train loss i: [0.1 	0.98	5.63	4.48	3.63	1.56] test loss i: [0.27	1.45	6.63	5.86	3.52	1.53] | 
| 05-02 01:10:54 epoch: 1202| time: 2.5s| train loss: +1.785e+01 | test loss: +1.591e+01 | 
| 05-02 01:10:54 epoch: 1202| train loss i: [0.09	1.84	5.5 	4.86	3.98	1.57] test loss i: [0.13	1.3 	5.64	3.92	3.29	1.64] | 
| 05-02 01:10:56 epoch: 1203| time: 2.5s| train loss: +1.803e+01 | test loss: +1.993e+01 | 
| 05-02 01:10:56 epoch: 1203| train loss i: [0.11	1.43	5.78	5.06	4.1 	1.53] test loss i: [0.18	0.72	7.75	5.13	4.07	2.06] | 
| 05-02 01:10:59 epoch: 1204| time: 2.5s| train loss: +1.714e+01 | test loss: +1.396e+01 | 
| 05-02 01:10:59 epoch: 1204| train loss i: [0.17	1.19	6.07	4.34	3.81	1.56] test loss i: [0.36	1.12	3.61	3.48	3.76	1.63] | 
| 05-02 01:11:01 epoch: 1205| time: 2.4s| train loss: +1.764e+01 | test loss: +1.594e+01 | 
| 05-02 01:11:01 epoch: 1205| train loss i: [0.16	1.23	5.81	4.85	3.96	1.63] test loss i: [0.32	1.01	4.86	4.91	3.14	1.7 ] | 
| 05-02 01:11:03 epoch: 1206| time: 2.5s| train loss: +1.678e+01 | test loss: +1.659e+01 | 
| 05-02 01:11:03 epoch: 1206| train loss i: [0.17	0.78	5.63	4.58	4.16	1.45] test loss i: [0.18	0.73	5.67	4.78	3.69	1.55] | 
| 05-02 01:11:06 epoch: 1207| time: 2.4s| train loss: +1.746e+01 | test loss: +2.093e+01 | 
| 05-02 01:11:06 epoch: 1207| train loss i: [0.21	1.61	4.94	5.36	3.78	1.57] test loss i: [0.89	1.56	5.28	6.35	4.6 	2.26] | 
| 05-02 01:11:08 epoch: 1208| time: 2.5s| train loss: +1.669e+01 | test loss: +1.946e+01 | 
| 05-02 01:11:08 epoch: 1208| train loss i: [0.18	0.93	5.45	4.83	3.67	1.64] test loss i: [0.44	1.42	5.92	6.22	3.69	1.77] | 
| 05-02 01:11:11 epoch: 1209| time: 2.5s| train loss: +1.702e+01 | test loss: +2.197e+01 | 
| 05-02 01:11:11 epoch: 1209| train loss i: [0.15	1.44	5.27	4.61	3.94	1.6 ] test loss i: [0.23	1.45	6.43	6.11	5.63	2.12] | 
| 05-02 01:11:13 epoch: 1210| time: 2.5s| train loss: +1.798e+01 | test loss: +1.568e+01 | 
| 05-02 01:11:13 epoch: 1210| train loss i: [0.24	1.42	5.99	4.96	3.73	1.64] test loss i: [0.25	0.65	5.77	3.83	3.38	1.81] | 
| 05-02 01:11:16 epoch: 1211| time: 2.5s| train loss: +1.886e+01 | test loss: +1.686e+01 | 
| 05-02 01:11:16 epoch: 1211| train loss i: [0.21	2.03	5.49	5.28	4.19	1.65] test loss i: [0.18	0.72	5.05	5.49	3.94	1.48] | 
| 05-02 01:11:18 epoch: 1212| time: 2.6s| train loss: +1.624e+01 | test loss: +2.339e+01 | 
| 05-02 01:11:18 epoch: 1212| train loss i: [0.12	1.21	5.17	4.44	3.8 	1.5 ] test loss i: [0.61	3.09	6.79	6.05	4.8 	2.04] | 
| 05-02 01:11:21 epoch: 1213| time: 2.6s| train loss: +1.701e+01 | test loss: +1.929e+01 | 
| 05-02 01:11:21 epoch: 1213| train loss i: [0.18	1.05	5.49	5.06	3.64	1.59] test loss i: [0.14	0.9 	5.68	6.52	4.03	2.02] | 
| 05-02 01:11:23 epoch: 1214| time: 2.5s| train loss: +1.785e+01 | test loss: +1.760e+01 | 
| 05-02 01:11:23 epoch: 1214| train loss i: [0.09	1.4 	5.66	5.09	4.04	1.56] test loss i: [0.25	0.68	5.76	5.7 	3.4 	1.81] | 
| 05-02 01:11:26 epoch: 1215| time: 2.5s| train loss: +1.726e+01 | test loss: +1.847e+01 | 
| 05-02 01:11:26 epoch: 1215| train loss i: [0.08	1.65	5.92	4.35	3.68	1.58] test loss i: [0.23	1.18	5.45	5.67	4.14	1.81] | 
| 05-02 01:11:28 epoch: 1216| time: 2.5s| train loss: +1.756e+01 | test loss: +2.445e+01 | 
| 05-02 01:11:28 epoch: 1216| train loss i: [0.12	1.69	5.26	5.22	3.63	1.63] test loss i: [0.23	2.12	6.84	6.98	5.61	2.66] | 
| 05-02 01:11:31 epoch: 1217| time: 2.5s| train loss: +1.722e+01 | test loss: +2.737e+01 | 
| 05-02 01:11:31 epoch: 1217| train loss i: [0.12	1.11	5.59	5.19	3.63	1.58] test loss i: [0.1 	5.25	8.46	6.69	4.69	2.19] | 
| 05-02 01:11:33 epoch: 1218| time: 2.5s| train loss: +1.820e+01 | test loss: +2.139e+01 | 
| 05-02 01:11:33 epoch: 1218| train loss i: [0.12	1.52	5.94	5.04	3.99	1.58] test loss i: [0.17	1.54	5.79	6.61	5.42	1.85] | 
| 05-02 01:11:36 epoch: 1219| time: 2.6s| train loss: +1.698e+01 | test loss: +2.116e+01 | 
| 05-02 01:11:36 epoch: 1219| train loss i: [0.1 	1.08	5.38	4.9 	3.93	1.59] test loss i: [0.22	2.05	6.66	5.13	5.04	2.05] | 
| 05-02 01:11:39 epoch: 1220| time: 2.5s| train loss: +1.726e+01 | test loss: +1.702e+01 | 
| 05-02 01:11:39 epoch: 1220| train loss i: [0.12	1.28	5.5 	5.01	3.79	1.56] test loss i: [0.69	0.72	5.41	4.6 	4.01	1.59] | 
| 05-02 01:11:41 epoch: 1221| time: 2.5s| train loss: +1.686e+01 | test loss: +2.271e+01 | 
| 05-02 01:11:41 epoch: 1221| train loss i: [0.08	0.89	5.78	4.68	3.84	1.57] test loss i: [0.16	2.11	7.45	6.43	4.17	2.39] | 
| 05-02 01:11:44 epoch: 1222| time: 2.6s| train loss: +1.774e+01 | test loss: +1.708e+01 | 
| 05-02 01:11:44 epoch: 1222| train loss i: [0.17	1.29	5.56	5.12	3.9 	1.69] test loss i: [0.14	2.23	5.1 	4.19	3.93	1.49] | 
| 05-02 01:11:46 epoch: 1223| time: 2.5s| train loss: +1.673e+01 | test loss: +1.573e+01 | 
| 05-02 01:11:46 epoch: 1223| train loss i: [0.14	1.  	5.26	5.17	3.63	1.53] test loss i: [0.13	0.41	5.2 	4.44	3.62	1.92] | 
| 05-02 01:11:49 epoch: 1224| time: 2.5s| train loss: +1.754e+01 | test loss: +1.412e+01 | 
| 05-02 01:11:49 epoch: 1224| train loss i: [0.11	1.3 	5.82	5.01	3.8 	1.5 ] test loss i: [0.15	1.15	4.29	4.17	2.9 	1.46] | 
| 05-02 01:11:51 epoch: 1225| time: 2.5s| train loss: +1.689e+01 | test loss: +1.929e+01 | 
| 05-02 01:11:51 epoch: 1225| train loss i: [0.16	1.36	5.04	4.79	3.98	1.56] test loss i: [0.31	3.25	5.79	5.05	3.24	1.66] | 
| 05-02 01:11:54 epoch: 1226| time: 2.4s| train loss: +1.784e+01 | test loss: +1.752e+01 | 
| 05-02 01:11:54 epoch: 1226| train loss i: [0.11	1.42	5.58	5.13	4.05	1.56] test loss i: [0.38	1.23	4.9 	5.68	3.54	1.78] | 
| 05-02 01:11:56 epoch: 1227| time: 2.5s| train loss: +1.738e+01 | test loss: +2.514e+01 | 
| 05-02 01:11:56 epoch: 1227| train loss i: [0.19	1.57	5.27	5.17	3.63	1.55] test loss i: [0.2 	2.88	6.44	6.96	6.49	2.18] | 
| 05-02 01:11:59 epoch: 1228| time: 2.5s| train loss: +1.755e+01 | test loss: +2.179e+01 | 
| 05-02 01:11:59 epoch: 1228| train loss i: [0.12	2.16	5.54	4.47	3.66	1.6 ] test loss i: [0.22	0.35	7.14	6.83	5.09	2.16] | 
| 05-02 01:12:01 epoch: 1229| time: 2.5s| train loss: +1.686e+01 | test loss: +1.663e+01 | 
| 05-02 01:12:01 epoch: 1229| train loss i: [0.11	1.64	4.82	5.  	3.75	1.54] test loss i: [0.24	0.7 	5.62	4.76	3.78	1.54] | 
| 05-02 01:12:03 epoch: 1230| time: 2.5s| train loss: +1.766e+01 | test loss: +1.683e+01 | 
| 05-02 01:12:03 epoch: 1230| train loss i: [0.16	0.98	5.76	4.96	4.19	1.61] test loss i: [0.06	0.24	5.33	5.32	4.3 	1.57] | 
| 05-02 01:12:06 epoch: 1231| time: 2.5s| train loss: +1.730e+01 | test loss: +2.275e+01 | 
| 05-02 01:12:06 epoch: 1231| train loss i: [0.11	1.55	5.45	4.78	3.93	1.49] test loss i: [0.15	3.29	4.73	7.52	4.94	2.12] | 
| 05-02 01:12:08 epoch: 1232| time: 2.4s| train loss: +1.749e+01 | test loss: +1.638e+01 | 
| 05-02 01:12:08 epoch: 1232| train loss i: [0.11	1.79	5.22	4.95	3.89	1.53] test loss i: [0.12	1.18	5.  	4.76	3.95	1.36] | 
| 05-02 01:12:11 epoch: 1233| time: 2.5s| train loss: +1.686e+01 | test loss: +1.969e+01 | 
| 05-02 01:12:11 epoch: 1233| train loss i: [0.17	0.95	5.29	4.9 	3.98	1.56] test loss i: [0.2 	2.07	5.99	5.59	3.85	1.98] | 
| 05-02 01:12:13 epoch: 1234| time: 2.4s| train loss: +1.707e+01 | test loss: +2.087e+01 | 
| 05-02 01:12:13 epoch: 1234| train loss i: [0.1 	1.69	5.15	4.84	3.77	1.51] test loss i: [0.2 	1.9 	6.41	5.48	4.93	1.95] | 
| 05-02 01:12:16 epoch: 1235| time: 2.4s| train loss: +1.718e+01 | test loss: +1.985e+01 | 
| 05-02 01:12:16 epoch: 1235| train loss i: [0.08	0.73	5.87	5.15	3.75	1.59] test loss i: [0.06	1.16	6.58	4.93	5.14	1.97] | 
| 05-02 01:12:18 epoch: 1236| time: 2.5s| train loss: +1.660e+01 | test loss: +2.609e+01 | 
| 05-02 01:12:18 epoch: 1236| train loss i: [0.12	1.45	4.99	4.61	3.93	1.49] test loss i: [0.29	1.44	9.81	6.92	5.26	2.37] | 
| 05-02 01:12:21 epoch: 1237| time: 2.5s| train loss: +1.620e+01 | test loss: +1.857e+01 | 
| 05-02 01:12:21 epoch: 1237| train loss i: [0.08	0.76	5.78	4.35	3.67	1.56] test loss i: [0.1 	2.39	5.78	4.41	4.22	1.67] | 
| 05-02 01:12:23 epoch: 1238| time: 2.5s| train loss: +1.754e+01 | test loss: +2.068e+01 | 
| 05-02 01:12:23 epoch: 1238| train loss i: [0.09	1.69	5.19	4.99	3.91	1.66] test loss i: [0.1 	1.31	6.17	6.76	4.3 	2.03] | 
| 05-02 01:12:26 epoch: 1239| time: 2.5s| train loss: +1.730e+01 | test loss: +1.700e+01 | 
| 05-02 01:12:26 epoch: 1239| train loss i: [0.09	1.36	5.39	4.93	3.98	1.54] test loss i: [0.08	0.76	4.82	5.86	4.04	1.43] | 
| 05-02 01:12:28 epoch: 1240| time: 2.4s| train loss: +1.724e+01 | test loss: +1.395e+01 | 
| 05-02 01:12:28 epoch: 1240| train loss i: [0.09	0.82	5.77	4.98	3.93	1.65] test loss i: [0.05	0.82	4.82	3.18	3.49	1.59] | 
| 05-02 01:12:30 epoch: 1241| time: 2.4s| train loss: +1.847e+01 | test loss: +1.404e+01 | 
| 05-02 01:12:30 epoch: 1241| train loss i: [0.11	2.54	5.54	4.92	3.66	1.69] test loss i: [0.19	0.29	3.99	4.54	3.5 	1.54] | 
| 05-02 01:12:33 epoch: 1242| time: 2.4s| train loss: +1.646e+01 | test loss: +1.762e+01 | 
| 05-02 01:12:33 epoch: 1242| train loss i: [0.13	0.99	5.15	5.08	3.59	1.52] test loss i: [0.23	0.65	5.26	6.25	3.54	1.68] | 
| 05-02 01:12:35 epoch: 1243| time: 2.4s| train loss: +1.755e+01 | test loss: +1.816e+01 | 
| 05-02 01:12:35 epoch: 1243| train loss i: [0.12	2.36	5.33	4.64	3.53	1.56] test loss i: [0.38	0.97	6.09	4.78	4.25	1.69] | 
| 05-02 01:12:38 epoch: 1244| time: 2.5s| train loss: +1.734e+01 | test loss: +1.900e+01 | 
| 05-02 01:12:38 epoch: 1244| train loss i: [0.28	2.32	4.96	4.65	3.56	1.58] test loss i: [0.64	1.21	5.49	5.32	4.64	1.69] | 
| 05-02 01:12:40 epoch: 1245| time: 2.5s| train loss: +1.733e+01 | test loss: +1.802e+01 | 
| 05-02 01:12:40 epoch: 1245| train loss i: [0.13	1.68	5.27	4.94	3.79	1.52] test loss i: [0.53	1.28	4.92	5.53	4.25	1.5 ] | 
| 05-02 01:12:43 epoch: 1246| time: 2.4s| train loss: +1.704e+01 | test loss: +1.588e+01 | 
| 05-02 01:12:43 epoch: 1246| train loss i: [0.12	1.41	4.99	4.83	4.12	1.58] test loss i: [0.14	1.01	4.99	4.74	3.34	1.65] | 
| 05-02 01:12:45 epoch: 1247| time: 2.4s| train loss: +1.856e+01 | test loss: +1.612e+01 | 
| 05-02 01:12:45 epoch: 1247| train loss i: [0.2 	1.68	5.98	5.07	3.99	1.65] test loss i: [0.24	0.61	5.8 	4.65	3.28	1.56] | 
| 05-02 01:12:48 epoch: 1248| time: 2.4s| train loss: +1.766e+01 | test loss: +1.581e+01 | 
| 05-02 01:12:48 epoch: 1248| train loss i: [0.09	1.36	6.15	4.73	3.82	1.52] test loss i: [0.11	0.56	5.6 	3.89	4.08	1.58] | 
| 05-02 01:12:50 epoch: 1249| time: 2.5s| train loss: +1.777e+01 | test loss: +1.849e+01 | 
| 05-02 01:12:50 epoch: 1249| train loss i: [0.14	1.8 	5.54	4.88	3.84	1.57] test loss i: [0.37	2.95	4.2 	4.38	4.8 	1.79] | 
| 05-02 01:12:53 epoch: 1250| time: 2.5s| train loss: +1.593e+01 | test loss: +2.160e+01 | 
| 05-02 01:12:53 epoch: 1250| train loss i: [0.16	0.91	4.67	4.65	3.93	1.62] test loss i: [0.47	1.15	6.37	6.56	5.22	1.83] | 
| 05-02 01:12:55 epoch: 1251| time: 2.4s| train loss: +1.710e+01 | test loss: +1.957e+01 | 
| 05-02 01:12:55 epoch: 1251| train loss i: [0.18	1.06	5.7 	4.95	3.69	1.52] test loss i: [0.72	2.58	4.62	5.21	4.16	2.29] | 
| 05-02 01:12:58 epoch: 1252| time: 2.5s| train loss: +1.717e+01 | test loss: +2.161e+01 | 
| 05-02 01:12:58 epoch: 1252| train loss i: [0.13	0.95	6.04	4.74	3.77	1.55] test loss i: [0.49	2.  	7.57	5.5 	4.45	1.61] | 
| 05-02 01:13:00 epoch: 1253| time: 2.5s| train loss: +1.729e+01 | test loss: +1.801e+01 | 
| 05-02 01:13:00 epoch: 1253| train loss i: [0.15	1.41	5.77	4.63	3.73	1.59] test loss i: [0.24	1.8 	5.98	4.74	3.65	1.6 ] | 
| 05-02 01:13:02 epoch: 1254| time: 2.4s| train loss: +1.625e+01 | test loss: +1.688e+01 | 
| 05-02 01:13:02 epoch: 1254| train loss i: [0.12	0.72	5.27	4.71	3.89	1.54] test loss i: [0.33	2.33	4.89	4.8 	3.22	1.32] | 
| 05-02 01:13:05 epoch: 1255| time: 2.4s| train loss: +1.689e+01 | test loss: +1.691e+01 | 
| 05-02 01:13:05 epoch: 1255| train loss i: [0.15	1.27	4.98	4.91	4.01	1.57] test loss i: [0.17	0.51	5.68	4.61	4.08	1.87] | 
| 05-02 01:13:07 epoch: 1256| time: 2.4s| train loss: +1.702e+01 | test loss: +2.091e+01 | 
| 05-02 01:13:07 epoch: 1256| train loss i: [0.15	1.59	5.33	4.8 	3.65	1.5 ] test loss i: [0.36	1.86	6.65	5.76	4.41	1.86] | 
| 05-02 01:13:10 epoch: 1257| time: 2.5s| train loss: +1.706e+01 | test loss: +1.730e+01 | 
| 05-02 01:13:10 epoch: 1257| train loss i: [0.25	0.86	5.59	4.98	3.84	1.54] test loss i: [0.5 	0.5 	4.63	5.5 	4.31	1.87] | 
| 05-02 01:13:12 epoch: 1258| time: 2.5s| train loss: +1.731e+01 | test loss: +1.913e+01 | 
| 05-02 01:13:12 epoch: 1258| train loss i: [0.16	0.87	5.93	4.67	4.06	1.63] test loss i: [0.2 	2.22	5.52	4.81	4.39	2.  ] | 
| 05-02 01:13:15 epoch: 1259| time: 2.5s| train loss: +1.700e+01 | test loss: +2.355e+01 | 
| 05-02 01:13:15 epoch: 1259| train loss i: [0.1 	1.24	5.27	4.88	3.9 	1.62] test loss i: [0.49	2.79	7.22	6.3 	4.65	2.11] | 
| 05-02 01:13:17 epoch: 1260| time: 2.5s| train loss: +1.791e+01 | test loss: +2.288e+01 | 
| 05-02 01:13:17 epoch: 1260| train loss i: [0.12	1.52	5.8 	5.09	3.78	1.6 ] test loss i: [0.36	1.08	8.94	6.18	4.39	1.93] | 
| 05-02 01:13:20 epoch: 1261| time: 2.4s| train loss: +1.748e+01 | test loss: +1.797e+01 | 
| 05-02 01:13:20 epoch: 1261| train loss i: [0.16	1.3 	5.77	4.91	3.79	1.56] test loss i: [0.1 	2.94	5.05	4.92	3.42	1.54] | 
| 05-02 01:13:22 epoch: 1262| time: 2.5s| train loss: +1.777e+01 | test loss: +1.546e+01 | 
| 05-02 01:13:22 epoch: 1262| train loss i: [0.11	1.35	5.28	5.18	4.25	1.6 ] test loss i: [0.13	0.28	4.71	5.45	3.28	1.61] | 
| 05-02 01:13:24 epoch: 1263| time: 2.4s| train loss: +1.697e+01 | test loss: +1.927e+01 | 
| 05-02 01:13:24 epoch: 1263| train loss i: [0.09	1.59	5.31	4.7 	3.65	1.62] test loss i: [0.23	0.38	6.54	5.55	4.81	1.76] | 
| 05-02 01:13:27 epoch: 1264| time: 2.4s| train loss: +1.715e+01 | test loss: +1.916e+01 | 
| 05-02 01:13:27 epoch: 1264| train loss i: [0.14	1.86	5.3 	4.39	3.86	1.6 ] test loss i: [0.22	0.72	6.84	5.56	3.87	1.94] | 
| 05-02 01:13:29 epoch: 1265| time: 2.5s| train loss: +1.766e+01 | test loss: +1.517e+01 | 
| 05-02 01:13:29 epoch: 1265| train loss i: [0.18	1.54	5.8 	4.87	3.75	1.52] test loss i: [0.16	0.77	5.08	3.84	3.93	1.39] | 
| 05-02 01:13:32 epoch: 1266| time: 2.4s| train loss: +1.724e+01 | test loss: +1.982e+01 | 
| 05-02 01:13:32 epoch: 1266| train loss i: [0.15	1.38	5.16	4.92	4.11	1.52] test loss i: [0.25	4.13	5.96	4.45	3.38	1.64] | 
| 05-02 01:13:34 epoch: 1267| time: 2.5s| train loss: +1.674e+01 | test loss: +1.737e+01 | 
| 05-02 01:13:34 epoch: 1267| train loss i: [0.17	1.12	5.14	4.56	4.12	1.62] test loss i: [0.13	1.32	6.21	4.53	3.67	1.52] | 
| 05-02 01:13:37 epoch: 1268| time: 2.5s| train loss: +1.756e+01 | test loss: +2.576e+01 | 
| 05-02 01:13:37 epoch: 1268| train loss i: [0.13	1.49	5.84	4.77	3.74	1.59] test loss i: [0.2 	2.59	8.43	6.47	5.7 	2.37] | 
| 05-02 01:13:39 epoch: 1269| time: 2.5s| train loss: +1.803e+01 | test loss: +1.948e+01 | 
| 05-02 01:13:39 epoch: 1269| train loss i: [0.16	1.95	5.4 	5.06	3.8 	1.66] test loss i: [0.27	0.65	6.42	5.54	4.69	1.9 ] | 
| 05-02 01:13:42 epoch: 1270| time: 2.5s| train loss: +1.617e+01 | test loss: +1.809e+01 | 
| 05-02 01:13:42 epoch: 1270| train loss i: [0.12	1.17	5.4 	4.47	3.5 	1.51] test loss i: [0.09	1.91	4.92	5.3 	4.36	1.5 ] | 
| 05-02 01:13:44 epoch: 1271| time: 2.5s| train loss: +1.799e+01 | test loss: +1.865e+01 | 
| 05-02 01:13:44 epoch: 1271| train loss i: [0.07	1.51	6.02	4.95	3.88	1.56] test loss i: [0.44	1.41	5.61	5.08	4.21	1.9 ] | 
| 05-02 01:13:47 epoch: 1272| time: 2.4s| train loss: +1.762e+01 | test loss: +1.947e+01 | 
| 05-02 01:13:47 epoch: 1272| train loss i: [0.12	1.61	5.74	4.89	3.77	1.49] test loss i: [0.22	2.01	6.42	4.94	3.92	1.96] | 
| 05-02 01:13:49 epoch: 1273| time: 2.5s| train loss: +1.811e+01 | test loss: +1.386e+01 | 
| 05-02 01:13:49 epoch: 1273| train loss i: [0.14	1.83	6.08	4.85	3.72	1.5 ] test loss i: [0.19	0.5 	3.77	3.81	3.94	1.65] | 
| 05-02 01:13:52 epoch: 1274| time: 2.4s| train loss: +1.730e+01 | test loss: +2.051e+01 | 
| 05-02 01:13:52 epoch: 1274| train loss i: [0.18	1.48	5.29	5.03	3.72	1.6 ] test loss i: [0.1 	0.67	7.48	5.66	4.53	2.06] | 
| 05-02 01:13:54 epoch: 1275| time: 2.5s| train loss: +1.772e+01 | test loss: +2.210e+01 | 
| 05-02 01:13:54 epoch: 1275| train loss i: [0.22	1.3 	5.34	5.57	3.79	1.51] test loss i: [0.39	0.86	6.61	6.65	5.87	1.73] | 
| 05-02 01:13:56 epoch: 1276| time: 2.5s| train loss: +1.637e+01 | test loss: +1.755e+01 | 
| 05-02 01:13:56 epoch: 1276| train loss i: [0.17	1.23	4.94	4.7 	3.78	1.56] test loss i: [0.22	0.8 	5.24	5.83	3.8 	1.67] | 
| 05-02 01:13:59 epoch: 1277| time: 2.5s| train loss: +1.827e+01 | test loss: +2.228e+01 | 
| 05-02 01:13:59 epoch: 1277| train loss i: [0.17	1.34	6.49	4.58	4.09	1.61] test loss i: [0.26	0.84	8.29	6.35	4.38	2.17] | 
| 05-02 01:14:01 epoch: 1278| time: 2.5s| train loss: +1.708e+01 | test loss: +1.931e+01 | 
| 05-02 01:14:01 epoch: 1278| train loss i: [0.2 	0.88	5.6 	5.03	3.89	1.47] test loss i: [0.48	1.6 	5.77	5.3 	3.93	2.23] | 
| 05-02 01:14:04 epoch: 1279| time: 2.5s| train loss: +1.738e+01 | test loss: +1.695e+01 | 
| 05-02 01:14:04 epoch: 1279| train loss i: [0.21	1.86	5.28	4.76	3.78	1.49] test loss i: [0.24	1.58	5.77	4.65	3.06	1.65] | 
| 05-02 01:14:06 epoch: 1280| time: 2.5s| train loss: +1.754e+01 | test loss: +1.678e+01 | 
| 05-02 01:14:06 epoch: 1280| train loss i: [0.17	1.78	5.52	5.02	3.61	1.43] test loss i: [0.38	0.63	5.53	4.57	3.95	1.72] | 
| 05-02 01:14:09 epoch: 1281| time: 2.5s| train loss: +1.675e+01 | test loss: +1.659e+01 | 
| 05-02 01:14:09 epoch: 1281| train loss i: [0.14	1.17	5.51	4.38	4.1 	1.46] test loss i: [0.16	0.93	5.59	4.43	3.88	1.6 ] | 
| 05-02 01:14:11 epoch: 1282| time: 2.4s| train loss: +1.724e+01 | test loss: +1.871e+01 | 
| 05-02 01:14:11 epoch: 1282| train loss i: [0.16	1.29	5.41	5.27	3.58	1.54] test loss i: [0.14	0.89	5.76	6.06	4.17	1.7 ] | 
| 05-02 01:14:14 epoch: 1283| time: 2.4s| train loss: +1.902e+01 | test loss: +2.373e+01 | 
| 05-02 01:14:14 epoch: 1283| train loss i: [0.24	1.77	6.22	5.43	3.8 	1.56] test loss i: [0.09	0.74	6.93	7.08	6.47	2.42] | 
| 05-02 01:14:16 epoch: 1284| time: 2.5s| train loss: +1.744e+01 | test loss: +1.352e+01 | 
| 05-02 01:14:16 epoch: 1284| train loss i: [0.17	1.61	5.94	4.54	3.62	1.56] test loss i: [0.18	1.23	3.8 	4.15	2.73	1.44] | 
| 05-02 01:14:19 epoch: 1285| time: 2.4s| train loss: +1.718e+01 | test loss: +1.536e+01 | 
| 05-02 01:14:19 epoch: 1285| train loss i: [0.17	1.69	5.05	4.79	3.9 	1.58] test loss i: [0.14	0.62	5.15	4.33	3.61	1.51] | 
| 05-02 01:14:21 epoch: 1286| time: 2.4s| train loss: +1.698e+01 | test loss: +1.572e+01 | 
| 05-02 01:14:21 epoch: 1286| train loss i: [0.16	0.87	5.76	4.86	3.67	1.65] test loss i: [0.11	1.  	5.  	4.32	3.75	1.53] | 
| 05-02 01:14:24 epoch: 1287| time: 2.5s| train loss: +1.721e+01 | test loss: +2.364e+01 | 
| 05-02 01:14:24 epoch: 1287| train loss i: [0.18	1.05	5.66	4.83	3.98	1.51] test loss i: [0.24	2.  	7.83	6.41	4.72	2.44] | 
| 05-02 01:14:26 epoch: 1288| time: 2.4s| train loss: +1.642e+01 | test loss: +1.834e+01 | 
| 05-02 01:14:26 epoch: 1288| train loss i: [0.15	1.11	5.49	4.49	3.7 	1.47] test loss i: [0.15	1.92	5.51	4.65	3.95	2.17] | 
| 05-02 01:14:28 epoch: 1289| time: 2.5s| train loss: +1.671e+01 | test loss: +2.134e+01 | 
| 05-02 01:14:28 epoch: 1289| train loss i: [0.13	1.6 	5.  	4.71	3.66	1.6 ] test loss i: [0.08	1.39	6.01	6.71	5.02	2.13] | 
| 05-02 01:14:31 epoch: 1290| time: 2.4s| train loss: +1.743e+01 | test loss: +1.977e+01 | 
| 05-02 01:14:31 epoch: 1290| train loss i: [0.1 	1.21	5.89	4.97	3.67	1.6 ] test loss i: [0.08	1.13	6.89	5.44	4.36	1.86] | 
| 05-02 01:14:33 epoch: 1291| time: 2.4s| train loss: +1.682e+01 | test loss: +2.159e+01 | 
| 05-02 01:14:33 epoch: 1291| train loss i: [0.11	1.65	4.92	4.9 	3.67	1.56] test loss i: [0.12	2.59	6.94	5.86	4.48	1.59] | 
| 05-02 01:14:36 epoch: 1292| time: 2.5s| train loss: +1.723e+01 | test loss: +2.446e+01 | 
| 05-02 01:14:36 epoch: 1292| train loss i: [0.11	0.67	5.91	5.25	3.74	1.55] test loss i: [0.32	2.28	8.76	6.21	4.79	2.09] | 
| 05-02 01:14:38 epoch: 1293| time: 2.4s| train loss: +1.779e+01 | test loss: +1.705e+01 | 
| 05-02 01:14:38 epoch: 1293| train loss i: [0.1 	2.32	5.27	4.76	3.83	1.51] test loss i: [0.13	1.23	3.98	6.27	3.91	1.53] | 
| 05-02 01:14:41 epoch: 1294| time: 2.4s| train loss: +1.727e+01 | test loss: +1.619e+01 | 
| 05-02 01:14:41 epoch: 1294| train loss i: [0.13	1.19	5.83	4.85	3.74	1.54] test loss i: [0.64	0.56	4.48	4.85	3.83	1.83] | 
| 05-02 01:14:43 epoch: 1295| time: 2.5s| train loss: +1.715e+01 | test loss: +1.628e+01 | 
| 05-02 01:14:43 epoch: 1295| train loss i: [0.15	1.93	5.08	4.66	3.69	1.63] test loss i: [0.11	2.39	4.48	4.29	3.03	1.98] | 
| 05-02 01:14:46 epoch: 1296| time: 2.4s| train loss: +1.713e+01 | test loss: +2.016e+01 | 
| 05-02 01:14:46 epoch: 1296| train loss i: [0.11	0.9 	5.52	4.97	4.04	1.6 ] test loss i: [0.24	2.29	6.27	5.4 	4.1 	1.84] | 
| 05-02 01:14:48 epoch: 1297| time: 2.5s| train loss: +1.685e+01 | test loss: +1.863e+01 | 
| 05-02 01:14:48 epoch: 1297| train loss i: [0.11	1.42	5.13	4.74	3.84	1.6 ] test loss i: [0.25	0.62	6.5 	5.46	4.02	1.78] | 
| 05-02 01:14:51 epoch: 1298| time: 2.4s| train loss: +1.725e+01 | test loss: +1.683e+01 | 
| 05-02 01:14:51 epoch: 1298| train loss i: [0.11	1.28	5.12	5.21	3.89	1.64] test loss i: [0.21	0.91	5.06	5.96	3.23	1.47] | 
| 05-02 01:14:53 epoch: 1299| time: 2.4s| train loss: +1.749e+01 | test loss: +2.484e+01 | 
| 05-02 01:14:53 epoch: 1299| train loss i: [0.13	1.51	5.79	4.95	3.54	1.56] test loss i: [0.07	1.95	8.47	7.39	5.06	1.91] | 
| 05-02 01:14:55 epoch: 1300| time: 2.5s| train loss: +1.753e+01 | test loss: +2.241e+01 | 
| 05-02 01:14:55 epoch: 1300| train loss i: [0.11	1.7 	5.65	4.96	3.56	1.56] test loss i: [0.21	4.29	7.75	4.41	3.81	1.95] | 
| 05-02 01:14:58 epoch: 1301| time: 2.4s| train loss: +1.629e+01 | test loss: +1.425e+01 | 
| 05-02 01:14:58 epoch: 1301| train loss i: [0.14	1.12	5.02	4.64	3.9 	1.48] test loss i: [0.12	1.67	3.86	3.86	3.12	1.62] | 
| 05-02 01:15:00 epoch: 1302| time: 2.5s| train loss: +1.836e+01 | test loss: +1.526e+01 | 
| 05-02 01:15:00 epoch: 1302| train loss i: [0.11	1.93	5.84	4.89	4.04	1.55] test loss i: [0.18	0.77	5.44	4.05	3.22	1.6 ] | 
| 05-02 01:15:03 epoch: 1303| time: 2.5s| train loss: +1.826e+01 | test loss: +1.871e+01 | 
| 05-02 01:15:03 epoch: 1303| train loss i: [0.1 	1.83	5.88	4.74	4.1 	1.61] test loss i: [0.08	1.23	7.17	5.02	3.36	1.86] | 
| 05-02 01:15:05 epoch: 1304| time: 2.5s| train loss: +1.680e+01 | test loss: +1.862e+01 | 
| 05-02 01:15:05 epoch: 1304| train loss i: [0.07	1.05	5.24	4.86	3.97	1.61] test loss i: [0.1 	0.62	6.54	4.58	5.05	1.74] | 
| 05-02 01:15:08 epoch: 1305| time: 2.4s| train loss: +1.770e+01 | test loss: +2.359e+01 | 
| 05-02 01:15:08 epoch: 1305| train loss i: [0.1 	1.46	5.45	5.09	4.04	1.56] test loss i: [0.14	2.69	6.33	6.01	6.23	2.18] | 
| 05-02 01:15:10 epoch: 1306| time: 2.5s| train loss: +1.699e+01 | test loss: +1.656e+01 | 
| 05-02 01:15:10 epoch: 1306| train loss i: [0.09	1.12	5.55	4.67	4.03	1.53] test loss i: [0.09	3.02	4.22	4.39	3.24	1.61] | 
| 05-02 01:15:13 epoch: 1307| time: 2.5s| train loss: +1.714e+01 | test loss: +1.897e+01 | 
| 05-02 01:15:13 epoch: 1307| train loss i: [0.1 	1.44	5.41	4.71	3.82	1.65] test loss i: [0.09	2.42	4.86	5.43	4.4 	1.79] | 
| 05-02 01:15:15 epoch: 1308| time: 2.5s| train loss: +1.681e+01 | test loss: +1.466e+01 | 
| 05-02 01:15:15 epoch: 1308| train loss i: [0.14	1.  	5.65	4.72	3.69	1.61] test loss i: [0.12	1.77	3.96	3.67	3.56	1.58] | 
| 05-02 01:15:18 epoch: 1309| time: 2.4s| train loss: +1.845e+01 | test loss: +2.134e+01 | 
| 05-02 01:15:18 epoch: 1309| train loss i: [0.13	1.81	5.9 	4.9 	4.09	1.62] test loss i: [0.68	1.33	7.48	5.75	4.48	1.62] | 
| 05-02 01:15:20 epoch: 1310| time: 2.5s| train loss: +1.838e+01 | test loss: +2.177e+01 | 
| 05-02 01:15:20 epoch: 1310| train loss i: [0.1 	1.39	6.01	5.37	3.91	1.59] test loss i: [0.14	1.37	7.8 	6.26	4.45	1.76] | 
| 05-02 01:15:23 epoch: 1311| time: 2.5s| train loss: +1.761e+01 | test loss: +1.990e+01 | 
| 05-02 01:15:23 epoch: 1311| train loss i: [0.17	1.42	5.66	5.09	3.63	1.65] test loss i: [0.15	1.71	6.9 	4.97	4.37	1.8 ] | 
| 05-02 01:15:25 epoch: 1312| time: 2.4s| train loss: +1.686e+01 | test loss: +2.351e+01 | 
| 05-02 01:15:25 epoch: 1312| train loss i: [0.16	1.16	5.41	4.56	4.  	1.57] test loss i: [0.07	2.15	8.54	5.64	5.05	2.04] | 
| 05-02 01:15:27 epoch: 1313| time: 2.5s| train loss: +1.585e+01 | test loss: +2.086e+01 | 
| 05-02 01:15:27 epoch: 1313| train loss i: [0.13	1.06	5.25	4.26	3.71	1.45] test loss i: [0.53	0.96	7.05	6.05	4.27	2.  ] | 
| 05-02 01:15:30 epoch: 1314| time: 2.5s| train loss: +1.643e+01 | test loss: +1.928e+01 | 
| 05-02 01:15:30 epoch: 1314| train loss i: [0.19	1.11	4.83	4.9 	3.84	1.55] test loss i: [0.12	2.  	6.03	4.96	4.21	1.95] | 
| 05-02 01:15:32 epoch: 1315| time: 2.5s| train loss: +1.750e+01 | test loss: +1.583e+01 | 
| 05-02 01:15:32 epoch: 1315| train loss i: [0.13	1.17	5.24	5.56	3.83	1.58] test loss i: [0.16	0.73	4.74	5.04	3.58	1.59] | 
| 05-02 01:15:35 epoch: 1316| time: 2.5s| train loss: +1.705e+01 | test loss: +1.516e+01 | 
| 05-02 01:15:35 epoch: 1316| train loss i: [0.13	1.26	5.43	4.67	3.99	1.57] test loss i: [0.07	0.4 	5.47	4.61	3.17	1.43] | 
| 05-02 01:15:37 epoch: 1317| time: 2.5s| train loss: +1.586e+01 | test loss: +1.796e+01 | 
| 05-02 01:15:37 epoch: 1317| train loss i: [0.11	1.28	4.64	4.6 	3.64	1.58] test loss i: [0.19	2.44	4.68	5.64	3.44	1.57] | 
| 05-02 01:15:40 epoch: 1318| time: 2.4s| train loss: +1.695e+01 | test loss: +1.676e+01 | 
| 05-02 01:15:40 epoch: 1318| train loss i: [0.1 	1.83	4.89	4.67	3.79	1.66] test loss i: [0.07	1.23	4.52	4.92	4.11	1.91] | 
| 05-02 01:15:42 epoch: 1319| time: 2.5s| train loss: +1.819e+01 | test loss: +1.761e+01 | 
| 05-02 01:15:42 epoch: 1319| train loss i: [0.15	1.95	5.49	5.14	3.81	1.65] test loss i: [0.43	1.27	5.27	5.08	4.01	1.54] | 
| 05-02 01:15:45 epoch: 1320| time: 2.4s| train loss: +1.680e+01 | test loss: +1.430e+01 | 
| 05-02 01:15:45 epoch: 1320| train loss i: [0.13	1.08	5.33	4.84	3.88	1.54] test loss i: [0.1 	0.46	4.43	4.6 	3.11	1.6 ] | 
| 05-02 01:15:47 epoch: 1321| time: 2.4s| train loss: +1.732e+01 | test loss: +2.571e+01 | 
| 05-02 01:15:47 epoch: 1321| train loss i: [0.1 	1.29	5.48	4.89	3.91	1.65] test loss i: [0.12	1.14	9.04	7.45	5.67	2.3 ] | 
| 05-02 01:15:50 epoch: 1322| time: 2.5s| train loss: +1.647e+01 | test loss: +1.590e+01 | 
| 05-02 01:15:50 epoch: 1322| train loss i: [0.09	1.01	5.43	4.57	3.76	1.61] test loss i: [0.13	0.68	5.87	3.84	3.91	1.47] | 
| 05-02 01:15:52 epoch: 1323| time: 2.5s| train loss: +1.730e+01 | test loss: +1.573e+01 | 
| 05-02 01:15:52 epoch: 1323| train loss i: [0.1 	1.85	5.12	4.66	4.02	1.55] test loss i: [0.13	1.24	4.35	4.42	3.95	1.65] | 
| 05-02 01:15:55 epoch: 1324| time: 2.5s| train loss: +1.742e+01 | test loss: +1.883e+01 | 
| 05-02 01:15:55 epoch: 1324| train loss i: [0.11	1.63	5.41	4.88	3.87	1.51] test loss i: [0.1 	2.38	5.62	5.81	3.27	1.65] | 
| 05-02 01:15:57 epoch: 1325| time: 2.5s| train loss: +1.659e+01 | test loss: +1.604e+01 | 
| 05-02 01:15:57 epoch: 1325| train loss i: [0.1 	0.99	5.48	4.86	3.62	1.54] test loss i: [0.12	0.63	5.51	5.02	3.11	1.65] | 
| 05-02 01:15:59 epoch: 1326| time: 2.4s| train loss: +1.637e+01 | test loss: +1.915e+01 | 
| 05-02 01:15:59 epoch: 1326| train loss i: [0.1 	1.29	4.94	4.49	3.95	1.6 ] test loss i: [0.13	2.24	5.91	4.52	4.43	1.93] | 
| 05-02 01:16:02 epoch: 1327| time: 2.5s| train loss: +1.733e+01 | test loss: +2.265e+01 | 
| 05-02 01:16:02 epoch: 1327| train loss i: [0.11	1.8 	5.19	4.93	3.78	1.52] test loss i: [0.12	3.5 	5.97	6.71	4.46	1.89] | 
| 05-02 01:16:04 epoch: 1328| time: 2.5s| train loss: +1.682e+01 | test loss: +2.344e+01 | 
| 05-02 01:16:04 epoch: 1328| train loss i: [0.19	1.23	5.34	4.64	3.82	1.6 ] test loss i: [0.3 	1.54	7.74	6.55	5.29	2.02] | 
| 05-02 01:16:07 epoch: 1329| time: 2.4s| train loss: +1.766e+01 | test loss: +1.432e+01 | 
| 05-02 01:16:07 epoch: 1329| train loss i: [0.15	1.57	5.14	5.32	3.79	1.69] test loss i: [0.12	0.57	4.61	4.13	3.4 	1.49] | 
| 05-02 01:16:09 epoch: 1330| time: 2.5s| train loss: +1.709e+01 | test loss: +1.762e+01 | 
| 05-02 01:16:09 epoch: 1330| train loss i: [0.12	1.55	5.21	4.67	3.96	1.59] test loss i: [0.38	1.78	5.35	4.33	4.16	1.62] | 
| 05-02 01:16:12 epoch: 1331| time: 2.4s| train loss: +1.591e+01 | test loss: +1.873e+01 | 
| 05-02 01:16:12 epoch: 1331| train loss i: [0.15	0.94	4.84	4.69	3.76	1.54] test loss i: [0.09	1.22	6.88	5.25	3.57	1.72] | 
| 05-02 01:16:14 epoch: 1332| time: 2.5s| train loss: +1.648e+01 | test loss: +1.627e+01 | 
| 05-02 01:16:14 epoch: 1332| train loss i: [0.11	1.16	5.48	4.41	3.72	1.6 ] test loss i: [0.23	0.96	4.93	4.98	3.56	1.61] | 
| 05-02 01:16:17 epoch: 1333| time: 2.5s| train loss: +1.707e+01 | test loss: +1.824e+01 | 
| 05-02 01:16:17 epoch: 1333| train loss i: [0.3 	1.31	5.27	4.85	3.81	1.55] test loss i: [0.24	0.73	5.31	5.64	4.22	2.11] | 
| 05-02 01:16:19 epoch: 1334| time: 2.4s| train loss: +1.821e+01 | test loss: +2.547e+01 | 
| 05-02 01:16:19 epoch: 1334| train loss i: [0.12	1.73	5.69	5.18	3.91	1.57] test loss i: [0.15	1.08	8.94	6.91	5.97	2.4 ] | 
| 05-02 01:16:22 epoch: 1335| time: 2.4s| train loss: +1.757e+01 | test loss: +2.228e+01 | 
| 05-02 01:16:22 epoch: 1335| train loss i: [0.11	1.25	5.79	4.93	3.9 	1.57] test loss i: [0.14	3.16	7.1 	5.57	4.52	1.79] | 
| 05-02 01:16:24 epoch: 1336| time: 2.5s| train loss: +1.734e+01 | test loss: +1.737e+01 | 
| 05-02 01:16:24 epoch: 1336| train loss i: [0.17	1.48	5.5 	4.94	3.7 	1.54] test loss i: [0.18	1.81	4.84	4.19	4.72	1.63] | 
| 05-02 01:16:26 epoch: 1337| time: 2.4s| train loss: +1.721e+01 | test loss: +1.550e+01 | 
| 05-02 01:16:26 epoch: 1337| train loss i: [0.19	1.48	5.38	4.72	3.86	1.59] test loss i: [0.3 	2.02	3.81	4.52	3.35	1.51] | 
| 05-02 01:16:29 epoch: 1338| time: 2.5s| train loss: +1.666e+01 | test loss: +1.621e+01 | 
| 05-02 01:16:29 epoch: 1338| train loss i: [0.15	1.29	5.31	4.8 	3.64	1.47] test loss i: [0.3 	0.83	4.76	4.92	3.69	1.72] | 
| 05-02 01:16:31 epoch: 1339| time: 2.4s| train loss: +1.701e+01 | test loss: +1.706e+01 | 
| 05-02 01:16:31 epoch: 1339| train loss i: [0.12	1.49	5.68	4.53	3.73	1.46] test loss i: [0.17	0.87	5.93	4.87	3.46	1.75] | 
| 05-02 01:16:34 epoch: 1340| time: 2.5s| train loss: +1.727e+01 | test loss: +1.903e+01 | 
| 05-02 01:16:34 epoch: 1340| train loss i: [0.1 	1.75	5.42	4.92	3.56	1.52] test loss i: [0.18	1.98	6.21	4.79	4.12	1.74] | 
| 05-02 01:16:36 epoch: 1341| time: 2.5s| train loss: +1.674e+01 | test loss: +2.136e+01 | 
| 05-02 01:16:36 epoch: 1341| train loss i: [0.12	1.4 	5.19	4.79	3.65	1.59] test loss i: [0.32	1.89	6.34	6.72	4.4 	1.69] | 
| 05-02 01:16:39 epoch: 1342| time: 2.4s| train loss: +1.717e+01 | test loss: +1.402e+01 | 
| 05-02 01:16:39 epoch: 1342| train loss i: [0.07	1.68	5.26	4.87	3.78	1.51] test loss i: [0.3 	0.5 	4.56	3.9 	3.13	1.64] | 
| 05-02 01:16:41 epoch: 1343| time: 2.5s| train loss: +1.755e+01 | test loss: +1.985e+01 | 
| 05-02 01:16:41 epoch: 1343| train loss i: [0.15	1.67	5.58	4.7 	3.87	1.57] test loss i: [0.1 	2.07	7.35	4.66	3.91	1.77] | 
| 05-02 01:16:44 epoch: 1344| time: 2.5s| train loss: +1.679e+01 | test loss: +2.102e+01 | 
| 05-02 01:16:44 epoch: 1344| train loss i: [0.12	1.56	5.13	4.62	3.73	1.64] test loss i: [0.37	2.27	5.65	5.75	4.81	2.17] | 
| 05-02 01:16:46 epoch: 1345| time: 2.4s| train loss: +1.744e+01 | test loss: +1.716e+01 | 
| 05-02 01:16:46 epoch: 1345| train loss i: [0.1 	1.58	5.4 	4.88	3.91	1.56] test loss i: [0.23	1.5 	5.63	4.95	3.39	1.46] | 
| 05-02 01:16:49 epoch: 1346| time: 2.5s| train loss: +1.722e+01 | test loss: +2.639e+01 | 
| 05-02 01:16:49 epoch: 1346| train loss i: [0.1 	1.27	5.07	5.39	3.84	1.54] test loss i: [0.18	3.22	8.77	7.09	5.16	1.96] | 
| 05-02 01:16:51 epoch: 1347| time: 2.4s| train loss: +1.751e+01 | test loss: +2.105e+01 | 
| 05-02 01:16:51 epoch: 1347| train loss i: [0.1 	1.56	5.49	4.98	3.89	1.5 ] test loss i: [0.31	1.36	6.41	6.62	4.43	1.92] | 
| 05-02 01:16:53 epoch: 1348| time: 2.4s| train loss: +1.727e+01 | test loss: +2.004e+01 | 
| 05-02 01:16:53 epoch: 1348| train loss i: [0.12	1.71	5.44	4.83	3.62	1.56] test loss i: [0.28	1.03	6.32	5.92	4.52	1.97] | 
| 05-02 01:16:56 epoch: 1349| time: 2.5s| train loss: +1.761e+01 | test loss: +1.397e+01 | 
| 05-02 01:16:56 epoch: 1349| train loss i: [0.09	1.36	5.74	4.9 	3.94	1.59] test loss i: [0.13	0.83	4.1 	4.24	3.16	1.51] | 
| 05-02 01:16:58 epoch: 1350| time: 2.4s| train loss: +1.639e+01 | test loss: +1.979e+01 | 
| 05-02 01:16:58 epoch: 1350| train loss i: [0.08	1.23	4.78	4.82	3.86	1.62] test loss i: [0.11	1.94	5.49	5.95	4.65	1.64] | 
| 05-02 01:17:01 epoch: 1351| time: 2.5s| train loss: +1.664e+01 | test loss: +1.546e+01 | 
| 05-02 01:17:01 epoch: 1351| train loss i: [0.1 	0.86	5.39	4.96	3.7 	1.62] test loss i: [0.15	0.83	4.63	4.89	3.3 	1.66] | 
| 05-02 01:17:03 epoch: 1352| time: 2.5s| train loss: +1.665e+01 | test loss: +1.893e+01 | 
| 05-02 01:17:03 epoch: 1352| train loss i: [0.1 	1.38	5.18	4.55	3.84	1.6 ] test loss i: [0.34	1.77	6.88	4.36	3.82	1.76] | 
| 05-02 01:17:06 epoch: 1353| time: 2.5s| train loss: +1.850e+01 | test loss: +1.708e+01 | 
| 05-02 01:17:06 epoch: 1353| train loss i: [0.12	1.49	6.31	4.88	4.03	1.66] test loss i: [0.26	3.13	4.47	4.13	3.54	1.55] | 
| 05-02 01:17:08 epoch: 1354| time: 2.5s| train loss: +1.763e+01 | test loss: +2.057e+01 | 
| 05-02 01:17:08 epoch: 1354| train loss i: [0.15	1.58	5.36	5.07	3.87	1.6 ] test loss i: [0.12	1.17	7.65	5.31	4.17	2.15] | 
| 05-02 01:17:11 epoch: 1355| time: 2.5s| train loss: +1.684e+01 | test loss: +1.529e+01 | 
| 05-02 01:17:11 epoch: 1355| train loss i: [0.11	1.23	5.07	5.11	3.77	1.56] test loss i: [0.2 	1.15	5.64	4.17	2.67	1.46] | 
| 05-02 01:17:13 epoch: 1356| time: 2.4s| train loss: +1.687e+01 | test loss: +2.333e+01 | 
| 05-02 01:17:13 epoch: 1356| train loss i: [0.15	1.44	4.83	5.17	3.7 	1.59] test loss i: [0.07	2.31	6.92	6.76	5.49	1.77] | 
| 05-02 01:17:16 epoch: 1357| time: 2.4s| train loss: +1.749e+01 | test loss: +1.688e+01 | 
| 05-02 01:17:16 epoch: 1357| train loss i: [0.18	1.43	5.56	4.84	3.99	1.49] test loss i: [0.1 	1.37	5.2 	5.02	3.49	1.7 ] | 
| 05-02 01:17:18 epoch: 1358| time: 2.4s| train loss: +1.597e+01 | test loss: +1.948e+01 | 
| 05-02 01:17:18 epoch: 1358| train loss i: [0.11	1.06	4.68	4.79	3.79	1.55] test loss i: [0.19	1.04	6.58	5.27	4.68	1.72] | 
| 05-02 01:17:21 epoch: 1359| time: 2.5s| train loss: +1.817e+01 | test loss: +1.748e+01 | 
| 05-02 01:17:21 epoch: 1359| train loss i: [0.16	1.66	5.87	5.08	3.82	1.58] test loss i: [0.07	1.09	5.23	4.99	4.35	1.74] | 
| 05-02 01:17:23 epoch: 1360| time: 2.5s| train loss: +1.719e+01 | test loss: +1.739e+01 | 
| 05-02 01:17:23 epoch: 1360| train loss i: [0.1 	1.34	5.47	4.87	3.78	1.62] test loss i: [0.23	1.41	5.26	5.07	3.9 	1.53] | 
| 05-02 01:17:26 epoch: 1361| time: 2.5s| train loss: +1.742e+01 | test loss: +1.840e+01 | 
| 05-02 01:17:26 epoch: 1361| train loss i: [0.08	1.5 	6.12	4.31	3.8 	1.61] test loss i: [0.12	1.24	5.28	5.89	4.21	1.67] | 
| 05-02 01:17:28 epoch: 1362| time: 2.5s| train loss: +1.729e+01 | test loss: +1.953e+01 | 
| 05-02 01:17:28 epoch: 1362| train loss i: [0.12	1.49	5.84	4.43	3.82	1.59] test loss i: [0.33	1.14	5.67	6.12	4.19	2.09] | 
| 05-02 01:17:31 epoch: 1363| time: 2.5s| train loss: +1.679e+01 | test loss: +2.580e+01 | 
| 05-02 01:17:31 epoch: 1363| train loss i: [0.1 	1.38	5.57	4.53	3.7 	1.5 ] test loss i: [0.32	1.29	9.58	6.72	5.69	2.2 ] | 
| 05-02 01:17:33 epoch: 1364| time: 2.5s| train loss: +1.788e+01 | test loss: +1.746e+01 | 
| 05-02 01:17:33 epoch: 1364| train loss i: [0.1 	1.6 	5.82	4.88	3.93	1.56] test loss i: [0.23	0.66	4.79	6.19	3.82	1.76] | 
| 05-02 01:17:35 epoch: 1365| time: 2.5s| train loss: +1.628e+01 | test loss: +2.004e+01 | 
| 05-02 01:17:35 epoch: 1365| train loss i: [0.1 	1.09	5.24	4.76	3.53	1.56] test loss i: [0.2 	1.76	5.39	6.43	4.58	1.69] | 
| 05-02 01:17:38 epoch: 1366| time: 2.5s| train loss: +1.677e+01 | test loss: +1.849e+01 | 
| 05-02 01:17:38 epoch: 1366| train loss i: [0.12	1.03	5.42	4.89	3.76	1.55] test loss i: [0.08	0.26	5.96	6.03	4.19	1.97] | 
| 05-02 01:17:40 epoch: 1367| time: 2.4s| train loss: +1.695e+01 | test loss: +2.113e+01 | 
| 05-02 01:17:40 epoch: 1367| train loss i: [0.1 	1.33	5.4 	4.8 	3.72	1.59] test loss i: [0.11	4.82	5.16	5.16	4.14	1.74] | 
| 05-02 01:17:43 epoch: 1368| time: 2.5s| train loss: +1.714e+01 | test loss: +1.863e+01 | 
| 05-02 01:17:43 epoch: 1368| train loss i: [0.09	1.38	5.24	5.05	3.81	1.57] test loss i: [0.08	1.19	6.12	5.01	4.26	1.99] | 
| 05-02 01:17:45 epoch: 1369| time: 2.4s| train loss: +1.684e+01 | test loss: +1.787e+01 | 
| 05-02 01:17:45 epoch: 1369| train loss i: [0.15	1.49	5.15	4.83	3.75	1.48] test loss i: [0.14	1.51	5.23	4.88	4.39	1.72] | 
| 05-02 01:17:48 epoch: 1370| time: 2.4s| train loss: +1.659e+01 | test loss: +1.718e+01 | 
| 05-02 01:17:48 epoch: 1370| train loss i: [0.11	0.99	5.21	4.94	3.78	1.56] test loss i: [0.16	0.38	5.68	4.95	4.31	1.71] | 
| 05-02 01:17:50 epoch: 1371| time: 2.5s| train loss: +1.687e+01 | test loss: +1.860e+01 | 
| 05-02 01:17:50 epoch: 1371| train loss i: [0.11	0.8 	5.36	5.13	3.87	1.59] test loss i: [0.07	3.4 	5.18	4.45	4.02	1.47] | 
| 05-02 01:17:53 epoch: 1372| time: 2.4s| train loss: +1.792e+01 | test loss: +1.781e+01 | 
| 05-02 01:17:53 epoch: 1372| train loss i: [0.23	1.54	5.76	4.79	4.02	1.58] test loss i: [0.12	2.65	5.38	4.11	4.09	1.47] | 
| 05-02 01:17:55 epoch: 1373| time: 2.5s| train loss: +1.738e+01 | test loss: +2.411e+01 | 
| 05-02 01:17:55 epoch: 1373| train loss i: [0.19	1.53	5.48	4.88	3.7 	1.6 ] test loss i: [0.16	1.41	7.8 	7.49	4.76	2.49] | 
| 05-02 01:17:58 epoch: 1374| time: 2.4s| train loss: +1.750e+01 | test loss: +1.698e+01 | 
| 05-02 01:17:58 epoch: 1374| train loss i: [0.13	1.79	5.45	4.98	3.55	1.61] test loss i: [0.28	0.89	5.57	4.65	3.8 	1.8 ] | 
| 05-02 01:18:00 epoch: 1375| time: 2.4s| train loss: +1.619e+01 | test loss: +2.065e+01 | 
| 05-02 01:18:00 epoch: 1375| train loss i: [0.11	1.35	4.64	4.91	3.59	1.59] test loss i: [0.13	1.71	6.8 	5.44	4.89	1.68] | 
| 05-02 01:18:02 epoch: 1376| time: 2.5s| train loss: +1.669e+01 | test loss: +1.622e+01 | 
| 05-02 01:18:02 epoch: 1376| train loss i: [0.12	0.97	5.29	4.98	3.79	1.55] test loss i: [0.21	1.11	5.53	4.01	3.41	1.95] | 
| 05-02 01:18:05 epoch: 1377| time: 2.5s| train loss: +1.696e+01 | test loss: +2.034e+01 | 
| 05-02 01:18:05 epoch: 1377| train loss i: [0.13	1.43	5.39	4.64	3.72	1.65] test loss i: [0.23	0.63	6.46	6.34	4.66	2.03] | 
| 05-02 01:18:07 epoch: 1378| time: 2.5s| train loss: +1.675e+01 | test loss: +1.705e+01 | 
| 05-02 01:18:07 epoch: 1378| train loss i: [0.14	1.55	5.39	4.69	3.34	1.63] test loss i: [0.13	0.44	5.51	4.57	4.68	1.72] | 
| 05-02 01:18:10 epoch: 1379| time: 2.6s| train loss: +1.626e+01 | test loss: +1.670e+01 | 
| 05-02 01:18:10 epoch: 1379| train loss i: [0.08	1.11	4.74	4.92	3.81	1.6 ] test loss i: [0.07	1.9 	5.61	4.29	3.24	1.59] | 
| 05-02 01:18:13 epoch: 1380| time: 2.5s| train loss: +1.743e+01 | test loss: +2.254e+01 | 
| 05-02 01:18:13 epoch: 1380| train loss i: [0.07	1.68	5.33	5.08	3.69	1.57] test loss i: [0.31	2.61	7.3 	6.21	4.14	1.97] | 
| 05-02 01:18:15 epoch: 1381| time: 2.5s| train loss: +1.676e+01 | test loss: +1.822e+01 | 
| 05-02 01:18:15 epoch: 1381| train loss i: [0.15	1.34	5.36	4.73	3.61	1.57] test loss i: [0.16	0.84	6.14	5.12	3.95	2.  ] | 
| 05-02 01:18:17 epoch: 1382| time: 2.5s| train loss: +1.717e+01 | test loss: +1.782e+01 | 
| 05-02 01:18:17 epoch: 1382| train loss i: [0.12	1.34	5.13	4.88	4.16	1.55] test loss i: [0.21	1.66	5.65	4.43	4.25	1.62] | 
| 05-02 01:18:20 epoch: 1383| time: 2.4s| train loss: +1.680e+01 | test loss: +2.060e+01 | 
| 05-02 01:18:20 epoch: 1383| train loss i: [0.13	0.96	5.67	4.51	3.93	1.6 ] test loss i: [0.11	0.81	6.46	5.79	4.98	2.44] | 
| 05-02 01:18:22 epoch: 1384| time: 2.4s| train loss: +1.640e+01 | test loss: +1.817e+01 | 
| 05-02 01:18:22 epoch: 1384| train loss i: [0.12	1.12	5.34	4.77	3.5 	1.56] test loss i: [0.07	0.31	5.94	5.91	4.01	1.93] | 
| 05-02 01:18:25 epoch: 1385| time: 2.5s| train loss: +1.748e+01 | test loss: +1.983e+01 | 
| 05-02 01:18:25 epoch: 1385| train loss i: [0.1 	1.39	5.35	5.02	4.01	1.6 ] test loss i: [0.27	2.97	5.4 	5.03	4.31	1.86] | 
| 05-02 01:18:27 epoch: 1386| time: 2.4s| train loss: +1.713e+01 | test loss: +2.075e+01 | 
| 05-02 01:18:27 epoch: 1386| train loss i: [0.09	1.58	5.06	4.97	3.86	1.56] test loss i: [0.53	2.13	5.4 	6.73	4.09	1.88] | 
| 05-02 01:18:30 epoch: 1387| time: 2.4s| train loss: +1.644e+01 | test loss: +1.592e+01 | 
| 05-02 01:18:30 epoch: 1387| train loss i: [0.09	1.04	5.1 	4.59	4.06	1.56] test loss i: [0.09	1.57	5.19	4.09	3.36	1.64] | 
| 05-02 01:18:32 epoch: 1388| time: 2.4s| train loss: +1.745e+01 | test loss: +2.035e+01 | 
| 05-02 01:18:32 epoch: 1388| train loss i: [0.09	1.43	5.57	4.74	4.06	1.57] test loss i: [0.08	0.71	6.18	5.91	5.58	1.89] | 
| 05-02 01:18:34 epoch: 1389| time: 2.4s| train loss: +1.727e+01 | test loss: +1.686e+01 | 
| 05-02 01:18:34 epoch: 1389| train loss i: [0.11	1.12	5.99	4.86	3.67	1.52] test loss i: [0.18	1.07	5.79	4.64	3.35	1.84] | 
| 05-02 01:18:37 epoch: 1390| time: 2.4s| train loss: +1.762e+01 | test loss: +1.733e+01 | 
| 05-02 01:18:37 epoch: 1390| train loss i: [0.1 	1.88	5.2 	4.93	3.91	1.61] test loss i: [0.16	0.97	5.64	4.78	3.87	1.91] | 
| 05-02 01:18:39 epoch: 1391| time: 2.4s| train loss: +1.733e+01 | test loss: +1.426e+01 | 
| 05-02 01:18:39 epoch: 1391| train loss i: [0.1 	1.27	5.65	4.76	3.92	1.63] test loss i: [0.07	0.69	4.78	3.87	3.41	1.43] | 
| 05-02 01:18:42 epoch: 1392| time: 2.4s| train loss: +1.667e+01 | test loss: +1.639e+01 | 
| 05-02 01:18:42 epoch: 1392| train loss i: [0.09	1.19	5.21	4.73	3.93	1.53] test loss i: [0.17	0.68	5.35	4.2 	4.18	1.81] | 
| 05-02 01:18:44 epoch: 1393| time: 2.4s| train loss: +1.728e+01 | test loss: +1.550e+01 | 
| 05-02 01:18:44 epoch: 1393| train loss i: [0.11	1.3 	5.58	4.89	3.9 	1.51] test loss i: [0.07	1.68	4.14	4.36	3.67	1.57] | 
| 05-02 01:18:46 epoch: 1394| time: 2.5s| train loss: +1.739e+01 | test loss: +2.512e+01 | 
| 05-02 01:18:46 epoch: 1394| train loss i: [0.08	1.7 	5.57	4.78	3.76	1.49] test loss i: [0.07	2.6 	7.42	6.61	5.99	2.43] | 
| 05-02 01:18:49 epoch: 1395| time: 2.4s| train loss: +1.858e+01 | test loss: +1.924e+01 | 
| 05-02 01:18:49 epoch: 1395| train loss i: [0.1 	2.05	5.51	5.28	4.09	1.56] test loss i: [0.38	1.41	6.04	5.24	4.39	1.78] | 
| 05-02 01:18:51 epoch: 1396| time: 2.5s| train loss: +1.674e+01 | test loss: +1.747e+01 | 
| 05-02 01:18:51 epoch: 1396| train loss i: [0.15	1.4 	5.24	4.6 	3.76	1.58] test loss i: [0.48	1.25	5.29	5.15	3.91	1.4 ] | 
| 05-02 01:18:54 epoch: 1397| time: 2.4s| train loss: +1.718e+01 | test loss: +1.726e+01 | 
| 05-02 01:18:54 epoch: 1397| train loss i: [0.15	1.36	5.34	4.82	3.89	1.63] test loss i: [0.31	2.09	4.84	4.01	4.06	1.94] | 
| 05-02 01:18:56 epoch: 1398| time: 2.4s| train loss: +1.792e+01 | test loss: +1.837e+01 | 
| 05-02 01:18:56 epoch: 1398| train loss i: [0.16	2.17	5.26	4.72	4.03	1.57] test loss i: [0.24	2.13	5.35	5.76	3.25	1.63] | 
| 05-02 01:18:59 epoch: 1399| time: 2.4s| train loss: +1.729e+01 | test loss: +1.852e+01 | 
| 05-02 01:18:59 epoch: 1399| train loss i: [0.15	1.42	5.43	5.  	3.72	1.58] test loss i: [0.13	1.35	7.63	4.48	3.23	1.7 ] | 
| 05-02 01:19:01 epoch: 1400| time: 2.4s| train loss: +1.762e+01 | test loss: +1.996e+01 | 
| 05-02 01:19:01 epoch: 1400| train loss i: [0.13	0.97	5.65	5.42	3.86	1.59] test loss i: [0.28	1.71	7.04	4.58	4.7 	1.65] | 
| 05-02 01:19:03 epoch: 1401| time: 2.5s| train loss: +1.679e+01 | test loss: +2.037e+01 | 
| 05-02 01:19:03 epoch: 1401| train loss i: [0.13	1.27	5.36	4.8 	3.69	1.54] test loss i: [0.73	1.62	7.05	4.98	4.05	1.94] | 
| 05-02 01:19:06 epoch: 1402| time: 2.5s| train loss: +1.741e+01 | test loss: +1.532e+01 | 
| 05-02 01:19:06 epoch: 1402| train loss i: [0.1 	1.55	5.27	5.06	3.94	1.49] test loss i: [0.18	0.8 	4.89	4.48	3.53	1.44] | 
| 05-02 01:19:08 epoch: 1403| time: 2.5s| train loss: +1.796e+01 | test loss: +1.782e+01 | 
| 05-02 01:19:08 epoch: 1403| train loss i: [0.12	1.21	6.04	5.15	3.84	1.59] test loss i: [0.08	1.62	5.89	4.81	3.78	1.64] | 
| 05-02 01:19:11 epoch: 1404| time: 2.5s| train loss: +1.688e+01 | test loss: +1.559e+01 | 
| 05-02 01:19:11 epoch: 1404| train loss i: [0.11	1.75	4.85	4.81	3.81	1.54] test loss i: [0.13	0.62	5.52	4.28	3.48	1.55] | 
| 05-02 01:19:13 epoch: 1405| time: 2.5s| train loss: +1.807e+01 | test loss: +1.973e+01 | 
| 05-02 01:19:13 epoch: 1405| train loss i: [0.19	2.14	5.55	4.7 	3.96	1.53] test loss i: [0.25	1.23	8.17	4.48	3.69	1.91] | 
| 05-02 01:19:16 epoch: 1406| time: 2.4s| train loss: +1.854e+01 | test loss: +1.722e+01 | 
| 05-02 01:19:16 epoch: 1406| train loss i: [0.19	1.82	6.04	4.84	4.03	1.63] test loss i: [0.41	0.95	5.7 	4.43	4.01	1.74] | 
| 05-02 01:19:18 epoch: 1407| time: 2.4s| train loss: +1.698e+01 | test loss: +2.248e+01 | 
| 05-02 01:19:18 epoch: 1407| train loss i: [0.18	1.55	5.2 	4.87	3.66	1.52] test loss i: [0.66	1.11	8.  	6.23	4.34	2.15] | 
| 05-02 01:19:21 epoch: 1408| time: 2.4s| train loss: +1.683e+01 | test loss: +1.740e+01 | 
| 05-02 01:19:21 epoch: 1408| train loss i: [0.22	0.78	5.79	4.92	3.63	1.49] test loss i: [0.25	1.76	4.7 	4.52	4.5 	1.67] | 
| 05-02 01:19:23 epoch: 1409| time: 2.5s| train loss: +1.791e+01 | test loss: +1.624e+01 | 
| 05-02 01:19:23 epoch: 1409| train loss i: [0.15	1.42	5.97	5.  	3.86	1.53] test loss i: [0.15	0.6 	5.17	4.62	3.87	1.82] | 
| 05-02 01:19:26 epoch: 1410| time: 2.5s| train loss: +1.683e+01 | test loss: +2.094e+01 | 
| 05-02 01:19:26 epoch: 1410| train loss i: [0.16	1.31	5.23	4.98	3.63	1.52] test loss i: [0.18	1.91	8.07	5.22	3.52	2.03] | 
| 05-02 01:19:28 epoch: 1411| time: 2.5s| train loss: +1.757e+01 | test loss: +2.265e+01 | 
| 05-02 01:19:28 epoch: 1411| train loss i: [0.23	1.15	5.41	5.05	4.22	1.52] test loss i: [0.93	2.93	7.26	5.63	3.96	1.96] | 
| 05-02 01:19:30 epoch: 1412| time: 2.5s| train loss: +1.727e+01 | test loss: +1.918e+01 | 
| 05-02 01:19:30 epoch: 1412| train loss i: [0.35	1.44	5.38	4.77	3.81	1.52] test loss i: [0.31	1.75	5.91	5.43	3.95	1.81] | 
| 05-02 01:19:33 epoch: 1413| time: 2.4s| train loss: +1.732e+01 | test loss: +2.176e+01 | 
| 05-02 01:19:33 epoch: 1413| train loss i: [0.26	1.49	5.36	4.86	3.76	1.58] test loss i: [0.31	2.07	5.99	6.98	4.54	1.87] | 
| 05-02 01:19:35 epoch: 1414| time: 2.5s| train loss: +1.664e+01 | test loss: +2.306e+01 | 
| 05-02 01:19:35 epoch: 1414| train loss i: [0.19	1.34	5.19	4.5 	3.87	1.54] test loss i: [0.17	1.15	8.4 	5.83	5.15	2.36] | 
| 05-02 01:19:38 epoch: 1415| time: 2.4s| train loss: +1.732e+01 | test loss: +1.562e+01 | 
| 05-02 01:19:38 epoch: 1415| train loss i: [0.11	1.58	5.28	4.68	4.06	1.6 ] test loss i: [0.4 	0.58	4.05	4.78	4.34	1.47] | 
| 05-02 01:19:40 epoch: 1416| time: 2.4s| train loss: +1.635e+01 | test loss: +1.863e+01 | 
| 05-02 01:19:40 epoch: 1416| train loss i: [0.11	0.9 	5.3 	4.9 	3.55	1.58] test loss i: [0.22	2.92	4.88	5.01	4.  	1.6 ] | 
| 05-02 01:19:43 epoch: 1417| time: 2.5s| train loss: +1.643e+01 | test loss: +2.552e+01 | 
| 05-02 01:19:43 epoch: 1417| train loss i: [0.12	0.81	5.42	4.76	3.71	1.61] test loss i: [0.1 	2.93	7.9 	7.4 	5.16	2.04] | 
| 05-02 01:19:45 epoch: 1418| time: 2.4s| train loss: +1.639e+01 | test loss: +1.882e+01 | 
| 05-02 01:19:45 epoch: 1418| train loss i: [0.13	1.7 	4.92	4.58	3.48	1.58] test loss i: [0.11	2.32	5.07	5.93	3.63	1.75] | 
| 05-02 01:19:48 epoch: 1419| time: 2.5s| train loss: +1.788e+01 | test loss: +1.524e+01 | 
| 05-02 01:19:48 epoch: 1419| train loss i: [0.11	1.48	6.08	4.79	3.84	1.58] test loss i: [0.38	0.69	5.36	4.1 	3.  	1.71] | 
| 05-02 01:19:50 epoch: 1420| time: 2.5s| train loss: +1.714e+01 | test loss: +1.843e+01 | 
| 05-02 01:19:50 epoch: 1420| train loss i: [0.23	1.58	5.11	5.12	3.45	1.66] test loss i: [0.12	0.49	6.73	5.24	4.07	1.79] | 
| 05-02 01:19:52 epoch: 1421| time: 2.4s| train loss: +1.725e+01 | test loss: +1.967e+01 | 
| 05-02 01:19:52 epoch: 1421| train loss i: [0.18	1.48	5.32	4.83	3.9 	1.55] test loss i: [0.23	2.1 	5.6 	5.68	4.24	1.82] | 
| 05-02 01:19:55 epoch: 1422| time: 2.5s| train loss: +1.785e+01 | test loss: +1.793e+01 | 
| 05-02 01:19:55 epoch: 1422| train loss i: [0.21	1.29	5.92	5.04	3.78	1.61] test loss i: [0.18	2.25	5.65	4.63	3.36	1.85] | 
| 05-02 01:19:57 epoch: 1423| time: 2.4s| train loss: +1.716e+01 | test loss: +1.968e+01 | 
| 05-02 01:19:57 epoch: 1423| train loss i: [0.17	1.8 	5.01	4.86	3.82	1.51] test loss i: [0.3 	0.18	7.  	5.25	4.72	2.23] | 
| 05-02 01:20:00 epoch: 1424| time: 2.4s| train loss: +1.647e+01 | test loss: +1.730e+01 | 
| 05-02 01:20:00 epoch: 1424| train loss i: [0.22	1.13	5.21	4.63	3.73	1.55] test loss i: [0.15	1.8 	5.59	4.31	3.86	1.58] | 
| 05-02 01:20:02 epoch: 1425| time: 2.5s| train loss: +1.740e+01 | test loss: +2.305e+01 | 
| 05-02 01:20:02 epoch: 1425| train loss i: [0.15	1.15	5.43	4.86	4.26	1.55] test loss i: [0.13	3.64	8.12	5.79	3.53	1.84] | 
| 05-02 01:20:05 epoch: 1426| time: 2.5s| train loss: +1.701e+01 | test loss: +1.401e+01 | 
| 05-02 01:20:05 epoch: 1426| train loss i: [0.14	1.31	5.13	4.99	3.91	1.53] test loss i: [0.09	0.49	4.45	4.09	3.42	1.47] | 
| 05-02 01:20:07 epoch: 1427| time: 2.5s| train loss: +1.787e+01 | test loss: +2.127e+01 | 
| 05-02 01:20:07 epoch: 1427| train loss i: [0.12	1.42	6.1 	4.64	4.07	1.52] test loss i: [0.46	3.35	5.93	5.9 	3.91	1.72] | 
| 05-02 01:20:10 epoch: 1428| time: 2.5s| train loss: +1.708e+01 | test loss: +1.895e+01 | 
| 05-02 01:20:10 epoch: 1428| train loss i: [0.14	1.64	5.37	5.  	3.37	1.55] test loss i: [0.21	1.91	5.44	5.1 	4.37	1.92] | 
| 05-02 01:20:12 epoch: 1429| time: 2.4s| train loss: +1.744e+01 | test loss: +1.621e+01 | 
| 05-02 01:20:12 epoch: 1429| train loss i: [0.13	1.27	5.41	4.83	4.18	1.62] test loss i: [0.15	1.05	5.87	4.17	3.25	1.72] | 
| 05-02 01:20:15 epoch: 1430| time: 2.5s| train loss: +1.712e+01 | test loss: +1.985e+01 | 
| 05-02 01:20:15 epoch: 1430| train loss i: [0.08	1.78	5.2 	4.82	3.63	1.61] test loss i: [0.35	3.12	4.85	6.84	2.97	1.72] | 
| 05-02 01:20:17 epoch: 1431| time: 2.5s| train loss: +1.681e+01 | test loss: +1.753e+01 | 
| 05-02 01:20:17 epoch: 1431| train loss i: [0.11	1.01	5.74	4.88	3.52	1.55] test loss i: [0.11	1.36	5.72	5.23	3.51	1.6 ] | 
| 05-02 01:20:20 epoch: 1432| time: 2.5s| train loss: +1.840e+01 | test loss: +1.366e+01 | 
| 05-02 01:20:20 epoch: 1432| train loss i: [0.1 	1.6 	5.89	5.12	4.18	1.51] test loss i: [0.19	0.27	4.57	3.95	2.95	1.74] | 
| 05-02 01:20:22 epoch: 1433| time: 2.5s| train loss: +1.687e+01 | test loss: +1.632e+01 | 
| 05-02 01:20:22 epoch: 1433| train loss i: [0.11	1.27	5.33	4.56	3.96	1.63] test loss i: [0.21	1.47	5.16	3.71	4.16	1.61] | 
| 05-02 01:20:25 epoch: 1434| time: 2.5s| train loss: +1.651e+01 | test loss: +1.464e+01 | 
| 05-02 01:20:25 epoch: 1434| train loss i: [0.09	1.29	5.08	4.66	3.81	1.58] test loss i: [0.12	0.51	4.44	3.93	4.09	1.55] | 
| 05-02 01:20:27 epoch: 1435| time: 2.4s| train loss: +1.754e+01 | test loss: +1.688e+01 | 
| 05-02 01:20:27 epoch: 1435| train loss i: [0.09	1.58	5.68	4.61	4.  	1.59] test loss i: [0.07	1.75	4.83	4.97	3.6 	1.65] | 
| 05-02 01:20:30 epoch: 1436| time: 2.5s| train loss: +1.686e+01 | test loss: +2.183e+01 | 
| 05-02 01:20:30 epoch: 1436| train loss i: [0.08	1.01	5.82	4.69	3.64	1.63] test loss i: [0.16	1.53	6.13	7.01	5.06	1.95] | 
| 05-02 01:20:32 epoch: 1437| time: 2.5s| train loss: +1.819e+01 | test loss: +1.868e+01 | 
| 05-02 01:20:32 epoch: 1437| train loss i: [0.11	2.27	5.46	5.08	3.73	1.55] test loss i: [0.39	2.39	5.89	4.75	3.67	1.6 ] | 
| 05-02 01:20:35 epoch: 1438| time: 2.5s| train loss: +1.786e+01 | test loss: +2.663e+01 | 
| 05-02 01:20:35 epoch: 1438| train loss i: [0.1 	1.49	5.85	4.76	4.06	1.6 ] test loss i: [0.38	3.77	9.14	6.19	5.09	2.05] | 
| 05-02 01:20:37 epoch: 1439| time: 2.5s| train loss: +1.623e+01 | test loss: +1.711e+01 | 
| 05-02 01:20:37 epoch: 1439| train loss i: [0.14	0.91	5.43	4.46	3.69	1.59] test loss i: [0.2 	1.6 	5.32	4.74	3.46	1.78] | 
| 05-02 01:20:39 epoch: 1440| time: 2.4s| train loss: +1.799e+01 | test loss: +1.585e+01 | 
| 05-02 01:20:39 epoch: 1440| train loss i: [0.12	1.63	5.74	4.97	4.04	1.49] test loss i: [0.16	0.64	5.08	4.19	4.03	1.75] | 
| 05-02 01:20:42 epoch: 1441| time: 2.5s| train loss: +1.655e+01 | test loss: +2.900e+01 | 
| 05-02 01:20:42 epoch: 1441| train loss i: [0.13	1.11	5.36	4.83	3.6 	1.51] test loss i: [0.82	4.35	8.74	6.42	6.38	2.28] | 
| 05-02 01:20:44 epoch: 1442| time: 2.5s| train loss: +1.711e+01 | test loss: +2.166e+01 | 
| 05-02 01:20:44 epoch: 1442| train loss i: [0.16	1.71	5.11	4.66	4.  	1.48] test loss i: [0.11	1.83	7.27	5.79	4.86	1.8 ] | 
| 05-02 01:20:47 epoch: 1443| time: 2.5s| train loss: +1.702e+01 | test loss: +2.170e+01 | 
| 05-02 01:20:47 epoch: 1443| train loss i: [0.14	1.31	5.38	4.92	3.6 	1.67] test loss i: [0.11	2.21	6.33	6.  	5.14	1.9 ] | 
| 05-02 01:20:49 epoch: 1444| time: 2.5s| train loss: +1.775e+01 | test loss: +1.571e+01 | 
| 05-02 01:20:49 epoch: 1444| train loss i: [0.13	1.44	5.6 	4.97	4.02	1.59] test loss i: [0.28	1.56	4.45	4.28	3.57	1.56] | 
| 05-02 01:20:52 epoch: 1445| time: 2.5s| train loss: +1.710e+01 | test loss: +1.962e+01 | 
| 05-02 01:20:52 epoch: 1445| train loss i: [0.19	1.7 	5.26	4.75	3.67	1.53] test loss i: [0.55	0.32	6.48	5.28	4.92	2.06] | 
| 05-02 01:20:54 epoch: 1446| time: 2.4s| train loss: +1.753e+01 | test loss: +2.874e+01 | 
| 05-02 01:20:54 epoch: 1446| train loss i: [0.13	1.64	5.83	4.76	3.62	1.54] test loss i: [ 0.22	 4.66	10.61	 5.59	 5.27	 2.38] | 
| 05-02 01:20:57 epoch: 1447| time: 2.5s| train loss: +1.681e+01 | test loss: +1.777e+01 | 
| 05-02 01:20:57 epoch: 1447| train loss i: [0.14	1.64	4.61	5.11	3.71	1.59] test loss i: [0.14	2.48	5.49	4.05	3.82	1.79] | 
| 05-02 01:20:59 epoch: 1448| time: 2.4s| train loss: +1.665e+01 | test loss: +2.429e+01 | 
| 05-02 01:20:59 epoch: 1448| train loss i: [0.08	1.53	5.34	4.45	3.68	1.57] test loss i: [0.21	4.21	7.74	5.82	4.21	2.11] | 
| 05-02 01:21:02 epoch: 1449| time: 2.5s| train loss: +1.631e+01 | test loss: +1.632e+01 | 
| 05-02 01:21:02 epoch: 1449| train loss i: [0.1 	1.14	5.18	4.64	3.69	1.55] test loss i: [0.11	1.28	5.3 	4.41	3.61	1.61] | 
| 05-02 01:21:04 epoch: 1450| time: 2.5s| train loss: +1.850e+01 | test loss: +2.378e+01 | 
| 05-02 01:21:04 epoch: 1450| train loss i: [0.17	1.41	5.92	5.3 	4.12	1.58] test loss i: [0.33	0.57	8.04	7.14	5.8 	1.89] | 
| 05-02 01:21:07 epoch: 1451| time: 2.4s| train loss: +1.742e+01 | test loss: +2.094e+01 | 
| 05-02 01:21:07 epoch: 1451| train loss i: [0.12	1.59	5.82	4.65	3.76	1.49] test loss i: [0.08	2.86	6.39	5.7 	4.39	1.54] | 
| 05-02 01:21:09 epoch: 1452| time: 2.5s| train loss: +1.656e+01 | test loss: +1.810e+01 | 
| 05-02 01:21:09 epoch: 1452| train loss i: [0.08	1.39	5.18	4.77	3.56	1.59] test loss i: [0.11	0.18	6.18	6.11	3.56	1.95] | 
| 05-02 01:21:11 epoch: 1453| time: 2.5s| train loss: +1.695e+01 | test loss: +1.570e+01 | 
| 05-02 01:21:11 epoch: 1453| train loss i: [0.1 	0.91	5.83	4.66	3.88	1.57] test loss i: [0.11	0.77	5.43	4.39	3.37	1.63] | 
| 05-02 01:21:14 epoch: 1454| time: 2.4s| train loss: +1.668e+01 | test loss: +1.736e+01 | 
| 05-02 01:21:14 epoch: 1454| train loss i: [0.1 	1.57	5.  	4.95	3.5 	1.55] test loss i: [0.27	0.86	5.  	5.34	4.15	1.74] | 
| 05-02 01:21:16 epoch: 1455| time: 2.5s| train loss: +1.699e+01 | test loss: +1.938e+01 | 
| 05-02 01:21:16 epoch: 1455| train loss i: [0.11	1.82	4.86	4.84	3.78	1.57] test loss i: [0.29	2.38	5.81	5.07	4.07	1.76] | 
| 05-02 01:21:19 epoch: 1456| time: 2.4s| train loss: +1.712e+01 | test loss: +1.659e+01 | 
| 05-02 01:21:19 epoch: 1456| train loss i: [0.14	1.22	5.37	4.93	3.87	1.59] test loss i: [0.15	2.18	4.43	5.3 	3.14	1.39] | 
| 05-02 01:21:21 epoch: 1457| time: 2.4s| train loss: +1.687e+01 | test loss: +1.956e+01 | 
| 05-02 01:21:21 epoch: 1457| train loss i: [0.09	1.4 	4.9 	4.94	3.97	1.56] test loss i: [0.05	3.76	4.74	4.88	4.31	1.81] | 
| 05-02 01:21:24 epoch: 1458| time: 2.5s| train loss: +1.784e+01 | test loss: +1.989e+01 | 
| 05-02 01:21:24 epoch: 1458| train loss i: [0.1 	1.25	6.14	4.93	3.75	1.67] test loss i: [0.08	1.99	5.97	6.02	4.05	1.78] | 
| 05-02 01:21:26 epoch: 1459| time: 2.5s| train loss: +1.676e+01 | test loss: +2.180e+01 | 
| 05-02 01:21:26 epoch: 1459| train loss i: [0.11	1.5 	5.1 	4.84	3.66	1.54] test loss i: [0.24	1.99	8.05	5.95	3.69	1.87] | 
| 05-02 01:21:29 epoch: 1460| time: 2.5s| train loss: +1.656e+01 | test loss: +1.334e+01 | 
| 05-02 01:21:29 epoch: 1460| train loss i: [0.11	1.1 	5.18	4.75	3.91	1.52] test loss i: [0.1 	0.54	4.47	3.82	2.77	1.63] | 
| 05-02 01:21:31 epoch: 1461| time: 2.5s| train loss: +1.762e+01 | test loss: +2.107e+01 | 
| 05-02 01:21:31 epoch: 1461| train loss i: [0.14	1.29	5.63	4.78	4.26	1.52] test loss i: [0.59	5.18	4.85	4.55	3.85	2.04] | 
| 05-02 01:21:34 epoch: 1462| time: 2.4s| train loss: +1.726e+01 | test loss: +1.748e+01 | 
| 05-02 01:21:34 epoch: 1462| train loss i: [0.11	1.46	5.28	4.98	3.87	1.56] test loss i: [0.1 	1.66	5.23	4.78	4.13	1.58] | 
| 05-02 01:21:36 epoch: 1463| time: 2.4s| train loss: +1.689e+01 | test loss: +1.893e+01 | 
| 05-02 01:21:36 epoch: 1463| train loss i: [0.1 	1.12	5.37	4.75	4.01	1.54] test loss i: [0.08	2.12	6.36	5.17	3.33	1.85] | 
| 05-02 01:21:38 epoch: 1464| time: 2.4s| train loss: +1.621e+01 | test loss: +2.646e+01 | 
| 05-02 01:21:38 epoch: 1464| train loss i: [0.09	0.86	5.55	4.45	3.73	1.53] test loss i: [0.3 	1.49	9.62	6.99	5.94	2.12] | 
| 05-02 01:21:41 epoch: 1465| time: 2.4s| train loss: +1.584e+01 | test loss: +2.003e+01 | 
| 05-02 01:21:41 epoch: 1465| train loss i: [0.08	0.89	5.38	4.29	3.67	1.53] test loss i: [0.43	0.72	6.81	5.97	4.32	1.77] | 
| 05-02 01:21:43 epoch: 1466| time: 2.5s| train loss: +1.667e+01 | test loss: +2.307e+01 | 
| 05-02 01:21:43 epoch: 1466| train loss i: [0.11	1.54	5.36	4.46	3.63	1.56] test loss i: [0.14	1.74	7.65	6.57	4.92	2.05] | 
| 05-02 01:21:46 epoch: 1467| time: 2.5s| train loss: +1.737e+01 | test loss: +1.775e+01 | 
| 05-02 01:21:46 epoch: 1467| train loss i: [0.11	1.26	5.58	5.08	3.83	1.51] test loss i: [0.11	0.95	6.72	4.56	3.6 	1.81] | 
| 05-02 01:21:48 epoch: 1468| time: 2.4s| train loss: +1.749e+01 | test loss: +1.703e+01 | 
| 05-02 01:21:48 epoch: 1468| train loss i: [0.14	1.42	5.94	4.89	3.53	1.56] test loss i: [0.1 	1.25	5.5 	4.49	4.  	1.69] | 
| 05-02 01:21:51 epoch: 1469| time: 2.5s| train loss: +1.712e+01 | test loss: +1.644e+01 | 
| 05-02 01:21:51 epoch: 1469| train loss i: [0.12	1.54	5.28	4.79	3.82	1.58] test loss i: [0.07	1.68	5.  	3.57	4.55	1.57] | 
| 05-02 01:21:53 epoch: 1470| time: 2.4s| train loss: +1.680e+01 | test loss: +1.610e+01 | 
| 05-02 01:21:53 epoch: 1470| train loss i: [0.13	1.44	4.88	5.06	3.77	1.52] test loss i: [0.2 	0.3 	5.61	4.73	3.66	1.6 ] | 
| 05-02 01:21:56 epoch: 1471| time: 2.5s| train loss: +1.628e+01 | test loss: +1.809e+01 | 
| 05-02 01:21:56 epoch: 1471| train loss i: [0.09	1.58	5.13	4.25	3.66	1.57] test loss i: [0.06	1.66	5.86	4.56	4.2 	1.75] | 
| 05-02 01:21:58 epoch: 1472| time: 2.5s| train loss: +1.611e+01 | test loss: +2.498e+01 | 
| 05-02 01:21:58 epoch: 1472| train loss i: [0.12	1.07	5.04	4.72	3.58	1.59] test loss i: [0.23	2.83	7.47	6.13	5.8 	2.52] | 
| 05-02 01:22:01 epoch: 1473| time: 2.6s| train loss: +1.795e+01 | test loss: +1.758e+01 | 
| 05-02 01:22:01 epoch: 1473| train loss i: [0.1 	1.87	5.7 	5.1 	3.67	1.5 ] test loss i: [0.06	1.58	7.1 	3.94	3.01	1.88] | 
| 05-02 01:22:03 epoch: 1474| time: 2.5s| train loss: +1.717e+01 | test loss: +1.703e+01 | 
| 05-02 01:22:03 epoch: 1474| train loss i: [0.17	1.25	5.44	4.76	4.  	1.55] test loss i: [0.23	1.36	5.67	4.63	3.59	1.55] | 
| 05-02 01:22:06 epoch: 1475| time: 2.5s| train loss: +1.697e+01 | test loss: +1.448e+01 | 
| 05-02 01:22:06 epoch: 1475| train loss i: [0.11	0.84	5.58	5.01	3.85	1.59] test loss i: [0.11	0.43	4.95	3.8 	3.62	1.58] | 
| 05-02 01:22:08 epoch: 1476| time: 2.4s| train loss: +1.712e+01 | test loss: +2.465e+01 | 
| 05-02 01:22:08 epoch: 1476| train loss i: [0.12	1.34	5.57	4.82	3.63	1.63] test loss i: [0.12	2.34	6.63	7.75	5.56	2.26] | 
| 05-02 01:22:11 epoch: 1477| time: 2.5s| train loss: +1.675e+01 | test loss: +1.818e+01 | 
| 05-02 01:22:11 epoch: 1477| train loss i: [0.13	1.01	5.2 	5.23	3.64	1.53] test loss i: [0.08	1.18	6.36	4.8 	3.93	1.82] | 
| 05-02 01:22:13 epoch: 1478| time: 2.1s| train loss: +1.699e+01 | test loss: +1.929e+01 | 
| 05-02 01:22:13 epoch: 1478| train loss i: [0.09	1.5 	5.08	4.91	3.74	1.68] test loss i: [0.36	1.32	5.05	6.17	4.61	1.79] | 
| 05-02 01:22:14 epoch: 1479| time: 1.6s| train loss: +1.644e+01 | test loss: +2.213e+01 | 
| 05-02 01:22:14 epoch: 1479| train loss i: [0.15	1.06	4.83	4.73	4.13	1.54] test loss i: [0.11	0.8 	7.77	5.87	5.3 	2.28] | 
| 05-02 01:22:16 epoch: 1480| time: 1.6s| train loss: +1.686e+01 | test loss: +1.605e+01 | 
| 05-02 01:22:16 epoch: 1480| train loss i: [0.16	1.14	5.12	4.87	3.99	1.58] test loss i: [0.17	0.23	5.54	3.89	4.53	1.69] | 
| 05-02 01:22:18 epoch: 1481| time: 1.7s| train loss: +1.653e+01 | test loss: +1.637e+01 | 
| 05-02 01:22:18 epoch: 1481| train loss i: [0.12	0.66	5.18	5.06	3.87	1.63] test loss i: [0.13	2.13	4.57	4.8 	3.27	1.46] | 
| 05-02 01:22:19 epoch: 1482| time: 1.7s| train loss: +1.680e+01 | test loss: +2.318e+01 | 
| 05-02 01:22:19 epoch: 1482| train loss i: [0.09	1.21	5.14	4.92	3.91	1.53] test loss i: [0.27	3.13	6.7 	6.73	4.35	2.  ] | 
| 05-02 01:22:21 epoch: 1483| time: 1.6s| train loss: +1.714e+01 | test loss: +1.702e+01 | 
| 05-02 01:22:21 epoch: 1483| train loss i: [0.1 	1.33	5.56	4.85	3.67	1.64] test loss i: [0.13	2.  	4.1 	4.19	4.9 	1.69] | 
| 05-02 01:22:23 epoch: 1484| time: 1.6s| train loss: +1.624e+01 | test loss: +2.074e+01 | 
| 05-02 01:22:23 epoch: 1484| train loss i: [0.13	0.62	5.23	4.85	3.84	1.57] test loss i: [0.48	2.67	6.24	5.64	3.85	1.85] | 
| 05-02 01:22:24 epoch: 1485| time: 1.6s| train loss: +1.609e+01 | test loss: +1.739e+01 | 
| 05-02 01:22:24 epoch: 1485| train loss i: [0.12	0.99	4.87	5.11	3.51	1.49] test loss i: [0.17	0.5 	5.73	5.89	3.5 	1.61] | 
| 05-02 01:22:26 epoch: 1486| time: 1.6s| train loss: +1.649e+01 | test loss: +1.653e+01 | 
| 05-02 01:22:26 epoch: 1486| train loss i: [0.06	1.35	5.04	4.62	3.92	1.51] test loss i: [0.06	0.57	4.9 	5.31	3.92	1.77] | 
| 05-02 01:22:28 epoch: 1487| time: 1.6s| train loss: +1.735e+01 | test loss: +1.914e+01 | 
| 05-02 01:22:28 epoch: 1487| train loss i: [0.19	1.44	5.47	4.99	3.68	1.57] test loss i: [0.18	1.56	6.77	5.14	3.82	1.66] | 
| 05-02 01:22:29 epoch: 1488| time: 1.6s| train loss: +1.688e+01 | test loss: +1.539e+01 | 
| 05-02 01:22:29 epoch: 1488| train loss i: [0.13	0.91	5.71	4.83	3.67	1.63] test loss i: [0.32	0.65	4.79	4.28	3.91	1.44] | 
| 05-02 01:22:31 epoch: 1489| time: 1.6s| train loss: +1.734e+01 | test loss: +1.424e+01 | 
| 05-02 01:22:31 epoch: 1489| train loss i: [0.23	2.11	4.91	4.76	3.69	1.64] test loss i: [0.15	1.04	3.58	3.62	4.49	1.35] | 
| 05-02 01:22:32 epoch: 1490| time: 1.6s| train loss: +1.689e+01 | test loss: +2.267e+01 | 
| 05-02 01:22:32 epoch: 1490| train loss i: [0.1 	1.18	5.37	4.67	3.96	1.6 ] test loss i: [0.45	1.65	6.1 	7.23	5.25	2.  ] | 
| 05-02 01:22:34 epoch: 1491| time: 1.7s| train loss: +1.738e+01 | test loss: +1.756e+01 | 
| 05-02 01:22:34 epoch: 1491| train loss i: [0.15	1.34	5.71	4.81	3.88	1.5 ] test loss i: [0.21	2.16	5.23	4.83	3.57	1.57] | 
| 05-02 01:22:36 epoch: 1492| time: 1.6s| train loss: +1.697e+01 | test loss: +1.689e+01 | 
| 05-02 01:22:36 epoch: 1492| train loss i: [0.11	1.44	5.56	4.15	4.08	1.62] test loss i: [0.06	1.42	6.35	3.7 	3.55	1.8 ] | 
| 05-02 01:22:37 epoch: 1493| time: 1.6s| train loss: +1.750e+01 | test loss: +1.613e+01 | 
| 05-02 01:22:37 epoch: 1493| train loss i: [0.12	1.53	5.26	5.1 	3.95	1.55] test loss i: [0.11	0.57	5.33	4.8 	3.68	1.65] | 
| 05-02 01:22:39 epoch: 1494| time: 1.6s| train loss: +1.741e+01 | test loss: +1.788e+01 | 
| 05-02 01:22:39 epoch: 1494| train loss i: [0.13	1.64	5.54	4.76	3.78	1.56] test loss i: [0.15	1.32	5.83	4.93	3.86	1.79] | 
| 05-02 01:22:41 epoch: 1495| time: 1.6s| train loss: +1.553e+01 | test loss: +1.691e+01 | 
| 05-02 01:22:41 epoch: 1495| train loss i: [0.11	0.51	4.77	4.81	3.78	1.55] test loss i: [0.26	0.91	5.02	5.25	3.85	1.62] | 
| 05-02 01:22:42 epoch: 1496| time: 1.6s| train loss: +1.761e+01 | test loss: +1.583e+01 | 
| 05-02 01:22:42 epoch: 1496| train loss i: [0.09	1.48	5.45	4.92	4.08	1.58] test loss i: [0.09	1.37	4.74	4.72	3.41	1.49] | 
| 05-02 01:22:44 epoch: 1497| time: 1.6s| train loss: +1.782e+01 | test loss: +1.824e+01 | 
| 05-02 01:22:44 epoch: 1497| train loss i: [0.12	1.82	5.37	4.88	4.08	1.55] test loss i: [0.81	0.92	6.37	4.68	3.65	1.81] | 
| 05-02 01:22:45 epoch: 1498| time: 1.6s| train loss: +1.797e+01 | test loss: +1.999e+01 | 
| 05-02 01:22:45 epoch: 1498| train loss i: [0.12	2.12	5.7 	4.65	3.81	1.56] test loss i: [0.11	1.41	5.65	6.39	4.56	1.89] | 
| 05-02 01:22:47 epoch: 1499| time: 1.6s| train loss: +1.840e+01 | test loss: +1.924e+01 | 
| 05-02 01:22:47 epoch: 1499| train loss i: [0.16	1.67	5.82	5.22	3.97	1.56] test loss i: [0.26	1.89	5.06	4.53	5.84	1.67] | 
| 05-02 01:22:49 epoch: 1500| time: 1.6s| train loss: +1.736e+01 | test loss: +1.809e+01 | 
| 05-02 01:22:49 epoch: 1500| train loss i: [0.15	1.54	5.31	4.79	3.97	1.59] test loss i: [0.22	2.99	5.4 	4.02	3.81	1.65] | 
| 05-02 01:22:50 epoch: 1501| time: 1.6s| train loss: +1.634e+01 | test loss: +1.459e+01 | 
| 05-02 01:22:50 epoch: 1501| train loss i: [0.16	1.04	5.32	4.6 	3.68	1.54] test loss i: [0.18	2.01	4.48	3.44	3.08	1.4 ] | 
| 05-02 01:22:52 epoch: 1502| time: 1.7s| train loss: +1.672e+01 | test loss: +2.188e+01 | 
| 05-02 01:22:52 epoch: 1502| train loss i: [0.18	0.93	5.31	5.14	3.64	1.53] test loss i: [0.77	2.54	7.86	5.37	3.42	1.93] | 
| 05-02 01:22:54 epoch: 1503| time: 1.6s| train loss: +1.804e+01 | test loss: +1.834e+01 | 
| 05-02 01:22:54 epoch: 1503| train loss i: [0.14	1.53	6.03	4.76	4.  	1.57] test loss i: [0.09	1.8 	5.95	4.82	3.5 	2.18] | 
| 05-02 01:22:55 epoch: 1504| time: 1.6s| train loss: +1.743e+01 | test loss: +1.463e+01 | 
| 05-02 01:22:55 epoch: 1504| train loss i: [0.13	1.66	5.92	4.43	3.73	1.56] test loss i: [0.07	0.59	4.79	4.42	3.11	1.65] | 
| 05-02 01:22:57 epoch: 1505| time: 1.6s| train loss: +1.728e+01 | test loss: +1.771e+01 | 
| 05-02 01:22:57 epoch: 1505| train loss i: [0.13	1.67	5.38	4.72	3.8 	1.59] test loss i: [0.47	0.64	5.27	4.62	4.68	2.01] | 
| 05-02 01:22:59 epoch: 1506| time: 1.6s| train loss: +1.764e+01 | test loss: +1.860e+01 | 
| 05-02 01:22:59 epoch: 1506| train loss i: [0.15	1.92	5.02	4.87	4.08	1.6 ] test loss i: [0.73	2.37	5.79	5.14	3.17	1.4 ] | 
| 05-02 01:23:00 epoch: 1507| time: 1.5s| train loss: +1.787e+01 | test loss: +1.814e+01 | 
| 05-02 01:23:00 epoch: 1507| train loss i: [0.21	1.19	6.  	4.89	3.95	1.62] test loss i: [0.84	1.04	5.61	4.91	4.21	1.52] | 
| 05-02 01:23:01 epoch: 1508| time: 1.1s| train loss: +1.808e+01 | test loss: +1.592e+01 | 
| 05-02 01:23:01 epoch: 1508| train loss i: [0.24	1.59	5.86	5.01	3.73	1.64] test loss i: [0.14	0.86	4.39	5.03	3.79	1.71] | 
| 05-02 01:23:02 epoch: 1509| time: 1.1s| train loss: +1.792e+01 | test loss: +2.238e+01 | 
| 05-02 01:23:02 epoch: 1509| train loss i: [0.16	1.47	5.82	5.09	3.79	1.59] test loss i: [0.07	1.4 	7.77	5.76	5.04	2.34] | 
| 05-02 01:23:03 epoch: 1510| time: 1.1s| train loss: +1.771e+01 | test loss: +1.893e+01 | 
| 05-02 01:23:03 epoch: 1510| train loss i: [0.1 	1.88	5.83	4.38	3.98	1.54] test loss i: [0.1 	2.12	6.07	5.01	3.71	1.91] | 
| 05-02 01:23:04 epoch: 1511| time: 1.1s| train loss: +1.743e+01 | test loss: +1.897e+01 | 
| 05-02 01:23:04 epoch: 1511| train loss i: [0.11	1.38	5.66	4.8 	3.92	1.56] test loss i: [0.23	0.43	6.6 	5.4 	4.52	1.78] | 
| 05-02 01:23:05 epoch: 1512| time: 1.0s| train loss: +1.717e+01 | test loss: +1.912e+01 | 
| 05-02 01:23:05 epoch: 1512| train loss i: [0.17	1.56	5.39	4.51	3.99	1.55] test loss i: [0.09	1.82	6.19	5.38	4.29	1.35] | 
| 05-02 01:23:07 epoch: 1513| time: 1.1s| train loss: +1.721e+01 | test loss: +1.965e+01 | 
| 05-02 01:23:07 epoch: 1513| train loss i: [0.1 	1.95	5.36	4.43	3.78	1.58] test loss i: [0.17	0.2 	5.68	6.5 	4.93	2.16] | 
| 05-02 01:23:08 epoch: 1514| time: 1.1s| train loss: +1.760e+01 | test loss: +1.862e+01 | 
| 05-02 01:23:08 epoch: 1514| train loss i: [0.08	1.89	5.53	4.79	3.79	1.51] test loss i: [0.13	0.94	6.52	5.16	4.11	1.76] | 
| 05-02 01:23:09 epoch: 1515| time: 1.1s| train loss: +1.821e+01 | test loss: +1.608e+01 | 
| 05-02 01:23:09 epoch: 1515| train loss i: [0.09	1.82	6.  	4.9 	3.89	1.5 ] test loss i: [0.11	0.82	4.93	4.93	3.62	1.68] | 
| 05-02 01:23:10 epoch: 1516| time: 1.1s| train loss: +1.687e+01 | test loss: +1.736e+01 | 
| 05-02 01:23:10 epoch: 1516| train loss i: [0.08	1.24	5.52	4.58	3.89	1.56] test loss i: [0.16	0.36	7.33	4.15	3.81	1.54] | 
| 05-02 01:23:11 epoch: 1517| time: 1.0s| train loss: +1.804e+01 | test loss: +2.475e+01 | 
| 05-02 01:23:11 epoch: 1517| train loss i: [0.09	1.82	6.19	4.56	3.77	1.61] test loss i: [0.17	1.5 	7.89	6.61	6.11	2.47] | 
| 05-02 01:23:12 epoch: 1518| time: 1.1s| train loss: +1.664e+01 | test loss: +1.450e+01 | 
| 05-02 01:23:12 epoch: 1518| train loss i: [0.12	1.32	5.33	4.7 	3.66	1.51] test loss i: [0.08	0.76	4.36	4.38	3.46	1.46] | 
| 05-02 01:23:13 epoch: 1519| time: 1.1s| train loss: +1.657e+01 | test loss: +2.231e+01 | 
| 05-02 01:23:13 epoch: 1519| train loss i: [0.09	1.95	4.72	4.6 	3.72	1.5 ] test loss i: [0.37	1.68	7.13	6.21	4.63	2.28] | 
| 05-02 01:23:14 epoch: 1520| time: 1.1s| train loss: +1.836e+01 | test loss: +1.718e+01 | 
| 05-02 01:23:14 epoch: 1520| train loss i: [0.1 	1.99	5.51	5.04	4.14	1.57] test loss i: [0.5 	1.77	4.94	4.93	3.42	1.63] | 
| 05-02 01:23:15 epoch: 1521| time: 1.1s| train loss: +1.701e+01 | test loss: +2.064e+01 | 
| 05-02 01:23:15 epoch: 1521| train loss i: [0.08	1.8 	5.24	4.66	3.65	1.57] test loss i: [0.04	2.  	5.44	6.55	4.72	1.89] | 
| 05-02 01:23:16 epoch: 1522| time: 1.1s| train loss: +1.609e+01 | test loss: +1.686e+01 | 
| 05-02 01:23:16 epoch: 1522| train loss i: [0.08	0.76	5.  	5.07	3.66	1.51] test loss i: [0.15	0.85	5.94	4.39	3.78	1.75] | 
| 05-02 01:23:17 epoch: 1523| time: 1.1s| train loss: +1.668e+01 | test loss: +3.020e+01 | 
| 05-02 01:23:17 epoch: 1523| train loss i: [0.12	1.17	5.52	4.6 	3.75	1.52] test loss i: [0.1 	4.27	9.52	7.82	6.35	2.14] | 
| 05-02 01:23:18 epoch: 1524| time: 1.0s| train loss: +1.758e+01 | test loss: +1.433e+01 | 
| 05-02 01:23:18 epoch: 1524| train loss i: [0.11	1.42	5.91	5.01	3.6 	1.52] test loss i: [0.28	0.94	4.19	3.92	3.33	1.68] | 
| 05-02 01:23:19 epoch: 1525| time: 1.1s| train loss: +1.730e+01 | test loss: +1.736e+01 | 
| 05-02 01:23:19 epoch: 1525| train loss i: [0.14	0.61	6.21	4.92	3.84	1.57] test loss i: [0.12	1.53	5.92	4.63	3.39	1.78] | 
| 05-02 01:23:21 epoch: 1526| time: 1.1s| train loss: +1.702e+01 | test loss: +1.612e+01 | 
| 05-02 01:23:21 epoch: 1526| train loss i: [0.08	0.99	5.42	5.02	3.97	1.56] test loss i: [0.11	2.82	3.93	3.89	3.89	1.48] | 
| 05-02 01:23:22 epoch: 1527| time: 1.1s| train loss: +1.767e+01 | test loss: +1.703e+01 | 
| 05-02 01:23:22 epoch: 1527| train loss i: [0.09	1.91	5.48	4.79	3.86	1.54] test loss i: [0.06	0.57	5.06	5.78	3.96	1.61] | 
| 05-02 01:23:23 epoch: 1528| time: 1.1s| train loss: +1.715e+01 | test loss: +1.961e+01 | 
| 05-02 01:23:23 epoch: 1528| train loss i: [0.07	1.79	5.1 	4.89	3.76	1.54] test loss i: [0.17	1.35	7.34	4.83	4.25	1.68] | 
| 05-02 01:23:24 epoch: 1529| time: 1.1s| train loss: +1.709e+01 | test loss: +1.946e+01 | 
| 05-02 01:23:24 epoch: 1529| train loss i: [0.08	0.93	6.22	4.66	3.59	1.61] test loss i: [0.09	1.08	6.25	6.4 	3.35	2.29] | 
| 05-02 01:23:25 epoch: 1530| time: 1.0s| train loss: +1.733e+01 | test loss: +2.342e+01 | 
| 05-02 01:23:25 epoch: 1530| train loss i: [0.15	0.99	5.87	5.04	3.73	1.55] test loss i: [0.15	0.73	7.96	7.1 	5.15	2.32] | 
| 05-02 01:23:26 epoch: 1531| time: 1.1s| train loss: +1.685e+01 | test loss: +1.930e+01 | 
| 05-02 01:23:26 epoch: 1531| train loss i: [0.11	1.32	5.34	4.79	3.75	1.54] test loss i: [0.11	1.92	5.76	5.29	4.46	1.76] | 
| 05-02 01:23:27 epoch: 1532| time: 1.1s| train loss: +1.800e+01 | test loss: +1.812e+01 | 
| 05-02 01:23:27 epoch: 1532| train loss i: [0.1 	1.57	5.62	5.37	3.71	1.63] test loss i: [0.06	1.28	5.48	5.48	4.07	1.74] | 
| 05-02 01:23:28 epoch: 1533| time: 1.1s| train loss: +1.693e+01 | test loss: +1.994e+01 | 
| 05-02 01:23:28 epoch: 1533| train loss i: [0.09	1.5 	5.4 	4.62	3.77	1.54] test loss i: [0.18	1.75	6.49	5.5 	3.96	2.05] | 
| 05-02 01:23:29 epoch: 1534| time: 1.1s| train loss: +1.762e+01 | test loss: +2.619e+01 | 
| 05-02 01:23:29 epoch: 1534| train loss i: [0.1 	1.68	5.44	5.26	3.51	1.63] test loss i: [0.27	2.69	7.4 	7.86	5.74	2.23] | 
| 05-02 01:23:30 epoch: 1535| time: 1.1s| train loss: +1.718e+01 | test loss: +1.607e+01 | 
| 05-02 01:23:30 epoch: 1535| train loss i: [0.07	1.39	5.71	4.54	3.92	1.56] test loss i: [0.1 	0.31	5.65	4.62	3.66	1.74] | 
| 05-02 01:23:31 epoch: 1536| time: 1.0s| train loss: +1.781e+01 | test loss: +1.444e+01 | 
| 05-02 01:23:31 epoch: 1536| train loss i: [0.07	1.7 	5.58	4.69	4.25	1.52] test loss i: [0.05	0.87	4.44	4.33	3.07	1.69] | 
| 05-02 01:23:32 epoch: 1537| time: 1.0s| train loss: +1.687e+01 | test loss: +1.434e+01 | 
| 05-02 01:23:32 epoch: 1537| train loss i: [0.07	1.22	5.32	5.04	3.68	1.54] test loss i: [0.11	0.65	4.55	3.9 	3.5 	1.63] | 
| 05-02 01:23:33 epoch: 1538| time: 1.1s| train loss: +1.697e+01 | test loss: +1.565e+01 | 
| 05-02 01:23:33 epoch: 1538| train loss i: [0.1 	1.28	5.12	5.04	3.89	1.53] test loss i: [0.07	1.02	4.81	4.54	3.48	1.73] | 
| 05-02 01:23:35 epoch: 1539| time: 1.1s| train loss: +1.678e+01 | test loss: +1.905e+01 | 
| 05-02 01:23:35 epoch: 1539| train loss i: [0.07	1.53	5.04	4.8 	3.77	1.57] test loss i: [0.07	1.09	6.11	5.3 	4.73	1.76] | 
| 05-02 01:23:36 epoch: 1540| time: 1.1s| train loss: +1.808e+01 | test loss: +1.603e+01 | 
| 05-02 01:23:36 epoch: 1540| train loss i: [0.06	1.9 	5.62	4.85	4.1 	1.54] test loss i: [0.22	0.82	4.19	5.06	3.99	1.74] | 
| 05-02 01:23:37 epoch: 1541| time: 1.1s| train loss: +1.683e+01 | test loss: +1.717e+01 | 
| 05-02 01:23:37 epoch: 1541| train loss i: [0.09	0.94	5.43	4.95	3.8 	1.62] test loss i: [0.11	0.47	5.81	4.54	4.58	1.66] | 
| 05-02 01:23:38 epoch: 1542| time: 1.1s| train loss: +1.676e+01 | test loss: +1.811e+01 | 
| 05-02 01:23:38 epoch: 1542| train loss i: [0.13	1.29	5.32	4.47	4.02	1.53] test loss i: [0.12	1.07	6.81	4.86	3.56	1.69] | 
| 05-02 01:23:39 epoch: 1543| time: 1.0s| train loss: +1.762e+01 | test loss: +2.095e+01 | 
| 05-02 01:23:39 epoch: 1543| train loss i: [0.15	1.3 	5.61	5.03	3.94	1.59] test loss i: [0.08	2.28	6.9 	5.38	4.29	2.02] | 
| 05-02 01:23:40 epoch: 1544| time: 1.1s| train loss: +1.718e+01 | test loss: +2.041e+01 | 
| 05-02 01:23:40 epoch: 1544| train loss i: [0.1 	1.77	5.04	4.85	3.92	1.51] test loss i: [0.22	1.31	5.64	6.92	4.39	1.95] | 
| 05-02 01:23:41 epoch: 1545| time: 1.1s| train loss: +1.638e+01 | test loss: +1.909e+01 | 
| 05-02 01:23:41 epoch: 1545| train loss i: [0.12	0.91	5.08	4.82	3.86	1.6 ] test loss i: [0.22	0.74	7.64	5.09	3.67	1.72] | 
| 05-02 01:23:42 epoch: 1546| time: 1.1s| train loss: +1.703e+01 | test loss: +1.624e+01 | 
| 05-02 01:23:42 epoch: 1546| train loss i: [0.2 	1.34	5.22	5.05	3.67	1.55] test loss i: [0.2 	0.83	4.65	5.39	3.4 	1.78] | 
| 05-02 01:23:43 epoch: 1547| time: 1.1s| train loss: +1.690e+01 | test loss: +1.589e+01 | 
| 05-02 01:23:43 epoch: 1547| train loss i: [0.16	0.94	5.49	4.86	3.94	1.51] test loss i: [0.24	2.09	4.39	4.27	3.09	1.82] | 
| 05-02 01:23:44 epoch: 1548| time: 1.1s| train loss: +1.705e+01 | test loss: +1.779e+01 | 
| 05-02 01:23:44 epoch: 1548| train loss i: [0.11	0.92	5.87	5.03	3.56	1.56] test loss i: [0.08	1.84	5.13	4.97	3.87	1.9 ] | 
| 05-02 01:23:45 epoch: 1549| time: 1.0s| train loss: +1.669e+01 | test loss: +1.649e+01 | 
| 05-02 01:23:45 epoch: 1549| train loss i: [0.07	1.13	5.46	4.72	3.75	1.56] test loss i: [0.15	1.74	5.5 	4.11	3.56	1.43] | 
| 05-02 01:23:46 epoch: 1550| time: 1.1s| train loss: +1.724e+01 | test loss: +1.767e+01 | 
| 05-02 01:23:46 epoch: 1550| train loss i: [0.1 	1.27	5.5 	5.07	3.72	1.59] test loss i: [0.34	0.87	5.35	5.23	4.18	1.7 ] | 
| 05-02 01:23:47 epoch: 1551| time: 1.1s| train loss: +1.794e+01 | test loss: +2.264e+01 | 
| 05-02 01:23:47 epoch: 1551| train loss i: [0.11	1.54	5.83	5.13	3.74	1.59] test loss i: [0.13	2.34	7.36	6.11	4.93	1.76] | 
| 05-02 01:23:49 epoch: 1552| time: 1.1s| train loss: +1.706e+01 | test loss: +2.042e+01 | 
| 05-02 01:23:49 epoch: 1552| train loss i: [0.08	1.09	5.03	5.28	3.98	1.6 ] test loss i: [0.1 	2.24	6.38	5.55	4.22	1.92] | 
| 05-02 01:23:50 epoch: 1553| time: 1.1s| train loss: +1.742e+01 | test loss: +1.990e+01 | 
| 05-02 01:23:50 epoch: 1553| train loss i: [0.08	1.36	5.73	4.86	3.75	1.64] test loss i: [0.05	2.35	6.56	4.85	4.56	1.54] | 
| 05-02 01:23:51 epoch: 1554| time: 1.0s| train loss: +1.665e+01 | test loss: +1.594e+01 | 
| 05-02 01:23:51 epoch: 1554| train loss i: [0.07	0.86	5.31	5.18	3.68	1.56] test loss i: [0.07	0.36	5.24	4.67	4.06	1.54] | 
| 05-02 01:23:52 epoch: 1555| time: 1.0s| train loss: +1.752e+01 | test loss: +2.019e+01 | 
| 05-02 01:23:52 epoch: 1555| train loss i: [0.11	1.42	5.51	4.82	4.11	1.56] test loss i: [0.07	0.78	6.53	5.11	5.46	2.23] | 
| 05-02 01:23:53 epoch: 1556| time: 1.1s| train loss: +1.695e+01 | test loss: +1.646e+01 | 
| 05-02 01:23:53 epoch: 1556| train loss i: [0.08	0.99	5.48	4.78	4.11	1.52] test loss i: [0.08	2.31	4.86	3.82	3.82	1.57] | 
| 05-02 01:23:54 epoch: 1557| time: 1.1s| train loss: +1.647e+01 | test loss: +2.262e+01 | 
| 05-02 01:23:54 epoch: 1557| train loss i: [0.07	1.01	5.38	4.72	3.69	1.6 ] test loss i: [0.17	2.45	8.42	5.3 	4.02	2.27] | 
| 05-02 01:23:55 epoch: 1558| time: 1.1s| train loss: +1.699e+01 | test loss: +1.817e+01 | 
| 05-02 01:23:55 epoch: 1558| train loss i: [0.07	0.73	5.86	4.85	3.85	1.63] test loss i: [0.26	0.83	5.11	5.49	4.54	1.94] | 
| 05-02 01:23:56 epoch: 1559| time: 1.1s| train loss: +1.618e+01 | test loss: +2.558e+01 | 
| 05-02 01:23:56 epoch: 1559| train loss i: [0.06	0.9 	5.  	4.89	3.78	1.55] test loss i: [0.3 	3.46	8.43	6.51	4.61	2.27] | 
| 05-02 01:23:57 epoch: 1560| time: 1.1s| train loss: +1.747e+01 | test loss: +1.724e+01 | 
| 05-02 01:23:57 epoch: 1560| train loss i: [0.08	1.55	5.47	5.05	3.77	1.56] test loss i: [0.11	1.38	5.08	5.29	3.69	1.7 ] | 
| 05-02 01:23:58 epoch: 1561| time: 1.1s| train loss: +1.715e+01 | test loss: +2.403e+01 | 
| 05-02 01:23:58 epoch: 1561| train loss i: [0.1 	1.2 	5.34	5.05	3.89	1.57] test loss i: [0.14	2.45	7.8 	6.07	5.31	2.26] | 
| 05-02 01:23:59 epoch: 1562| time: 1.1s| train loss: +1.686e+01 | test loss: +1.601e+01 | 
| 05-02 01:23:59 epoch: 1562| train loss i: [0.12	1.06	5.52	4.74	3.85	1.57] test loss i: [0.14	1.24	5.6 	3.94	3.38	1.7 ] | 
| 05-02 01:24:00 epoch: 1563| time: 1.1s| train loss: +1.660e+01 | test loss: +1.715e+01 | 
| 05-02 01:24:00 epoch: 1563| train loss i: [0.14	1.17	5.21	4.82	3.65	1.62] test loss i: [0.07	0.91	6.02	5.07	3.54	1.54] | 
| 05-02 01:24:01 epoch: 1564| time: 1.1s| train loss: +1.779e+01 | test loss: +2.003e+01 | 
| 05-02 01:24:01 epoch: 1564| train loss i: [0.09	1.65	5.76	4.79	3.87	1.64] test loss i: [0.21	2.94	5.37	5.74	3.98	1.78] | 
| 05-02 01:24:03 epoch: 1565| time: 1.1s| train loss: +1.718e+01 | test loss: +2.086e+01 | 
| 05-02 01:24:03 epoch: 1565| train loss i: [0.1 	1.3 	5.47	4.9 	3.81	1.61] test loss i: [0.08	1.6 	7.29	5.52	4.69	1.68] | 
| 05-02 01:24:04 epoch: 1566| time: 1.1s| train loss: +1.687e+01 | test loss: +1.698e+01 | 
| 05-02 01:24:04 epoch: 1566| train loss i: [0.11	1.45	5.24	4.67	3.81	1.58] test loss i: [0.1 	1.5 	6.42	4.15	2.99	1.81] | 
| 05-02 01:24:05 epoch: 1567| time: 1.1s| train loss: +1.754e+01 | test loss: +1.828e+01 | 
| 05-02 01:24:05 epoch: 1567| train loss i: [0.09	1.47	5.9 	4.65	3.81	1.63] test loss i: [0.11	1.85	5.61	5.33	3.76	1.62] | 
| 05-02 01:24:06 epoch: 1568| time: 1.1s| train loss: +1.642e+01 | test loss: +1.842e+01 | 
| 05-02 01:24:06 epoch: 1568| train loss i: [0.09	1.12	5.02	4.65	3.93	1.6 ] test loss i: [0.25	2.77	5.45	4.64	3.85	1.46] | 
| 05-02 01:24:07 epoch: 1569| time: 1.1s| train loss: +1.713e+01 | test loss: +2.591e+01 | 
| 05-02 01:24:07 epoch: 1569| train loss i: [0.09	1.36	5.72	4.61	3.77	1.58] test loss i: [0.15	3.61	8.71	6.46	4.77	2.19] | 
| 05-02 01:24:08 epoch: 1570| time: 1.1s| train loss: +1.760e+01 | test loss: +1.576e+01 | 
| 05-02 01:24:08 epoch: 1570| train loss i: [0.09	1.99	4.96	4.97	4.04	1.54] test loss i: [0.1 	0.75	5.1 	4.36	3.77	1.68] | 
| 05-02 01:24:09 epoch: 1571| time: 1.1s| train loss: +1.667e+01 | test loss: +2.793e+01 | 
| 05-02 01:24:09 epoch: 1571| train loss i: [0.11	1.41	4.75	5.15	3.71	1.54] test loss i: [0.16	2.59	8.99	8.25	5.78	2.17] | 
| 05-02 01:24:10 epoch: 1572| time: 1.0s| train loss: +1.586e+01 | test loss: +1.618e+01 | 
| 05-02 01:24:10 epoch: 1572| train loss i: [0.09	0.73	5.14	4.93	3.41	1.56] test loss i: [0.21	1.99	5.28	4.52	2.8 	1.37] | 
| 05-02 01:24:11 epoch: 1573| time: 1.1s| train loss: +1.669e+01 | test loss: +2.317e+01 | 
| 05-02 01:24:11 epoch: 1573| train loss i: [0.07	1.12	5.55	4.67	3.68	1.6 ] test loss i: [0.14	2.43	6.62	7.09	4.99	1.9 ] | 
| 05-02 01:24:12 epoch: 1574| time: 1.1s| train loss: +1.676e+01 | test loss: +1.693e+01 | 
| 05-02 01:24:12 epoch: 1574| train loss i: [0.06	1.07	5.42	4.94	3.69	1.57] test loss i: [0.07	0.67	4.74	5.96	3.54	1.95] | 
| 05-02 01:24:13 epoch: 1575| time: 1.1s| train loss: +1.609e+01 | test loss: +1.516e+01 | 
| 05-02 01:24:13 epoch: 1575| train loss i: [0.08	0.86	5.19	4.81	3.64	1.51] test loss i: [0.15	0.61	4.74	4.42	3.47	1.78] | 
| 05-02 01:24:14 epoch: 1576| time: 1.1s| train loss: +1.640e+01 | test loss: +1.546e+01 | 
| 05-02 01:24:14 epoch: 1576| train loss i: [0.07	1.24	4.96	4.58	3.94	1.6 ] test loss i: [0.11	2.03	3.92	3.91	3.88	1.61] | 
| 05-02 01:24:16 epoch: 1577| time: 1.1s| train loss: +1.677e+01 | test loss: +2.110e+01 | 
| 05-02 01:24:16 epoch: 1577| train loss i: [0.1 	1.24	5.12	5.13	3.66	1.52] test loss i: [0.19	1.06	7.04	6.1 	4.63	2.09] | 
| 05-02 01:24:17 epoch: 1578| time: 1.0s| train loss: +1.683e+01 | test loss: +1.801e+01 | 
| 05-02 01:24:17 epoch: 1578| train loss i: [0.07	1.21	5.28	5.  	3.72	1.55] test loss i: [0.42	2.25	5.46	4.07	3.83	1.98] | 
| 05-02 01:24:18 epoch: 1579| time: 1.1s| train loss: +1.654e+01 | test loss: +1.850e+01 | 
| 05-02 01:24:18 epoch: 1579| train loss i: [0.09	0.88	5.17	4.84	4.03	1.54] test loss i: [0.09	2.15	5.68	5.01	3.9 	1.68] | 
| 05-02 01:24:19 epoch: 1580| time: 1.1s| train loss: +1.710e+01 | test loss: +1.419e+01 | 
| 05-02 01:24:19 epoch: 1580| train loss i: [0.08	0.87	5.91	4.89	3.75	1.6 ] test loss i: [0.1 	0.71	3.34	4.02	4.35	1.68] | 
| 05-02 01:24:20 epoch: 1581| time: 1.1s| train loss: +1.709e+01 | test loss: +1.885e+01 | 
| 05-02 01:24:20 epoch: 1581| train loss i: [0.08	1.32	5.84	4.47	3.85	1.53] test loss i: [0.04	1.69	5.45	5.57	4.4 	1.71] | 
| 05-02 01:24:21 epoch: 1582| time: 1.1s| train loss: +1.655e+01 | test loss: +1.718e+01 | 
| 05-02 01:24:21 epoch: 1582| train loss i: [0.1 	1.16	5.05	4.9 	3.84	1.52] test loss i: [0.1 	0.88	5.86	5.47	3.47	1.4 ] | 
| 05-02 01:24:22 epoch: 1583| time: 1.1s| train loss: +1.752e+01 | test loss: +1.772e+01 | 
| 05-02 01:24:22 epoch: 1583| train loss i: [0.07	1.07	5.48	5.43	3.96	1.51] test loss i: [0.07	1.78	5.42	4.51	3.94	2.  ] | 
| 05-02 01:24:23 epoch: 1584| time: 1.1s| train loss: +1.651e+01 | test loss: +1.843e+01 | 
| 05-02 01:24:23 epoch: 1584| train loss i: [0.08	0.89	5.13	4.9 	3.92	1.59] test loss i: [0.06	0.95	6.39	5.62	3.6 	1.81] | 
| 05-02 01:24:24 epoch: 1585| time: 1.1s| train loss: +1.707e+01 | test loss: +1.893e+01 | 
| 05-02 01:24:24 epoch: 1585| train loss i: [0.09	1.36	5.25	4.84	3.9 	1.63] test loss i: [0.07	1.33	6.18	5.52	4.09	1.74] | 
| 05-02 01:24:25 epoch: 1586| time: 1.1s| train loss: +1.756e+01 | test loss: +1.491e+01 | 
| 05-02 01:24:25 epoch: 1586| train loss i: [0.08	1.58	5.6 	4.84	3.88	1.59] test loss i: [0.1 	1.24	4.63	4.26	3.11	1.57] | 
| 05-02 01:24:26 epoch: 1587| time: 1.1s| train loss: +1.689e+01 | test loss: +2.703e+01 | 
| 05-02 01:24:26 epoch: 1587| train loss i: [0.07	1.27	5.36	4.74	3.83	1.63] test loss i: [0.09	1.75	8.46	9.12	5.37	2.24] | 
| 05-02 01:24:27 epoch: 1588| time: 1.1s| train loss: +1.697e+01 | test loss: +1.901e+01 | 
| 05-02 01:24:27 epoch: 1588| train loss i: [0.1 	1.77	5.35	4.57	3.63	1.55] test loss i: [0.08	1.54	5.28	6.34	3.98	1.78] | 
| 05-02 01:24:28 epoch: 1589| time: 1.0s| train loss: +1.750e+01 | test loss: +2.030e+01 | 
| 05-02 01:24:28 epoch: 1589| train loss i: [0.07	1.32	5.82	5.02	3.74	1.52] test loss i: [0.08	0.83	6.89	6.58	4.26	1.65] | 
| 05-02 01:24:30 epoch: 1590| time: 1.1s| train loss: +1.678e+01 | test loss: +1.970e+01 | 
| 05-02 01:24:30 epoch: 1590| train loss i: [0.09	1.33	5.36	4.75	3.63	1.61] test loss i: [0.13	1.47	6.93	5.34	4.1 	1.73] | 
| 05-02 01:24:31 epoch: 1591| time: 1.1s| train loss: +1.669e+01 | test loss: +2.533e+01 | 
| 05-02 01:24:31 epoch: 1591| train loss i: [0.07	1.46	5.05	4.64	3.79	1.67] test loss i: [0.17	2.11	8.45	7.37	5.14	2.1 ] | 
| 05-02 01:24:32 epoch: 1592| time: 1.1s| train loss: +1.709e+01 | test loss: +1.871e+01 | 
| 05-02 01:24:32 epoch: 1592| train loss i: [0.12	1.56	5.49	4.58	3.82	1.53] test loss i: [0.12	1.1 	6.05	5.34	4.36	1.73] | 
| 05-02 01:24:33 epoch: 1593| time: 1.1s| train loss: +1.701e+01 | test loss: +2.662e+01 | 
| 05-02 01:24:33 epoch: 1593| train loss i: [0.09	0.91	5.61	5.29	3.63	1.47] test loss i: [0.15	3.3 	8.45	6.44	5.84	2.42] | 
| 05-02 01:24:34 epoch: 1594| time: 1.1s| train loss: +1.664e+01 | test loss: +1.502e+01 | 
| 05-02 01:24:34 epoch: 1594| train loss i: [0.08	0.92	5.14	5.04	3.82	1.64] test loss i: [0.05	1.37	4.9 	3.87	3.35	1.47] | 
| 05-02 01:24:35 epoch: 1595| time: 1.0s| train loss: +1.715e+01 | test loss: +1.824e+01 | 
| 05-02 01:24:35 epoch: 1595| train loss i: [0.07	1.24	5.75	4.62	3.85	1.62] test loss i: [0.08	0.9 	4.98	6.13	4.39	1.75] | 
| 05-02 01:24:36 epoch: 1596| time: 1.0s| train loss: +1.756e+01 | test loss: +1.884e+01 | 
| 05-02 01:24:36 epoch: 1596| train loss i: [0.09	1.5 	5.38	5.31	3.72	1.57] test loss i: [0.12	1.61	6.54	4.55	4.15	1.87] | 
| 05-02 01:24:37 epoch: 1597| time: 1.1s| train loss: +1.663e+01 | test loss: +2.024e+01 | 
| 05-02 01:24:37 epoch: 1597| train loss i: [0.05	1.08	5.3 	4.82	3.81	1.57] test loss i: [0.07	1.95	6.53	5.87	4.02	1.81] | 
| 05-02 01:24:38 epoch: 1598| time: 1.1s| train loss: +1.733e+01 | test loss: +2.055e+01 | 
| 05-02 01:24:38 epoch: 1598| train loss i: [0.08	1.84	5.03	4.67	4.1 	1.61] test loss i: [0.09	0.63	7.98	5.6 	4.28	1.97] | 
| 05-02 01:24:39 epoch: 1599| time: 1.1s| train loss: +1.675e+01 | test loss: +2.098e+01 | 
| 05-02 01:24:39 epoch: 1599| train loss i: [0.12	1.12	5.  	4.69	4.21	1.61] test loss i: [0.09	3.21	6.27	5.23	4.62	1.56] | 
| 05-02 01:24:40 epoch: 1600| time: 1.1s| train loss: +1.692e+01 | test loss: +1.724e+01 | 
| 05-02 01:24:40 epoch: 1600| train loss i: [0.06	1.63	5.16	4.69	3.81	1.57] test loss i: [0.15	1.23	6.49	4.6 	3.17	1.61] | 
| 05-02 01:24:41 epoch: 1601| time: 1.1s| train loss: +1.798e+01 | test loss: +1.419e+01 | 
| 05-02 01:24:41 epoch: 1601| train loss i: [0.1 	2.19	5.77	4.82	3.51	1.59] test loss i: [0.08	0.42	4.39	4.23	3.51	1.56] | 
| 05-02 01:24:42 epoch: 1602| time: 1.0s| train loss: +1.701e+01 | test loss: +1.891e+01 | 
| 05-02 01:24:42 epoch: 1602| train loss i: [0.13	1.59	5.13	5.09	3.51	1.57] test loss i: [0.08	1.36	5.68	4.76	4.88	2.15] | 
| 05-02 01:24:43 epoch: 1603| time: 1.1s| train loss: +1.668e+01 | test loss: +1.446e+01 | 
| 05-02 01:24:43 epoch: 1603| train loss i: [0.13	1.44	5.16	4.88	3.64	1.43] test loss i: [0.26	1.4 	4.  	4.03	3.21	1.57] | 
| 05-02 01:24:45 epoch: 1604| time: 1.1s| train loss: +1.585e+01 | test loss: +1.592e+01 | 
| 05-02 01:24:45 epoch: 1604| train loss i: [0.13	0.37	5.15	5.  	3.68	1.52] test loss i: [0.13	0.76	4.53	5.28	3.65	1.58] | 
| 05-02 01:24:46 epoch: 1605| time: 1.1s| train loss: +1.755e+01 | test loss: +1.622e+01 | 
| 05-02 01:24:46 epoch: 1605| train loss i: [0.12	1.43	5.63	4.94	3.89	1.53] test loss i: [0.12	2.11	5.21	3.77	3.43	1.58] | 
| 05-02 01:24:47 epoch: 1606| time: 1.1s| train loss: +1.727e+01 | test loss: +1.806e+01 | 
| 05-02 01:24:47 epoch: 1606| train loss i: [0.11	1.23	5.5 	5.1 	3.74	1.59] test loss i: [0.1 	0.74	4.76	5.36	5.46	1.63] | 
| 05-02 01:24:48 epoch: 1607| time: 1.1s| train loss: +1.643e+01 | test loss: +2.233e+01 | 
| 05-02 01:24:48 epoch: 1607| train loss i: [0.08	1.25	4.94	4.7 	3.94	1.52] test loss i: [0.13	1.71	6.63	6.35	5.38	2.14] | 
| 05-02 01:24:49 epoch: 1608| time: 1.1s| train loss: +1.776e+01 | test loss: +1.478e+01 | 
| 05-02 01:24:49 epoch: 1608| train loss i: [0.08	1.87	5.42	4.94	3.88	1.57] test loss i: [0.06	0.57	4.99	4.27	3.11	1.77] | 
| 05-02 01:24:50 epoch: 1609| time: 1.1s| train loss: +1.682e+01 | test loss: +1.499e+01 | 
| 05-02 01:24:50 epoch: 1609| train loss i: [0.07	0.98	5.66	4.66	3.88	1.56] test loss i: [0.32	0.81	4.77	4.27	3.26	1.56] | 
| 05-02 01:24:51 epoch: 1610| time: 1.1s| train loss: +1.752e+01 | test loss: +1.877e+01 | 
| 05-02 01:24:51 epoch: 1610| train loss i: [0.06	1.27	5.55	5.15	3.81	1.68] test loss i: [0.31	3.69	4.87	4.74	3.35	1.8 ] | 
| 05-02 01:24:52 epoch: 1611| time: 1.1s| train loss: +1.784e+01 | test loss: +1.867e+01 | 
| 05-02 01:24:52 epoch: 1611| train loss i: [0.09	1.54	5.78	4.94	3.91	1.58] test loss i: [0.17	1.24	6.71	4.99	3.87	1.7 ] | 
| 05-02 01:24:53 epoch: 1612| time: 1.0s| train loss: +1.691e+01 | test loss: +2.682e+01 | 
| 05-02 01:24:53 epoch: 1612| train loss i: [0.1 	1.4 	5.29	4.73	3.84	1.55] test loss i: [0.21	3.62	8.78	5.99	5.96	2.25] | 
| 05-02 01:24:54 epoch: 1613| time: 1.0s| train loss: +1.675e+01 | test loss: +1.881e+01 | 
| 05-02 01:24:54 epoch: 1613| train loss i: [0.1 	0.85	5.34	4.95	3.94	1.58] test loss i: [0.11	2.27	5.05	5.65	3.92	1.82] | 
| 05-02 01:24:55 epoch: 1614| time: 1.1s| train loss: +1.679e+01 | test loss: +1.870e+01 | 
| 05-02 01:24:55 epoch: 1614| train loss i: [0.09	0.87	5.78	4.89	3.59	1.57] test loss i: [0.16	3.25	4.85	4.69	3.92	1.83] | 
| 05-02 01:24:56 epoch: 1615| time: 1.1s| train loss: +1.811e+01 | test loss: +1.606e+01 | 
| 05-02 01:24:56 epoch: 1615| train loss i: [0.09	1.69	5.92	4.97	3.95	1.5 ] test loss i: [0.12	1.8 	4.26	4.49	3.75	1.64] | 
| 05-02 01:24:58 epoch: 1616| time: 1.1s| train loss: +1.723e+01 | test loss: +1.724e+01 | 
| 05-02 01:24:58 epoch: 1616| train loss i: [0.1 	1.69	5.15	4.89	3.87	1.55] test loss i: [0.14	1.42	4.84	4.92	3.87	2.06] | 
| 05-02 01:24:59 epoch: 1617| time: 1.1s| train loss: +1.759e+01 | test loss: +1.963e+01 | 
| 05-02 01:24:59 epoch: 1617| train loss i: [0.1 	1.52	5.33	5.18	3.85	1.61] test loss i: [0.11	1.07	6.92	5.44	4.15	1.93] | 
| 05-02 01:25:00 epoch: 1618| time: 1.0s| train loss: +1.799e+01 | test loss: +1.514e+01 | 
| 05-02 01:25:00 epoch: 1618| train loss i: [0.31	1.43	5.74	4.94	3.98	1.59] test loss i: [0.09	1.26	4.66	4.12	3.56	1.45] | 
| 05-02 01:25:01 epoch: 1619| time: 1.0s| train loss: +1.762e+01 | test loss: +2.347e+01 | 
| 05-02 01:25:01 epoch: 1619| train loss i: [0.14	1.54	5.56	5.13	3.71	1.55] test loss i: [0.1 	1.85	8.55	6.16	4.95	1.86] | 
| 05-02 01:25:02 epoch: 1620| time: 1.1s| train loss: +1.668e+01 | test loss: +1.597e+01 | 
| 05-02 01:25:02 epoch: 1620| train loss i: [0.1 	1.06	5.57	4.76	3.69	1.49] test loss i: [0.15	1.58	4.14	5.14	3.49	1.47] | 
| 05-02 01:25:03 epoch: 1621| time: 1.1s| train loss: +1.746e+01 | test loss: +1.712e+01 | 
| 05-02 01:25:03 epoch: 1621| train loss i: [0.09	1.66	5.74	4.71	3.71	1.54] test loss i: [0.23	1.07	5.64	4.36	3.96	1.86] | 
| 05-02 01:25:04 epoch: 1622| time: 1.1s| train loss: +1.785e+01 | test loss: +1.548e+01 | 
| 05-02 01:25:04 epoch: 1622| train loss i: [0.13	1.72	5.93	4.78	3.71	1.58] test loss i: [0.05	1.2 	3.81	4.56	4.06	1.81] | 
| 05-02 01:25:05 epoch: 1623| time: 1.1s| train loss: +1.645e+01 | test loss: +1.548e+01 | 
| 05-02 01:25:05 epoch: 1623| train loss i: [0.07	1.12	5.36	4.53	3.83	1.54] test loss i: [0.06	0.51	4.84	4.45	3.89	1.73] | 
| 05-02 01:25:06 epoch: 1624| time: 1.0s| train loss: +1.766e+01 | test loss: +2.517e+01 | 
| 05-02 01:25:06 epoch: 1624| train loss i: [0.05	1.8 	5.74	4.9 	3.61	1.56] test loss i: [0.11	2.94	7.96	6.51	5.77	1.88] | 
| 05-02 01:25:07 epoch: 1625| time: 1.0s| train loss: +1.641e+01 | test loss: +1.658e+01 | 
| 05-02 01:25:07 epoch: 1625| train loss i: [0.06	1.47	4.99	4.7 	3.62	1.58] test loss i: [0.04	2.15	4.97	3.93	3.8 	1.69] | 
| 05-02 01:25:08 epoch: 1626| time: 1.1s| train loss: +1.660e+01 | test loss: +1.612e+01 | 
| 05-02 01:25:08 epoch: 1626| train loss i: [0.09	1.25	5.19	4.71	3.79	1.58] test loss i: [0.11	0.39	6.46	4.02	3.45	1.69] | 
| 05-02 01:25:09 epoch: 1627| time: 1.1s| train loss: +1.720e+01 | test loss: +1.981e+01 | 
| 05-02 01:25:09 epoch: 1627| train loss i: [0.1 	1.43	5.52	4.7 	3.93	1.53] test loss i: [0.04	0.92	7.63	5.48	4.06	1.68] | 
| 05-02 01:25:10 epoch: 1628| time: 1.1s| train loss: +1.758e+01 | test loss: +1.581e+01 | 
| 05-02 01:25:10 epoch: 1628| train loss i: [0.08	1.33	6.19	4.64	3.82	1.51] test loss i: [0.26	0.25	5.26	4.74	3.68	1.62] | 
| 05-02 01:25:11 epoch: 1629| time: 1.1s| train loss: +1.696e+01 | test loss: +1.436e+01 | 
| 05-02 01:25:11 epoch: 1629| train loss i: [0.12	1.08	5.45	4.98	3.76	1.56] test loss i: [0.15	0.73	4.39	3.73	3.75	1.6 ] | 
| 05-02 01:25:13 epoch: 1630| time: 1.1s| train loss: +1.602e+01 | test loss: +2.043e+01 | 
| 05-02 01:25:13 epoch: 1630| train loss i: [0.15	1.06	5.08	4.55	3.7 	1.48] test loss i: [0.4 	1.96	6.22	5.44	4.59	1.82] | 
| 05-02 01:25:14 epoch: 1631| time: 1.1s| train loss: +1.816e+01 | test loss: +1.675e+01 | 
| 05-02 01:25:14 epoch: 1631| train loss i: [0.12	2.06	5.67	4.75	3.98	1.58] test loss i: [0.1 	1.76	5.47	4.8 	3.19	1.44] | 
| 05-02 01:25:15 epoch: 1632| time: 1.1s| train loss: +1.675e+01 | test loss: +2.170e+01 | 
| 05-02 01:25:15 epoch: 1632| train loss i: [0.14	1.24	5.13	4.92	3.77	1.55] test loss i: [0.33	0.71	7.55	5.81	5.15	2.14] | 
| 05-02 01:25:16 epoch: 1633| time: 1.1s| train loss: +1.780e+01 | test loss: +2.337e+01 | 
| 05-02 01:25:16 epoch: 1633| train loss i: [0.12	1.41	6.2 	4.8 	3.71	1.56] test loss i: [0.41	2.28	7.02	6.56	5.03	2.08] | 
| 05-02 01:25:17 epoch: 1634| time: 1.1s| train loss: +1.665e+01 | test loss: +1.643e+01 | 
| 05-02 01:25:17 epoch: 1634| train loss i: [0.11	1.44	5.14	4.77	3.75	1.45] test loss i: [0.11	1.47	4.92	4.39	3.97	1.57] | 
| 05-02 01:25:18 epoch: 1635| time: 1.1s| train loss: +1.761e+01 | test loss: +1.901e+01 | 
| 05-02 01:25:18 epoch: 1635| train loss i: [0.09	1.59	5.36	5.15	3.89	1.51] test loss i: [0.12	0.27	6.49	5.46	4.78	1.9 ] | 
| 05-02 01:25:19 epoch: 1636| time: 1.1s| train loss: +1.632e+01 | test loss: +2.055e+01 | 
| 05-02 01:25:19 epoch: 1636| train loss i: [0.08	1.15	5.15	4.63	3.81	1.5 ] test loss i: [0.19	2.15	5.71	5.7 	5.03	1.77] | 
| 05-02 01:25:20 epoch: 1637| time: 1.0s| train loss: +1.718e+01 | test loss: +2.047e+01 | 
| 05-02 01:25:20 epoch: 1637| train loss i: [0.06	1.34	5.6 	5.06	3.61	1.51] test loss i: [0.08	0.46	6.2 	6.73	4.96	2.03] | 
| 05-02 01:25:21 epoch: 1638| time: 1.1s| train loss: +1.690e+01 | test loss: +1.785e+01 | 
| 05-02 01:25:21 epoch: 1638| train loss i: [0.09	1.33	5.41	4.76	3.73	1.59] test loss i: [0.18	1.64	5.45	4.8 	3.86	1.92] | 
| 05-02 01:25:22 epoch: 1639| time: 1.1s| train loss: +1.613e+01 | test loss: +1.556e+01 | 
| 05-02 01:25:22 epoch: 1639| train loss i: [0.15	1.07	5.02	4.78	3.57	1.52] test loss i: [0.08	0.52	4.42	5.57	3.4 	1.57] | 
| 05-02 01:25:23 epoch: 1640| time: 1.1s| train loss: +1.700e+01 | test loss: +2.199e+01 | 
| 05-02 01:25:23 epoch: 1640| train loss i: [0.07	1.13	5.24	5.2 	3.79	1.56] test loss i: [0.28	3.1 	7.02	5.73	3.76	2.09] | 
| 05-02 01:25:24 epoch: 1641| time: 1.1s| train loss: +1.778e+01 | test loss: +2.003e+01 | 
| 05-02 01:25:24 epoch: 1641| train loss i: [0.08	1.63	5.91	4.73	3.85	1.58] test loss i: [0.24	3.36	5.58	4.98	4.29	1.58] | 
| 05-02 01:25:25 epoch: 1642| time: 1.1s| train loss: +1.675e+01 | test loss: +1.860e+01 | 
| 05-02 01:25:25 epoch: 1642| train loss i: [0.12	1.07	5.32	4.77	3.89	1.58] test loss i: [0.2 	2.78	6.29	4.45	3.27	1.61] | 
| 05-02 01:25:26 epoch: 1643| time: 1.0s| train loss: +1.694e+01 | test loss: +1.881e+01 | 
| 05-02 01:25:26 epoch: 1643| train loss i: [0.07	1.41	5.43	4.67	3.71	1.64] test loss i: [0.4 	1.25	5.99	5.95	3.73	1.49] | 
| 05-02 01:25:28 epoch: 1644| time: 1.1s| train loss: +1.851e+01 | test loss: +1.731e+01 | 
| 05-02 01:25:28 epoch: 1644| train loss i: [0.11	1.86	5.71	5.41	3.89	1.53] test loss i: [0.27	0.93	5.76	5.44	3.45	1.46] | 
| 05-02 01:25:29 epoch: 1645| time: 1.1s| train loss: +1.732e+01 | test loss: +2.269e+01 | 
| 05-02 01:25:29 epoch: 1645| train loss i: [0.08	1.48	5.55	4.65	3.99	1.57] test loss i: [0.11	1.99	7.03	6.86	4.72	1.98] | 
| 05-02 01:25:30 epoch: 1646| time: 1.1s| train loss: +1.814e+01 | test loss: +1.712e+01 | 
| 05-02 01:25:30 epoch: 1646| train loss i: [0.07	1.8 	6.13	4.88	3.73	1.53] test loss i: [0.04	1.88	5.36	5.17	2.93	1.74] | 
| 05-02 01:25:31 epoch: 1647| time: 1.1s| train loss: +1.750e+01 | test loss: +1.602e+01 | 
| 05-02 01:25:31 epoch: 1647| train loss i: [0.07	1.77	5.58	4.89	3.7 	1.49] test loss i: [0.08	0.7 	5.61	4.32	3.71	1.59] | 
| 05-02 01:25:32 epoch: 1648| time: 1.1s| train loss: +1.689e+01 | test loss: +2.297e+01 | 
| 05-02 01:25:32 epoch: 1648| train loss i: [0.09	1.45	4.92	4.84	3.94	1.64] test loss i: [0.07	2.31	7.77	5.97	4.76	2.1 ] | 
| 05-02 01:25:33 epoch: 1649| time: 1.1s| train loss: +1.720e+01 | test loss: +2.152e+01 | 
| 05-02 01:25:33 epoch: 1649| train loss i: [0.1 	1.45	5.53	4.68	3.85	1.59] test loss i: [0.14	1.38	6.86	6.71	4.45	1.98] | 
| 05-02 01:25:34 epoch: 1650| time: 1.0s| train loss: +1.648e+01 | test loss: +1.745e+01 | 
| 05-02 01:25:34 epoch: 1650| train loss i: [0.09	0.92	5.12	4.9 	3.89	1.54] test loss i: [0.11	1.23	5.06	4.96	4.26	1.82] | 
| 05-02 01:25:35 epoch: 1651| time: 1.1s| train loss: +1.771e+01 | test loss: +1.597e+01 | 
| 05-02 01:25:35 epoch: 1651| train loss i: [0.08	1.86	5.35	4.91	3.88	1.62] test loss i: [0.09	0.85	4.9 	4.69	3.89	1.55] | 
| 05-02 01:25:36 epoch: 1652| time: 1.1s| train loss: +1.726e+01 | test loss: +1.787e+01 | 
| 05-02 01:25:36 epoch: 1652| train loss i: [0.07	1.74	5.33	4.71	3.84	1.57] test loss i: [0.1 	0.23	7.26	5.08	3.45	1.74] | 
| 05-02 01:25:37 epoch: 1653| time: 1.1s| train loss: +1.714e+01 | test loss: +2.358e+01 | 
| 05-02 01:25:37 epoch: 1653| train loss i: [0.09	1.47	5.17	4.48	4.29	1.63] test loss i: [0.13	0.57	8.86	6.4 	5.81	1.81] | 
| 05-02 01:25:38 epoch: 1654| time: 1.1s| train loss: +1.684e+01 | test loss: +1.294e+01 | 
| 05-02 01:25:38 epoch: 1654| train loss i: [0.12	1.74	5.08	4.65	3.67	1.58] test loss i: [0.19	0.45	4.54	3.47	2.93	1.36] | 
| 05-02 01:25:39 epoch: 1655| time: 1.1s| train loss: +1.738e+01 | test loss: +1.489e+01 | 
| 05-02 01:25:39 epoch: 1655| train loss i: [0.09	1.4 	5.45	4.83	4.1 	1.52] test loss i: [0.07	1.08	4.53	4.16	3.6 	1.45] | 
| 05-02 01:25:40 epoch: 1656| time: 1.1s| train loss: +1.637e+01 | test loss: +2.599e+01 | 
| 05-02 01:25:40 epoch: 1656| train loss i: [0.09	0.67	4.99	4.94	4.11	1.55] test loss i: [0.13	3.11	7.86	7.35	5.47	2.07] | 
| 05-02 01:25:42 epoch: 1657| time: 1.0s| train loss: +1.745e+01 | test loss: +1.490e+01 | 
| 05-02 01:25:42 epoch: 1657| train loss i: [0.09	1.55	5.4 	4.92	4.01	1.48] test loss i: [0.13	0.98	4.78	4.23	3.52	1.26] | 
| 05-02 01:25:43 epoch: 1658| time: 1.1s| train loss: +1.791e+01 | test loss: +1.871e+01 | 
| 05-02 01:25:43 epoch: 1658| train loss i: [0.13	1.55	6.05	4.88	3.72	1.58] test loss i: [0.25	2.9 	4.83	4.66	4.46	1.6 ] | 
| 05-02 01:25:44 epoch: 1659| time: 1.1s| train loss: +1.674e+01 | test loss: +2.340e+01 | 
| 05-02 01:25:44 epoch: 1659| train loss i: [0.1 	1.26	5.23	4.71	3.87	1.57] test loss i: [0.39	0.29	7.48	7.89	4.87	2.48] | 
| 05-02 01:25:45 epoch: 1660| time: 1.1s| train loss: +1.741e+01 | test loss: +2.368e+01 | 
| 05-02 01:25:45 epoch: 1660| train loss i: [0.08	1.82	5.29	4.59	4.02	1.61] test loss i: [0.18	2.66	6.23	7.58	5.04	1.99] | 
| 05-02 01:25:46 epoch: 1661| time: 1.1s| train loss: +1.707e+01 | test loss: +2.152e+01 | 
| 05-02 01:25:46 epoch: 1661| train loss i: [0.12	1.07	5.63	4.87	3.88	1.5 ] test loss i: [0.4 	2.83	6.78	5.44	4.27	1.8 ] | 
| 05-02 01:25:47 epoch: 1662| time: 1.1s| train loss: +1.766e+01 | test loss: +2.444e+01 | 
| 05-02 01:25:47 epoch: 1662| train loss i: [0.16	0.91	6.19	4.86	3.95	1.59] test loss i: [1.01	4.87	6.6 	5.29	4.55	2.11] | 
| 05-02 01:25:48 epoch: 1663| time: 1.0s| train loss: +1.701e+01 | test loss: +1.872e+01 | 
| 05-02 01:25:48 epoch: 1663| train loss i: [0.19	1.09	5.6 	4.95	3.64	1.53] test loss i: [0.65	1.06	5.78	5.3 	4.02	1.91] | 
| 05-02 01:25:49 epoch: 1664| time: 1.1s| train loss: +1.712e+01 | test loss: +2.071e+01 | 
| 05-02 01:25:49 epoch: 1664| train loss i: [0.18	1.35	5.34	4.72	4.06	1.47] test loss i: [0.34	1.98	6.65	4.87	4.91	1.97] | 
| 05-02 01:25:50 epoch: 1665| time: 1.1s| train loss: +1.687e+01 | test loss: +1.441e+01 | 
| 05-02 01:25:50 epoch: 1665| train loss i: [0.14	1.21	5.11	4.87	3.95	1.59] test loss i: [0.04	1.06	4.92	3.82	3.18	1.39] | 
| 05-02 01:25:51 epoch: 1666| time: 1.1s| train loss: +1.724e+01 | test loss: +1.781e+01 | 
| 05-02 01:25:51 epoch: 1666| train loss i: [0.09	1.71	5.4 	4.7 	3.75	1.58] test loss i: [0.13	2.  	6.16	4.77	3.4 	1.37] | 
| 05-02 01:25:52 epoch: 1667| time: 1.1s| train loss: +1.647e+01 | test loss: +1.453e+01 | 
| 05-02 01:25:52 epoch: 1667| train loss i: [0.1 	1.45	4.68	4.89	3.8 	1.55] test loss i: [0.1 	0.49	3.59	4.74	4.01	1.59] | 
| 05-02 01:25:53 epoch: 1668| time: 1.1s| train loss: +1.662e+01 | test loss: +2.088e+01 | 
| 05-02 01:25:53 epoch: 1668| train loss i: [0.1 	1.46	5.17	4.6 	3.74	1.55] test loss i: [0.15	2.53	6.05	5.47	4.56	2.11] | 
| 05-02 01:25:54 epoch: 1669| time: 1.0s| train loss: +1.779e+01 | test loss: +1.769e+01 | 
| 05-02 01:25:54 epoch: 1669| train loss i: [0.08	1.54	5.91	4.82	3.86	1.58] test loss i: [0.12	0.76	5.86	5.33	4.09	1.54] | 
| 05-02 01:25:55 epoch: 1670| time: 1.1s| train loss: +1.777e+01 | test loss: +1.792e+01 | 
| 05-02 01:25:55 epoch: 1670| train loss i: [0.11	1.31	5.58	5.23	3.98	1.56] test loss i: [0.1 	0.48	6.66	4.89	4.  	1.8 ] | 
| 05-02 01:25:57 epoch: 1671| time: 1.1s| train loss: +1.721e+01 | test loss: +1.752e+01 | 
| 05-02 01:25:57 epoch: 1671| train loss i: [0.09	1.32	5.52	4.53	4.14	1.61] test loss i: [0.05	2.26	6.08	3.98	3.43	1.72] | 
| 05-02 01:25:58 epoch: 1672| time: 1.1s| train loss: +1.673e+01 | test loss: +2.128e+01 | 
| 05-02 01:25:58 epoch: 1672| train loss i: [0.09	1.46	4.76	4.83	3.99	1.6 ] test loss i: [0.1 	1.14	6.27	6.06	5.72	1.99] | 
| 05-02 01:25:59 epoch: 1673| time: 1.1s| train loss: +1.708e+01 | test loss: +2.161e+01 | 
| 05-02 01:25:59 epoch: 1673| train loss i: [0.13	1.29	5.22	4.83	4.03	1.59] test loss i: [0.23	4.97	5.64	4.62	4.41	1.74] | 
| 05-02 01:26:00 epoch: 1674| time: 1.1s| train loss: +1.608e+01 | test loss: +1.865e+01 | 
| 05-02 01:26:00 epoch: 1674| train loss i: [0.08	1.07	4.86	4.94	3.57	1.56] test loss i: [0.16	1.29	5.47	5.42	4.53	1.78] | 
| 05-02 01:26:01 epoch: 1675| time: 1.1s| train loss: +1.749e+01 | test loss: +1.822e+01 | 
| 05-02 01:26:01 epoch: 1675| train loss i: [0.09	1.32	5.27	5.21	3.98	1.63] test loss i: [0.07	1.44	6.13	5.01	3.54	2.03] | 
| 05-02 01:26:02 epoch: 1676| time: 1.1s| train loss: +1.699e+01 | test loss: +1.686e+01 | 
| 05-02 01:26:02 epoch: 1676| train loss i: [0.09	1.62	5.23	4.75	3.79	1.51] test loss i: [0.35	0.66	5.87	4.67	3.69	1.61] | 
| 05-02 01:26:03 epoch: 1677| time: 1.1s| train loss: +1.737e+01 | test loss: +1.693e+01 | 
| 05-02 01:26:03 epoch: 1677| train loss i: [0.14	1.62	5.39	4.76	3.95	1.51] test loss i: [0.1 	0.8 	4.99	4.99	4.47	1.59] | 
| 05-02 01:26:04 epoch: 1678| time: 1.1s| train loss: +1.637e+01 | test loss: +1.793e+01 | 
| 05-02 01:26:04 epoch: 1678| train loss i: [0.11	1.6 	4.8 	4.48	3.86	1.52] test loss i: [0.07	1.65	6.18	4.38	3.79	1.86] | 
| 05-02 01:26:05 epoch: 1679| time: 1.1s| train loss: +1.708e+01 | test loss: +1.622e+01 | 
| 05-02 01:26:05 epoch: 1679| train loss i: [0.13	1.51	5.09	4.78	3.95	1.62] test loss i: [0.1 	0.76	5.46	4.5 	3.95	1.45] | 
| 05-02 01:26:06 epoch: 1680| time: 1.1s| train loss: +1.687e+01 | test loss: +2.501e+01 | 
| 05-02 01:26:06 epoch: 1680| train loss i: [0.08	0.95	5.38	5.17	3.73	1.56] test loss i: [0.15	1.38	9.57	6.23	5.42	2.26] | 
| 05-02 01:26:07 epoch: 1681| time: 1.1s| train loss: +1.682e+01 | test loss: +1.747e+01 | 
| 05-02 01:26:07 epoch: 1681| train loss i: [0.14	1.25	5.24	4.9 	3.74	1.56] test loss i: [0.07	0.6 	6.28	4.72	4.19	1.6 ] | 
| 05-02 01:26:08 epoch: 1682| time: 1.0s| train loss: +1.758e+01 | test loss: +2.166e+01 | 
| 05-02 01:26:08 epoch: 1682| train loss i: [0.14	1.84	5.81	4.71	3.58	1.5 ] test loss i: [0.16	2.51	7.69	4.94	4.4 	1.97] | 
| 05-02 01:26:09 epoch: 1683| time: 1.1s| train loss: +1.710e+01 | test loss: +1.556e+01 | 
| 05-02 01:26:09 epoch: 1683| train loss i: [0.09	1.14	5.61	4.72	3.97	1.56] test loss i: [0.1 	0.7 	4.47	4.79	3.9 	1.59] | 
| 05-02 01:26:10 epoch: 1684| time: 1.1s| train loss: +1.668e+01 | test loss: +2.255e+01 | 
| 05-02 01:26:10 epoch: 1684| train loss i: [0.12	0.95	5.27	4.9 	3.94	1.51] test loss i: [0.2 	2.64	6.55	6.54	4.46	2.16] | 
| 05-02 01:26:12 epoch: 1685| time: 1.1s| train loss: +1.750e+01 | test loss: +1.601e+01 | 
| 05-02 01:26:12 epoch: 1685| train loss i: [0.14	1.51	5.61	4.56	4.02	1.67] test loss i: [0.41	0.65	4.38	4.86	3.95	1.75] | 
| 05-02 01:26:13 epoch: 1686| time: 1.1s| train loss: +1.778e+01 | test loss: +1.464e+01 | 
| 05-02 01:26:13 epoch: 1686| train loss i: [0.17	1.42	6.  	4.86	3.85	1.49] test loss i: [0.06	0.54	5.11	3.8 	3.44	1.7 ] | 
| 05-02 01:26:14 epoch: 1687| time: 1.1s| train loss: +1.709e+01 | test loss: +2.130e+01 | 
| 05-02 01:26:14 epoch: 1687| train loss i: [0.11	1.54	4.91	4.94	4.  	1.59] test loss i: [0.18	2.36	5.97	6.02	4.85	1.93] | 
| 05-02 01:26:15 epoch: 1688| time: 1.1s| train loss: +1.669e+01 | test loss: +1.812e+01 | 
| 05-02 01:26:15 epoch: 1688| train loss i: [0.13	1.2 	4.94	5.23	3.58	1.6 ] test loss i: [0.36	0.84	4.72	5.84	4.41	1.95] | 
| 05-02 01:26:16 epoch: 1689| time: 1.1s| train loss: +1.724e+01 | test loss: +1.875e+01 | 
| 05-02 01:26:16 epoch: 1689| train loss i: [0.08	1.42	5.71	4.65	3.87	1.51] test loss i: [0.11	1.27	5.39	5.53	4.51	1.95] | 
| 05-02 01:26:17 epoch: 1690| time: 1.1s| train loss: +1.773e+01 | test loss: +2.116e+01 | 
| 05-02 01:26:17 epoch: 1690| train loss i: [0.09	1.99	5.4 	4.76	3.93	1.56] test loss i: [0.08	1.98	6.77	6.16	4.1 	2.06] | 
| 05-02 01:26:18 epoch: 1691| time: 1.1s| train loss: +1.737e+01 | test loss: +1.455e+01 | 
| 05-02 01:26:18 epoch: 1691| train loss i: [0.13	1.7 	5.56	4.6 	3.71	1.67] test loss i: [0.05	0.41	4.21	4.23	3.8 	1.85] | 
| 05-02 01:26:19 epoch: 1692| time: 1.1s| train loss: +1.730e+01 | test loss: +1.658e+01 | 
| 05-02 01:26:19 epoch: 1692| train loss i: [0.11	1.67	5.44	4.73	3.86	1.49] test loss i: [0.18	2.  	4.62	4.42	3.9 	1.46] | 
| 05-02 01:26:20 epoch: 1693| time: 1.1s| train loss: +1.716e+01 | test loss: +1.718e+01 | 
| 05-02 01:26:20 epoch: 1693| train loss i: [0.11	1.87	5.26	4.53	3.84	1.54] test loss i: [0.09	0.77	5.73	4.36	4.  	2.24] | 
| 05-02 01:26:21 epoch: 1694| time: 1.1s| train loss: +1.765e+01 | test loss: +1.892e+01 | 
| 05-02 01:26:21 epoch: 1694| train loss i: [0.1 	1.11	6.1 	4.74	3.97	1.64] test loss i: [0.17	0.38	6.67	5.82	3.97	1.91] | 
| 05-02 01:26:22 epoch: 1695| time: 1.1s| train loss: +1.640e+01 | test loss: +2.210e+01 | 
| 05-02 01:26:22 epoch: 1695| train loss i: [0.07	0.94	4.98	4.87	3.91	1.62] test loss i: [0.07	2.75	5.77	5.8 	5.56	2.14] | 
| 05-02 01:26:23 epoch: 1696| time: 1.0s| train loss: +1.687e+01 | test loss: +1.785e+01 | 
| 05-02 01:26:23 epoch: 1696| train loss i: [0.07	0.97	5.5 	4.95	3.82	1.56] test loss i: [0.1 	2.06	4.59	5.41	3.91	1.78] | 
| 05-02 01:26:25 epoch: 1697| time: 1.1s| train loss: +1.684e+01 | test loss: +1.966e+01 | 
| 05-02 01:26:25 epoch: 1697| train loss i: [0.09	0.86	5.77	4.73	3.76	1.64] test loss i: [0.06	1.32	6.44	5.04	4.75	2.05] | 
| 05-02 01:26:26 epoch: 1698| time: 1.1s| train loss: +1.702e+01 | test loss: +1.872e+01 | 
| 05-02 01:26:26 epoch: 1698| train loss i: [0.09	1.85	5.01	4.78	3.73	1.55] test loss i: [0.14	1.41	5.82	4.82	4.55	1.97] | 
| 05-02 01:26:27 epoch: 1699| time: 1.1s| train loss: +1.838e+01 | test loss: +2.384e+01 | 
| 05-02 01:26:27 epoch: 1699| train loss i: [0.12	2.29	6.03	4.56	3.84	1.55] test loss i: [0.31	0.57	9.06	6.47	5.44	1.99] | 
| 05-02 01:26:28 epoch: 1700| time: 1.1s| train loss: +1.751e+01 | test loss: +1.490e+01 | 
| 05-02 01:26:28 epoch: 1700| train loss i: [0.09	1.28	5.5 	5.18	3.9 	1.56] test loss i: [0.06	1.88	4.17	3.7 	3.63	1.48] | 
| 05-02 01:26:29 epoch: 1701| time: 1.1s| train loss: +1.739e+01 | test loss: +1.902e+01 | 
| 05-02 01:26:29 epoch: 1701| train loss i: [0.07	2.13	5.07	4.64	3.91	1.57] test loss i: [0.13	1.14	6.65	5.45	4.08	1.57] | 
| 05-02 01:26:30 epoch: 1702| time: 1.1s| train loss: +1.675e+01 | test loss: +1.946e+01 | 
| 05-02 01:26:30 epoch: 1702| train loss i: [0.1 	0.86	5.69	4.71	3.79	1.6 ] test loss i: [0.35	1.32	5.19	6.93	3.94	1.72] | 
| 05-02 01:26:31 epoch: 1703| time: 1.1s| train loss: +1.694e+01 | test loss: +2.163e+01 | 
| 05-02 01:26:31 epoch: 1703| train loss i: [0.1 	1.78	5.21	4.7 	3.76	1.4 ] test loss i: [0.21	1.74	6.34	6.41	5.12	1.82] | 
| 05-02 01:26:32 epoch: 1704| time: 1.1s| train loss: +1.720e+01 | test loss: +1.936e+01 | 
| 05-02 01:26:32 epoch: 1704| train loss i: [0.09	1.4 	5.47	4.86	3.74	1.63] test loss i: [0.59	0.68	6.6 	5.72	3.89	1.88] | 
| 05-02 01:26:33 epoch: 1705| time: 1.1s| train loss: +1.677e+01 | test loss: +1.521e+01 | 
| 05-02 01:26:33 epoch: 1705| train loss i: [0.1 	0.97	5.75	4.37	4.03	1.54] test loss i: [0.25	1.36	4.5 	4.11	3.61	1.38] | 
| 05-02 01:26:34 epoch: 1706| time: 1.0s| train loss: +1.731e+01 | test loss: +1.799e+01 | 
| 05-02 01:26:34 epoch: 1706| train loss i: [0.13	1.84	5.33	4.8 	3.74	1.47] test loss i: [0.21	0.56	6.54	4.57	4.45	1.67] | 
| 05-02 01:26:35 epoch: 1707| time: 1.1s| train loss: +1.687e+01 | test loss: +1.611e+01 | 
| 05-02 01:26:35 epoch: 1707| train loss i: [0.11	1.23	5.18	5.26	3.55	1.54] test loss i: [0.4 	2.2 	4.3 	4.04	3.7 	1.48] | 
| 05-02 01:26:36 epoch: 1708| time: 1.1s| train loss: +1.709e+01 | test loss: +1.632e+01 | 
| 05-02 01:26:36 epoch: 1708| train loss i: [0.12	1.55	4.9 	4.84	4.11	1.57] test loss i: [0.15	1.08	4.49	5.4 	3.7 	1.5 ] | 
| 05-02 01:26:37 epoch: 1709| time: 1.1s| train loss: +1.713e+01 | test loss: +2.440e+01 | 
| 05-02 01:26:37 epoch: 1709| train loss i: [0.08	1.35	5.59	4.68	3.85	1.57] test loss i: [0.09	3.03	7.08	6.83	5.02	2.35] | 
| 05-02 01:26:39 epoch: 1710| time: 1.1s| train loss: +1.675e+01 | test loss: +1.791e+01 | 
| 05-02 01:26:39 epoch: 1710| train loss i: [0.07	0.84	5.44	4.97	3.85	1.57] test loss i: [0.1 	1.39	6.28	4.73	3.8 	1.6 ] | 
| 05-02 01:26:40 epoch: 1711| time: 1.1s| train loss: +1.802e+01 | test loss: +2.063e+01 | 
| 05-02 01:26:40 epoch: 1711| train loss i: [0.06	2.04	5.52	4.95	3.85	1.59] test loss i: [0.28	0.61	4.89	7.47	5.4 	1.98] | 
| 05-02 01:26:41 epoch: 1712| time: 1.1s| train loss: +1.732e+01 | test loss: +1.694e+01 | 
| 05-02 01:26:41 epoch: 1712| train loss i: [0.11	1.57	5.3 	5.08	3.72	1.55] test loss i: [0.19	0.36	5.32	5.52	4.  	1.55] | 
| 05-02 01:26:42 epoch: 1713| time: 1.1s| train loss: +1.681e+01 | test loss: +1.740e+01 | 
| 05-02 01:26:42 epoch: 1713| train loss i: [0.08	1.34	5.44	4.74	3.69	1.52] test loss i: [0.05	1.51	4.62	6.2 	3.39	1.64] | 
| 05-02 01:26:43 epoch: 1714| time: 1.1s| train loss: +1.687e+01 | test loss: +1.737e+01 | 
| 05-02 01:26:43 epoch: 1714| train loss i: [0.07	1.14	5.74	4.91	3.56	1.45] test loss i: [0.16	0.78	5.23	5.86	3.84	1.51] | 
| 05-02 01:26:44 epoch: 1715| time: 1.1s| train loss: +1.744e+01 | test loss: +1.661e+01 | 
| 05-02 01:26:44 epoch: 1715| train loss i: [0.09	1.26	5.73	5.01	3.8 	1.56] test loss i: [0.07	1.06	5.57	4.79	3.49	1.63] | 
| 05-02 01:26:45 epoch: 1716| time: 1.1s| train loss: +1.755e+01 | test loss: +1.566e+01 | 
| 05-02 01:26:45 epoch: 1716| train loss i: [0.09	1.88	5.43	4.82	3.78	1.54] test loss i: [0.11	0.46	5.2 	4.39	3.74	1.77] | 
| 05-02 01:26:46 epoch: 1717| time: 1.1s| train loss: +1.694e+01 | test loss: +2.047e+01 | 
| 05-02 01:26:46 epoch: 1717| train loss i: [0.07	1.36	5.37	4.8 	3.84	1.51] test loss i: [0.07	1.44	8.23	4.71	4.27	1.75] | 
| 05-02 01:26:47 epoch: 1718| time: 1.1s| train loss: +1.623e+01 | test loss: +2.164e+01 | 
| 05-02 01:26:47 epoch: 1718| train loss i: [0.1 	0.95	5.51	4.41	3.66	1.61] test loss i: [0.07	1.25	7.12	6.12	4.97	2.13] | 
| 05-02 01:26:48 epoch: 1719| time: 1.1s| train loss: +1.582e+01 | test loss: +1.787e+01 | 
| 05-02 01:26:48 epoch: 1719| train loss i: [0.08	1.13	4.95	4.5 	3.65	1.51] test loss i: [0.1 	1.08	6.44	5.36	3.3 	1.59] | 
| 05-02 01:26:49 epoch: 1720| time: 1.1s| train loss: +1.701e+01 | test loss: +2.162e+01 | 
| 05-02 01:26:49 epoch: 1720| train loss i: [0.11	1.56	5.04	4.68	4.03	1.59] test loss i: [0.1 	0.89	6.24	6.77	5.51	2.12] | 
| 05-02 01:26:51 epoch: 1721| time: 1.1s| train loss: +1.712e+01 | test loss: +1.972e+01 | 
| 05-02 01:26:51 epoch: 1721| train loss i: [0.08	0.99	6.23	4.43	3.78	1.62] test loss i: [0.28	1.11	6.96	5.37	4.18	1.83] | 
| 05-02 01:26:52 epoch: 1722| time: 1.0s| train loss: +1.574e+01 | test loss: +2.267e+01 | 
| 05-02 01:26:52 epoch: 1722| train loss i: [0.11	1.05	5.  	4.46	3.58	1.54] test loss i: [0.34	1.07	9.24	6.57	3.77	1.68] | 
| 05-02 01:26:53 epoch: 1723| time: 1.1s| train loss: +1.718e+01 | test loss: +1.695e+01 | 
| 05-02 01:26:53 epoch: 1723| train loss i: [0.11	1.26	5.3 	5.06	3.97	1.48] test loss i: [0.32	1.8 	4.88	4.61	3.81	1.53] | 
| 05-02 01:26:54 epoch: 1724| time: 1.1s| train loss: +1.705e+01 | test loss: +1.597e+01 | 
| 05-02 01:26:54 epoch: 1724| train loss i: [0.1 	1.72	5.33	4.61	3.78	1.51] test loss i: [0.09	0.67	5.72	3.68	4.05	1.77] | 
| 05-02 01:26:55 epoch: 1725| time: 1.1s| train loss: +1.652e+01 | test loss: +2.197e+01 | 
| 05-02 01:26:55 epoch: 1725| train loss i: [0.08	1.38	5.36	4.46	3.72	1.53] test loss i: [0.13	1.96	6.7 	6.28	4.99	1.91] | 
| 05-02 01:26:56 epoch: 1726| time: 1.1s| train loss: +1.574e+01 | test loss: +1.852e+01 | 
| 05-02 01:26:56 epoch: 1726| train loss i: [0.11	0.65	4.89	4.87	3.67	1.55] test loss i: [0.09	1.45	6.26	4.96	3.93	1.83] | 
| 05-02 01:26:57 epoch: 1727| time: 1.1s| train loss: +1.671e+01 | test loss: +2.385e+01 | 
| 05-02 01:26:57 epoch: 1727| train loss i: [0.16	1.44	5.  	4.64	3.97	1.49] test loss i: [0.38	0.84	8.29	6.44	5.61	2.29] | 
| 05-02 01:26:58 epoch: 1728| time: 1.1s| train loss: +1.800e+01 | test loss: +1.797e+01 | 
| 05-02 01:26:58 epoch: 1728| train loss i: [0.09	1.32	6.42	4.76	3.83	1.57] test loss i: [0.14	2.  	5.08	5.29	3.77	1.7 ] | 
| 05-02 01:26:59 epoch: 1729| time: 1.0s| train loss: +1.653e+01 | test loss: +1.695e+01 | 
| 05-02 01:26:59 epoch: 1729| train loss i: [0.11	1.09	5.22	4.88	3.7 	1.54] test loss i: [0.21	0.37	5.65	6.09	3.04	1.59] | 
| 05-02 01:27:00 epoch: 1730| time: 1.1s| train loss: +1.631e+01 | test loss: +1.978e+01 | 
| 05-02 01:27:00 epoch: 1730| train loss i: [0.09	1.12	5.15	4.59	3.83	1.54] test loss i: [0.37	2.  	6.17	5.74	3.71	1.78] | 
| 05-02 01:27:01 epoch: 1731| time: 1.1s| train loss: +1.635e+01 | test loss: +2.350e+01 | 
| 05-02 01:27:01 epoch: 1731| train loss i: [0.07	0.91	5.2 	4.88	3.77	1.53] test loss i: [0.12	2.39	7.86	6.09	4.94	2.08] | 
| 05-02 01:27:02 epoch: 1732| time: 1.1s| train loss: +1.635e+01 | test loss: +1.635e+01 | 
| 05-02 01:27:02 epoch: 1732| train loss i: [0.06	1.24	5.39	4.41	3.7 	1.56] test loss i: [0.06	0.71	5.44	4.9 	3.33	1.91] | 
| 05-02 01:27:03 epoch: 1733| time: 1.1s| train loss: +1.724e+01 | test loss: +1.986e+01 | 
| 05-02 01:27:03 epoch: 1733| train loss i: [0.08	1.72	5.81	4.53	3.47	1.64] test loss i: [0.2 	2.15	5.9 	5.76	3.69	2.16] | 
| 05-02 01:27:05 epoch: 1734| time: 1.1s| train loss: +1.646e+01 | test loss: +1.624e+01 | 
| 05-02 01:27:05 epoch: 1734| train loss i: [0.07	0.92	5.29	4.98	3.68	1.51] test loss i: [0.04	1.32	5.37	4.28	3.63	1.6 ] | 
| 05-02 01:27:06 epoch: 1735| time: 1.1s| train loss: +1.678e+01 | test loss: +2.357e+01 | 
| 05-02 01:27:06 epoch: 1735| train loss i: [0.09	0.89	5.25	5.05	3.86	1.64] test loss i: [0.26	2.62	7.54	6.31	4.79	2.06] | 
| 05-02 01:27:07 epoch: 1736| time: 1.1s| train loss: +1.593e+01 | test loss: +1.770e+01 | 
| 05-02 01:27:07 epoch: 1736| train loss i: [0.08	0.93	4.91	4.74	3.75	1.53] test loss i: [0.05	0.66	5.88	4.96	4.5 	1.65] | 
| 05-02 01:27:08 epoch: 1737| time: 1.1s| train loss: +1.729e+01 | test loss: +1.816e+01 | 
| 05-02 01:27:08 epoch: 1737| train loss i: [0.06	0.67	5.76	5.06	4.22	1.51] test loss i: [0.14	1.33	6.9 	4.88	3.42	1.49] | 
| 05-02 01:27:09 epoch: 1738| time: 1.1s| train loss: +1.553e+01 | test loss: +1.622e+01 | 
| 05-02 01:27:09 epoch: 1738| train loss i: [0.09	0.77	4.99	4.77	3.39	1.53] test loss i: [0.13	1.22	5.51	4.49	3.37	1.49] | 
| 05-02 01:27:10 epoch: 1739| time: 1.1s| train loss: +1.666e+01 | test loss: +1.609e+01 | 
| 05-02 01:27:10 epoch: 1739| train loss i: [0.05	1.15	5.4 	4.78	3.7 	1.59] test loss i: [0.11	0.24	5.94	4.72	3.41	1.67] | 
| 05-02 01:27:11 epoch: 1740| time: 1.1s| train loss: +1.672e+01 | test loss: +1.646e+01 | 
| 05-02 01:27:11 epoch: 1740| train loss i: [0.08	0.97	5.39	4.88	3.89	1.51] test loss i: [0.07	1.47	5.43	4.09	3.68	1.72] | 
| 05-02 01:27:12 epoch: 1741| time: 1.1s| train loss: +1.709e+01 | test loss: +1.722e+01 | 
| 05-02 01:27:12 epoch: 1741| train loss i: [0.07	1.87	5.34	4.74	3.54	1.53] test loss i: [0.11	1.17	4.87	5.39	4.17	1.51] | 
| 05-02 01:27:13 epoch: 1742| time: 1.1s| train loss: +1.719e+01 | test loss: +1.933e+01 | 
| 05-02 01:27:13 epoch: 1742| train loss i: [0.1 	1.19	5.16	5.36	3.86	1.52] test loss i: [0.15	2.19	5.79	5.34	4.08	1.77] | 
| 05-02 01:27:14 epoch: 1743| time: 1.1s| train loss: +1.715e+01 | test loss: +2.038e+01 | 
| 05-02 01:27:14 epoch: 1743| train loss i: [0.08	1.33	5.56	4.82	3.8 	1.57] test loss i: [0.63	1.65	6.3 	5.51	4.21	2.1 ] | 
| 05-02 01:27:15 epoch: 1744| time: 1.1s| train loss: +1.713e+01 | test loss: +1.563e+01 | 
| 05-02 01:27:15 epoch: 1744| train loss i: [0.12	1.67	5.25	4.83	3.73	1.54] test loss i: [0.06	1.06	4.56	4.52	3.91	1.53] | 
| 05-02 01:27:16 epoch: 1745| time: 1.1s| train loss: +1.753e+01 | test loss: +2.566e+01 | 
| 05-02 01:27:16 epoch: 1745| train loss i: [0.08	1.11	5.81	5.05	3.94	1.54] test loss i: [0.09	1.14	8.39	8.46	5.51	2.06] | 
| 05-02 01:27:17 epoch: 1746| time: 1.1s| train loss: +1.764e+01 | test loss: +1.904e+01 | 
| 05-02 01:27:17 epoch: 1746| train loss i: [0.08	1.1 	6.07	4.96	3.88	1.55] test loss i: [0.12	1.73	5.68	5.37	4.32	1.82] | 
| 05-02 01:27:19 epoch: 1747| time: 1.1s| train loss: +1.736e+01 | test loss: +1.726e+01 | 
| 05-02 01:27:19 epoch: 1747| train loss i: [0.05	0.76	6.19	5.03	3.69	1.64] test loss i: [0.03	2.09	6.07	4.31	3.11	1.65] | 
| 05-02 01:27:20 epoch: 1748| time: 1.1s| train loss: +1.720e+01 | test loss: +1.501e+01 | 
| 05-02 01:27:20 epoch: 1748| train loss i: [0.07	1.53	5.11	5.02	3.86	1.62] test loss i: [0.07	0.42	5.35	4.36	3.33	1.47] | 
| 05-02 01:27:21 epoch: 1749| time: 1.1s| train loss: +1.815e+01 | test loss: +1.485e+01 | 
| 05-02 01:27:21 epoch: 1749| train loss i: [0.07	1.54	6.  	5.09	3.92	1.53] test loss i: [0.03	1.52	3.58	4.65	3.52	1.55] | 
| 05-02 01:27:22 epoch: 1750| time: 1.1s| train loss: +1.847e+01 | test loss: +1.740e+01 | 
| 05-02 01:27:22 epoch: 1750| train loss i: [0.09	1.73	6.22	5.07	3.8 	1.56] test loss i: [0.08	1.35	6.21	4.5 	3.58	1.69] | 
| 05-02 01:27:23 epoch: 1751| time: 1.0s| train loss: +1.727e+01 | test loss: +1.666e+01 | 
| 05-02 01:27:23 epoch: 1751| train loss i: [0.11	0.65	5.94	5.24	3.74	1.59] test loss i: [0.18	0.72	5.02	5.4 	3.56	1.78] | 
| 05-02 01:27:24 epoch: 1752| time: 1.1s| train loss: +1.704e+01 | test loss: +1.665e+01 | 
| 05-02 01:27:24 epoch: 1752| train loss i: [0.15	1.27	5.19	4.99	3.9 	1.56] test loss i: [0.08	0.52	5.94	4.69	3.88	1.53] | 
| 05-02 01:27:25 epoch: 1753| time: 1.1s| train loss: +1.722e+01 | test loss: +1.971e+01 | 
| 05-02 01:27:25 epoch: 1753| train loss i: [0.09	1.28	5.37	5.01	3.88	1.59] test loss i: [0.22	3.24	5.82	5.15	3.69	1.6 ] | 
| 05-02 01:27:26 epoch: 1754| time: 1.1s| train loss: +1.632e+01 | test loss: +1.484e+01 | 
| 05-02 01:27:26 epoch: 1754| train loss i: [0.13	0.84	5.09	4.84	3.84	1.58] test loss i: [0.06	0.52	4.68	4.49	3.57	1.52] | 
| 05-02 01:27:27 epoch: 1755| time: 1.1s| train loss: +1.699e+01 | test loss: +2.356e+01 | 
| 05-02 01:27:27 epoch: 1755| train loss i: [0.13	1.06	5.16	4.93	4.08	1.63] test loss i: [0.07	2.42	8.02	6.06	4.87	2.12] | 
| 05-02 01:27:28 epoch: 1756| time: 1.1s| train loss: +1.741e+01 | test loss: +1.823e+01 | 
| 05-02 01:27:28 epoch: 1756| train loss i: [0.08	1.49	5.48	4.99	3.71	1.65] test loss i: [0.19	2.58	4.69	5.64	3.58	1.55] | 
| 05-02 01:27:29 epoch: 1757| time: 1.1s| train loss: +1.801e+01 | test loss: +1.706e+01 | 
| 05-02 01:27:29 epoch: 1757| train loss i: [0.09	1.71	5.96	4.91	3.84	1.51] test loss i: [0.45	0.88	5.71	5.25	3.15	1.62] | 
| 05-02 01:27:30 epoch: 1758| time: 1.1s| train loss: +1.677e+01 | test loss: +1.509e+01 | 
| 05-02 01:27:30 epoch: 1758| train loss i: [0.11	1.05	5.19	4.79	4.09	1.53] test loss i: [0.19	1.45	5.1 	3.87	3.09	1.41] | 
| 05-02 01:27:31 epoch: 1759| time: 1.1s| train loss: +1.791e+01 | test loss: +1.394e+01 | 
| 05-02 01:27:31 epoch: 1759| train loss i: [0.11	1.77	5.36	5.4 	3.79	1.48] test loss i: [0.48	1.  	4.23	3.81	2.97	1.45] | 
| 05-02 01:27:33 epoch: 1760| time: 1.1s| train loss: +1.731e+01 | test loss: +1.517e+01 | 
| 05-02 01:27:33 epoch: 1760| train loss i: [0.11	1.37	5.28	5.18	3.82	1.56] test loss i: [0.26	1.27	5.13	3.73	3.25	1.54] | 
| 05-02 01:27:34 epoch: 1761| time: 1.1s| train loss: +1.723e+01 | test loss: +1.955e+01 | 
| 05-02 01:27:34 epoch: 1761| train loss i: [0.07	1.59	5.59	4.54	3.84	1.6 ] test loss i: [0.13	1.78	6.03	5.85	4.06	1.69] | 
| 05-02 01:27:35 epoch: 1762| time: 1.1s| train loss: +1.668e+01 | test loss: +1.650e+01 | 
| 05-02 01:27:35 epoch: 1762| train loss i: [0.05	1.09	5.27	4.89	3.87	1.52] test loss i: [0.14	0.58	5.54	4.68	3.48	2.09] | 
| 05-02 01:27:36 epoch: 1763| time: 1.1s| train loss: +1.655e+01 | test loss: +1.556e+01 | 
| 05-02 01:27:36 epoch: 1763| train loss i: [0.06	1.05	5.5 	4.57	3.85	1.52] test loss i: [0.08	1.13	4.85	4.71	3.4 	1.38] | 
| 05-02 01:27:37 epoch: 1764| time: 1.0s| train loss: +1.719e+01 | test loss: +1.851e+01 | 
| 05-02 01:27:37 epoch: 1764| train loss i: [0.06	1.3 	5.82	4.56	3.86	1.58] test loss i: [0.07	1.65	5.01	4.84	5.09	1.85] | 
| 05-02 01:27:38 epoch: 1765| time: 1.1s| train loss: +1.761e+01 | test loss: +1.880e+01 | 
| 05-02 01:27:38 epoch: 1765| train loss i: [0.08	1.19	5.65	5.17	3.96	1.57] test loss i: [0.29	0.35	6.42	5.74	3.79	2.22] | 
| 05-02 01:27:39 epoch: 1766| time: 1.1s| train loss: +1.775e+01 | test loss: +2.545e+01 | 
| 05-02 01:27:39 epoch: 1766| train loss i: [0.07	1.88	5.55	4.84	3.84	1.57] test loss i: [0.11	0.68	9.87	6.93	5.85	2.01] | 
| 05-02 01:27:40 epoch: 1767| time: 1.1s| train loss: +1.744e+01 | test loss: +1.594e+01 | 
| 05-02 01:27:40 epoch: 1767| train loss i: [0.07	1.56	5.17	5.09	4.  	1.55] test loss i: [0.06	2.04	4.22	4.32	3.72	1.58] | 
| 05-02 01:27:41 epoch: 1768| time: 1.1s| train loss: +1.683e+01 | test loss: +1.638e+01 | 
| 05-02 01:27:41 epoch: 1768| train loss i: [0.07	1.29	5.71	4.74	3.52	1.5 ] test loss i: [0.06	2.12	4.66	3.62	4.  	1.91] | 
| 05-02 01:27:42 epoch: 1769| time: 1.1s| train loss: +1.718e+01 | test loss: +1.724e+01 | 
| 05-02 01:27:42 epoch: 1769| train loss i: [0.1 	0.92	5.99	4.87	3.76	1.54] test loss i: [0.05	1.56	5.39	5.72	3.03	1.49] | 
| 05-02 01:27:43 epoch: 1770| time: 1.1s| train loss: +1.699e+01 | test loss: +1.464e+01 | 
| 05-02 01:27:43 epoch: 1770| train loss i: [0.11	1.5 	5.34	4.83	3.7 	1.51] test loss i: [0.27	0.28	4.18	4.21	4.3 	1.4 ] | 
| 05-02 01:27:44 epoch: 1771| time: 1.1s| train loss: +1.779e+01 | test loss: +1.464e+01 | 
| 05-02 01:27:44 epoch: 1771| train loss i: [0.14	1.84	5.82	5.02	3.43	1.55] test loss i: [0.16	1.37	4.35	4.13	3.19	1.45] | 
| 05-02 01:27:46 epoch: 1772| time: 1.1s| train loss: +1.712e+01 | test loss: +2.564e+01 | 
| 05-02 01:27:46 epoch: 1772| train loss i: [0.15	1.31	5.34	4.93	3.86	1.53] test loss i: [0.53	1.01	8.48	7.34	5.87	2.41] | 
| 05-02 01:27:47 epoch: 1773| time: 1.0s| train loss: +1.743e+01 | test loss: +2.158e+01 | 
| 05-02 01:27:47 epoch: 1773| train loss i: [0.12	2.36	5.12	4.53	3.75	1.56] test loss i: [0.42	0.82	6.25	5.82	5.97	2.3 ] | 
| 05-02 01:27:48 epoch: 1774| time: 1.1s| train loss: +1.730e+01 | test loss: +2.012e+01 | 
| 05-02 01:27:48 epoch: 1774| train loss i: [0.14	1.58	5.66	4.66	3.66	1.6 ] test loss i: [0.13	1.57	7.56	5.27	3.86	1.74] | 
| 05-02 01:27:49 epoch: 1775| time: 1.1s| train loss: +1.750e+01 | test loss: +1.425e+01 | 
| 05-02 01:27:49 epoch: 1775| train loss i: [0.12	1.7 	5.22	4.96	3.94	1.55] test loss i: [0.11	1.06	4.75	3.81	3.07	1.46] | 
| 05-02 01:27:50 epoch: 1776| time: 1.1s| train loss: +1.705e+01 | test loss: +1.421e+01 | 
| 05-02 01:27:50 epoch: 1776| train loss i: [0.11	1.86	5.25	4.61	3.62	1.59] test loss i: [0.09	0.91	4.44	3.9 	3.46	1.41] | 
| 05-02 01:27:51 epoch: 1777| time: 1.1s| train loss: +1.764e+01 | test loss: +1.696e+01 | 
| 05-02 01:27:51 epoch: 1777| train loss i: [0.12	1.45	5.73	4.97	3.85	1.52] test loss i: [0.08	2.29	4.24	4.29	4.3 	1.75] | 
| 05-02 01:27:52 epoch: 1778| time: 1.1s| train loss: +1.724e+01 | test loss: +1.669e+01 | 
| 05-02 01:27:52 epoch: 1778| train loss i: [0.08	1.54	5.5 	4.55	3.98	1.58] test loss i: [0.05	1.07	5.26	4.96	3.68	1.66] | 
| 05-02 01:27:53 epoch: 1779| time: 1.1s| train loss: +1.668e+01 | test loss: +2.351e+01 | 
| 05-02 01:27:53 epoch: 1779| train loss i: [0.07	0.84	5.62	4.65	4.02	1.48] test loss i: [0.05	1.81	7.11	5.89	6.42	2.23] | 
| 05-02 01:27:54 epoch: 1780| time: 1.1s| train loss: +1.702e+01 | test loss: +1.301e+01 | 
| 05-02 01:27:54 epoch: 1780| train loss i: [0.07	1.29	5.54	4.8 	3.75	1.57] test loss i: [0.03	0.07	4.18	3.73	3.54	1.45] | 
| 05-02 01:27:55 epoch: 1781| time: 1.1s| train loss: +1.684e+01 | test loss: +1.637e+01 | 
| 05-02 01:27:55 epoch: 1781| train loss i: [0.06	1.2 	5.6 	4.7 	3.79	1.5 ] test loss i: [0.06	1.18	4.7 	4.7 	4.11	1.62] | 
| 05-02 01:27:56 epoch: 1782| time: 1.1s| train loss: +1.699e+01 | test loss: +1.514e+01 | 
| 05-02 01:27:56 epoch: 1782| train loss i: [0.07	1.58	5.56	4.51	3.8 	1.47] test loss i: [0.05	1.09	4.99	4.37	3.22	1.43] | 
| 05-02 01:27:57 epoch: 1783| time: 1.1s| train loss: +1.755e+01 | test loss: +1.400e+01 | 
| 05-02 01:27:57 epoch: 1783| train loss i: [0.06	1.92	5.66	4.49	3.8 	1.63] test loss i: [0.04	0.98	3.57	4.25	3.43	1.74] | 
| 05-02 01:27:58 epoch: 1784| time: 1.1s| train loss: +1.739e+01 | test loss: +1.569e+01 | 
| 05-02 01:27:58 epoch: 1784| train loss i: [0.08	1.36	5.73	5.11	3.55	1.55] test loss i: [0.06	0.79	5.54	4.13	3.74	1.44] | 
| 05-02 01:27:59 epoch: 1785| time: 1.1s| train loss: +1.794e+01 | test loss: +1.732e+01 | 
| 05-02 01:27:59 epoch: 1785| train loss i: [0.07	2.1 	5.77	4.89	3.52	1.59] test loss i: [0.21	2.41	5.2 	4.2 	3.59	1.71] | 
| 05-02 01:28:01 epoch: 1786| time: 1.0s| train loss: +1.736e+01 | test loss: +1.830e+01 | 
| 05-02 01:28:01 epoch: 1786| train loss i: [0.1 	1.61	5.2 	5.02	3.87	1.57] test loss i: [0.05	2.32	4.68	5.42	4.16	1.68] | 
| 05-02 01:28:02 epoch: 1787| time: 1.1s| train loss: +1.781e+01 | test loss: +1.862e+01 | 
| 05-02 01:28:02 epoch: 1787| train loss i: [0.07	1.99	5.54	4.72	3.85	1.63] test loss i: [0.06	1.18	6.05	5.76	3.98	1.59] | 
| 05-02 01:28:03 epoch: 1788| time: 1.1s| train loss: +1.769e+01 | test loss: +2.248e+01 | 
| 05-02 01:28:03 epoch: 1788| train loss i: [0.05	1.73	5.59	4.86	3.93	1.54] test loss i: [0.14	3.48	7.88	5.  	4.5 	1.49] | 
| 05-02 01:28:04 epoch: 1789| time: 1.1s| train loss: +1.679e+01 | test loss: +1.366e+01 | 
| 05-02 01:28:04 epoch: 1789| train loss i: [0.05	1.19	5.19	4.99	3.81	1.56] test loss i: [0.09	0.14	4.18	4.39	3.2 	1.67] | 
| 05-02 01:28:05 epoch: 1790| time: 1.1s| train loss: +1.783e+01 | test loss: +1.936e+01 | 
| 05-02 01:28:05 epoch: 1790| train loss i: [0.07	1.27	6.11	4.94	3.83	1.61] test loss i: [0.05	2.15	6.64	4.96	3.88	1.69] | 
| 05-02 01:28:06 epoch: 1791| time: 1.0s| train loss: +1.636e+01 | test loss: +2.177e+01 | 
| 05-02 01:28:06 epoch: 1791| train loss i: [0.11	0.73	5.2 	4.98	3.8 	1.54] test loss i: [0.11	2.01	6.49	6.7 	4.5 	1.98] | 
| 05-02 01:28:07 epoch: 1792| time: 1.0s| train loss: +1.602e+01 | test loss: +1.835e+01 | 
| 05-02 01:28:07 epoch: 1792| train loss i: [0.11	1.04	4.98	4.5 	3.81	1.59] test loss i: [0.16	2.01	4.46	5.54	4.46	1.72] | 
| 05-02 01:28:08 epoch: 1793| time: 1.1s| train loss: +1.708e+01 | test loss: +1.721e+01 | 
| 05-02 01:28:08 epoch: 1793| train loss i: [0.09	1.54	5.55	4.53	3.79	1.58] test loss i: [0.07	1.94	5.93	4.21	3.47	1.59] | 
| 05-02 01:28:09 epoch: 1794| time: 1.1s| train loss: +1.610e+01 | test loss: +1.610e+01 | 
| 05-02 01:28:09 epoch: 1794| train loss i: [0.09	0.97	5.14	4.88	3.5 	1.52] test loss i: [0.16	0.79	4.91	5.44	3.08	1.72] | 
| 05-02 01:28:10 epoch: 1795| time: 1.1s| train loss: +1.682e+01 | test loss: +1.779e+01 | 
| 05-02 01:28:10 epoch: 1795| train loss i: [0.07	1.63	5.2 	4.67	3.68	1.56] test loss i: [0.08	2.55	5.51	4.75	3.43	1.48] | 
| 05-02 01:28:11 epoch: 1796| time: 1.1s| train loss: +1.573e+01 | test loss: +1.478e+01 | 
| 05-02 01:28:11 epoch: 1796| train loss i: [0.1 	1.13	4.7 	4.63	3.62	1.56] test loss i: [0.44	0.32	4.59	4.65	3.33	1.45] | 
| 05-02 01:28:12 epoch: 1797| time: 1.0s| train loss: +1.884e+01 | test loss: +1.948e+01 | 
| 05-02 01:28:12 epoch: 1797| train loss i: [0.11	2.32	6.15	4.67	4.04	1.55] test loss i: [0.08	1.9 	6.21	5.04	4.34	1.9 ] | 
| 05-02 01:28:13 epoch: 1798| time: 1.0s| train loss: +1.715e+01 | test loss: +1.735e+01 | 
| 05-02 01:28:13 epoch: 1798| train loss i: [0.1 	1.49	5.4 	4.87	3.75	1.54] test loss i: [0.15	1.1 	5.48	5.1 	3.62	1.9 ] | 
| 05-02 01:28:14 epoch: 1799| time: 1.1s| train loss: +1.613e+01 | test loss: +1.494e+01 | 
| 05-02 01:28:14 epoch: 1799| train loss i: [0.07	1.11	5.07	4.76	3.59	1.53] test loss i: [0.1 	0.29	3.9 	4.63	4.47	1.55] | 
| 05-02 01:28:16 epoch: 1800| time: 1.1s| train loss: +1.599e+01 | test loss: +1.661e+01 | 
| 05-02 01:28:16 epoch: 1800| train loss i: [0.07	1.05	4.95	4.63	3.8 	1.48] test loss i: [0.03	1.01	5.01	5.43	3.62	1.5 ] | 
| 05-02 01:28:17 epoch: 1801| time: 1.1s| train loss: +1.670e+01 | test loss: +2.169e+01 | 
| 05-02 01:28:17 epoch: 1801| train loss i: [0.1 	1.11	5.61	4.65	3.76	1.46] test loss i: [0.24	1.66	7.53	6.39	3.94	1.94] | 
| 05-02 01:28:18 epoch: 1802| time: 1.1s| train loss: +1.711e+01 | test loss: +2.264e+01 | 
| 05-02 01:28:18 epoch: 1802| train loss i: [0.06	1.1 	5.72	4.87	3.85	1.5 ] test loss i: [0.04	1.61	8.61	4.97	5.59	1.82] | 
| 05-02 01:28:19 epoch: 1803| time: 1.1s| train loss: +1.679e+01 | test loss: +2.106e+01 | 
| 05-02 01:28:19 epoch: 1803| train loss i: [0.05	1.62	5.01	4.85	3.73	1.53] test loss i: [0.07	1.06	5.74	6.4 	5.82	1.97] | 
| 05-02 01:28:20 epoch: 1804| time: 1.0s| train loss: +1.731e+01 | test loss: +2.366e+01 | 
| 05-02 01:28:20 epoch: 1804| train loss i: [0.09	1.3 	5.3 	5.36	3.71	1.54] test loss i: [0.12	2.7 	7.28	7.23	4.34	1.98] | 
| 05-02 01:28:21 epoch: 1805| time: 1.1s| train loss: +1.661e+01 | test loss: +2.232e+01 | 
| 05-02 01:28:21 epoch: 1805| train loss i: [0.07	0.99	5.42	4.7 	3.86	1.57] test loss i: [0.09	4.29	6.44	5.36	4.1 	2.04] | 
| 05-02 01:28:22 epoch: 1806| time: 1.1s| train loss: +1.659e+01 | test loss: +1.834e+01 | 
| 05-02 01:28:22 epoch: 1806| train loss i: [0.08	1.07	5.68	4.42	3.79	1.55] test loss i: [0.12	0.26	7.03	4.96	4.03	1.95] | 
| 05-02 01:28:23 epoch: 1807| time: 1.1s| train loss: +1.585e+01 | test loss: +1.671e+01 | 
| 05-02 01:28:23 epoch: 1807| train loss i: [0.09	1.28	5.  	4.39	3.53	1.56] test loss i: [0.16	0.28	6.26	4.92	3.37	1.71] | 
| 05-02 01:28:24 epoch: 1808| time: 1.1s| train loss: +1.676e+01 | test loss: +1.945e+01 | 
| 05-02 01:28:24 epoch: 1808| train loss i: [0.07	1.27	5.31	4.85	3.7 	1.57] test loss i: [0.03	0.99	4.82	7.02	4.73	1.85] | 
| 05-02 01:28:25 epoch: 1809| time: 1.1s| train loss: +1.777e+01 | test loss: +1.791e+01 | 
| 05-02 01:28:25 epoch: 1809| train loss i: [0.1 	1.7 	5.06	5.06	4.27	1.58] test loss i: [0.08	1.68	4.48	5.13	4.83	1.71] | 
| 05-02 01:28:26 epoch: 1810| time: 1.0s| train loss: +1.673e+01 | test loss: +1.819e+01 | 
| 05-02 01:28:26 epoch: 1810| train loss i: [0.1 	0.92	5.45	4.86	3.7 	1.71] test loss i: [0.05	0.56	5.27	5.68	4.61	2.02] | 
| 05-02 01:28:27 epoch: 1811| time: 1.0s| train loss: +1.720e+01 | test loss: +2.101e+01 | 
| 05-02 01:28:27 epoch: 1811| train loss i: [0.1 	1.15	5.98	4.7 	3.74	1.54] test loss i: [0.08	2.91	5.16	5.56	5.1 	2.2 ] | 
| 05-02 01:28:28 epoch: 1812| time: 1.1s| train loss: +1.730e+01 | test loss: +1.882e+01 | 
| 05-02 01:28:28 epoch: 1812| train loss i: [0.08	1.14	5.96	4.83	3.68	1.6 ] test loss i: [0.22	3.07	4.56	4.87	3.92	2.18] | 
| 05-02 01:28:29 epoch: 1813| time: 1.1s| train loss: +1.671e+01 | test loss: +1.642e+01 | 
| 05-02 01:28:29 epoch: 1813| train loss i: [0.08	1.7 	4.81	4.76	3.84	1.51] test loss i: [0.08	0.5 	5.89	5.  	3.35	1.6 ] | 
| 05-02 01:28:31 epoch: 1814| time: 1.1s| train loss: +1.772e+01 | test loss: +1.876e+01 | 
| 05-02 01:28:31 epoch: 1814| train loss i: [0.12	1.5 	5.28	5.18	4.09	1.54] test loss i: [0.07	1.58	6.03	5.5 	4.08	1.5 ] | 
| 05-02 01:28:32 epoch: 1815| time: 1.1s| train loss: +1.735e+01 | test loss: +1.805e+01 | 
| 05-02 01:28:32 epoch: 1815| train loss i: [0.08	1.44	5.95	4.57	3.76	1.56] test loss i: [0.11	2.33	6.05	4.49	3.47	1.6 ] | 
| 05-02 01:28:33 epoch: 1816| time: 1.0s| train loss: +1.675e+01 | test loss: +1.858e+01 | 
| 05-02 01:28:33 epoch: 1816| train loss i: [0.11	1.66	4.84	4.85	3.83	1.46] test loss i: [0.07	1.09	6.95	5.22	3.58	1.66] | 
| 05-02 01:28:34 epoch: 1817| time: 1.0s| train loss: +1.786e+01 | test loss: +1.952e+01 | 
| 05-02 01:28:34 epoch: 1817| train loss i: [0.11	1.37	5.76	5.26	3.74	1.62] test loss i: [0.07	1.44	6.83	5.71	3.51	1.97] | 
| 05-02 01:28:35 epoch: 1818| time: 1.1s| train loss: +1.778e+01 | test loss: +1.973e+01 | 
| 05-02 01:28:35 epoch: 1818| train loss i: [0.1 	1.72	6.11	4.39	3.87	1.58] test loss i: [0.07	2.63	5.94	5.13	4.37	1.6 ] | 
| 05-02 01:28:36 epoch: 1819| time: 1.1s| train loss: +1.756e+01 | test loss: +2.272e+01 | 
| 05-02 01:28:36 epoch: 1819| train loss i: [0.12	1.28	5.75	4.63	4.14	1.63] test loss i: [0.11	1.31	7.84	6.69	4.69	2.08] | 
| 05-02 01:28:37 epoch: 1820| time: 1.1s| train loss: +1.709e+01 | test loss: +2.036e+01 | 
| 05-02 01:28:37 epoch: 1820| train loss i: [0.19	1.31	5.78	4.5 	3.79	1.51] test loss i: [0.09	3.24	5.36	6.7 	3.44	1.53] | 
| 05-02 01:28:38 epoch: 1821| time: 1.1s| train loss: +1.695e+01 | test loss: +1.919e+01 | 
| 05-02 01:28:38 epoch: 1821| train loss i: [0.14	1.52	5.25	4.82	3.68	1.54] test loss i: [0.09	2.67	6.83	3.86	4.1 	1.64] | 
| 05-02 01:28:39 epoch: 1822| time: 1.1s| train loss: +1.560e+01 | test loss: +1.743e+01 | 
| 05-02 01:28:39 epoch: 1822| train loss i: [0.08	0.66	5.22	4.73	3.35	1.56] test loss i: [0.46	1.8 	5.47	4.12	3.89	1.68] | 
| 05-02 01:28:40 epoch: 1823| time: 1.0s| train loss: +1.672e+01 | test loss: +1.498e+01 | 
| 05-02 01:28:40 epoch: 1823| train loss i: [0.08	1.14	5.18	4.6 	4.12	1.59] test loss i: [0.13	1.01	4.18	3.85	4.13	1.68] | 
| 05-02 01:28:41 epoch: 1824| time: 1.1s| train loss: +1.773e+01 | test loss: +1.793e+01 | 
| 05-02 01:28:41 epoch: 1824| train loss i: [0.07	2.02	5.64	4.7 	3.73	1.56] test loss i: [0.13	1.17	6.12	5.17	3.55	1.8 ] | 
| 05-02 01:28:42 epoch: 1825| time: 1.1s| train loss: +1.713e+01 | test loss: +1.522e+01 | 
| 05-02 01:28:42 epoch: 1825| train loss i: [0.09	1.55	5.04	4.92	3.95	1.58] test loss i: [0.18	1.34	4.52	4.4 	3.08	1.71] | 
| 05-02 01:28:43 epoch: 1826| time: 1.1s| train loss: +1.567e+01 | test loss: +1.632e+01 | 
| 05-02 01:28:43 epoch: 1826| train loss i: [0.07	1.05	5.09	4.31	3.62	1.54] test loss i: [0.1 	0.89	4.74	5.56	3.42	1.62] | 
| 05-02 01:28:44 epoch: 1827| time: 1.1s| train loss: +1.702e+01 | test loss: +1.829e+01 | 
| 05-02 01:28:44 epoch: 1827| train loss i: [0.07	1.56	5.31	4.68	3.8 	1.6 ] test loss i: [0.1 	0.85	5.8 	5.24	4.42	1.88] | 
| 05-02 01:28:46 epoch: 1828| time: 1.0s| train loss: +1.638e+01 | test loss: +1.963e+01 | 
| 05-02 01:28:46 epoch: 1828| train loss i: [0.07	1.11	5.2 	4.85	3.66	1.5 ] test loss i: [0.12	2.06	5.55	6.45	3.86	1.58] | 
| 05-02 01:28:47 epoch: 1829| time: 1.0s| train loss: +1.665e+01 | test loss: +1.578e+01 | 
| 05-02 01:28:47 epoch: 1829| train loss i: [0.06	0.82	5.76	4.71	3.73	1.58] test loss i: [0.26	0.77	4.73	4.44	3.9 	1.67] | 
| 05-02 01:28:48 epoch: 1830| time: 1.0s| train loss: +1.667e+01 | test loss: +1.412e+01 | 
| 05-02 01:28:48 epoch: 1830| train loss i: [0.11	0.8 	6.01	4.58	3.59	1.57] test loss i: [0.04	1.11	4.  	4.15	3.19	1.63] | 
| 05-02 01:28:49 epoch: 1831| time: 1.1s| train loss: +1.644e+01 | test loss: +1.775e+01 | 
| 05-02 01:28:49 epoch: 1831| train loss i: [0.05	1.35	5.02	4.9 	3.53	1.59] test loss i: [0.12	0.94	5.44	5.39	4.07	1.78] | 
| 05-02 01:28:50 epoch: 1832| time: 1.1s| train loss: +1.739e+01 | test loss: +1.693e+01 | 
| 05-02 01:28:50 epoch: 1832| train loss i: [0.08	1.46	5.94	4.46	3.9 	1.54] test loss i: [0.07	0.22	6.12	4.76	3.9 	1.86] | 
| 05-02 01:28:51 epoch: 1833| time: 1.1s| train loss: +1.760e+01 | test loss: +2.086e+01 | 
| 05-02 01:28:51 epoch: 1833| train loss i: [0.07	0.92	5.58	5.4 	4.09	1.56] test loss i: [0.09	0.97	7.54	6.08	4.37	1.81] | 
| 05-02 01:28:52 epoch: 1834| time: 1.1s| train loss: +1.630e+01 | test loss: +1.616e+01 | 
| 05-02 01:28:52 epoch: 1834| train loss i: [0.08	1.22	5.36	4.59	3.55	1.51] test loss i: [0.05	1.23	5.57	3.88	3.84	1.58] | 
| 05-02 01:28:53 epoch: 1835| time: 1.1s| train loss: +1.624e+01 | test loss: +1.970e+01 | 
| 05-02 01:28:53 epoch: 1835| train loss i: [0.06	0.89	5.1 	4.83	3.86	1.49] test loss i: [0.11	2.38	6.17	5.35	4.  	1.69] | 
| 05-02 01:28:54 epoch: 1836| time: 1.0s| train loss: +1.670e+01 | test loss: +1.667e+01 | 
| 05-02 01:28:54 epoch: 1836| train loss i: [0.05	1.18	5.37	4.92	3.6 	1.58] test loss i: [0.05	1.47	5.54	4.84	3.11	1.66] | 
| 05-02 01:28:55 epoch: 1837| time: 1.1s| train loss: +1.715e+01 | test loss: +2.029e+01 | 
| 05-02 01:28:55 epoch: 1837| train loss i: [0.06	0.92	6.09	4.92	3.59	1.57] test loss i: [0.05	1.96	7.35	4.95	4.11	1.86] | 
| 05-02 01:28:56 epoch: 1838| time: 1.1s| train loss: +1.621e+01 | test loss: +1.827e+01 | 
| 05-02 01:28:56 epoch: 1838| train loss i: [0.07	1.71	4.66	4.65	3.54	1.58] test loss i: [0.05	1.89	5.73	4.9 	3.93	1.77] | 
| 05-02 01:28:57 epoch: 1839| time: 1.1s| train loss: +1.674e+01 | test loss: +1.924e+01 | 
| 05-02 01:28:57 epoch: 1839| train loss i: [0.06	0.68	5.66	4.62	4.14	1.59] test loss i: [0.05	1.05	6.63	5.99	3.92	1.59] | 
| 05-02 01:28:58 epoch: 1840| time: 1.1s| train loss: +1.733e+01 | test loss: +1.985e+01 | 
| 05-02 01:28:58 epoch: 1840| train loss i: [0.06	1.91	5.21	4.84	3.8 	1.49] test loss i: [0.04	2.17	6.53	5.6 	4.06	1.45] | 
| 05-02 01:28:59 epoch: 1841| time: 1.1s| train loss: +1.680e+01 | test loss: +1.424e+01 | 
| 05-02 01:28:59 epoch: 1841| train loss i: [0.06	1.3 	5.61	4.61	3.78	1.46] test loss i: [0.06	0.54	4.14	4.65	3.03	1.81] | 
| 05-02 01:29:01 epoch: 1842| time: 1.1s| train loss: +1.705e+01 | test loss: +1.857e+01 | 
| 05-02 01:29:01 epoch: 1842| train loss i: [0.06	1.76	5.23	4.65	3.79	1.56] test loss i: [0.05	1.65	6.76	4.37	3.99	1.75] | 
| 05-02 01:29:02 epoch: 1843| time: 1.0s| train loss: +1.705e+01 | test loss: +1.614e+01 | 
| 05-02 01:29:02 epoch: 1843| train loss i: [0.06	0.71	6.2 	4.45	4.06	1.57] test loss i: [0.07	1.54	4.64	4.9 	3.62	1.37] | 
| 05-02 01:29:03 epoch: 1844| time: 1.1s| train loss: +1.638e+01 | test loss: +1.813e+01 | 
| 05-02 01:29:03 epoch: 1844| train loss i: [0.15	0.88	5.21	5.05	3.63	1.47] test loss i: [0.05	0.8 	5.57	4.78	5.13	1.8 ] | 
| 05-02 01:29:04 epoch: 1845| time: 1.1s| train loss: +1.664e+01 | test loss: +2.513e+01 | 
| 05-02 01:29:04 epoch: 1845| train loss i: [0.08	1.63	5.25	4.59	3.55	1.53] test loss i: [0.22	1.37	7.74	7.8 	5.79	2.2 ] | 
| 05-02 01:29:05 epoch: 1846| time: 1.1s| train loss: +1.728e+01 | test loss: +1.688e+01 | 
| 05-02 01:29:05 epoch: 1846| train loss i: [0.07	1.43	5.09	5.21	3.85	1.63] test loss i: [0.05	1.93	6.  	4.21	3.2 	1.5 ] | 
| 05-02 01:29:06 epoch: 1847| time: 1.1s| train loss: +1.628e+01 | test loss: +1.972e+01 | 
| 05-02 01:29:06 epoch: 1847| train loss i: [0.07	0.88	4.99	4.67	4.18	1.48] test loss i: [0.03	1.6 	6.9 	5.06	4.07	2.06] | 
| 05-02 01:29:07 epoch: 1848| time: 1.1s| train loss: +1.647e+01 | test loss: +1.742e+01 | 
| 05-02 01:29:07 epoch: 1848| train loss i: [0.08	1.32	5.23	4.74	3.55	1.56] test loss i: [0.08	1.02	6.24	4.76	3.57	1.77] | 
| 05-02 01:29:08 epoch: 1849| time: 1.1s| train loss: +1.788e+01 | test loss: +1.996e+01 | 
| 05-02 01:29:08 epoch: 1849| train loss i: [0.07	1.92	5.83	4.77	3.74	1.55] test loss i: [0.22	3.28	5.38	4.91	4.44	1.72] | 
| 05-02 01:29:09 epoch: 1850| time: 1.0s| train loss: +1.758e+01 | test loss: +1.699e+01 | 
| 05-02 01:29:09 epoch: 1850| train loss i: [0.08	1.56	5.73	4.8 	3.79	1.63] test loss i: [0.03	1.16	6.69	4.31	3.27	1.53] | 
| 05-02 01:29:10 epoch: 1851| time: 1.0s| train loss: +1.613e+01 | test loss: +1.585e+01 | 
| 05-02 01:29:10 epoch: 1851| train loss i: [0.11	1.27	4.97	4.34	3.85	1.58] test loss i: [0.16	1.38	4.  	5.04	3.7 	1.58] | 
| 05-02 01:29:11 epoch: 1852| time: 1.0s| train loss: +1.643e+01 | test loss: +1.899e+01 | 
| 05-02 01:29:11 epoch: 1852| train loss i: [0.08	1.52	4.85	4.9 	3.52	1.55] test loss i: [0.27	1.71	5.88	5.63	3.73	1.77] | 
| 05-02 01:29:12 epoch: 1853| time: 1.1s| train loss: +1.678e+01 | test loss: +1.612e+01 | 
| 05-02 01:29:12 epoch: 1853| train loss i: [0.11	1.51	5.38	4.53	3.71	1.54] test loss i: [0.3 	1.46	4.25	4.68	3.77	1.66] | 
| 05-02 01:29:13 epoch: 1854| time: 1.1s| train loss: +1.707e+01 | test loss: +1.437e+01 | 
| 05-02 01:29:13 epoch: 1854| train loss i: [0.14	1.08	5.35	4.96	3.99	1.56] test loss i: [0.2 	0.55	3.84	3.98	4.06	1.74] | 
| 05-02 01:29:14 epoch: 1855| time: 1.1s| train loss: +1.733e+01 | test loss: +1.976e+01 | 
| 05-02 01:29:14 epoch: 1855| train loss i: [0.09	1.19	5.76	4.8 	3.93	1.56] test loss i: [0.04	1.46	7.42	4.34	4.96	1.54] | 
| 05-02 01:29:16 epoch: 1856| time: 1.1s| train loss: +1.711e+01 | test loss: +2.407e+01 | 
| 05-02 01:29:16 epoch: 1856| train loss i: [0.07	0.97	5.58	5.06	3.87	1.56] test loss i: [0.19	2.28	6.6 	6.7 	6.06	2.24] | 
| 05-02 01:29:17 epoch: 1857| time: 1.1s| train loss: +1.676e+01 | test loss: +1.836e+01 | 
| 05-02 01:29:17 epoch: 1857| train loss i: [0.11	1.5 	5.59	4.56	3.53	1.47] test loss i: [0.14	0.47	5.26	5.26	5.3 	1.92] | 
| 05-02 01:29:18 epoch: 1858| time: 1.0s| train loss: +1.733e+01 | test loss: +1.861e+01 | 
| 05-02 01:29:18 epoch: 1858| train loss i: [0.1 	1.49	5.17	5.19	3.8 	1.58] test loss i: [0.11	1.58	5.64	4.87	4.67	1.74] | 
| 05-02 01:29:19 epoch: 1859| time: 1.0s| train loss: +1.751e+01 | test loss: +1.769e+01 | 
| 05-02 01:29:19 epoch: 1859| train loss i: [0.06	1.66	5.35	5.07	3.89	1.48] test loss i: [0.15	1.12	5.57	4.88	4.42	1.56] | 
| 05-02 01:29:20 epoch: 1860| time: 1.1s| train loss: +1.705e+01 | test loss: +2.115e+01 | 
| 05-02 01:29:20 epoch: 1860| train loss i: [0.08	1.45	5.57	4.62	3.75	1.57] test loss i: [0.15	1.17	7.86	5.76	4.12	2.1 ] | 
| 05-02 01:29:21 epoch: 1861| time: 1.1s| train loss: +1.734e+01 | test loss: +1.741e+01 | 
| 05-02 01:29:21 epoch: 1861| train loss i: [0.06	1.83	5.11	4.83	3.84	1.66] test loss i: [0.23	0.34	4.63	5.4 	4.77	2.04] | 
| 05-02 01:29:22 epoch: 1862| time: 1.1s| train loss: +1.667e+01 | test loss: +2.281e+01 | 
| 05-02 01:29:22 epoch: 1862| train loss i: [0.06	1.53	5.14	4.81	3.53	1.6 ] test loss i: [0.44	0.87	7.55	6.96	5.09	1.89] | 
| 05-02 01:29:23 epoch: 1863| time: 1.1s| train loss: +1.615e+01 | test loss: +1.691e+01 | 
| 05-02 01:29:23 epoch: 1863| train loss i: [0.08	1.09	4.95	4.68	3.75	1.61] test loss i: [0.07	0.26	5.93	5.06	3.79	1.81] | 
| 05-02 01:29:24 epoch: 1864| time: 1.0s| train loss: +1.711e+01 | test loss: +2.415e+01 | 
| 05-02 01:29:24 epoch: 1864| train loss i: [0.06	1.76	5.28	4.67	3.79	1.55] test loss i: [0.24	1.47	7.92	7.56	4.83	2.13] | 
| 05-02 01:29:25 epoch: 1865| time: 1.1s| train loss: +1.641e+01 | test loss: +1.934e+01 | 
| 05-02 01:29:25 epoch: 1865| train loss i: [0.07	0.98	5.47	4.81	3.52	1.58] test loss i: [0.11	2.39	5.65	4.67	4.88	1.64] | 
| 05-02 01:29:26 epoch: 1866| time: 1.1s| train loss: +1.723e+01 | test loss: +2.282e+01 | 
| 05-02 01:29:26 epoch: 1866| train loss i: [0.07	1.17	6.06	4.83	3.54	1.56] test loss i: [0.21	1.67	6.96	6.99	4.51	2.48] | 
| 05-02 01:29:27 epoch: 1867| time: 1.1s| train loss: +1.785e+01 | test loss: +1.559e+01 | 
| 05-02 01:29:27 epoch: 1867| train loss i: [0.06	1.89	5.57	4.89	3.84	1.6 ] test loss i: [0.19	1.33	5.08	4.19	3.4 	1.4 ] | 
| 05-02 01:29:28 epoch: 1868| time: 1.1s| train loss: +1.682e+01 | test loss: +1.536e+01 | 
| 05-02 01:29:28 epoch: 1868| train loss i: [0.08	1.5 	5.08	4.64	3.93	1.59] test loss i: [0.05	0.71	4.95	4.81	3.49	1.36] | 
| 05-02 01:29:29 epoch: 1869| time: 1.1s| train loss: +1.667e+01 | test loss: +1.870e+01 | 
| 05-02 01:29:29 epoch: 1869| train loss i: [0.13	1.02	5.56	4.64	3.75	1.58] test loss i: [0.09	0.73	6.3 	5.36	4.18	2.04] | 
| 05-02 01:29:31 epoch: 1870| time: 1.1s| train loss: +1.813e+01 | test loss: +1.887e+01 | 
| 05-02 01:29:31 epoch: 1870| train loss i: [0.11	1.8 	5.93	4.96	3.7 	1.64] test loss i: [0.07	0.95	6.22	5.42	3.99	2.21] | 
| 05-02 01:29:32 epoch: 1871| time: 1.1s| train loss: +1.673e+01 | test loss: +1.975e+01 | 
| 05-02 01:29:32 epoch: 1871| train loss i: [0.13	1.36	5.14	4.8 	3.73	1.58] test loss i: [0.12	2.55	5.66	4.93	4.53	1.96] | 
| 05-02 01:29:33 epoch: 1872| time: 1.1s| train loss: +1.667e+01 | test loss: +2.732e+01 | 
| 05-02 01:29:33 epoch: 1872| train loss i: [0.1 	1.51	5.06	4.72	3.71	1.57] test loss i: [0.17	2.1 	9.55	6.74	6.22	2.54] | 
| 05-02 01:29:34 epoch: 1873| time: 1.0s| train loss: +1.803e+01 | test loss: +1.604e+01 | 
| 05-02 01:29:34 epoch: 1873| train loss i: [0.11	1.61	5.79	5.07	3.93	1.53] test loss i: [0.26	0.98	4.61	5.31	3.1 	1.78] | 
| 05-02 01:29:35 epoch: 1874| time: 1.0s| train loss: +1.645e+01 | test loss: +1.835e+01 | 
| 05-02 01:29:35 epoch: 1874| train loss i: [0.11	1.38	5.27	4.47	3.62	1.6 ] test loss i: [0.12	0.54	6.29	5.08	4.64	1.68] | 
| 05-02 01:29:36 epoch: 1875| time: 1.1s| train loss: +1.709e+01 | test loss: +1.566e+01 | 
| 05-02 01:29:36 epoch: 1875| train loss i: [0.18	1.52	5.62	4.65	3.53	1.6 ] test loss i: [0.22	0.49	4.03	5.49	3.61	1.82] | 
| 05-02 01:29:37 epoch: 1876| time: 1.1s| train loss: +1.674e+01 | test loss: +1.688e+01 | 
| 05-02 01:29:37 epoch: 1876| train loss i: [0.15	0.96	5.17	4.91	3.94	1.61] test loss i: [0.15	1.19	5.49	4.76	3.52	1.78] | 
| 05-02 01:29:38 epoch: 1877| time: 1.1s| train loss: +1.799e+01 | test loss: +1.870e+01 | 
| 05-02 01:29:38 epoch: 1877| train loss i: [0.09	1.64	5.55	5.22	3.92	1.56] test loss i: [0.09	0.98	6.04	5.59	4.23	1.78] | 
| 05-02 01:29:39 epoch: 1878| time: 1.1s| train loss: +1.652e+01 | test loss: +1.724e+01 | 
| 05-02 01:29:39 epoch: 1878| train loss i: [0.08	0.98	5.52	4.68	3.71	1.56] test loss i: [0.13	0.64	5.22	4.58	4.91	1.75] | 
| 05-02 01:29:40 epoch: 1879| time: 1.1s| train loss: +1.787e+01 | test loss: +1.692e+01 | 
| 05-02 01:29:40 epoch: 1879| train loss i: [0.09	2.2 	5.81	4.53	3.7 	1.54] test loss i: [0.08	0.37	6.47	4.86	3.57	1.58] | 
| 05-02 01:29:41 epoch: 1880| time: 1.1s| train loss: +1.716e+01 | test loss: +2.142e+01 | 
| 05-02 01:29:41 epoch: 1880| train loss i: [0.07	1.41	5.53	4.72	3.85	1.57] test loss i: [0.09	1.75	6.8 	4.95	5.77	2.08] | 
| 05-02 01:29:42 epoch: 1881| time: 1.0s| train loss: +1.647e+01 | test loss: +1.684e+01 | 
| 05-02 01:29:42 epoch: 1881| train loss i: [0.1 	1.23	5.32	4.62	3.63	1.59] test loss i: [0.07	2.05	5.27	4.15	3.78	1.52] | 
| 05-02 01:29:43 epoch: 1882| time: 1.0s| train loss: +1.721e+01 | test loss: +2.294e+01 | 
| 05-02 01:29:43 epoch: 1882| train loss i: [0.12	1.42	5.48	4.72	3.88	1.59] test loss i: [0.23	2.75	6.59	6.03	5.46	1.88] | 
| 05-02 01:29:44 epoch: 1883| time: 1.1s| train loss: +1.637e+01 | test loss: +1.769e+01 | 
| 05-02 01:29:44 epoch: 1883| train loss i: [0.14	0.81	5.46	4.68	3.69	1.58] test loss i: [0.15	1.1 	5.73	4.95	3.99	1.78] | 
| 05-02 01:29:46 epoch: 1884| time: 1.1s| train loss: +1.791e+01 | test loss: +1.901e+01 | 
| 05-02 01:29:46 epoch: 1884| train loss i: [0.12	2.17	5.48	4.94	3.64	1.57] test loss i: [0.07	3.86	5.16	4.39	3.79	1.73] | 
| 05-02 01:29:47 epoch: 1885| time: 1.1s| train loss: +1.649e+01 | test loss: +1.931e+01 | 
| 05-02 01:29:47 epoch: 1885| train loss i: [0.1 	1.3 	5.02	4.85	3.71	1.5 ] test loss i: [0.1 	2.7 	6.12	4.64	4.19	1.58] | 
| 05-02 01:29:48 epoch: 1886| time: 1.1s| train loss: +1.705e+01 | test loss: +1.618e+01 | 
| 05-02 01:29:48 epoch: 1886| train loss i: [0.07	1.15	5.51	4.53	4.2 	1.58] test loss i: [0.15	0.76	4.96	4.41	4.05	1.86] | 
| 05-02 01:29:49 epoch: 1887| time: 1.0s| train loss: +1.665e+01 | test loss: +1.973e+01 | 
| 05-02 01:29:49 epoch: 1887| train loss i: [0.13	1.36	5.29	4.54	3.8 	1.52] test loss i: [0.07	2.67	7.09	4.43	3.72	1.75] | 
| 05-02 01:29:50 epoch: 1888| time: 1.0s| train loss: +1.757e+01 | test loss: +1.790e+01 | 
| 05-02 01:29:50 epoch: 1888| train loss i: [0.07	1.63	5.53	4.84	3.94	1.57] test loss i: [0.19	3.01	3.9 	5.75	3.32	1.72] | 
| 05-02 01:29:51 epoch: 1889| time: 1.1s| train loss: +1.762e+01 | test loss: +1.833e+01 | 
| 05-02 01:29:51 epoch: 1889| train loss i: [0.15	1.8 	5.64	4.77	3.71	1.55] test loss i: [0.08	3.26	5.44	4.52	3.43	1.61] | 
| 05-02 01:29:52 epoch: 1890| time: 1.1s| train loss: +1.645e+01 | test loss: +2.326e+01 | 
| 05-02 01:29:52 epoch: 1890| train loss i: [0.1 	1.61	4.72	4.97	3.52	1.52] test loss i: [0.25	2.24	8.94	5.07	4.78	1.98] | 
| 05-02 01:29:53 epoch: 1891| time: 1.1s| train loss: +1.607e+01 | test loss: +1.641e+01 | 
| 05-02 01:29:53 epoch: 1891| train loss i: [0.07	0.98	4.9 	4.87	3.71	1.53] test loss i: [0.08	0.75	5.89	4.81	3.43	1.46] | 
| 05-02 01:29:54 epoch: 1892| time: 1.1s| train loss: +1.766e+01 | test loss: +2.527e+01 | 
| 05-02 01:29:54 epoch: 1892| train loss i: [0.1 	1.3 	5.85	4.91	3.91	1.58] test loss i: [0.23	3.58	8.07	6.66	4.71	2.02] | 
| 05-02 01:29:55 epoch: 1893| time: 1.0s| train loss: +1.760e+01 | test loss: +1.773e+01 | 
| 05-02 01:29:55 epoch: 1893| train loss i: [0.08	2.23	5.25	4.64	3.81	1.59] test loss i: [0.27	0.73	6.47	5.51	3.18	1.57] | 
| 05-02 01:29:56 epoch: 1894| time: 1.0s| train loss: +1.701e+01 | test loss: +1.617e+01 | 
| 05-02 01:29:56 epoch: 1894| train loss i: [0.1 	1.04	6.12	4.46	3.74	1.55] test loss i: [0.09	0.82	5.38	4.79	3.44	1.66] | 
| 05-02 01:29:57 epoch: 1895| time: 1.1s| train loss: +1.636e+01 | test loss: +2.319e+01 | 
| 05-02 01:29:57 epoch: 1895| train loss i: [0.08	0.92	5.4 	4.64	3.72	1.6 ] test loss i: [0.12	2.64	6.34	5.39	6.57	2.12] | 
| 05-02 01:29:58 epoch: 1896| time: 1.1s| train loss: +1.671e+01 | test loss: +1.983e+01 | 
| 05-02 01:29:58 epoch: 1896| train loss i: [0.12	1.58	5.41	4.47	3.57	1.58] test loss i: [0.12	0.64	6.36	6.17	4.43	2.11] | 
| 05-02 01:29:59 epoch: 1897| time: 1.1s| train loss: +1.785e+01 | test loss: +2.030e+01 | 
| 05-02 01:29:59 epoch: 1897| train loss i: [0.08	1.9 	5.64	5.11	3.56	1.56] test loss i: [0.07	3.06	5.84	6.1 	3.68	1.56] | 
| 05-02 01:30:01 epoch: 1898| time: 1.1s| train loss: +1.623e+01 | test loss: +1.853e+01 | 
| 05-02 01:30:01 epoch: 1898| train loss i: [0.1 	1.33	4.75	4.66	3.8 	1.6 ] test loss i: [0.12	1.62	6.78	4.6 	3.9 	1.51] | 
| 05-02 01:30:02 epoch: 1899| time: 1.1s| train loss: +1.710e+01 | test loss: +1.919e+01 | 
| 05-02 01:30:02 epoch: 1899| train loss i: [0.06	1.46	5.3 	4.97	3.86	1.45] test loss i: [0.12	2.33	5.56	5.51	4.01	1.66] | 
| 05-02 01:30:03 epoch: 1900| time: 1.1s| train loss: +1.623e+01 | test loss: +1.626e+01 | 
| 05-02 01:30:03 epoch: 1900| train loss i: [0.07	1.18	5.48	4.2 	3.79	1.5 ] test loss i: [0.04	1.45	5.46	4.22	3.52	1.57] | 
| 05-02 01:30:04 epoch: 1901| time: 1.1s| train loss: +1.747e+01 | test loss: +2.014e+01 | 
| 05-02 01:30:04 epoch: 1901| train loss i: [0.06	1.43	5.61	5.02	3.9 	1.45] test loss i: [0.06	1.34	6.99	4.8 	4.89	2.05] | 
| 05-02 01:30:05 epoch: 1902| time: 1.1s| train loss: +1.662e+01 | test loss: +1.704e+01 | 
| 05-02 01:30:05 epoch: 1902| train loss i: [0.06	1.25	5.19	4.8 	3.74	1.6 ] test loss i: [0.04	1.03	5.62	5.1 	3.7 	1.56] | 
| 05-02 01:30:06 epoch: 1903| time: 1.0s| train loss: +1.616e+01 | test loss: +1.540e+01 | 
| 05-02 01:30:06 epoch: 1903| train loss i: [0.06	1.14	5.29	4.38	3.76	1.53] test loss i: [0.04	0.69	5.23	4.26	3.6 	1.58] | 
| 05-02 01:30:07 epoch: 1904| time: 1.0s| train loss: +1.740e+01 | test loss: +1.809e+01 | 
| 05-02 01:30:07 epoch: 1904| train loss i: [0.07	1.49	5.13	5.19	3.87	1.65] test loss i: [0.09	1.15	7.  	4.42	3.63	1.81] | 
| 05-02 01:30:08 epoch: 1905| time: 1.1s| train loss: +1.713e+01 | test loss: +1.825e+01 | 
| 05-02 01:30:08 epoch: 1905| train loss i: [0.06	1.24	5.54	4.8 	3.91	1.58] test loss i: [0.09	1.12	6.41	5.2 	3.78	1.66] | 
| 05-02 01:30:09 epoch: 1906| time: 1.1s| train loss: +1.758e+01 | test loss: +2.545e+01 | 
| 05-02 01:30:09 epoch: 1906| train loss i: [0.05	1.51	5.8 	4.77	3.98	1.47] test loss i: [0.14	1.96	8.37	7.35	5.44	2.18] | 
| 05-02 01:30:10 epoch: 1907| time: 1.1s| train loss: +1.625e+01 | test loss: +1.762e+01 | 
| 05-02 01:30:10 epoch: 1907| train loss i: [0.05	0.8 	4.87	5.19	3.77	1.57] test loss i: [0.1 	2.76	5.54	4.22	3.33	1.68] | 
| 05-02 01:30:11 epoch: 1908| time: 1.1s| train loss: +1.672e+01 | test loss: +1.753e+01 | 
| 05-02 01:30:11 epoch: 1908| train loss i: [0.08	1.05	5.16	4.78	4.08	1.57] test loss i: [0.05	0.22	5.62	5.01	4.84	1.79] | 
| 05-02 01:30:12 epoch: 1909| time: 1.1s| train loss: +1.688e+01 | test loss: +1.780e+01 | 
| 05-02 01:30:12 epoch: 1909| train loss i: [0.06	1.26	5.29	4.95	3.73	1.59] test loss i: [0.07	0.37	6.6 	4.75	4.5 	1.51] | 
| 05-02 01:30:13 epoch: 1910| time: 1.0s| train loss: +1.751e+01 | test loss: +2.274e+01 | 
| 05-02 01:30:13 epoch: 1910| train loss i: [0.16	1.72	5.45	5.01	3.58	1.59] test loss i: [0.14	1.62	7.73	6.1 	5.24	1.91] | 
| 05-02 01:30:15 epoch: 1911| time: 1.0s| train loss: +1.753e+01 | test loss: +1.692e+01 | 
| 05-02 01:30:15 epoch: 1911| train loss i: [0.06	1.81	5.66	4.7 	3.76	1.54] test loss i: [0.1 	0.35	5.93	4.95	3.83	1.76] | 
| 05-02 01:30:16 epoch: 1912| time: 1.1s| train loss: +1.747e+01 | test loss: +2.358e+01 | 
| 05-02 01:30:16 epoch: 1912| train loss i: [0.06	1.6 	5.63	4.98	3.56	1.63] test loss i: [0.05	0.86	8.13	6.48	5.92	2.13] | 
| 05-02 01:30:17 epoch: 1913| time: 1.1s| train loss: +1.710e+01 | test loss: +2.224e+01 | 
| 05-02 01:30:17 epoch: 1913| train loss i: [0.06	0.95	5.9 	4.71	3.96	1.52] test loss i: [0.12	2.72	6.54	5.67	5.17	2.02] | 
| 05-02 01:30:18 epoch: 1914| time: 1.1s| train loss: +1.745e+01 | test loss: +1.955e+01 | 
| 05-02 01:30:18 epoch: 1914| train loss i: [0.06	1.36	5.65	5.02	3.85	1.51] test loss i: [0.07	1.51	6.46	5.32	4.56	1.62] | 
| 05-02 01:30:19 epoch: 1915| time: 1.1s| train loss: +1.637e+01 | test loss: +1.733e+01 | 
| 05-02 01:30:19 epoch: 1915| train loss i: [0.07	0.95	5.27	4.47	4.05	1.55] test loss i: [0.04	0.17	5.36	5.67	4.08	2.01] | 
| 05-02 01:30:20 epoch: 1916| time: 1.0s| train loss: +1.609e+01 | test loss: +1.565e+01 | 
| 05-02 01:30:20 epoch: 1916| train loss i: [0.1 	1.17	4.7 	4.73	3.83	1.57] test loss i: [0.1 	0.08	5.7 	4.05	3.79	1.93] | 
| 05-02 01:30:21 epoch: 1917| time: 1.0s| train loss: +1.673e+01 | test loss: +1.631e+01 | 
| 05-02 01:30:21 epoch: 1917| train loss i: [0.09	1.23	5.49	4.59	3.81	1.5 ] test loss i: [0.12	0.98	5.43	4.4 	3.85	1.51] | 
| 05-02 01:30:22 epoch: 1918| time: 1.1s| train loss: +1.676e+01 | test loss: +2.420e+01 | 
| 05-02 01:30:22 epoch: 1918| train loss i: [0.1 	1.01	5.29	5.11	3.62	1.63] test loss i: [0.04	0.85	8.38	7.09	5.9 	1.95] | 
| 05-02 01:30:23 epoch: 1919| time: 1.1s| train loss: +1.803e+01 | test loss: +1.798e+01 | 
| 05-02 01:30:23 epoch: 1919| train loss i: [0.13	1.6 	5.19	5.45	4.13	1.53] test loss i: [0.14	1.04	4.67	4.83	5.4 	1.9 ] | 
| 05-02 01:30:24 epoch: 1920| time: 1.1s| train loss: +1.762e+01 | test loss: +1.822e+01 | 
| 05-02 01:30:24 epoch: 1920| train loss i: [0.11	1.37	5.97	4.79	3.74	1.64] test loss i: [0.09	3.21	5.48	4.44	3.6 	1.4 ] | 
| 05-02 01:30:25 epoch: 1921| time: 1.1s| train loss: +1.788e+01 | test loss: +1.605e+01 | 
| 05-02 01:30:25 epoch: 1921| train loss i: [0.14	1.52	6.02	4.81	3.9 	1.49] test loss i: [0.11	1.42	5.73	3.86	3.37	1.57] | 
| 05-02 01:30:26 epoch: 1922| time: 1.0s| train loss: +1.740e+01 | test loss: +2.022e+01 | 
| 05-02 01:30:26 epoch: 1922| train loss i: [0.09	1.29	5.9 	4.82	3.73	1.59] test loss i: [0.08	3.23	5.55	5.08	4.51	1.76] | 
| 05-02 01:30:27 epoch: 1923| time: 1.0s| train loss: +1.634e+01 | test loss: +1.950e+01 | 
| 05-02 01:30:27 epoch: 1923| train loss i: [0.13	0.72	5.17	4.73	4.07	1.52] test loss i: [0.29	2.43	6.09	5.1 	3.83	1.76] | 
| 05-02 01:30:28 epoch: 1924| time: 1.1s| train loss: +1.752e+01 | test loss: +2.296e+01 | 
| 05-02 01:30:28 epoch: 1924| train loss i: [0.1 	1.46	5.85	4.79	3.64	1.68] test loss i: [0.25	1.89	7.6 	6.07	5.09	2.05] | 
| 05-02 01:30:29 epoch: 1925| time: 1.1s| train loss: +1.696e+01 | test loss: +1.784e+01 | 
| 05-02 01:30:29 epoch: 1925| train loss i: [0.13	1.25	5.47	4.85	3.71	1.55] test loss i: [0.08	1.18	6.3 	4.87	3.69	1.72] | 
| 05-02 01:30:31 epoch: 1926| time: 1.1s| train loss: +1.840e+01 | test loss: +2.010e+01 | 
| 05-02 01:30:31 epoch: 1926| train loss i: [0.1 	2.01	5.71	5.1 	3.9 	1.57] test loss i: [0.14	1.61	6.47	4.78	5.22	1.89] | 
| 05-02 01:30:32 epoch: 1927| time: 1.1s| train loss: +1.698e+01 | test loss: +2.077e+01 | 
| 05-02 01:30:32 epoch: 1927| train loss i: [0.07	1.37	5.44	5.03	3.53	1.54] test loss i: [0.14	2.08	6.79	5.45	4.38	1.94] | 
| 05-02 01:30:33 epoch: 1928| time: 1.1s| train loss: +1.664e+01 | test loss: +1.612e+01 | 
| 05-02 01:30:33 epoch: 1928| train loss i: [0.07	1.1 	5.71	4.5 	3.71	1.55] test loss i: [0.06	1.8 	4.15	5.3 	3.4 	1.41] | 
| 05-02 01:30:34 epoch: 1929| time: 1.0s| train loss: +1.745e+01 | test loss: +1.702e+01 | 
| 05-02 01:30:34 epoch: 1929| train loss i: [0.1 	1.74	5.23	4.84	4.01	1.52] test loss i: [0.13	2.13	4.84	4.2 	4.23	1.48] | 
| 05-02 01:30:35 epoch: 1930| time: 1.1s| train loss: +1.763e+01 | test loss: +1.561e+01 | 
| 05-02 01:30:35 epoch: 1930| train loss i: [0.07	2.17	5.49	4.66	3.63	1.62] test loss i: [0.27	0.55	5.22	4.22	3.92	1.43] | 
| 05-02 01:30:36 epoch: 1931| time: 1.1s| train loss: +1.592e+01 | test loss: +1.780e+01 | 
| 05-02 01:30:36 epoch: 1931| train loss i: [0.08	0.59	5.04	4.86	3.79	1.55] test loss i: [0.06	0.57	5.49	5.63	4.28	1.76] | 
| 05-02 01:30:37 epoch: 1932| time: 1.1s| train loss: +1.702e+01 | test loss: +2.028e+01 | 
| 05-02 01:30:37 epoch: 1932| train loss i: [0.06	1.57	5.38	4.5 	3.97	1.54] test loss i: [0.25	2.81	4.97	5.91	4.58	1.76] | 
| 05-02 01:30:38 epoch: 1933| time: 1.1s| train loss: +1.747e+01 | test loss: +1.916e+01 | 
| 05-02 01:30:38 epoch: 1933| train loss i: [0.05	1.67	5.35	5.05	3.78	1.57] test loss i: [0.07	2.33	6.38	4.76	3.7 	1.93] | 
| 05-02 01:30:39 epoch: 1934| time: 1.1s| train loss: +1.788e+01 | test loss: +1.533e+01 | 
| 05-02 01:30:39 epoch: 1934| train loss i: [0.06	1.67	5.6 	5.25	3.68	1.62] test loss i: [0.09	0.99	5.08	3.92	3.53	1.72] | 
| 05-02 01:30:40 epoch: 1935| time: 1.0s| train loss: +1.615e+01 | test loss: +1.836e+01 | 
| 05-02 01:30:40 epoch: 1935| train loss i: [0.07	1.05	5.31	4.42	3.79	1.51] test loss i: [0.09	2.06	5.47	4.61	4.37	1.76] | 
| 05-02 01:30:41 epoch: 1936| time: 1.0s| train loss: +1.631e+01 | test loss: +2.068e+01 | 
| 05-02 01:30:41 epoch: 1936| train loss i: [0.08	1.01	5.18	4.74	3.75	1.55] test loss i: [0.07	1.38	7.72	5.51	4.43	1.58] | 
| 05-02 01:30:42 epoch: 1937| time: 1.0s| train loss: +1.692e+01 | test loss: +1.632e+01 | 
| 05-02 01:30:42 epoch: 1937| train loss i: [0.09	1.46	5.31	4.63	3.86	1.57] test loss i: [0.04	1.12	6.96	3.68	3.06	1.46] | 
| 05-02 01:30:43 epoch: 1938| time: 1.1s| train loss: +1.727e+01 | test loss: +1.998e+01 | 
| 05-02 01:30:43 epoch: 1938| train loss i: [0.08	1.8 	5.  	5.19	3.64	1.55] test loss i: [0.13	1.97	6.07	5.97	3.87	1.97] | 
| 05-02 01:30:44 epoch: 1939| time: 1.1s| train loss: +1.704e+01 | test loss: +1.714e+01 | 
| 05-02 01:30:44 epoch: 1939| train loss i: [0.14	1.11	5.24	5.01	4.01	1.53] test loss i: [0.06	1.3 	5.17	4.87	3.88	1.86] | 
| 05-02 01:30:46 epoch: 1940| time: 1.1s| train loss: +1.654e+01 | test loss: +1.633e+01 | 
| 05-02 01:30:46 epoch: 1940| train loss i: [0.09	1.37	5.12	4.55	3.95	1.46] test loss i: [0.1 	0.36	5.26	4.85	3.94	1.83] | 
| 05-02 01:30:47 epoch: 1941| time: 1.0s| train loss: +1.761e+01 | test loss: +1.782e+01 | 
| 05-02 01:30:47 epoch: 1941| train loss i: [0.1 	1.5 	5.81	4.87	3.83	1.49] test loss i: [0.25	2.58	6.06	3.9 	3.26	1.77] | 
| 05-02 01:30:48 epoch: 1942| time: 1.0s| train loss: +1.672e+01 | test loss: +2.374e+01 | 
| 05-02 01:30:48 epoch: 1942| train loss i: [0.12	1.56	4.65	4.91	3.94	1.53] test loss i: [0.32	1.  	7.65	7.48	5.19	2.09] | 
| 05-02 01:30:49 epoch: 1943| time: 1.1s| train loss: +1.718e+01 | test loss: +1.549e+01 | 
| 05-02 01:30:49 epoch: 1943| train loss i: [0.05	1.63	5.34	4.92	3.68	1.55] test loss i: [0.04	0.28	5.28	4.54	3.77	1.58] | 
| 05-02 01:30:50 epoch: 1944| time: 1.1s| train loss: +1.691e+01 | test loss: +1.613e+01 | 
| 05-02 01:30:50 epoch: 1944| train loss i: [0.06	1.34	5.27	4.77	3.88	1.58] test loss i: [0.12	0.29	5.53	4.7 	3.72	1.77] | 
| 05-02 01:30:51 epoch: 1945| time: 1.1s| train loss: +1.650e+01 | test loss: +1.786e+01 | 
| 05-02 01:30:51 epoch: 1945| train loss i: [0.07	0.99	5.43	4.91	3.56	1.54] test loss i: [0.08	2.04	4.73	5.69	3.73	1.59] | 
| 05-02 01:30:52 epoch: 1946| time: 1.1s| train loss: +1.707e+01 | test loss: +1.719e+01 | 
| 05-02 01:30:52 epoch: 1946| train loss i: [0.08	1.26	5.76	4.5 	3.89	1.58] test loss i: [0.08	2.43	4.64	4.67	3.58	1.8 ] | 
| 05-02 01:30:53 epoch: 1947| time: 1.0s| train loss: +1.741e+01 | test loss: +1.484e+01 | 
| 05-02 01:30:53 epoch: 1947| train loss i: [0.08	1.62	5.37	4.84	3.97	1.52] test loss i: [0.09	0.35	4.58	4.88	3.23	1.71] | 
| 05-02 01:30:54 epoch: 1948| time: 1.0s| train loss: +1.674e+01 | test loss: +1.788e+01 | 
| 05-02 01:30:54 epoch: 1948| train loss i: [0.06	1.41	5.47	4.41	3.84	1.54] test loss i: [0.06	3.22	4.12	4.84	3.81	1.83] | 
| 05-02 01:30:55 epoch: 1949| time: 1.0s| train loss: +1.803e+01 | test loss: +1.318e+01 | 
| 05-02 01:30:55 epoch: 1949| train loss i: [0.1 	1.64	5.86	5.16	3.68	1.59] test loss i: [0.11	0.75	4.08	3.55	3.33	1.35] | 
| 05-02 01:30:56 epoch: 1950| time: 1.1s| train loss: +1.826e+01 | test loss: +1.956e+01 | 
| 05-02 01:30:56 epoch: 1950| train loss i: [0.06	2.03	6.35	4.58	3.66	1.58] test loss i: [0.12	1.87	6.19	5.19	4.1 	2.08] | 
| 05-02 01:30:57 epoch: 1951| time: 1.1s| train loss: +1.671e+01 | test loss: +1.546e+01 | 
| 05-02 01:30:57 epoch: 1951| train loss i: [0.07	1.77	4.87	4.73	3.75	1.52] test loss i: [0.08	1.11	5.14	4.04	3.45	1.65] | 
| 05-02 01:30:58 epoch: 1952| time: 1.1s| train loss: +1.749e+01 | test loss: +1.791e+01 | 
| 05-02 01:30:58 epoch: 1952| train loss i: [0.08	1.84	5.02	5.16	3.81	1.58] test loss i: [0.1 	0.64	6.06	4.6 	4.45	2.07] | 
| 05-02 01:30:59 epoch: 1953| time: 1.1s| train loss: +1.642e+01 | test loss: +2.428e+01 | 
| 05-02 01:30:59 epoch: 1953| train loss i: [0.09	1.48	4.94	4.77	3.59	1.54] test loss i: [0.2 	4.29	7.61	5.5 	4.25	2.44] | 
| 05-02 01:31:01 epoch: 1954| time: 1.0s| train loss: +1.686e+01 | test loss: +2.494e+01 | 
| 05-02 01:31:01 epoch: 1954| train loss i: [0.1 	1.34	5.14	5.  	3.72	1.56] test loss i: [0.17	2.94	7.86	7.13	4.89	1.94] | 
| 05-02 01:31:02 epoch: 1955| time: 1.1s| train loss: +1.733e+01 | test loss: +1.756e+01 | 
| 05-02 01:31:02 epoch: 1955| train loss i: [0.07	1.32	5.34	5.05	4.02	1.53] test loss i: [0.07	1.62	5.46	5.16	3.46	1.79] | 
| 05-02 01:31:03 epoch: 1956| time: 1.1s| train loss: +1.748e+01 | test loss: +2.246e+01 | 
| 05-02 01:31:03 epoch: 1956| train loss i: [0.06	1.75	5.75	4.61	3.85	1.46] test loss i: [0.13	1.56	6.3 	7.09	5.3 	2.08] | 
| 05-02 01:31:04 epoch: 1957| time: 1.1s| train loss: +1.618e+01 | test loss: +2.538e+01 | 
| 05-02 01:31:04 epoch: 1957| train loss i: [0.06	1.31	5.11	4.42	3.81	1.47] test loss i: [0.1 	3.55	6.8 	7.08	5.73	2.12] | 
| 05-02 01:31:05 epoch: 1958| time: 1.1s| train loss: +1.712e+01 | test loss: +1.764e+01 | 
| 05-02 01:31:05 epoch: 1958| train loss i: [0.09	1.36	5.47	4.64	3.98	1.57] test loss i: [0.06	0.48	5.76	5.92	3.68	1.74] | 
| 05-02 01:31:06 epoch: 1959| time: 1.1s| train loss: +1.661e+01 | test loss: +1.861e+01 | 
| 05-02 01:31:06 epoch: 1959| train loss i: [0.11	1.21	5.28	4.75	3.64	1.62] test loss i: [0.1 	2.38	5.85	4.6 	3.68	2.  ] | 
| 05-02 01:31:07 epoch: 1960| time: 1.1s| train loss: +1.738e+01 | test loss: +1.739e+01 | 
| 05-02 01:31:07 epoch: 1960| train loss i: [0.08	1.41	5.77	4.87	3.87	1.39] test loss i: [0.09	1.68	5.64	4.4 	3.82	1.75] | 
| 05-02 01:31:08 epoch: 1961| time: 1.1s| train loss: +1.685e+01 | test loss: +1.485e+01 | 
| 05-02 01:31:08 epoch: 1961| train loss i: [0.12	1.5 	5.38	4.91	3.4 	1.55] test loss i: [0.1 	0.59	4.1 	4.55	3.97	1.54] | 
| 05-02 01:31:09 epoch: 1962| time: 1.0s| train loss: +1.702e+01 | test loss: +2.539e+01 | 
| 05-02 01:31:09 epoch: 1962| train loss i: [0.14	1.37	5.45	4.81	3.65	1.6 ] test loss i: [0.07	3.91	8.28	6.47	4.59	2.09] | 
| 05-02 01:31:10 epoch: 1963| time: 1.1s| train loss: +1.729e+01 | test loss: +2.219e+01 | 
| 05-02 01:31:10 epoch: 1963| train loss i: [0.16	1.75	5.29	4.89	3.62	1.58] test loss i: [0.06	0.8 	7.52	6.92	4.63	2.25] | 
| 05-02 01:31:11 epoch: 1964| time: 1.1s| train loss: +1.725e+01 | test loss: +1.934e+01 | 
| 05-02 01:31:11 epoch: 1964| train loss i: [0.07	1.58	5.42	5.03	3.61	1.53] test loss i: [0.05	1.11	5.65	5.39	5.26	1.88] | 
| 05-02 01:31:12 epoch: 1965| time: 1.1s| train loss: +1.635e+01 | test loss: +1.749e+01 | 
| 05-02 01:31:12 epoch: 1965| train loss i: [0.07	1.25	5.19	4.61	3.75	1.48] test loss i: [0.15	1.19	6.55	4.26	3.53	1.82] | 
| 05-02 01:31:13 epoch: 1966| time: 1.1s| train loss: +1.635e+01 | test loss: +1.328e+01 | 
| 05-02 01:31:13 epoch: 1966| train loss i: [0.06	0.98	5.22	4.48	4.05	1.56] test loss i: [0.04	0.44	4.49	3.38	3.53	1.4 ] | 
| 05-02 01:31:14 epoch: 1967| time: 1.1s| train loss: +1.678e+01 | test loss: +1.689e+01 | 
| 05-02 01:31:14 epoch: 1967| train loss i: [0.13	1.09	5.46	4.77	3.78	1.55] test loss i: [0.05	1.19	5.59	4.9 	3.53	1.63] | 
| 05-02 01:31:16 epoch: 1968| time: 1.0s| train loss: +1.790e+01 | test loss: +1.715e+01 | 
| 05-02 01:31:16 epoch: 1968| train loss i: [0.12	1.63	5.41	5.15	3.96	1.64] test loss i: [0.06	2.56	5.  	4.18	3.77	1.58] | 
| 05-02 01:31:17 epoch: 1969| time: 1.0s| train loss: +1.639e+01 | test loss: +2.356e+01 | 
| 05-02 01:31:17 epoch: 1969| train loss i: [0.1 	1.37	5.1 	4.51	3.73	1.57] test loss i: [0.46	2.05	7.43	6.44	5.42	1.76] | 
| 05-02 01:31:18 epoch: 1970| time: 1.1s| train loss: +1.684e+01 | test loss: +2.103e+01 | 
| 05-02 01:31:18 epoch: 1970| train loss i: [0.1 	0.98	5.33	4.92	4.  	1.5 ] test loss i: [0.12	2.24	6.39	5.94	4.49	1.85] | 
| 05-02 01:31:19 epoch: 1971| time: 1.1s| train loss: +1.694e+01 | test loss: +1.684e+01 | 
| 05-02 01:31:19 epoch: 1971| train loss i: [0.09	1.23	5.56	4.93	3.59	1.53] test loss i: [0.05	1.09	5.21	5.46	3.54	1.49] | 
| 05-02 01:31:20 epoch: 1972| time: 1.1s| train loss: +1.623e+01 | test loss: +2.049e+01 | 
| 05-02 01:31:20 epoch: 1972| train loss i: [0.1 	1.08	5.02	4.93	3.54	1.56] test loss i: [0.11	2.65	5.16	5.85	4.49	2.24] | 
| 05-02 01:31:21 epoch: 1973| time: 1.1s| train loss: +1.662e+01 | test loss: +1.928e+01 | 
| 05-02 01:31:21 epoch: 1973| train loss i: [0.12	1.06	5.34	4.63	3.92	1.56] test loss i: [0.06	0.5 	6.36	6.02	4.22	2.11] | 
| 05-02 01:31:22 epoch: 1974| time: 1.1s| train loss: +1.724e+01 | test loss: +1.743e+01 | 
| 05-02 01:31:22 epoch: 1974| train loss i: [0.09	0.96	5.57	4.95	4.11	1.57] test loss i: [0.1 	0.94	5.61	5.24	3.73	1.81] | 
| 05-02 01:31:23 epoch: 1975| time: 1.1s| train loss: +1.711e+01 | test loss: +1.557e+01 | 
| 05-02 01:31:23 epoch: 1975| train loss i: [0.13	1.72	5.15	5.14	3.46	1.51] test loss i: [0.06	0.54	4.69	5.53	3.09	1.67] | 
| 05-02 01:31:24 epoch: 1976| time: 1.0s| train loss: +1.762e+01 | test loss: +1.855e+01 | 
| 05-02 01:31:24 epoch: 1976| train loss i: [0.1 	1.31	6.11	4.78	3.76	1.55] test loss i: [0.63	2.12	5.89	4.57	3.89	1.44] | 
| 05-02 01:31:25 epoch: 1977| time: 1.0s| train loss: +1.661e+01 | test loss: +1.955e+01 | 
| 05-02 01:31:25 epoch: 1977| train loss i: [0.08	1.26	5.01	4.71	3.9 	1.65] test loss i: [0.08	2.84	5.21	5.32	4.22	1.88] | 
| 05-02 01:31:26 epoch: 1978| time: 1.0s| train loss: +1.709e+01 | test loss: +1.523e+01 | 
| 05-02 01:31:26 epoch: 1978| train loss i: [0.07	1.31	5.05	5.39	3.66	1.62] test loss i: [0.12	0.55	5.35	4.27	3.36	1.58] | 
| 05-02 01:31:27 epoch: 1979| time: 1.1s| train loss: +1.704e+01 | test loss: +1.493e+01 | 
| 05-02 01:31:27 epoch: 1979| train loss i: [0.05	1.32	5.43	4.72	3.98	1.54] test loss i: [0.04	1.12	4.87	3.59	3.62	1.67] | 
| 05-02 01:31:28 epoch: 1980| time: 1.1s| train loss: +1.730e+01 | test loss: +1.575e+01 | 
| 05-02 01:31:28 epoch: 1980| train loss i: [0.05	1.52	5.26	4.74	4.1 	1.62] test loss i: [0.03	0.89	4.59	4.87	3.83	1.55] | 
| 05-02 01:31:29 epoch: 1981| time: 1.1s| train loss: +1.635e+01 | test loss: +1.884e+01 | 
| 05-02 01:31:29 epoch: 1981| train loss i: [0.04	1.28	4.54	5.04	3.85	1.61] test loss i: [0.1 	0.81	7.18	4.95	3.89	1.91] | 
| 05-02 01:31:31 epoch: 1982| time: 1.1s| train loss: +1.605e+01 | test loss: +1.605e+01 | 
| 05-02 01:31:31 epoch: 1982| train loss i: [0.05	1.13	5.06	4.58	3.64	1.59] test loss i: [0.06	0.74	4.61	5.47	3.48	1.69] | 
| 05-02 01:31:32 epoch: 1983| time: 1.1s| train loss: +1.733e+01 | test loss: +1.483e+01 | 
| 05-02 01:31:32 epoch: 1983| train loss i: [0.07	1.25	5.73	4.59	4.12	1.55] test loss i: [0.18	0.49	4.68	4.19	3.69	1.59] | 
| 05-02 01:31:33 epoch: 1984| time: 1.1s| train loss: +1.738e+01 | test loss: +1.812e+01 | 
| 05-02 01:31:33 epoch: 1984| train loss i: [0.09	1.6 	5.4 	4.9 	3.85	1.54] test loss i: [0.05	2.79	4.55	5.07	4.07	1.6 ] | 
| 05-02 01:31:34 epoch: 1985| time: 1.1s| train loss: +1.771e+01 | test loss: +1.697e+01 | 
| 05-02 01:31:34 epoch: 1985| train loss i: [0.09	1.  	6.19	4.92	3.94	1.56] test loss i: [0.17	2.25	4.78	4.32	3.83	1.62] | 
| 05-02 01:31:35 epoch: 1986| time: 1.1s| train loss: +1.706e+01 | test loss: +1.407e+01 | 
| 05-02 01:31:35 epoch: 1986| train loss i: [0.11	0.86	5.64	5.07	3.87	1.51] test loss i: [0.19	0.53	4.82	3.9 	3.17	1.45] | 
| 05-02 01:31:36 epoch: 1987| time: 1.1s| train loss: +1.796e+01 | test loss: +2.132e+01 | 
| 05-02 01:31:36 epoch: 1987| train loss i: [0.1 	1.88	5.81	4.83	3.82	1.53] test loss i: [0.08	2.44	6.36	6.09	4.65	1.7 ] | 
| 05-02 01:31:37 epoch: 1988| time: 1.0s| train loss: +1.739e+01 | test loss: +1.756e+01 | 
| 05-02 01:31:37 epoch: 1988| train loss i: [0.08	1.43	5.61	4.94	3.8 	1.53] test loss i: [0.04	2.3 	5.38	4.71	3.3 	1.83] | 
| 05-02 01:31:38 epoch: 1989| time: 1.1s| train loss: +1.681e+01 | test loss: +1.554e+01 | 
| 05-02 01:31:38 epoch: 1989| train loss i: [0.26	1.06	5.82	4.41	3.79	1.48] test loss i: [0.08	0.81	5.13	4.44	3.52	1.55] | 
| 05-02 01:31:39 epoch: 1990| time: 1.1s| train loss: +1.628e+01 | test loss: +1.476e+01 | 
| 05-02 01:31:39 epoch: 1990| train loss i: [0.07	0.77	5.45	4.75	3.72	1.52] test loss i: [0.07	0.79	5.05	4.2 	3.11	1.54] | 
| 05-02 01:31:40 epoch: 1991| time: 1.1s| train loss: +1.701e+01 | test loss: +1.802e+01 | 
| 05-02 01:31:40 epoch: 1991| train loss i: [0.07	1.53	5.18	4.85	3.81	1.56] test loss i: [0.08	2.  	6.05	4.73	3.64	1.52] | 
| 05-02 01:31:41 epoch: 1992| time: 1.1s| train loss: +1.684e+01 | test loss: +1.463e+01 | 
| 05-02 01:31:41 epoch: 1992| train loss i: [0.07	1.19	4.91	5.43	3.64	1.61] test loss i: [0.11	1.27	4.32	4.06	3.36	1.52] | 
| 05-02 01:31:42 epoch: 1993| time: 1.0s| train loss: +1.782e+01 | test loss: +1.769e+01 | 
| 05-02 01:31:42 epoch: 1993| train loss i: [0.12	2.07	4.97	4.95	4.07	1.64] test loss i: [0.22	2.9 	4.86	4.33	3.38	2.  ] | 
| 05-02 01:31:43 epoch: 1994| time: 1.0s| train loss: +1.740e+01 | test loss: +2.031e+01 | 
| 05-02 01:31:43 epoch: 1994| train loss i: [0.11	1.26	5.67	5.02	3.78	1.55] test loss i: [0.25	2.42	6.84	4.85	4.09	1.85] | 
| 05-02 01:31:44 epoch: 1995| time: 1.1s| train loss: +1.750e+01 | test loss: +1.725e+01 | 
| 05-02 01:31:44 epoch: 1995| train loss i: [0.11	1.56	5.62	4.77	3.94	1.51] test loss i: [0.08	0.85	6.26	4.41	3.86	1.79] | 
| 05-02 01:31:45 epoch: 1996| time: 1.1s| train loss: +1.607e+01 | test loss: +1.599e+01 | 
| 05-02 01:31:45 epoch: 1996| train loss i: [0.09	1.26	5.17	4.6 	3.44	1.51] test loss i: [0.07	1.24	5.  	4.22	3.86	1.6 ] | 
| 05-02 01:31:47 epoch: 1997| time: 1.1s| train loss: +1.778e+01 | test loss: +2.065e+01 | 
| 05-02 01:31:47 epoch: 1997| train loss i: [0.1 	1.3 	5.92	4.86	3.98	1.61] test loss i: [0.16	1.16	6.33	6.54	4.53	1.92] | 
| 05-02 01:31:48 epoch: 1998| time: 1.1s| train loss: +1.716e+01 | test loss: +1.842e+01 | 
| 05-02 01:31:48 epoch: 1998| train loss i: [0.09	1.25	5.53	4.73	3.98	1.58] test loss i: [0.08	1.12	7.09	4.61	3.79	1.73] | 
| 05-02 01:31:49 epoch: 1999| time: 1.1s| train loss: +1.723e+01 | test loss: +2.541e+01 | 
| 05-02 01:31:49 epoch: 1999| train loss i: [0.06	1.42	5.53	5.21	3.49	1.51] test loss i: [0.09	2.12	9.07	6.52	5.39	2.23] | 
| 05-02 01:31:50 epoch: 2000| time: 1.0s| train loss: +1.603e+01 | test loss: +1.531e+01 | 
| 05-02 01:31:50 epoch: 2000| train loss i: [0.08	0.96	4.84	4.76	3.79	1.62] test loss i: [0.11	0.85	5.05	4.66	3.26	1.37] | 
| 05-02 01:31:51 epoch: 2001| time: 1.1s| train loss: +1.705e+01 | test loss: +1.645e+01 | 
| 05-02 01:31:51 epoch: 2001| train loss i: [0.06	1.33	5.48	4.76	3.85	1.58] test loss i: [0.12	0.67	5.43	4.54	4.17	1.53] | 
| 05-02 01:31:52 epoch: 2002| time: 1.1s| train loss: +1.687e+01 | test loss: +2.021e+01 | 
| 05-02 01:31:52 epoch: 2002| train loss i: [0.06	1.12	5.64	4.7 	3.82	1.54] test loss i: [0.09	0.78	6.92	6.29	4.16	1.96] | 
| 05-02 01:31:53 epoch: 2003| time: 1.1s| train loss: +1.605e+01 | test loss: +1.790e+01 | 
| 05-02 01:31:53 epoch: 2003| train loss i: [0.12	1.24	4.56	4.71	3.88	1.54] test loss i: [0.26	0.81	4.74	4.88	5.13	2.09] | 
| 05-02 01:31:54 epoch: 2004| time: 1.0s| train loss: +1.687e+01 | test loss: +1.963e+01 | 
| 05-02 01:31:54 epoch: 2004| train loss i: [0.07	1.34	5.18	5.01	3.74	1.53] test loss i: [0.07	3.96	4.98	4.75	4.15	1.72] | 
| 05-02 01:31:55 epoch: 2005| time: 1.0s| train loss: +1.766e+01 | test loss: +1.602e+01 | 
| 05-02 01:31:55 epoch: 2005| train loss i: [0.05	1.52	6.04	4.76	3.74	1.55] test loss i: [0.09	1.43	5.28	3.5 	4.03	1.7 ] | 
| 05-02 01:31:56 epoch: 2006| time: 1.1s| train loss: +1.671e+01 | test loss: +1.700e+01 | 
| 05-02 01:31:56 epoch: 2006| train loss i: [0.07	1.22	5.04	4.94	3.87	1.57] test loss i: [0.1 	1.03	6.31	3.88	3.87	1.81] | 
| 05-02 01:31:57 epoch: 2007| time: 1.1s| train loss: +1.661e+01 | test loss: +2.084e+01 | 
| 05-02 01:31:57 epoch: 2007| train loss i: [0.06	1.36	5.24	4.62	3.78	1.55] test loss i: [0.1 	1.78	6.43	5.92	4.78	1.85] | 
| 05-02 01:31:58 epoch: 2008| time: 1.1s| train loss: +1.722e+01 | test loss: +1.640e+01 | 
| 05-02 01:31:58 epoch: 2008| train loss i: [0.09	1.09	5.65	4.95	3.87	1.58] test loss i: [0.04	0.8 	5.03	5.54	3.51	1.48] | 
| 05-02 01:31:59 epoch: 2009| time: 1.1s| train loss: +1.740e+01 | test loss: +2.019e+01 | 
| 05-02 01:31:59 epoch: 2009| train loss i: [0.08	1.81	5.13	4.9 	3.81	1.67] test loss i: [0.09	1.51	6.93	5.57	4.15	1.95] | 
| 05-02 01:32:00 epoch: 2010| time: 1.0s| train loss: +1.635e+01 | test loss: +2.123e+01 | 
| 05-02 01:32:00 epoch: 2010| train loss i: [0.09	1.04	5.04	4.67	3.89	1.63] test loss i: [0.23	2.31	6.24	5.72	4.48	2.25] | 
| 05-02 01:32:01 epoch: 2011| time: 1.1s| train loss: +1.778e+01 | test loss: +2.301e+01 | 
| 05-02 01:32:01 epoch: 2011| train loss i: [0.1 	1.59	5.85	4.73	3.97	1.54] test loss i: [0.35	2.9 	7.49	5.27	4.84	2.16] | 
| 05-02 01:32:03 epoch: 2012| time: 1.1s| train loss: +1.690e+01 | test loss: +1.504e+01 | 
| 05-02 01:32:03 epoch: 2012| train loss i: [0.1 	1.16	5.67	4.76	3.63	1.57] test loss i: [0.06	1.38	4.51	4.4 	3.1 	1.6 ] | 
| 05-02 01:32:04 epoch: 2013| time: 1.1s| train loss: +1.673e+01 | test loss: +1.840e+01 | 
| 05-02 01:32:04 epoch: 2013| train loss i: [0.07	1.35	4.81	5.08	3.83	1.6 ] test loss i: [0.05	3.16	5.01	4.69	3.58	1.91] | 
| 05-02 01:32:05 epoch: 2014| time: 1.1s| train loss: +1.699e+01 | test loss: +1.950e+01 | 
| 05-02 01:32:05 epoch: 2014| train loss i: [0.05	1.51	5.52	4.66	3.72	1.52] test loss i: [0.04	3.43	5.69	4.82	3.7 	1.82] | 
| 05-02 01:32:06 epoch: 2015| time: 1.0s| train loss: +1.772e+01 | test loss: +1.769e+01 | 
| 05-02 01:32:06 epoch: 2015| train loss i: [0.07	1.52	5.68	5.04	3.85	1.56] test loss i: [0.05	1.21	5.91	5.37	3.43	1.72] | 
| 05-02 01:32:07 epoch: 2016| time: 1.0s| train loss: +1.642e+01 | test loss: +1.795e+01 | 
| 05-02 01:32:07 epoch: 2016| train loss i: [0.07	1.33	4.68	4.9 	3.94	1.5 ] test loss i: [0.16	2.06	5.36	4.39	4.37	1.6 ] | 
| 05-02 01:32:08 epoch: 2017| time: 1.1s| train loss: +1.705e+01 | test loss: +1.802e+01 | 
| 05-02 01:32:08 epoch: 2017| train loss i: [0.08	1.52	5.43	4.83	3.64	1.55] test loss i: [0.07	1.73	6.28	3.99	4.35	1.6 ] | 
| 05-02 01:32:09 epoch: 2018| time: 1.1s| train loss: +1.650e+01 | test loss: +1.883e+01 | 
| 05-02 01:32:09 epoch: 2018| train loss i: [0.1 	1.39	5.2 	4.69	3.53	1.59] test loss i: [0.21	1.64	5.9 	5.39	3.97	1.72] | 
| 05-02 01:32:10 epoch: 2019| time: 1.1s| train loss: +1.635e+01 | test loss: +1.861e+01 | 
| 05-02 01:32:10 epoch: 2019| train loss i: [0.07	1.2 	5.09	4.39	4.03	1.57] test loss i: [0.11	0.81	7.22	4.79	3.74	1.92] | 
| 05-02 01:32:11 epoch: 2020| time: 1.1s| train loss: +1.726e+01 | test loss: +2.573e+01 | 
| 05-02 01:32:11 epoch: 2020| train loss i: [0.07	1.17	5.32	4.85	4.29	1.56] test loss i: [0.13	2.41	8.69	6.96	5.58	1.96] | 
| 05-02 01:32:12 epoch: 2021| time: 1.0s| train loss: +1.767e+01 | test loss: +1.826e+01 | 
| 05-02 01:32:12 epoch: 2021| train loss i: [0.08	1.41	5.87	5.07	3.63	1.61] test loss i: [0.05	1.88	5.93	4.82	3.94	1.64] | 
| 05-02 01:32:13 epoch: 2022| time: 1.1s| train loss: +1.654e+01 | test loss: +2.078e+01 | 
| 05-02 01:32:13 epoch: 2022| train loss i: [0.09	1.35	5.18	4.56	3.88	1.47] test loss i: [0.09	1.83	6.13	6.69	4.34	1.7 ] | 
| 05-02 01:32:14 epoch: 2023| time: 1.1s| train loss: +1.728e+01 | test loss: +1.579e+01 | 
| 05-02 01:32:14 epoch: 2023| train loss i: [0.09	1.88	5.17	4.75	3.78	1.6 ] test loss i: [0.06	0.8 	5.42	4.85	3.15	1.51] | 
| 05-02 01:32:15 epoch: 2024| time: 1.1s| train loss: +1.601e+01 | test loss: +2.121e+01 | 
| 05-02 01:32:15 epoch: 2024| train loss i: [0.08	1.03	4.77	4.65	3.96	1.51] test loss i: [0.07	2.49	6.12	5.24	5.31	1.99] | 
| 05-02 01:32:16 epoch: 2025| time: 1.1s| train loss: +1.619e+01 | test loss: +2.433e+01 | 
| 05-02 01:32:16 epoch: 2025| train loss i: [0.06	0.99	5.25	4.77	3.55	1.55] test loss i: [0.17	2.82	7.07	6.37	5.73	2.18] | 
| 05-02 01:32:17 epoch: 2026| time: 1.0s| train loss: +1.761e+01 | test loss: +1.797e+01 | 
| 05-02 01:32:17 epoch: 2026| train loss i: [0.06	1.51	5.55	5.21	3.8 	1.47] test loss i: [0.07	0.34	6.81	5.01	4.15	1.58] | 
| 05-02 01:32:18 epoch: 2027| time: 1.1s| train loss: +1.653e+01 | test loss: +2.524e+01 | 
| 05-02 01:32:18 epoch: 2027| train loss i: [0.09	0.97	5.27	5.  	3.59	1.61] test loss i: [0.2 	5.2 	5.54	7.51	4.67	2.11] | 
| 05-02 01:32:20 epoch: 2028| time: 1.1s| train loss: +1.688e+01 | test loss: +1.785e+01 | 
| 05-02 01:32:20 epoch: 2028| train loss i: [0.05	1.35	5.37	4.84	3.79	1.47] test loss i: [0.04	2.08	5.14	4.93	3.92	1.74] | 
| 05-02 01:32:21 epoch: 2029| time: 1.1s| train loss: +1.705e+01 | test loss: +1.394e+01 | 
| 05-02 01:32:21 epoch: 2029| train loss i: [0.05	1.05	5.83	5.01	3.49	1.62] test loss i: [0.06	1.91	3.35	3.8 	3.43	1.4 ] | 
| 05-02 01:32:22 epoch: 2030| time: 1.1s| train loss: +1.702e+01 | test loss: +2.189e+01 | 
| 05-02 01:32:22 epoch: 2030| train loss i: [0.05	1.06	5.6 	4.84	3.95	1.52] test loss i: [0.06	1.46	6.69	6.33	5.41	1.94] | 
| 05-02 01:32:23 epoch: 2031| time: 1.0s| train loss: +1.697e+01 | test loss: +1.563e+01 | 
| 05-02 01:32:23 epoch: 2031| train loss i: [0.06	1.39	5.2 	4.91	3.88	1.53] test loss i: [0.08	1.13	4.93	4.22	3.51	1.76] | 
| 05-02 01:32:24 epoch: 2032| time: 1.0s| train loss: +1.708e+01 | test loss: +1.601e+01 | 
| 05-02 01:32:24 epoch: 2032| train loss i: [0.06	1.32	5.51	4.79	3.87	1.54] test loss i: [0.03	0.94	5.3 	4.68	3.54	1.52] | 
| 05-02 01:32:25 epoch: 2033| time: 1.1s| train loss: +1.745e+01 | test loss: +2.276e+01 | 
| 05-02 01:32:25 epoch: 2033| train loss i: [0.06	1.42	5.48	4.82	4.15	1.52] test loss i: [0.16	3.62	6.87	5.41	4.9 	1.79] | 
| 05-02 01:32:26 epoch: 2034| time: 1.1s| train loss: +1.723e+01 | test loss: +1.654e+01 | 
| 05-02 01:32:26 epoch: 2034| train loss i: [0.07	1.41	5.57	4.65	3.95	1.57] test loss i: [0.05	2.14	5.2 	4.2 	3.26	1.69] | 
| 05-02 01:32:27 epoch: 2035| time: 1.1s| train loss: +1.695e+01 | test loss: +1.590e+01 | 
| 05-02 01:32:27 epoch: 2035| train loss i: [0.07	1.07	5.67	4.78	3.83	1.53] test loss i: [0.04	1.6 	4.76	3.9 	4.04	1.55] | 
| 05-02 01:32:28 epoch: 2036| time: 1.1s| train loss: +1.636e+01 | test loss: +1.688e+01 | 
| 05-02 01:32:28 epoch: 2036| train loss i: [0.06	1.22	5.02	4.73	3.79	1.54] test loss i: [0.14	0.96	6.2 	4.49	3.58	1.51] | 
| 05-02 01:32:29 epoch: 2037| time: 1.1s| train loss: +1.637e+01 | test loss: +2.070e+01 | 
| 05-02 01:32:29 epoch: 2037| train loss i: [0.05	1.43	4.65	5.11	3.55	1.58] test loss i: [0.05	1.47	6.57	6.22	4.79	1.6 ] | 
| 05-02 01:32:30 epoch: 2038| time: 1.1s| train loss: +1.685e+01 | test loss: +1.451e+01 | 
| 05-02 01:32:30 epoch: 2038| train loss i: [0.06	1.26	5.39	4.85	3.75	1.55] test loss i: [0.12	0.82	4.66	4.38	2.9 	1.64] | 
| 05-02 01:32:31 epoch: 2039| time: 1.1s| train loss: +1.653e+01 | test loss: +1.503e+01 | 
| 05-02 01:32:31 epoch: 2039| train loss i: [0.08	0.58	5.69	4.87	3.7 	1.62] test loss i: [0.05	1.88	4.18	4.23	3.06	1.62] | 
| 05-02 01:32:32 epoch: 2040| time: 1.1s| train loss: +1.633e+01 | test loss: +1.846e+01 | 
| 05-02 01:32:32 epoch: 2040| train loss i: [0.07	1.04	5.28	4.6 	3.8 	1.53] test loss i: [0.08	2.84	4.45	5.21	4.33	1.56] | 
| 05-02 01:32:34 epoch: 2041| time: 1.2s| train loss: +1.662e+01 | test loss: +1.643e+01 | 
| 05-02 01:32:34 epoch: 2041| train loss i: [0.06	1.31	5.33	4.62	3.74	1.57] test loss i: [0.04	0.54	5.54	5.01	3.51	1.79] | 
| 05-02 01:32:35 epoch: 2042| time: 1.2s| train loss: +1.790e+01 | test loss: +2.005e+01 | 
| 05-02 01:32:35 epoch: 2042| train loss i: [0.09	2.06	5.34	4.91	3.97	1.51] test loss i: [0.25	1.4 	6.02	6.15	4.14	2.09] | 
| 05-02 01:32:36 epoch: 2043| time: 1.2s| train loss: +1.658e+01 | test loss: +1.773e+01 | 
| 05-02 01:32:36 epoch: 2043| train loss i: [0.14	1.15	4.99	4.56	4.1 	1.64] test loss i: [0.16	0.99	5.38	4.67	4.43	2.1 ] | 
| 05-02 01:32:37 epoch: 2044| time: 1.2s| train loss: +1.636e+01 | test loss: +2.195e+01 | 
| 05-02 01:32:37 epoch: 2044| train loss i: [0.14	1.  	5.07	4.68	3.92	1.55] test loss i: [0.2 	0.23	8.12	6.51	4.58	2.31] | 
| 05-02 01:32:38 epoch: 2045| time: 1.2s| train loss: +1.710e+01 | test loss: +2.272e+01 | 
| 05-02 01:32:38 epoch: 2045| train loss i: [0.1 	1.54	5.47	4.45	3.84	1.71] test loss i: [0.13	2.29	7.59	6.36	4.2 	2.15] | 
| 05-02 01:32:39 epoch: 2046| time: 1.2s| train loss: +1.809e+01 | test loss: +2.376e+01 | 
| 05-02 01:32:39 epoch: 2046| train loss i: [0.1 	2.3 	5.54	4.73	3.92	1.5 ] test loss i: [0.14	3.24	7.06	6.41	4.67	2.25] | 
| 05-02 01:32:40 epoch: 2047| time: 1.1s| train loss: +1.692e+01 | test loss: +1.775e+01 | 
| 05-02 01:32:40 epoch: 2047| train loss i: [0.09	0.48	6.03	4.72	4.01	1.57] test loss i: [0.04	0.11	7.05	4.87	3.92	1.76] | 
| 05-02 01:32:42 epoch: 2048| time: 1.1s| train loss: +1.688e+01 | test loss: +1.407e+01 | 
| 05-02 01:32:42 epoch: 2048| train loss i: [0.08	1.11	5.39	5.03	3.67	1.6 ] test loss i: [0.04	0.7 	4.42	3.85	3.41	1.65] | 
| 05-02 01:32:43 epoch: 2049| time: 1.1s| train loss: +1.778e+01 | test loss: +1.709e+01 | 
| 05-02 01:32:43 epoch: 2049| train loss i: [0.08	2.02	5.52	4.56	4.01	1.59] test loss i: [0.1 	0.81	6.11	4.71	3.89	1.47] | 
| 05-02 01:32:44 epoch: 2050| time: 1.2s| train loss: +1.735e+01 | test loss: +2.279e+01 | 
| 05-02 01:32:44 epoch: 2050| train loss i: [0.08	1.31	6.04	4.75	3.66	1.53] test loss i: [0.11	0.84	8.12	6.72	4.8 	2.21] | 
| 05-02 01:32:45 epoch: 2051| time: 1.2s| train loss: +1.611e+01 | test loss: +1.883e+01 | 
| 05-02 01:32:45 epoch: 2051| train loss i: [0.14	1.32	4.84	4.47	3.83	1.52] test loss i: [0.11	0.99	7.  	4.98	3.94	1.81] | 
| 05-02 01:32:46 epoch: 2052| time: 1.1s| train loss: +1.746e+01 | test loss: +1.730e+01 | 
| 05-02 01:32:46 epoch: 2052| train loss i: [0.08	1.85	5.35	4.72	3.94	1.52] test loss i: [0.06	2.2 	5.27	4.8 	3.43	1.54] | 
| 05-02 01:32:47 epoch: 2053| time: 1.1s| train loss: +1.775e+01 | test loss: +1.701e+01 | 
| 05-02 01:32:47 epoch: 2053| train loss i: [0.1 	1.79	5.39	4.98	3.84	1.65] test loss i: [0.1 	1.71	5.65	4.34	3.57	1.63] | 
| 05-02 01:32:48 epoch: 2054| time: 1.2s| train loss: +1.678e+01 | test loss: +1.478e+01 | 
| 05-02 01:32:48 epoch: 2054| train loss i: [0.07	0.92	5.46	4.96	3.81	1.56] test loss i: [0.08	0.39	4.31	4.97	3.15	1.88] | 
| 05-02 01:32:50 epoch: 2055| time: 1.2s| train loss: +1.727e+01 | test loss: +1.530e+01 | 
| 05-02 01:32:50 epoch: 2055| train loss i: [0.08	1.89	5.18	4.92	3.64	1.55] test loss i: [0.19	0.56	5.7 	3.89	3.25	1.73] | 
| 05-02 01:32:51 epoch: 2056| time: 1.2s| train loss: +1.752e+01 | test loss: +1.817e+01 | 
| 05-02 01:32:51 epoch: 2056| train loss i: [0.06	1.35	5.63	4.95	3.91	1.62] test loss i: [0.04	2.07	5.86	5.43	3.11	1.67] | 
| 05-02 01:32:52 epoch: 2057| time: 1.1s| train loss: +1.663e+01 | test loss: +2.454e+01 | 
| 05-02 01:32:52 epoch: 2057| train loss i: [0.08	1.26	5.16	4.7 	3.79	1.64] test loss i: [0.11	1.92	7.69	7.4 	5.35	2.07] | 
| 05-02 01:32:53 epoch: 2058| time: 1.1s| train loss: +1.694e+01 | test loss: +1.602e+01 | 
| 05-02 01:32:53 epoch: 2058| train loss i: [0.06	1.85	5.24	4.59	3.69	1.51] test loss i: [0.05	0.98	4.52	5.29	3.63	1.56] | 
| 05-02 01:32:54 epoch: 2059| time: 1.2s| train loss: +1.806e+01 | test loss: +2.117e+01 | 
| 05-02 01:32:54 epoch: 2059| train loss i: [0.08	1.54	5.78	5.16	3.98	1.52] test loss i: [0.08	1.07	7.45	5.74	4.61	2.23] | 
| 05-02 01:32:55 epoch: 2060| time: 1.2s| train loss: +1.642e+01 | test loss: +1.723e+01 | 
| 05-02 01:32:55 epoch: 2060| train loss i: [0.1 	1.53	4.83	4.4 	4.04	1.53] test loss i: [0.04	1.62	5.43	5.16	3.35	1.64] | 
| 05-02 01:32:56 epoch: 2061| time: 1.2s| train loss: +1.704e+01 | test loss: +2.119e+01 | 
| 05-02 01:32:56 epoch: 2061| train loss i: [0.04	1.39	5.5 	4.64	3.93	1.53] test loss i: [0.12	2.2 	5.63	5.59	5.57	2.07] | 
| 05-02 01:32:58 epoch: 2062| time: 1.1s| train loss: +1.735e+01 | test loss: +1.479e+01 | 
| 05-02 01:32:58 epoch: 2062| train loss i: [0.05	1.2 	5.33	5.15	4.05	1.57] test loss i: [0.05	0.87	3.73	4.6 	3.96	1.58] | 
| 05-02 01:32:59 epoch: 2063| time: 1.1s| train loss: +1.766e+01 | test loss: +1.965e+01 | 
| 05-02 01:32:59 epoch: 2063| train loss i: [0.04	1.46	5.9 	4.79	3.83	1.63] test loss i: [0.04	1.74	5.87	5.95	4.36	1.7 ] | 
| 05-02 01:33:00 epoch: 2064| time: 1.2s| train loss: +1.658e+01 | test loss: +2.185e+01 | 
| 05-02 01:33:00 epoch: 2064| train loss i: [0.04	0.8 	5.23	4.95	3.95	1.6 ] test loss i: [0.07	1.27	6.63	6.75	5.23	1.9 ] | 
| 05-02 01:33:01 epoch: 2065| time: 1.2s| train loss: +1.705e+01 | test loss: +1.998e+01 | 
| 05-02 01:33:01 epoch: 2065| train loss i: [0.05	1.71	5.22	4.89	3.67	1.52] test loss i: [0.2 	1.98	5.63	5.65	4.72	1.82] | 
| 05-02 01:33:02 epoch: 2066| time: 1.2s| train loss: +1.694e+01 | test loss: +1.842e+01 | 
| 05-02 01:33:02 epoch: 2066| train loss i: [0.08	1.26	5.55	4.62	3.89	1.54] test loss i: [0.22	1.04	6.09	5.67	3.72	1.68] | 
| 05-02 01:33:03 epoch: 2067| time: 1.1s| train loss: +1.741e+01 | test loss: +1.634e+01 | 
| 05-02 01:33:03 epoch: 2067| train loss i: [0.1 	1.62	5.45	4.75	3.89	1.6 ] test loss i: [0.16	0.48	5.15	4.97	4.05	1.52] | 
| 05-02 01:33:04 epoch: 2068| time: 1.1s| train loss: +1.710e+01 | test loss: +2.364e+01 | 
| 05-02 01:33:04 epoch: 2068| train loss i: [0.08	1.25	5.32	5.07	3.83	1.54] test loss i: [0.27	0.89	8.85	6.62	4.8 	2.22] | 
| 05-02 01:33:06 epoch: 2069| time: 1.1s| train loss: +1.730e+01 | test loss: +2.184e+01 | 
| 05-02 01:33:06 epoch: 2069| train loss i: [0.12	1.38	5.57	4.81	3.89	1.54] test loss i: [0.16	4.  	6.41	4.84	4.75	1.68] | 
| 05-02 01:33:07 epoch: 2070| time: 1.1s| train loss: +1.620e+01 | test loss: +1.812e+01 | 
| 05-02 01:33:07 epoch: 2070| train loss i: [0.09	0.9 	5.13	4.83	3.74	1.51] test loss i: [0.24	0.45	5.76	5.77	4.11	1.78] | 
| 05-02 01:33:08 epoch: 2071| time: 1.1s| train loss: +1.636e+01 | test loss: +1.401e+01 | 
| 05-02 01:33:08 epoch: 2071| train loss i: [0.1 	0.91	5.33	4.7 	3.74	1.59] test loss i: [0.04	0.54	3.94	4.29	3.7 	1.5 ] | 
| 05-02 01:33:09 epoch: 2072| time: 1.0s| train loss: +1.709e+01 | test loss: +2.084e+01 | 
| 05-02 01:33:09 epoch: 2072| train loss i: [0.07	0.89	5.87	5.16	3.52	1.59] test loss i: [0.44	1.82	6.16	5.28	4.9 	2.24] | 
| 05-02 01:33:10 epoch: 2073| time: 1.0s| train loss: +1.679e+01 | test loss: +1.647e+01 | 
| 05-02 01:33:10 epoch: 2073| train loss i: [0.08	0.9 	5.58	4.76	3.82	1.65] test loss i: [0.18	0.87	5.97	4.7 	3.12	1.63] | 
| 05-02 01:33:11 epoch: 2074| time: 1.1s| train loss: +1.696e+01 | test loss: +2.317e+01 | 
| 05-02 01:33:11 epoch: 2074| train loss i: [0.09	1.38	5.51	4.78	3.69	1.51] test loss i: [0.21	1.17	7.9 	6.71	5.15	2.04] | 
| 05-02 01:33:12 epoch: 2075| time: 1.1s| train loss: +1.718e+01 | test loss: +1.519e+01 | 
| 05-02 01:33:12 epoch: 2075| train loss i: [0.13	1.44	5.5 	4.89	3.69	1.52] test loss i: [0.12	1.06	4.41	4.45	3.61	1.53] | 
| 05-02 01:33:13 epoch: 2076| time: 1.1s| train loss: +1.717e+01 | test loss: +1.732e+01 | 
| 05-02 01:33:13 epoch: 2076| train loss i: [0.1 	0.55	5.95	5.1 	3.87	1.61] test loss i: [0.07	1.76	5.16	4.62	3.93	1.79] | 
| 05-02 01:33:14 epoch: 2077| time: 1.1s| train loss: +1.680e+01 | test loss: +1.996e+01 | 
| 05-02 01:33:14 epoch: 2077| train loss i: [0.06	1.29	5.46	4.76	3.63	1.59] test loss i: [0.03	1.38	6.32	6.26	3.86	2.12] | 
| 05-02 01:33:15 epoch: 2078| time: 1.0s| train loss: +1.636e+01 | test loss: +2.197e+01 | 
| 05-02 01:33:15 epoch: 2078| train loss i: [0.08	0.97	5.15	4.9 	3.78	1.49] test loss i: [0.39	0.7 	7.9 	6.35	4.86	1.76] | 
| 05-02 01:33:16 epoch: 2079| time: 1.1s| train loss: +1.612e+01 | test loss: +1.958e+01 | 
| 05-02 01:33:16 epoch: 2079| train loss i: [0.1 	0.98	5.07	4.63	3.79	1.55] test loss i: [0.06	2.23	7.08	4.55	3.86	1.8 ] | 
| 05-02 01:33:17 epoch: 2080| time: 1.1s| train loss: +1.799e+01 | test loss: +1.975e+01 | 
| 05-02 01:33:17 epoch: 2080| train loss i: [0.12	1.89	5.61	4.84	3.99	1.54] test loss i: [0.16	2.59	6.96	4.24	4.02	1.79] | 
| 05-02 01:33:18 epoch: 2081| time: 1.1s| train loss: +1.638e+01 | test loss: +1.510e+01 | 
| 05-02 01:33:18 epoch: 2081| train loss i: [0.13	0.98	5.38	4.57	3.74	1.58] test loss i: [0.12	0.34	4.63	4.  	4.15	1.87] | 
| 05-02 01:33:19 epoch: 2082| time: 1.1s| train loss: +1.761e+01 | test loss: +1.691e+01 | 
| 05-02 01:33:19 epoch: 2082| train loss i: [0.15	1.56	5.93	4.59	3.72	1.66] test loss i: [0.14	1.18	5.22	4.59	4.34	1.44] | 
| 05-02 01:33:21 epoch: 2083| time: 1.1s| train loss: +1.720e+01 | test loss: +2.469e+01 | 
| 05-02 01:33:21 epoch: 2083| train loss i: [0.11	1.15	5.46	5.  	3.85	1.62] test loss i: [0.06	3.34	8.42	6.2 	4.79	1.87] | 
| 05-02 01:33:22 epoch: 2084| time: 1.1s| train loss: +1.846e+01 | test loss: +2.254e+01 | 
| 05-02 01:33:22 epoch: 2084| train loss i: [0.1 	1.93	6.17	4.66	4.05	1.55] test loss i: [0.19	2.52	6.08	6.7 	5.04	2.  ] | 
| 05-02 01:33:23 epoch: 2085| time: 1.1s| train loss: +1.685e+01 | test loss: +2.217e+01 | 
| 05-02 01:33:23 epoch: 2085| train loss i: [0.07	1.56	5.  	4.85	3.83	1.53] test loss i: [0.08	0.81	6.4 	7.96	4.97	1.95] | 
| 05-02 01:33:24 epoch: 2086| time: 1.1s| train loss: +1.616e+01 | test loss: +1.640e+01 | 
| 05-02 01:33:24 epoch: 2086| train loss i: [0.1 	0.92	4.91	4.83	3.87	1.53] test loss i: [0.18	1.47	5.62	4.42	3.32	1.39] | 
| 05-02 01:33:25 epoch: 2087| time: 1.1s| train loss: +1.702e+01 | test loss: +1.820e+01 | 
| 05-02 01:33:25 epoch: 2087| train loss i: [0.07	1.6 	5.27	4.87	3.63	1.58] test loss i: [0.08	2.78	5.95	4.52	3.38	1.49] | 
| 05-02 01:33:26 epoch: 2088| time: 1.1s| train loss: +1.689e+01 | test loss: +1.894e+01 | 
| 05-02 01:33:26 epoch: 2088| train loss i: [0.05	1.89	5.01	4.76	3.6 	1.57] test loss i: [0.11	1.15	6.02	5.35	4.16	2.15] | 
| 05-02 01:33:27 epoch: 2089| time: 1.0s| train loss: +1.672e+01 | test loss: +2.180e+01 | 
| 05-02 01:33:27 epoch: 2089| train loss i: [0.08	1.53	5.03	4.53	4.07	1.49] test loss i: [0.18	2.71	6.62	5.05	5.18	2.06] | 
| 05-02 01:33:28 epoch: 2090| time: 1.1s| train loss: +1.794e+01 | test loss: +1.719e+01 | 
| 05-02 01:33:28 epoch: 2090| train loss i: [0.09	1.94	5.55	5.06	3.75	1.55] test loss i: [0.27	0.99	5.54	5.11	3.6 	1.67] | 
| 05-02 01:33:29 epoch: 2091| time: 1.1s| train loss: +1.621e+01 | test loss: +2.274e+01 | 
| 05-02 01:33:29 epoch: 2091| train loss i: [0.06	1.  	5.12	4.72	3.71	1.61] test loss i: [0.08	1.91	6.99	6.31	4.85	2.59] | 
| 05-02 01:33:30 epoch: 2092| time: 1.1s| train loss: +1.671e+01 | test loss: +1.780e+01 | 
| 05-02 01:33:30 epoch: 2092| train loss i: [0.06	1.1 	4.87	5.  	4.07	1.6 ] test loss i: [0.04	0.96	6.26	4.6 	4.25	1.69] | 
| 05-02 01:33:31 epoch: 2093| time: 1.1s| train loss: +1.657e+01 | test loss: +1.521e+01 | 
| 05-02 01:33:31 epoch: 2093| train loss i: [0.06	0.91	5.29	4.84	3.89	1.59] test loss i: [0.09	0.47	4.63	4.57	3.67	1.79] | 
| 05-02 01:33:32 epoch: 2094| time: 1.0s| train loss: +1.734e+01 | test loss: +1.760e+01 | 
| 05-02 01:33:32 epoch: 2094| train loss i: [0.09	1.71	5.73	4.73	3.51	1.56] test loss i: [0.03	1.63	6.65	3.72	3.96	1.6 ] | 
| 05-02 01:33:33 epoch: 2095| time: 1.0s| train loss: +1.797e+01 | test loss: +1.667e+01 | 
| 05-02 01:33:33 epoch: 2095| train loss i: [0.07	1.98	6.08	4.3 	3.96	1.59] test loss i: [0.05	1.18	5.38	4.95	3.42	1.69] | 
| 05-02 01:33:34 epoch: 2096| time: 1.1s| train loss: +1.752e+01 | test loss: +2.422e+01 | 
| 05-02 01:33:34 epoch: 2096| train loss i: [0.07	1.73	5.48	4.4 	4.24	1.6 ] test loss i: [ 0.06	 1.76	10.35	 5.64	 4.52	 1.9 ] | 
| 05-02 01:33:36 epoch: 2097| time: 1.1s| train loss: +1.610e+01 | test loss: +2.220e+01 | 
| 05-02 01:33:36 epoch: 2097| train loss i: [0.06	1.06	4.91	4.86	3.67	1.54] test loss i: [0.18	1.23	6.15	6.11	6.59	1.94] | 
| 05-02 01:33:37 epoch: 2098| time: 1.1s| train loss: +1.708e+01 | test loss: +1.713e+01 | 
| 05-02 01:33:37 epoch: 2098| train loss i: [0.08	1.32	5.28	5.01	3.83	1.57] test loss i: [0.05	0.82	5.63	4.4 	4.48	1.76] | 
| 05-02 01:33:38 epoch: 2099| time: 1.0s| train loss: +1.675e+01 | test loss: +1.793e+01 | 
| 05-02 01:33:38 epoch: 2099| train loss i: [0.06	1.74	4.98	4.7 	3.58	1.68] test loss i: [0.2 	0.48	6.56	4.96	3.98	1.76] | 
| 05-02 01:33:39 epoch: 2100| time: 1.0s| train loss: +1.663e+01 | test loss: +1.426e+01 | 
| 05-02 01:33:39 epoch: 2100| train loss i: [0.1 	0.94	5.42	4.74	3.85	1.57] test loss i: [0.06	0.09	5.93	3.93	2.94	1.3 ] | 
| 05-02 01:33:40 epoch: 2101| time: 1.1s| train loss: +1.659e+01 | test loss: +1.778e+01 | 
| 05-02 01:33:40 epoch: 2101| train loss i: [0.06	1.11	5.23	4.81	3.82	1.55] test loss i: [0.15	1.74	5.48	5.26	3.67	1.48] | 
| 05-02 01:33:41 epoch: 2102| time: 1.1s| train loss: +1.688e+01 | test loss: +1.894e+01 | 
| 05-02 01:33:41 epoch: 2102| train loss i: [0.1 	1.5 	5.15	4.77	3.95	1.4 ] test loss i: [0.18	1.42	5.43	4.87	5.  	2.03] | 
| 05-02 01:33:42 epoch: 2103| time: 1.1s| train loss: +1.606e+01 | test loss: +1.793e+01 | 
| 05-02 01:33:42 epoch: 2103| train loss i: [0.09	0.71	5.45	4.63	3.64	1.54] test loss i: [0.11	1.41	5.69	5.2 	3.98	1.54] | 
| 05-02 01:33:43 epoch: 2104| time: 1.1s| train loss: +1.741e+01 | test loss: +1.584e+01 | 
| 05-02 01:33:43 epoch: 2104| train loss i: [0.08	1.43	5.45	5.02	3.85	1.58] test loss i: [0.04	1.31	4.81	4.38	3.54	1.75] | 
| 05-02 01:33:44 epoch: 2105| time: 1.1s| train loss: +1.723e+01 | test loss: +2.032e+01 | 
| 05-02 01:33:44 epoch: 2105| train loss i: [0.05	1.16	5.96	4.97	3.54	1.55] test loss i: [0.13	2.77	5.64	4.84	4.8 	2.14] | 
| 05-02 01:33:45 epoch: 2106| time: 1.1s| train loss: +1.656e+01 | test loss: +1.733e+01 | 
| 05-02 01:33:45 epoch: 2106| train loss i: [0.08	1.17	5.44	4.5 	3.86	1.52] test loss i: [0.14	0.79	5.88	4.78	3.89	1.85] | 
| 05-02 01:33:46 epoch: 2107| time: 1.1s| train loss: +1.642e+01 | test loss: +1.797e+01 | 
| 05-02 01:33:46 epoch: 2107| train loss i: [0.09	0.91	5.36	4.98	3.58	1.5 ] test loss i: [0.09	0.96	6.28	5.06	3.88	1.71] | 
| 05-02 01:33:47 epoch: 2108| time: 1.1s| train loss: +1.705e+01 | test loss: +1.884e+01 | 
| 05-02 01:33:47 epoch: 2108| train loss i: [0.1 	1.5 	5.  	5.  	3.88	1.57] test loss i: [0.06	1.87	6.08	4.86	4.22	1.76] | 
| 05-02 01:33:48 epoch: 2109| time: 1.1s| train loss: +1.692e+01 | test loss: +1.903e+01 | 
| 05-02 01:33:48 epoch: 2109| train loss i: [0.08	1.17	5.08	5.31	3.75	1.52] test loss i: [0.16	1.43	4.47	6.28	5.02	1.67] | 
| 05-02 01:33:49 epoch: 2110| time: 1.1s| train loss: +1.775e+01 | test loss: +1.676e+01 | 
| 05-02 01:33:49 epoch: 2110| train loss i: [0.16	2.14	5.26	4.96	3.7 	1.53] test loss i: [0.07	0.97	5.79	4.64	3.59	1.71] | 
| 05-02 01:33:50 epoch: 2111| time: 1.1s| train loss: +1.703e+01 | test loss: +1.501e+01 | 
| 05-02 01:33:50 epoch: 2111| train loss i: [0.13	1.63	5.21	4.91	3.58	1.57] test loss i: [0.09	0.98	4.57	4.43	3.38	1.55] | 
| 05-02 01:33:52 epoch: 2112| time: 1.0s| train loss: +1.692e+01 | test loss: +1.681e+01 | 
| 05-02 01:33:52 epoch: 2112| train loss i: [0.07	1.41	5.39	4.77	3.76	1.52] test loss i: [0.06	1.14	6.37	4.3 	3.42	1.52] | 
| 05-02 01:33:53 epoch: 2113| time: 1.1s| train loss: +1.630e+01 | test loss: +1.862e+01 | 
| 05-02 01:33:53 epoch: 2113| train loss i: [0.05	1.16	5.69	4.55	3.37	1.47] test loss i: [0.08	1.76	5.93	4.59	4.54	1.72] | 
| 05-02 01:33:54 epoch: 2114| time: 1.1s| train loss: +1.643e+01 | test loss: +1.794e+01 | 
| 05-02 01:33:54 epoch: 2114| train loss i: [0.07	0.93	5.39	4.84	3.7 	1.5 ] test loss i: [0.04	1.34	6.62	4.83	3.63	1.48] | 
| 05-02 01:33:55 epoch: 2115| time: 1.1s| train loss: +1.810e+01 | test loss: +2.049e+01 | 
| 05-02 01:33:55 epoch: 2115| train loss i: [0.08	1.73	6.05	4.64	4.09	1.51] test loss i: [0.04	2.7 	6.26	4.85	4.98	1.65] | 
| 05-02 01:33:56 epoch: 2116| time: 1.1s| train loss: +1.741e+01 | test loss: +2.431e+01 | 
| 05-02 01:33:56 epoch: 2116| train loss i: [0.08	1.49	6.08	4.61	3.64	1.5 ] test loss i: [0.09	1.01	8.  	6.97	6.02	2.21] | 
| 05-02 01:33:57 epoch: 2117| time: 1.0s| train loss: +1.714e+01 | test loss: +1.664e+01 | 
| 05-02 01:33:57 epoch: 2117| train loss i: [0.09	1.88	4.96	4.7 	3.97	1.55] test loss i: [0.08	0.61	6.04	4.8 	3.69	1.42] | 
| 05-02 01:33:58 epoch: 2118| time: 1.0s| train loss: +1.685e+01 | test loss: +1.323e+01 | 
| 05-02 01:33:58 epoch: 2118| train loss i: [0.06	1.46	5.39	4.64	3.72	1.59] test loss i: [0.04	1.2 	3.37	3.93	3.27	1.43] | 
| 05-02 01:33:59 epoch: 2119| time: 1.1s| train loss: +1.606e+01 | test loss: +1.843e+01 | 
| 05-02 01:33:59 epoch: 2119| train loss i: [0.06	1.13	4.95	4.78	3.66	1.47] test loss i: [0.05	1.49	6.55	5.18	3.51	1.64] | 
| 05-02 01:34:00 epoch: 2120| time: 1.1s| train loss: +1.780e+01 | test loss: +2.017e+01 | 
| 05-02 01:34:00 epoch: 2120| train loss i: [0.09	1.64	5.46	5.47	3.59	1.54] test loss i: [0.19	0.5 	7.69	5.31	4.44	2.04] | 
| 05-02 01:34:01 epoch: 2121| time: 1.1s| train loss: +1.685e+01 | test loss: +2.327e+01 | 
| 05-02 01:34:01 epoch: 2121| train loss i: [0.1 	0.92	5.26	5.01	4.11	1.46] test loss i: [0.09	0.7 	7.78	6.9 	5.65	2.14] | 
| 05-02 01:34:02 epoch: 2122| time: 1.1s| train loss: +1.726e+01 | test loss: +1.896e+01 | 
| 05-02 01:34:02 epoch: 2122| train loss i: [0.1 	1.06	5.57	4.83	4.1 	1.59] test loss i: [0.16	0.18	5.58	6.71	4.35	1.99] | 
| 05-02 01:34:03 epoch: 2123| time: 1.0s| train loss: +1.625e+01 | test loss: +2.075e+01 | 
| 05-02 01:34:03 epoch: 2123| train loss i: [0.09	1.34	5.18	4.58	3.58	1.49] test loss i: [0.15	3.  	6.46	5.62	3.72	1.8 ] | 
| 05-02 01:34:04 epoch: 2124| time: 1.1s| train loss: +1.801e+01 | test loss: +1.857e+01 | 
| 05-02 01:34:04 epoch: 2124| train loss i: [0.1 	1.98	5.81	4.86	3.76	1.49] test loss i: [0.08	1.65	4.52	6.87	3.88	1.57] | 
| 05-02 01:34:05 epoch: 2125| time: 1.1s| train loss: +1.588e+01 | test loss: +1.733e+01 | 
| 05-02 01:34:05 epoch: 2125| train loss i: [0.06	0.93	4.99	4.52	3.77	1.61] test loss i: [0.13	0.91	6.48	4.55	3.8 	1.47] | 
| 05-02 01:34:06 epoch: 2126| time: 1.1s| train loss: +1.723e+01 | test loss: +1.568e+01 | 
| 05-02 01:34:06 epoch: 2126| train loss i: [0.08	1.68	5.23	4.7 	3.99	1.56] test loss i: [0.08	1.9 	4.14	4.33	3.61	1.62] | 
| 05-02 01:34:08 epoch: 2127| time: 1.1s| train loss: +1.846e+01 | test loss: +1.571e+01 | 
| 05-02 01:34:08 epoch: 2127| train loss i: [0.07	2.26	5.64	5.06	3.8 	1.63] test loss i: [0.04	1.43	5.54	3.29	3.9 	1.51] | 
| 05-02 01:34:09 epoch: 2128| time: 1.0s| train loss: +1.698e+01 | test loss: +1.912e+01 | 
| 05-02 01:34:09 epoch: 2128| train loss i: [0.07	1.04	5.71	5.08	3.51	1.57] test loss i: [0.17	2.56	5.55	5.56	3.83	1.46] | 
| 05-02 01:34:10 epoch: 2129| time: 1.1s| train loss: +1.720e+01 | test loss: +1.700e+01 | 
| 05-02 01:34:10 epoch: 2129| train loss i: [0.08	1.04	6.01	4.72	3.74	1.61] test loss i: [0.04	1.31	5.32	5.05	3.81	1.46] | 
| 05-02 01:34:11 epoch: 2130| time: 1.1s| train loss: +1.743e+01 | test loss: +2.439e+01 | 
| 05-02 01:34:11 epoch: 2130| train loss i: [0.05	1.28	6.06	4.79	3.7 	1.55] test loss i: [0.06	1.13	9.64	6.52	4.59	2.45] | 
| 05-02 01:34:12 epoch: 2131| time: 1.1s| train loss: +1.593e+01 | test loss: +1.797e+01 | 
| 05-02 01:34:12 epoch: 2131| train loss i: [0.07	1.05	4.88	4.77	3.61	1.55] test loss i: [0.23	1.93	5.29	4.36	4.6 	1.57] | 
| 05-02 01:34:13 epoch: 2132| time: 1.1s| train loss: +1.620e+01 | test loss: +1.998e+01 | 
| 05-02 01:34:13 epoch: 2132| train loss i: [0.07	1.26	5.  	4.76	3.51	1.61] test loss i: [0.07	1.96	7.15	5.37	3.51	1.93] | 
| 05-02 01:34:14 epoch: 2133| time: 1.1s| train loss: +1.670e+01 | test loss: +2.174e+01 | 
| 05-02 01:34:14 epoch: 2133| train loss i: [0.06	1.21	5.46	4.89	3.59	1.49] test loss i: [0.19	2.22	5.23	6.32	5.51	2.26] | 
| 05-02 01:34:15 epoch: 2134| time: 1.0s| train loss: +1.714e+01 | test loss: +1.938e+01 | 
| 05-02 01:34:15 epoch: 2134| train loss i: [0.08	1.31	5.57	4.66	3.96	1.57] test loss i: [0.09	2.04	6.12	4.92	4.29	1.92] | 
| 05-02 01:34:16 epoch: 2135| time: 1.1s| train loss: +1.739e+01 | test loss: +2.067e+01 | 
| 05-02 01:34:16 epoch: 2135| train loss i: [0.09	1.49	5.28	4.83	4.08	1.62] test loss i: [0.29	0.85	7.84	5.29	4.65	1.76] | 
| 05-02 01:34:17 epoch: 2136| time: 1.1s| train loss: +1.684e+01 | test loss: +1.657e+01 | 
| 05-02 01:34:17 epoch: 2136| train loss i: [0.11	1.17	5.62	4.61	3.85	1.48] test loss i: [0.05	1.81	4.36	4.8 	3.84	1.71] | 
| 05-02 01:34:18 epoch: 2137| time: 1.1s| train loss: +1.573e+01 | test loss: +1.682e+01 | 
| 05-02 01:34:18 epoch: 2137| train loss i: [0.07	0.74	5.16	4.74	3.53	1.5 ] test loss i: [0.11	1.8 	4.5 	4.85	3.8 	1.75] | 
| 05-02 01:34:19 epoch: 2138| time: 1.1s| train loss: +1.730e+01 | test loss: +1.489e+01 | 
| 05-02 01:34:19 epoch: 2138| train loss i: [0.08	1.92	5.27	4.79	3.73	1.51] test loss i: [0.06	0.45	4.77	4.83	3.2 	1.58] | 
| 05-02 01:34:20 epoch: 2139| time: 1.1s| train loss: +1.733e+01 | test loss: +1.612e+01 | 
| 05-02 01:34:20 epoch: 2139| train loss i: [0.06	1.3 	5.56	4.96	3.99	1.46] test loss i: [0.12	1.31	5.24	4.11	3.68	1.66] | 
| 05-02 01:34:21 epoch: 2140| time: 1.1s| train loss: +1.700e+01 | test loss: +1.430e+01 | 
| 05-02 01:34:21 epoch: 2140| train loss i: [0.06	1.36	5.5 	4.94	3.6 	1.54] test loss i: [0.27	0.83	4.7 	4.11	2.86	1.53] | 
| 05-02 01:34:22 epoch: 2141| time: 1.0s| train loss: +1.738e+01 | test loss: +1.497e+01 | 
| 05-02 01:34:22 epoch: 2141| train loss i: [0.08	1.25	5.84	4.86	3.83	1.53] test loss i: [0.07	0.55	4.9 	3.87	4.06	1.51] | 
| 05-02 01:34:23 epoch: 2142| time: 1.0s| train loss: +1.643e+01 | test loss: +1.621e+01 | 
| 05-02 01:34:23 epoch: 2142| train loss i: [0.12	1.06	5.23	4.5 	3.95	1.58] test loss i: [0.07	1.41	4.29	4.89	4.1 	1.45] | 
| 05-02 01:34:25 epoch: 2143| time: 1.1s| train loss: +1.605e+01 | test loss: +1.731e+01 | 
| 05-02 01:34:25 epoch: 2143| train loss i: [0.09	0.83	5.19	4.68	3.64	1.61] test loss i: [0.04	2.3 	5.08	4.86	3.35	1.69] | 
| 05-02 01:34:26 epoch: 2144| time: 1.1s| train loss: +1.676e+01 | test loss: +1.606e+01 | 
| 05-02 01:34:26 epoch: 2144| train loss i: [0.1 	1.28	5.15	5.  	3.73	1.5 ] test loss i: [0.06	1.32	5.2 	4.75	3.17	1.57] | 
| 05-02 01:34:27 epoch: 2145| time: 1.1s| train loss: +1.658e+01 | test loss: +2.502e+01 | 
| 05-02 01:34:27 epoch: 2145| train loss i: [0.07	1.09	5.55	4.67	3.58	1.61] test loss i: [0.17	3.36	7.88	6.53	4.73	2.34] | 
| 05-02 01:34:28 epoch: 2146| time: 1.1s| train loss: +1.592e+01 | test loss: +1.948e+01 | 
| 05-02 01:34:28 epoch: 2146| train loss i: [0.06	0.87	5.  	4.7 	3.71	1.58] test loss i: [0.08	2.61	5.94	5.28	3.61	1.96] | 
| 05-02 01:34:29 epoch: 2147| time: 1.1s| train loss: +1.764e+01 | test loss: +1.790e+01 | 
| 05-02 01:34:29 epoch: 2147| train loss i: [0.1 	1.76	5.27	4.96	4.06	1.48] test loss i: [0.06	0.75	7.27	5.06	3.09	1.67] | 
| 05-02 01:34:30 epoch: 2148| time: 1.1s| train loss: +1.691e+01 | test loss: +1.461e+01 | 
| 05-02 01:34:30 epoch: 2148| train loss i: [0.13	1.32	5.36	4.84	3.78	1.5 ] test loss i: [0.09	1.05	4.07	4.63	3.31	1.47] | 
| 05-02 01:34:31 epoch: 2149| time: 1.1s| train loss: +1.586e+01 | test loss: +2.273e+01 | 
| 05-02 01:34:31 epoch: 2149| train loss i: [0.07	1.  	4.75	4.73	3.72	1.59] test loss i: [0.09	1.3 	8.08	6.33	4.87	2.06] | 
| 05-02 01:34:32 epoch: 2150| time: 1.1s| train loss: +1.663e+01 | test loss: +2.114e+01 | 
| 05-02 01:34:32 epoch: 2150| train loss i: [0.08	1.24	5.1 	4.84	3.76	1.62] test loss i: [0.08	2.06	7.47	5.2 	4.52	1.81] | 
| 05-02 01:34:33 epoch: 2151| time: 1.1s| train loss: +1.681e+01 | test loss: +1.412e+01 | 
| 05-02 01:34:33 epoch: 2151| train loss i: [0.07	1.08	5.61	4.7 	3.78	1.57] test loss i: [0.09	0.6 	4.4 	3.6 	3.88	1.56] | 
| 05-02 01:34:34 epoch: 2152| time: 1.1s| train loss: +1.754e+01 | test loss: +1.690e+01 | 
| 05-02 01:34:34 epoch: 2152| train loss i: [0.06	1.79	5.48	4.93	3.75	1.54] test loss i: [0.1 	2.16	4.84	4.14	4.19	1.47] | 
| 05-02 01:34:35 epoch: 2153| time: 1.1s| train loss: +1.667e+01 | test loss: +1.739e+01 | 
| 05-02 01:34:35 epoch: 2153| train loss i: [0.07	1.07	5.64	4.79	3.56	1.54] test loss i: [0.11	3.47	4.56	3.75	4.18	1.33] | 
| 05-02 01:34:36 epoch: 2154| time: 1.1s| train loss: +1.665e+01 | test loss: +1.736e+01 | 
| 05-02 01:34:36 epoch: 2154| train loss i: [0.1 	1.16	5.54	4.65	3.63	1.57] test loss i: [0.17	3.11	4.94	4.29	3.26	1.59] | 
| 05-02 01:34:37 epoch: 2155| time: 1.1s| train loss: +1.681e+01 | test loss: +1.699e+01 | 
| 05-02 01:34:37 epoch: 2155| train loss i: [0.09	1.4 	5.39	4.4 	3.94	1.59] test loss i: [0.14	0.97	5.52	4.78	3.79	1.79] | 
| 05-02 01:34:38 epoch: 2156| time: 1.0s| train loss: +1.725e+01 | test loss: +1.733e+01 | 
| 05-02 01:34:38 epoch: 2156| train loss i: [0.07	1.67	5.72	4.64	3.65	1.5 ] test loss i: [0.08	3.93	5.03	3.48	3.39	1.42] | 
| 05-02 01:34:40 epoch: 2157| time: 1.1s| train loss: +1.670e+01 | test loss: +2.112e+01 | 
| 05-02 01:34:40 epoch: 2157| train loss i: [0.09	0.74	5.49	4.92	3.84	1.62] test loss i: [0.08	1.05	6.2 	6.42	5.3 	2.09] | 
| 05-02 01:34:41 epoch: 2158| time: 1.1s| train loss: +1.699e+01 | test loss: +1.994e+01 | 
| 05-02 01:34:41 epoch: 2158| train loss i: [0.1 	1.76	5.31	4.72	3.61	1.49] test loss i: [0.1 	2.95	5.59	5.49	4.01	1.8 ] | 
| 05-02 01:34:42 epoch: 2159| time: 1.1s| train loss: +1.672e+01 | test loss: +1.437e+01 | 
| 05-02 01:34:42 epoch: 2159| train loss i: [0.08	1.2 	5.39	4.73	3.81	1.5 ] test loss i: [0.05	0.62	4.71	4.05	3.4 	1.54] | 
| 05-02 01:34:43 epoch: 2160| time: 1.1s| train loss: +1.683e+01 | test loss: +1.919e+01 | 
| 05-02 01:34:43 epoch: 2160| train loss i: [0.07	1.39	5.33	4.88	3.62	1.53] test loss i: [0.07	2.78	5.48	5.29	4.  	1.58] | 
| 05-02 01:34:44 epoch: 2161| time: 1.0s| train loss: +1.710e+01 | test loss: +1.602e+01 | 
| 05-02 01:34:44 epoch: 2161| train loss i: [0.05	1.53	5.5 	4.62	3.86	1.54] test loss i: [0.04	0.58	5.77	4.7 	3.41	1.52] | 
| 05-02 01:34:45 epoch: 2162| time: 1.1s| train loss: +1.745e+01 | test loss: +1.649e+01 | 
| 05-02 01:34:45 epoch: 2162| train loss i: [0.06	1.59	5.66	4.75	3.88	1.51] test loss i: [0.06	0.22	6.28	4.05	4.17	1.72] | 
| 05-02 01:34:46 epoch: 2163| time: 1.1s| train loss: +1.694e+01 | test loss: +2.458e+01 | 
| 05-02 01:34:46 epoch: 2163| train loss i: [0.06	1.78	5.33	4.79	3.47	1.52] test loss i: [0.04	1.3 	8.74	7.01	5.09	2.39] | 
| 05-02 01:34:47 epoch: 2164| time: 1.1s| train loss: +1.721e+01 | test loss: +1.906e+01 | 
| 05-02 01:34:47 epoch: 2164| train loss i: [0.05	1.4 	5.65	4.78	3.77	1.56] test loss i: [0.03	2.12	5.07	5.37	4.63	1.83] | 
| 05-02 01:34:48 epoch: 2165| time: 1.1s| train loss: +1.690e+01 | test loss: +1.815e+01 | 
| 05-02 01:34:48 epoch: 2165| train loss i: [0.06	1.17	5.94	4.7 	3.54	1.49] test loss i: [0.07	2.61	5.42	4.84	3.31	1.91] | 
| 05-02 01:34:49 epoch: 2166| time: 1.1s| train loss: +1.663e+01 | test loss: +1.632e+01 | 
| 05-02 01:34:49 epoch: 2166| train loss i: [0.06	0.93	5.26	5.19	3.65	1.55] test loss i: [0.05	0.39	4.86	5.07	4.25	1.7 ] | 
| 05-02 01:34:50 epoch: 2167| time: 1.1s| train loss: +1.785e+01 | test loss: +1.941e+01 | 
| 05-02 01:34:50 epoch: 2167| train loss i: [0.04	1.93	5.66	4.87	3.82	1.52] test loss i: [0.16	1.61	6.2 	5.01	4.46	1.96] | 
| 05-02 01:34:51 epoch: 2168| time: 1.1s| train loss: +1.727e+01 | test loss: +1.654e+01 | 
| 05-02 01:34:51 epoch: 2168| train loss i: [0.05	1.44	5.35	4.85	4.04	1.54] test loss i: [0.04	2.65	5.1 	3.86	3.28	1.6 ] | 
| 05-02 01:34:52 epoch: 2169| time: 1.1s| train loss: +1.679e+01 | test loss: +2.324e+01 | 
| 05-02 01:34:52 epoch: 2169| train loss i: [0.05	0.81	5.83	4.9 	3.64	1.57] test loss i: [0.08	1.75	7.81	6.41	4.95	2.24] | 
| 05-02 01:34:53 epoch: 2170| time: 1.1s| train loss: +1.652e+01 | test loss: +1.572e+01 | 
| 05-02 01:34:53 epoch: 2170| train loss i: [0.04	0.91	5.5 	4.8 	3.76	1.51] test loss i: [0.06	0.48	5.76	4.58	3.33	1.51] | 
| 05-02 01:34:54 epoch: 2171| time: 1.1s| train loss: +1.656e+01 | test loss: +1.958e+01 | 
| 05-02 01:34:54 epoch: 2171| train loss i: [0.07	1.39	4.98	4.54	4.04	1.55] test loss i: [0.06	1.6 	5.86	6.19	4.14	1.73] | 
| 05-02 01:34:56 epoch: 2172| time: 1.0s| train loss: +1.632e+01 | test loss: +2.633e+01 | 
| 05-02 01:34:56 epoch: 2172| train loss i: [0.08	1.16	5.38	4.68	3.49	1.53] test loss i: [0.16	2.19	8.73	7.89	5.22	2.14] | 
| 05-02 01:34:57 epoch: 2173| time: 1.1s| train loss: +1.689e+01 | test loss: +1.451e+01 | 
| 05-02 01:34:57 epoch: 2173| train loss i: [0.05	1.41	5.68	4.74	3.48	1.53] test loss i: [0.03	0.61	4.62	4.63	3.3 	1.32] | 
| 05-02 01:34:58 epoch: 2174| time: 1.1s| train loss: +1.582e+01 | test loss: +1.798e+01 | 
| 05-02 01:34:58 epoch: 2174| train loss i: [0.08	1.02	5.16	4.71	3.35	1.5 ] test loss i: [0.06	1.57	5.86	4.89	3.64	1.96] | 
| 05-02 01:34:59 epoch: 2175| time: 1.1s| train loss: +1.713e+01 | test loss: +1.824e+01 | 
| 05-02 01:34:59 epoch: 2175| train loss i: [0.09	1.91	5.59	4.25	3.77	1.52] test loss i: [0.04	1.72	6.86	4.39	3.5 	1.73] | 
| 05-02 01:35:00 epoch: 2176| time: 1.1s| train loss: +1.689e+01 | test loss: +1.578e+01 | 
| 05-02 01:35:00 epoch: 2176| train loss i: [0.06	0.89	5.77	4.9 	3.69	1.58] test loss i: [0.22	1.28	5.38	3.95	3.51	1.44] | 
| 05-02 01:35:01 epoch: 2177| time: 1.1s| train loss: +1.767e+01 | test loss: +1.380e+01 | 
| 05-02 01:35:01 epoch: 2177| train loss i: [0.09	1.11	6.08	4.82	4.  	1.58] test loss i: [0.04	0.22	4.2 	4.56	3.39	1.39] | 
| 05-02 01:35:02 epoch: 2178| time: 1.0s| train loss: +1.663e+01 | test loss: +1.902e+01 | 
| 05-02 01:35:02 epoch: 2178| train loss i: [0.05	0.79	5.21	4.99	4.05	1.53] test loss i: [0.04	1.62	6.36	5.5 	3.85	1.64] | 
| 05-02 01:35:03 epoch: 2179| time: 1.1s| train loss: +1.640e+01 | test loss: +1.665e+01 | 
| 05-02 01:35:03 epoch: 2179| train loss i: [0.07	1.4 	4.68	4.74	4.01	1.49] test loss i: [0.07	2.28	4.31	4.44	3.54	2.  ] | 
| 05-02 01:35:04 epoch: 2180| time: 1.1s| train loss: +1.769e+01 | test loss: +2.616e+01 | 
| 05-02 01:35:04 epoch: 2180| train loss i: [0.08	1.35	5.32	5.17	4.15	1.61] test loss i: [0.12	3.27	8.42	7.3 	4.93	2.13] | 
| 05-02 01:35:05 epoch: 2181| time: 1.1s| train loss: +1.657e+01 | test loss: +1.677e+01 | 
| 05-02 01:35:05 epoch: 2181| train loss i: [0.06	1.05	5.3 	5.02	3.58	1.56] test loss i: [0.12	0.71	4.55	5.23	4.19	1.98] | 
| 05-02 01:35:06 epoch: 2182| time: 1.1s| train loss: +1.628e+01 | test loss: +1.865e+01 | 
| 05-02 01:35:06 epoch: 2182| train loss i: [0.06	0.91	5.26	4.85	3.54	1.65] test loss i: [0.06	1.07	6.68	4.93	4.15	1.76] | 
| 05-02 01:35:07 epoch: 2183| time: 1.0s| train loss: +1.628e+01 | test loss: +1.919e+01 | 
| 05-02 01:35:07 epoch: 2183| train loss i: [0.08	1.18	5.09	4.67	3.72	1.53] test loss i: [0.05	3.19	5.01	5.05	4.21	1.67] | 
| 05-02 01:35:08 epoch: 2184| time: 1.1s| train loss: +1.628e+01 | test loss: +2.190e+01 | 
| 05-02 01:35:08 epoch: 2184| train loss i: [0.07	0.8 	5.27	4.87	3.73	1.55] test loss i: [0.13	1.11	7.31	5.13	6.21	2.02] | 
| 05-02 01:35:09 epoch: 2185| time: 1.1s| train loss: +1.610e+01 | test loss: +1.890e+01 | 
| 05-02 01:35:09 epoch: 2185| train loss i: [0.07	1.38	4.94	4.69	3.52	1.49] test loss i: [0.09	2.58	6.31	4.77	3.3 	1.85] | 
| 05-02 01:35:10 epoch: 2186| time: 1.1s| train loss: +1.579e+01 | test loss: +1.956e+01 | 
| 05-02 01:35:10 epoch: 2186| train loss i: [0.09	1.05	4.98	4.56	3.53	1.59] test loss i: [0.19	1.26	6.51	6.01	3.6 	1.98] | 
| 05-02 01:35:11 epoch: 2187| time: 1.1s| train loss: +1.636e+01 | test loss: +1.658e+01 | 
| 05-02 01:35:11 epoch: 2187| train loss i: [0.05	0.86	5.07	4.92	3.89	1.57] test loss i: [0.04	2.25	4.34	4.45	3.81	1.68] | 
| 05-02 01:35:13 epoch: 2188| time: 1.1s| train loss: +1.713e+01 | test loss: +1.545e+01 | 
| 05-02 01:35:13 epoch: 2188| train loss i: [0.09	1.41	5.54	4.9 	3.69	1.5 ] test loss i: [0.21	0.57	4.77	4.64	3.75	1.52] | 
| 05-02 01:35:14 epoch: 2189| time: 1.0s| train loss: +1.557e+01 | test loss: +1.974e+01 | 
| 05-02 01:35:14 epoch: 2189| train loss i: [0.08	0.72	4.97	4.56	3.6 	1.64] test loss i: [0.2 	2.12	5.89	5.37	4.49	1.66] | 
| 05-02 01:35:15 epoch: 2190| time: 1.1s| train loss: +1.605e+01 | test loss: +1.400e+01 | 
| 05-02 01:35:15 epoch: 2190| train loss i: [0.1 	1.37	4.86	4.37	3.83	1.52] test loss i: [0.18	0.11	5.4 	4.02	2.85	1.45] | 
| 05-02 01:35:16 epoch: 2191| time: 1.1s| train loss: +1.751e+01 | test loss: +2.166e+01 | 
| 05-02 01:35:16 epoch: 2191| train loss i: [0.09	1.88	5.43	4.95	3.56	1.6 ] test loss i: [0.09	3.21	5.89	5.59	4.99	1.89] | 
| 05-02 01:35:17 epoch: 2192| time: 1.1s| train loss: +1.690e+01 | test loss: +1.701e+01 | 
| 05-02 01:35:17 epoch: 2192| train loss i: [0.07	1.48	5.11	4.69	3.99	1.55] test loss i: [0.05	0.96	5.15	5.16	3.94	1.76] | 
| 05-02 01:35:18 epoch: 2193| time: 1.1s| train loss: +1.666e+01 | test loss: +1.764e+01 | 
| 05-02 01:35:18 epoch: 2193| train loss i: [0.07	1.78	5.02	4.38	3.84	1.57] test loss i: [0.06	0.53	6.16	5.4 	3.85	1.65] | 
| 05-02 01:35:19 epoch: 2194| time: 1.1s| train loss: +1.704e+01 | test loss: +1.700e+01 | 
| 05-02 01:35:19 epoch: 2194| train loss i: [0.07	0.99	5.57	4.94	3.94	1.53] test loss i: [0.07	1.77	4.88	5.24	3.27	1.78] | 
| 05-02 01:35:20 epoch: 2195| time: 1.1s| train loss: +1.612e+01 | test loss: +1.900e+01 | 
| 05-02 01:35:20 epoch: 2195| train loss i: [0.08	1.3 	4.51	4.88	3.82	1.52] test loss i: [0.09	2.57	5.75	5.03	3.68	1.87] | 
| 05-02 01:35:21 epoch: 2196| time: 1.1s| train loss: +1.856e+01 | test loss: +2.092e+01 | 
| 05-02 01:35:21 epoch: 2196| train loss i: [0.07	2.09	5.9 	5.05	3.92	1.53] test loss i: [0.1 	1.61	6.66	6.03	4.55	1.98] | 
| 05-02 01:35:22 epoch: 2197| time: 1.1s| train loss: +1.744e+01 | test loss: +1.520e+01 | 
| 05-02 01:35:22 epoch: 2197| train loss i: [0.09	1.37	6.07	4.62	3.84	1.46] test loss i: [0.09	0.98	4.76	4.27	3.64	1.46] | 
| 05-02 01:35:23 epoch: 2198| time: 1.1s| train loss: +1.705e+01 | test loss: +1.538e+01 | 
| 05-02 01:35:23 epoch: 2198| train loss i: [0.06	1.56	5.37	4.8 	3.66	1.61] test loss i: [0.08	0.2 	5.13	4.11	3.98	1.88] | 
| 05-02 01:35:24 epoch: 2199| time: 1.1s| train loss: +1.685e+01 | test loss: +2.904e+01 | 
| 05-02 01:35:24 epoch: 2199| train loss i: [0.06	1.18	5.34	4.75	3.86	1.66] test loss i: [ 0.26	 3.1 	10.03	 8.03	 5.04	 2.57] | 
| 05-02 01:35:25 epoch: 2200| time: 1.0s| train loss: +1.625e+01 | test loss: +1.979e+01 | 
| 05-02 01:35:25 epoch: 2200| train loss i: [0.08	1.12	5.38	4.86	3.29	1.52] test loss i: [0.07	2.06	6.56	4.98	4.37	1.75] | 
| 05-02 01:35:26 epoch: 2201| time: 1.1s| train loss: +1.658e+01 | test loss: +1.830e+01 | 
| 05-02 01:35:26 epoch: 2201| train loss i: [0.06	1.07	5.49	4.77	3.72	1.46] test loss i: [0.17	3.76	5.23	3.76	3.74	1.66] | 
| 05-02 01:35:27 epoch: 2202| time: 1.1s| train loss: +1.653e+01 | test loss: +2.624e+01 | 
| 05-02 01:35:27 epoch: 2202| train loss i: [0.07	0.79	5.35	4.76	4.01	1.55] test loss i: [0.07	3.57	8.67	6.67	4.91	2.36] | 
| 05-02 01:35:29 epoch: 2203| time: 1.1s| train loss: +1.668e+01 | test loss: +1.920e+01 | 
| 05-02 01:35:29 epoch: 2203| train loss i: [0.06	1.19	5.38	4.58	3.93	1.54] test loss i: [0.3 	1.85	6.6 	4.57	4.29	1.6 ] | 
| 05-02 01:35:30 epoch: 2204| time: 1.1s| train loss: +1.759e+01 | test loss: +1.552e+01 | 
| 05-02 01:35:30 epoch: 2204| train loss i: [0.1 	1.81	5.51	4.99	3.66	1.52] test loss i: [0.09	0.28	5.55	4.89	3.13	1.58] | 
| 05-02 01:35:31 epoch: 2205| time: 1.0s| train loss: +1.625e+01 | test loss: +1.591e+01 | 
| 05-02 01:35:31 epoch: 2205| train loss i: [0.06	0.67	5.48	4.72	3.81	1.51] test loss i: [0.08	0.87	5.49	4.02	3.94	1.51] | 
| 05-02 01:35:32 epoch: 2206| time: 1.0s| train loss: +1.711e+01 | test loss: +2.773e+01 | 
| 05-02 01:35:32 epoch: 2206| train loss i: [0.07	1.05	5.61	5.11	3.77	1.5 ] test loss i: [0.18	1.14	9.34	9.  	5.88	2.19] | 
| 05-02 01:35:33 epoch: 2207| time: 1.1s| train loss: +1.639e+01 | test loss: +1.958e+01 | 
| 05-02 01:35:33 epoch: 2207| train loss i: [0.08	1.69	5.06	4.35	3.67	1.55] test loss i: [0.05	0.86	6.69	5.3 	4.8 	1.89] | 
| 05-02 01:35:34 epoch: 2208| time: 1.1s| train loss: +1.695e+01 | test loss: +1.887e+01 | 
| 05-02 01:35:34 epoch: 2208| train loss i: [0.07	1.8 	5.33	4.57	3.64	1.54] test loss i: [0.04	1.97	6.41	4.95	4.03	1.47] | 
| 05-02 01:35:35 epoch: 2209| time: 1.1s| train loss: +1.663e+01 | test loss: +2.336e+01 | 
| 05-02 01:35:35 epoch: 2209| train loss i: [0.07	0.86	5.5 	4.79	3.83	1.59] test loss i: [0.05	2.59	7.26	5.77	5.67	2.02] | 
| 05-02 01:35:36 epoch: 2210| time: 1.1s| train loss: +1.669e+01 | test loss: +1.566e+01 | 
| 05-02 01:35:36 epoch: 2210| train loss i: [0.04	1.11	5.83	4.49	3.65	1.57] test loss i: [0.04	0.71	5.89	3.8 	3.66	1.56] | 
| 05-02 01:35:37 epoch: 2211| time: 1.1s| train loss: +1.609e+01 | test loss: +2.186e+01 | 
| 05-02 01:35:37 epoch: 2211| train loss i: [0.04	0.8 	4.77	5.29	3.62	1.57] test loss i: [0.08	1.39	6.68	6.18	5.48	2.06] | 
| 05-02 01:35:38 epoch: 2212| time: 1.1s| train loss: +1.735e+01 | test loss: +1.977e+01 | 
| 05-02 01:35:38 epoch: 2212| train loss i: [0.06	1.3 	5.72	4.89	3.8 	1.58] test loss i: [0.06	0.26	7.64	5.63	4.28	1.91] | 
| 05-02 01:35:39 epoch: 2213| time: 1.1s| train loss: +1.722e+01 | test loss: +1.969e+01 | 
| 05-02 01:35:39 epoch: 2213| train loss i: [0.06	1.41	5.63	4.83	3.71	1.58] test loss i: [0.06	1.32	6.85	4.89	4.5 	2.07] | 
| 05-02 01:35:40 epoch: 2214| time: 1.1s| train loss: +1.619e+01 | test loss: +1.782e+01 | 
| 05-02 01:35:40 epoch: 2214| train loss i: [0.09	0.99	5.17	4.68	3.67	1.59] test loss i: [0.06	1.13	6.89	4.57	3.7 	1.46] | 
| 05-02 01:35:41 epoch: 2215| time: 1.1s| train loss: +1.673e+01 | test loss: +1.683e+01 | 
| 05-02 01:35:41 epoch: 2215| train loss i: [0.15	1.31	5.14	4.69	3.95	1.49] test loss i: [0.11	1.05	6.15	4.2 	3.42	1.9 ] | 
| 05-02 01:35:42 epoch: 2216| time: 1.0s| train loss: +1.569e+01 | test loss: +2.219e+01 | 
| 05-02 01:35:42 epoch: 2216| train loss i: [0.12	0.68	4.64	4.71	4.08	1.46] test loss i: [0.26	0.8 	6.69	6.28	5.98	2.18] | 
| 05-02 01:35:43 epoch: 2217| time: 1.1s| train loss: +1.698e+01 | test loss: +1.905e+01 | 
| 05-02 01:35:43 epoch: 2217| train loss i: [0.14	1.41	5.29	4.75	3.83	1.57] test loss i: [0.23	0.92	6.5 	5.02	4.35	2.03] | 
| 05-02 01:35:45 epoch: 2218| time: 1.1s| train loss: +1.683e+01 | test loss: +1.554e+01 | 
| 05-02 01:35:45 epoch: 2218| train loss i: [0.13	1.4 	5.48	4.69	3.61	1.53] test loss i: [0.09	0.67	4.65	4.16	4.24	1.73] | 
| 05-02 01:35:46 epoch: 2219| time: 1.1s| train loss: +1.663e+01 | test loss: +1.818e+01 | 
| 05-02 01:35:46 epoch: 2219| train loss i: [0.14	1.31	5.01	4.86	3.71	1.6 ] test loss i: [0.18	1.14	6.47	4.4 	4.33	1.66] | 
| 05-02 01:35:47 epoch: 2220| time: 1.1s| train loss: +1.718e+01 | test loss: +2.074e+01 | 
| 05-02 01:35:47 epoch: 2220| train loss i: [0.1 	1.13	5.6 	4.99	3.8 	1.55] test loss i: [0.13	3.  	5.34	5.51	4.63	2.12] | 
| 05-02 01:35:48 epoch: 2221| time: 1.0s| train loss: +1.722e+01 | test loss: +1.919e+01 | 
| 05-02 01:35:48 epoch: 2221| train loss i: [0.14	1.39	5.51	4.88	3.74	1.56] test loss i: [0.13	2.16	5.77	4.45	4.89	1.79] | 
| 05-02 01:35:49 epoch: 2222| time: 1.0s| train loss: +1.713e+01 | test loss: +1.728e+01 | 
| 05-02 01:35:49 epoch: 2222| train loss i: [0.05	1.06	5.39	5.11	3.88	1.63] test loss i: [0.08	2.59	5.09	4.61	3.45	1.46] | 
| 05-02 01:35:50 epoch: 2223| time: 1.0s| train loss: +1.660e+01 | test loss: +2.156e+01 | 
| 05-02 01:35:50 epoch: 2223| train loss i: [0.07	1.11	5.22	4.78	3.89	1.53] test loss i: [0.06	2.95	6.78	5.25	4.84	1.68] | 
| 05-02 01:35:51 epoch: 2224| time: 1.1s| train loss: +1.706e+01 | test loss: +1.876e+01 | 
| 05-02 01:35:51 epoch: 2224| train loss i: [0.09	1.47	5.14	5.01	3.82	1.52] test loss i: [0.06	1.37	6.38	5.12	3.57	2.26] | 
| 05-02 01:35:52 epoch: 2225| time: 1.1s| train loss: +1.717e+01 | test loss: +1.542e+01 | 
| 05-02 01:35:52 epoch: 2225| train loss i: [0.08	1.47	5.17	4.98	3.83	1.63] test loss i: [0.05	1.95	5.7 	3.38	2.86	1.48] | 
| 05-02 01:35:53 epoch: 2226| time: 1.1s| train loss: +1.751e+01 | test loss: +1.441e+01 | 
| 05-02 01:35:53 epoch: 2226| train loss i: [0.05	1.32	5.73	4.86	3.98	1.58] test loss i: [0.12	0.61	4.29	4.69	3.17	1.52] | 
| 05-02 01:35:54 epoch: 2227| time: 1.1s| train loss: +1.625e+01 | test loss: +2.066e+01 | 
| 05-02 01:35:54 epoch: 2227| train loss i: [0.08	1.3 	4.97	4.63	3.72	1.56] test loss i: [0.13	2.44	6.2 	5.98	3.73	2.17] | 
| 05-02 01:35:55 epoch: 2228| time: 1.0s| train loss: +1.628e+01 | test loss: +1.491e+01 | 
| 05-02 01:35:55 epoch: 2228| train loss i: [0.05	1.02	4.92	5.02	3.68	1.58] test loss i: [0.13	1.04	3.97	4.59	3.61	1.57] | 
| 05-02 01:35:56 epoch: 2229| time: 1.0s| train loss: +1.630e+01 | test loss: +1.893e+01 | 
| 05-02 01:35:56 epoch: 2229| train loss i: [0.06	1.22	5.13	4.77	3.66	1.47] test loss i: [0.1 	1.2 	6.52	4.53	4.54	2.04] | 
| 05-02 01:35:57 epoch: 2230| time: 1.0s| train loss: +1.795e+01 | test loss: +2.007e+01 | 
| 05-02 01:35:57 epoch: 2230| train loss i: [0.04	1.34	6.13	4.9 	3.99	1.55] test loss i: [0.16	1.46	5.67	6.08	4.78	1.92] | 
| 05-02 01:35:58 epoch: 2231| time: 1.0s| train loss: +1.590e+01 | test loss: +1.850e+01 | 
| 05-02 01:35:58 epoch: 2231| train loss i: [0.05	1.02	5.07	4.55	3.58	1.63] test loss i: [0.04	2.94	5.61	4.37	3.59	1.95] | 
| 05-02 01:35:59 epoch: 2232| time: 1.0s| train loss: +1.727e+01 | test loss: +1.655e+01 | 
| 05-02 01:35:59 epoch: 2232| train loss i: [0.06	1.29	5.44	4.92	3.93	1.63] test loss i: [0.14	1.58	5.18	4.28	3.68	1.69] | 
| 05-02 01:36:00 epoch: 2233| time: 1.0s| train loss: +1.773e+01 | test loss: +1.609e+01 | 
| 05-02 01:36:00 epoch: 2233| train loss i: [0.04	1.95	5.51	4.94	3.76	1.54] test loss i: [0.06	0.32	5.7 	4.17	3.76	2.08] | 
| 05-02 01:36:01 epoch: 2234| time: 1.1s| train loss: +1.684e+01 | test loss: +1.952e+01 | 
| 05-02 01:36:01 epoch: 2234| train loss i: [0.07	1.1 	5.67	4.8 	3.63	1.56] test loss i: [0.17	2.08	4.59	6.53	4.46	1.7 ] | 
| 05-02 01:36:03 epoch: 2235| time: 1.1s| train loss: +1.722e+01 | test loss: +2.376e+01 | 
| 05-02 01:36:03 epoch: 2235| train loss i: [0.06	1.41	5.57	4.84	3.8 	1.53] test loss i: [0.08	1.7 	6.7 	6.99	6.03	2.26] | 
| 05-02 01:36:04 epoch: 2236| time: 1.1s| train loss: +1.576e+01 | test loss: +2.707e+01 | 
| 05-02 01:36:04 epoch: 2236| train loss i: [0.05	1.  	4.92	4.55	3.74	1.5 ] test loss i: [0.18	3.53	7.76	7.03	6.25	2.32] | 
| 05-02 01:36:05 epoch: 2237| time: 1.1s| train loss: +1.590e+01 | test loss: +1.807e+01 | 
| 05-02 01:36:05 epoch: 2237| train loss i: [0.05	1.04	4.6 	4.69	3.93	1.59] test loss i: [0.07	2.02	5.59	5.05	3.74	1.6 ] | 
| 05-02 01:36:06 epoch: 2238| time: 1.0s| train loss: +1.689e+01 | test loss: +1.850e+01 | 
| 05-02 01:36:06 epoch: 2238| train loss i: [0.05	1.24	4.97	4.83	4.19	1.61] test loss i: [0.11	0.64	6.62	5.57	3.62	1.93] | 
| 05-02 01:36:07 epoch: 2239| time: 1.1s| train loss: +1.616e+01 | test loss: +1.615e+01 | 
| 05-02 01:36:07 epoch: 2239| train loss i: [0.06	1.29	5.08	4.52	3.59	1.62] test loss i: [0.06	0.77	5.46	4.89	3.21	1.76] | 
| 05-02 01:36:08 epoch: 2240| time: 1.1s| train loss: +1.720e+01 | test loss: +2.017e+01 | 
| 05-02 01:36:08 epoch: 2240| train loss i: [0.08	1.58	5.37	4.87	3.74	1.56] test loss i: [0.05	2.71	6.3 	5.06	4.09	1.97] | 
| 05-02 01:36:09 epoch: 2241| time: 1.1s| train loss: +1.715e+01 | test loss: +2.113e+01 | 
| 05-02 01:36:09 epoch: 2241| train loss i: [0.06	1.3 	5.23	4.96	4.01	1.59] test loss i: [0.09	1.36	6.63	6.2 	4.85	2.  ] | 
| 05-02 01:36:10 epoch: 2242| time: 1.1s| train loss: +1.666e+01 | test loss: +1.772e+01 | 
| 05-02 01:36:10 epoch: 2242| train loss i: [0.09	1.29	5.55	4.61	3.66	1.46] test loss i: [0.15	1.35	6.23	4.13	4.24	1.62] | 
| 05-02 01:36:11 epoch: 2243| time: 1.1s| train loss: +1.698e+01 | test loss: +1.667e+01 | 
| 05-02 01:36:11 epoch: 2243| train loss i: [0.05	1.17	5.55	4.72	3.93	1.56] test loss i: [0.04	1.01	4.88	5.21	4.13	1.41] | 
| 05-02 01:36:12 epoch: 2244| time: 1.1s| train loss: +1.701e+01 | test loss: +1.597e+01 | 
| 05-02 01:36:12 epoch: 2244| train loss i: [0.05	1.  	5.84	4.63	3.85	1.63] test loss i: [0.05	1.32	5.36	4.29	3.56	1.4 ] | 
| 05-02 01:36:13 epoch: 2245| time: 1.1s| train loss: +1.761e+01 | test loss: +1.566e+01 | 
| 05-02 01:36:13 epoch: 2245| train loss i: [0.06	1.51	5.73	5.14	3.66	1.52] test loss i: [0.05	1.27	4.21	4.59	4.09	1.46] | 
| 05-02 01:36:14 epoch: 2246| time: 1.1s| train loss: +1.665e+01 | test loss: +1.722e+01 | 
| 05-02 01:36:14 epoch: 2246| train loss i: [0.07	1.17	5.19	4.81	3.71	1.71] test loss i: [0.14	0.91	6.51	4.67	3.58	1.41] | 
| 05-02 01:36:15 epoch: 2247| time: 1.1s| train loss: +1.700e+01 | test loss: +1.672e+01 | 
| 05-02 01:36:15 epoch: 2247| train loss i: [0.05	1.21	5.31	4.88	3.98	1.57] test loss i: [0.04	2.16	4.9 	4.12	3.66	1.84] | 
| 05-02 01:36:16 epoch: 2248| time: 1.1s| train loss: +1.635e+01 | test loss: +1.991e+01 | 
| 05-02 01:36:16 epoch: 2248| train loss i: [0.07	1.04	5.02	4.96	3.74	1.52] test loss i: [0.15	1.94	6.52	5.02	4.45	1.84] | 
| 05-02 01:36:17 epoch: 2249| time: 1.1s| train loss: +1.604e+01 | test loss: +1.961e+01 | 
| 05-02 01:36:17 epoch: 2249| train loss i: [0.08	0.74	5.21	4.74	3.82	1.45] test loss i: [0.06	4.24	4.1 	5.85	3.73	1.62] | 
| 05-02 01:36:19 epoch: 2250| time: 1.1s| train loss: +1.658e+01 | test loss: +1.817e+01 | 
| 05-02 01:36:19 epoch: 2250| train loss i: [0.09	1.49	5.18	4.7 	3.54	1.57] test loss i: [0.11	0.8 	6.18	5.39	3.94	1.75] | 
| 05-02 01:36:20 epoch: 2251| time: 1.1s| train loss: +1.752e+01 | test loss: +2.396e+01 | 
| 05-02 01:36:20 epoch: 2251| train loss i: [0.07	1.86	5.53	4.73	3.86	1.46] test loss i: [0.09	1.56	8.05	6.63	5.5 	2.13] | 
| 05-02 01:36:21 epoch: 2252| time: 1.1s| train loss: +1.709e+01 | test loss: +1.665e+01 | 
| 05-02 01:36:21 epoch: 2252| train loss i: [0.07	1.4 	5.24	4.95	3.87	1.55] test loss i: [0.07	0.47	6.38	4.89	3.48	1.36] | 
| 05-02 01:36:22 epoch: 2253| time: 1.1s| train loss: +1.724e+01 | test loss: +1.369e+01 | 
| 05-02 01:36:22 epoch: 2253| train loss i: [0.08	1.02	5.66	4.84	4.04	1.61] test loss i: [0.03	0.58	3.87	4.4 	3.32	1.5 ] | 
| 05-02 01:36:23 epoch: 2254| time: 1.1s| train loss: +1.666e+01 | test loss: +1.621e+01 | 
| 05-02 01:36:23 epoch: 2254| train loss i: [0.05	1.16	5.35	4.71	3.83	1.55] test loss i: [0.06	1.43	5.43	4.49	3.04	1.77] | 
| 05-02 01:36:24 epoch: 2255| time: 1.1s| train loss: +1.734e+01 | test loss: +1.714e+01 | 
| 05-02 01:36:24 epoch: 2255| train loss i: [0.04	1.47	5.52	4.85	3.88	1.57] test loss i: [0.08	1.14	5.1 	5.51	3.79	1.52] | 
| 05-02 01:36:25 epoch: 2256| time: 1.1s| train loss: +1.660e+01 | test loss: +1.677e+01 | 
| 05-02 01:36:25 epoch: 2256| train loss i: [0.05	1.21	5.49	4.54	3.8 	1.52] test loss i: [0.03	1.4 	4.11	5.96	3.88	1.39] | 
| 05-02 01:36:26 epoch: 2257| time: 1.1s| train loss: +1.676e+01 | test loss: +1.812e+01 | 
| 05-02 01:36:26 epoch: 2257| train loss i: [0.05	1.76	4.88	4.77	3.68	1.62] test loss i: [0.04	2.83	4.  	5.54	3.81	1.89] | 
| 05-02 01:36:27 epoch: 2258| time: 1.1s| train loss: +1.727e+01 | test loss: +1.553e+01 | 
| 05-02 01:36:27 epoch: 2258| train loss i: [0.07	1.62	5.1 	4.94	3.89	1.66] test loss i: [0.03	1.85	3.66	4.68	3.68	1.63] | 
| 05-02 01:36:28 epoch: 2259| time: 1.1s| train loss: +1.687e+01 | test loss: +1.570e+01 | 
| 05-02 01:36:28 epoch: 2259| train loss i: [0.09	1.04	5.41	5.07	3.68	1.58] test loss i: [0.07	0.52	4.89	4.74	3.95	1.51] | 
| 05-02 01:36:29 epoch: 2260| time: 1.1s| train loss: +1.747e+01 | test loss: +2.364e+01 | 
| 05-02 01:36:29 epoch: 2260| train loss i: [0.06	1.42	5.88	4.66	3.92	1.53] test loss i: [0.08	3.58	7.29	5.77	4.76	2.17] | 
| 05-02 01:36:30 epoch: 2261| time: 1.1s| train loss: +1.697e+01 | test loss: +1.910e+01 | 
| 05-02 01:36:30 epoch: 2261| train loss i: [0.07	1.56	5.35	4.7 	3.79	1.51] test loss i: [0.12	1.08	6.71	5.19	4.23	1.78] | 
| 05-02 01:36:31 epoch: 2262| time: 1.1s| train loss: +1.629e+01 | test loss: +1.543e+01 | 
| 05-02 01:36:31 epoch: 2262| train loss i: [0.06	1.3 	5.25	4.39	3.68	1.61] test loss i: [0.17	0.86	4.3 	5.12	3.43	1.55] | 
| 05-02 01:36:32 epoch: 2263| time: 1.1s| train loss: +1.625e+01 | test loss: +1.647e+01 | 
| 05-02 01:36:32 epoch: 2263| train loss i: [0.06	1.34	5.17	4.5 	3.65	1.52] test loss i: [0.05	0.83	5.25	5.83	3.05	1.47] | 
| 05-02 01:36:34 epoch: 2264| time: 1.1s| train loss: +1.672e+01 | test loss: +1.903e+01 | 
| 05-02 01:36:34 epoch: 2264| train loss i: [0.06	1.23	5.21	4.83	3.79	1.59] test loss i: [0.13	1.45	5.75	5.53	4.43	1.74] | 
| 05-02 01:36:35 epoch: 2265| time: 1.1s| train loss: +1.657e+01 | test loss: +1.890e+01 | 
| 05-02 01:36:35 epoch: 2265| train loss i: [0.07	0.98	5.16	4.93	3.86	1.58] test loss i: [0.2 	1.5 	6.71	5.31	3.5 	1.68] | 
| 05-02 01:36:36 epoch: 2266| time: 1.1s| train loss: +1.738e+01 | test loss: +1.634e+01 | 
| 05-02 01:36:36 epoch: 2266| train loss i: [0.08	1.66	5.52	4.88	3.66	1.58] test loss i: [0.07	0.8 	5.41	4.62	3.64	1.81] | 
| 05-02 01:36:37 epoch: 2267| time: 1.1s| train loss: +1.743e+01 | test loss: +1.839e+01 | 
| 05-02 01:36:37 epoch: 2267| train loss i: [0.07	1.69	5.3 	5.07	3.72	1.58] test loss i: [0.16	0.91	5.75	6.01	3.94	1.61] | 
| 05-02 01:36:38 epoch: 2268| time: 1.1s| train loss: +1.748e+01 | test loss: +1.380e+01 | 
| 05-02 01:36:38 epoch: 2268| train loss i: [0.07	1.51	5.51	4.89	3.93	1.57] test loss i: [0.12	0.77	3.78	3.83	3.93	1.37] | 
| 05-02 01:36:39 epoch: 2269| time: 1.1s| train loss: +1.736e+01 | test loss: +1.697e+01 | 
| 05-02 01:36:39 epoch: 2269| train loss i: [0.07	1.17	5.11	5.65	3.78	1.57] test loss i: [0.07	1.39	4.36	5.74	3.65	1.76] | 
| 05-02 01:36:40 epoch: 2270| time: 1.1s| train loss: +1.691e+01 | test loss: +2.292e+01 | 
| 05-02 01:36:40 epoch: 2270| train loss i: [0.06	1.22	5.36	4.9 	3.81	1.56] test loss i: [0.05	1.64	7.28	6.94	4.99	2.02] | 
| 05-02 01:36:41 epoch: 2271| time: 1.1s| train loss: +1.636e+01 | test loss: +1.525e+01 | 
| 05-02 01:36:41 epoch: 2271| train loss i: [0.08	1.17	5.17	4.61	3.69	1.63] test loss i: [0.18	0.9 	4.67	4.62	3.21	1.67] | 
| 05-02 01:36:42 epoch: 2272| time: 1.1s| train loss: +1.614e+01 | test loss: +1.758e+01 | 
| 05-02 01:36:42 epoch: 2272| train loss i: [0.07	0.77	5.11	4.87	3.72	1.6 ] test loss i: [0.14	1.3 	5.41	4.69	4.41	1.65] | 
| 05-02 01:36:43 epoch: 2273| time: 1.1s| train loss: +1.698e+01 | test loss: +1.891e+01 | 
| 05-02 01:36:43 epoch: 2273| train loss i: [0.08	1.44	5.21	4.96	3.77	1.52] test loss i: [0.05	0.7 	7.4 	5.33	3.8 	1.62] | 
| 05-02 01:36:44 epoch: 2274| time: 1.1s| train loss: +1.669e+01 | test loss: +2.488e+01 | 
| 05-02 01:36:44 epoch: 2274| train loss i: [0.05	1.53	4.74	5.06	3.72	1.6 ] test loss i: [0.13	4.01	6.71	5.84	6.28	1.91] | 
| 05-02 01:36:45 epoch: 2275| time: 1.1s| train loss: +1.749e+01 | test loss: +1.339e+01 | 
| 05-02 01:36:45 epoch: 2275| train loss i: [0.07	1.42	5.53	4.96	3.91	1.6 ] test loss i: [0.1 	0.73	4.66	3.19	3.2 	1.5 ] | 
| 05-02 01:36:46 epoch: 2276| time: 1.1s| train loss: +1.757e+01 | test loss: +1.795e+01 | 
| 05-02 01:36:46 epoch: 2276| train loss i: [0.12	1.18	5.94	4.9 	3.95	1.48] test loss i: [0.07	1.54	6.37	4.57	3.72	1.69] | 
| 05-02 01:36:47 epoch: 2277| time: 1.1s| train loss: +1.623e+01 | test loss: +2.395e+01 | 
| 05-02 01:36:47 epoch: 2277| train loss i: [0.07	1.33	5.12	4.27	3.89	1.55] test loss i: [0.15	3.62	5.24	7.06	5.54	2.34] | 
| 05-02 01:36:49 epoch: 2278| time: 1.1s| train loss: +1.662e+01 | test loss: +1.893e+01 | 
| 05-02 01:36:49 epoch: 2278| train loss i: [0.1 	1.06	5.17	4.94	3.75	1.59] test loss i: [0.06	2.34	5.83	4.79	4.07	1.84] | 
| 05-02 01:36:50 epoch: 2279| time: 1.1s| train loss: +1.698e+01 | test loss: +2.302e+01 | 
| 05-02 01:36:50 epoch: 2279| train loss i: [0.05	1.5 	5.43	4.64	3.87	1.49] test loss i: [0.09	1.13	7.32	7.75	4.75	1.99] | 
| 05-02 01:36:51 epoch: 2280| time: 1.1s| train loss: +1.743e+01 | test loss: +1.409e+01 | 
| 05-02 01:36:51 epoch: 2280| train loss i: [0.06	2.26	5.31	4.7 	3.57	1.54] test loss i: [0.07	0.78	4.31	4.04	3.21	1.68] | 
| 05-02 01:36:52 epoch: 2281| time: 1.1s| train loss: +1.717e+01 | test loss: +1.861e+01 | 
| 05-02 01:36:52 epoch: 2281| train loss i: [0.07	1.51	4.87	5.04	4.11	1.57] test loss i: [0.17	3.24	4.62	4.8 	4.17	1.62] | 
| 05-02 01:36:53 epoch: 2282| time: 1.1s| train loss: +1.772e+01 | test loss: +1.571e+01 | 
| 05-02 01:36:53 epoch: 2282| train loss i: [0.1 	2.13	5.49	4.44	3.94	1.62] test loss i: [0.05	1.22	4.87	4.64	3.41	1.52] | 
| 05-02 01:36:54 epoch: 2283| time: 1.1s| train loss: +1.723e+01 | test loss: +2.037e+01 | 
| 05-02 01:36:54 epoch: 2283| train loss i: [0.06	1.18	5.83	4.63	3.98	1.55] test loss i: [0.16	1.41	7.32	5.49	4.14	1.84] | 
| 05-02 01:36:55 epoch: 2284| time: 1.1s| train loss: +1.789e+01 | test loss: +2.208e+01 | 
| 05-02 01:36:55 epoch: 2284| train loss i: [0.06	1.3 	5.97	5.12	3.89	1.56] test loss i: [0.07	2.55	7.36	5.7 	4.34	2.08] | 
| 05-02 01:36:56 epoch: 2285| time: 1.1s| train loss: +1.707e+01 | test loss: +1.772e+01 | 
| 05-02 01:36:56 epoch: 2285| train loss i: [0.06	1.49	5.42	4.76	3.74	1.6 ] test loss i: [0.12	1.25	5.21	5.6 	3.72	1.83] | 
| 05-02 01:36:57 epoch: 2286| time: 1.1s| train loss: +1.692e+01 | test loss: +1.684e+01 | 
| 05-02 01:36:57 epoch: 2286| train loss i: [0.08	1.56	5.39	4.59	3.86	1.43] test loss i: [0.09	2.17	4.58	5.14	3.3 	1.56] | 
| 05-02 01:36:58 epoch: 2287| time: 1.1s| train loss: +1.809e+01 | test loss: +2.121e+01 | 
| 05-02 01:36:58 epoch: 2287| train loss i: [0.04	1.93	5.81	4.88	3.85	1.58] test loss i: [0.05	2.48	7.69	4.98	3.82	2.19] | 
| 05-02 01:36:59 epoch: 2288| time: 1.1s| train loss: +1.632e+01 | test loss: +2.033e+01 | 
| 05-02 01:36:59 epoch: 2288| train loss i: [0.04	0.91	4.95	4.79	4.07	1.56] test loss i: [0.07	1.78	6.78	5.53	4.4 	1.77] | 
| 05-02 01:37:00 epoch: 2289| time: 1.1s| train loss: +1.665e+01 | test loss: +2.435e+01 | 
| 05-02 01:37:00 epoch: 2289| train loss i: [0.05	1.56	4.81	5.  	3.64	1.57] test loss i: [0.07	2.05	7.55	7.66	4.99	2.03] | 
| 05-02 01:37:01 epoch: 2290| time: 1.1s| train loss: +1.737e+01 | test loss: +1.781e+01 | 
| 05-02 01:37:01 epoch: 2290| train loss i: [0.06	1.7 	5.26	4.74	4.08	1.54] test loss i: [0.2 	1.83	4.18	6.08	3.78	1.74] | 
| 05-02 01:37:02 epoch: 2291| time: 1.1s| train loss: +1.603e+01 | test loss: +2.424e+01 | 
| 05-02 01:37:02 epoch: 2291| train loss i: [0.1 	0.94	4.94	4.58	3.91	1.56] test loss i: [0.16	2.68	7.65	6.13	5.74	1.88] | 
| 05-02 01:37:04 epoch: 2292| time: 1.1s| train loss: +1.771e+01 | test loss: +1.490e+01 | 
| 05-02 01:37:04 epoch: 2292| train loss i: [0.09	1.86	5.78	4.57	3.85	1.55] test loss i: [0.12	0.92	4.76	4.35	3.21	1.54] | 
| 05-02 01:37:05 epoch: 2293| time: 1.1s| train loss: +1.591e+01 | test loss: +1.514e+01 | 
| 05-02 01:37:05 epoch: 2293| train loss i: [0.07	0.64	5.01	4.9 	3.73	1.56] test loss i: [0.04	1.06	4.21	4.85	3.52	1.46] | 
| 05-02 01:37:06 epoch: 2294| time: 1.1s| train loss: +1.642e+01 | test loss: +2.990e+01 | 
| 05-02 01:37:06 epoch: 2294| train loss i: [0.07	0.8 	5.41	4.81	3.76	1.56] test loss i: [0.22	3.8 	9.76	8.86	5.22	2.05] | 
| 05-02 01:37:07 epoch: 2295| time: 1.1s| train loss: +1.722e+01 | test loss: +2.230e+01 | 
| 05-02 01:37:07 epoch: 2295| train loss i: [0.06	1.2 	5.4 	5.25	3.74	1.57] test loss i: [0.13	3.19	6.44	5.59	4.83	2.11] | 
| 05-02 01:37:08 epoch: 2296| time: 1.1s| train loss: +1.708e+01 | test loss: +1.470e+01 | 
| 05-02 01:37:08 epoch: 2296| train loss i: [0.07	1.21	5.45	5.13	3.64	1.59] test loss i: [0.11	1.14	4.55	4.25	3.38	1.27] | 
| 05-02 01:37:09 epoch: 2297| time: 1.1s| train loss: +1.719e+01 | test loss: +1.572e+01 | 
| 05-02 01:37:09 epoch: 2297| train loss i: [0.07	1.32	6.09	4.55	3.64	1.51] test loss i: [0.09	0.9 	3.86	5.72	3.69	1.46] | 
| 05-02 01:37:10 epoch: 2298| time: 1.1s| train loss: +1.716e+01 | test loss: +1.505e+01 | 
| 05-02 01:37:10 epoch: 2298| train loss i: [0.08	1.49	5.37	4.74	3.86	1.61] test loss i: [0.04	1.08	4.8 	4.22	3.39	1.53] | 
| 05-02 01:37:11 epoch: 2299| time: 1.1s| train loss: +1.669e+01 | test loss: +1.696e+01 | 
| 05-02 01:37:11 epoch: 2299| train loss i: [0.06	1.02	5.54	4.96	3.57	1.53] test loss i: [0.07	0.5 	7.25	3.72	3.63	1.79] | 
| 05-02 01:37:12 epoch: 2300| time: 1.1s| train loss: +1.677e+01 | test loss: +2.186e+01 | 
| 05-02 01:37:12 epoch: 2300| train loss i: [0.06	1.32	5.39	4.75	3.64	1.59] test loss i: [0.11	1.57	7.14	6.9 	4.33	1.81] | 
| 05-02 01:37:13 epoch: 2301| time: 1.1s| train loss: +1.714e+01 | test loss: +1.596e+01 | 
| 05-02 01:37:13 epoch: 2301| train loss i: [0.08	1.4 	5.22	5.03	3.85	1.56] test loss i: [0.05	0.49	4.98	5.42	3.38	1.63] | 
| 05-02 01:37:14 epoch: 2302| time: 1.1s| train loss: +1.714e+01 | test loss: +2.068e+01 | 
| 05-02 01:37:14 epoch: 2302| train loss i: [0.06	1.39	5.3 	5.06	3.72	1.62] test loss i: [0.04	2.36	7.07	5.25	4.17	1.79] | 
| 05-02 01:37:15 epoch: 2303| time: 1.1s| train loss: +1.677e+01 | test loss: +1.822e+01 | 
| 05-02 01:37:15 epoch: 2303| train loss i: [0.06	1.33	5.44	4.59	3.77	1.58] test loss i: [0.05	0.83	7.56	4.59	3.77	1.41] | 
| 05-02 01:37:16 epoch: 2304| time: 1.1s| train loss: +1.701e+01 | test loss: +2.284e+01 | 
| 05-02 01:37:16 epoch: 2304| train loss i: [0.06	0.85	5.73	5.07	3.75	1.55] test loss i: [0.1 	2.35	5.82	7.26	5.16	2.15] | 
| 05-02 01:37:17 epoch: 2305| time: 1.1s| train loss: +1.822e+01 | test loss: +1.852e+01 | 
| 05-02 01:37:17 epoch: 2305| train loss i: [0.07	1.91	5.85	5.01	3.79	1.61] test loss i: [0.04	1.19	6.2 	5.57	3.67	1.84] | 
| 05-02 01:37:18 epoch: 2306| time: 1.1s| train loss: +1.714e+01 | test loss: +2.454e+01 | 
| 05-02 01:37:18 epoch: 2306| train loss i: [0.06	1.43	5.43	4.89	3.79	1.55] test loss i: [0.14	1.96	6.4 	8.35	5.33	2.35] | 
| 05-02 01:37:20 epoch: 2307| time: 1.1s| train loss: +1.646e+01 | test loss: +1.857e+01 | 
| 05-02 01:37:20 epoch: 2307| train loss i: [0.07	1.09	5.18	4.7 	3.82	1.6 ] test loss i: [0.07	0.91	6.83	5.11	4.02	1.64] | 
| 05-02 01:37:21 epoch: 2308| time: 1.1s| train loss: +1.664e+01 | test loss: +1.884e+01 | 
| 05-02 01:37:21 epoch: 2308| train loss i: [0.09	1.31	5.4 	4.7 	3.65	1.49] test loss i: [0.09	1.19	5.67	5.52	4.53	1.84] | 
| 05-02 01:37:22 epoch: 2309| time: 1.1s| train loss: +1.632e+01 | test loss: +1.619e+01 | 
| 05-02 01:37:22 epoch: 2309| train loss i: [0.09	1.2 	5.09	4.85	3.63	1.46] test loss i: [0.1 	0.91	5.67	4.27	3.71	1.54] | 
| 05-02 01:37:23 epoch: 2310| time: 1.1s| train loss: +1.788e+01 | test loss: +1.883e+01 | 
| 05-02 01:37:23 epoch: 2310| train loss i: [0.07	2.02	5.48	4.78	3.95	1.57] test loss i: [0.06	0.89	6.63	5.1 	4.14	2.  ] | 
| 05-02 01:37:24 epoch: 2311| time: 1.1s| train loss: +1.713e+01 | test loss: +1.528e+01 | 
| 05-02 01:37:24 epoch: 2311| train loss i: [0.07	1.07	5.65	5.07	3.72	1.55] test loss i: [0.06	1.22	5.13	3.88	3.47	1.51] | 
| 05-02 01:37:25 epoch: 2312| time: 1.1s| train loss: +1.714e+01 | test loss: +1.885e+01 | 
| 05-02 01:37:25 epoch: 2312| train loss i: [0.05	1.23	5.89	4.82	3.6 	1.55] test loss i: [0.07	3.46	5.36	4.45	3.83	1.69] | 
| 05-02 01:37:26 epoch: 2313| time: 1.1s| train loss: +1.687e+01 | test loss: +2.047e+01 | 
| 05-02 01:37:26 epoch: 2313| train loss i: [0.04	1.16	5.36	4.95	3.79	1.56] test loss i: [0.06	2.38	8.14	4.57	3.74	1.57] | 
| 05-02 01:37:27 epoch: 2314| time: 1.1s| train loss: +1.633e+01 | test loss: +2.083e+01 | 
| 05-02 01:37:27 epoch: 2314| train loss i: [0.06	0.61	5.6 	4.62	3.83	1.59] test loss i: [0.06	2.06	5.27	5.47	5.95	2.03] | 
| 05-02 01:37:28 epoch: 2315| time: 1.1s| train loss: +1.840e+01 | test loss: +2.201e+01 | 
| 05-02 01:37:28 epoch: 2315| train loss i: [0.05	1.9 	6.09	5.07	3.72	1.58] test loss i: [0.1 	2.35	6.75	6.63	4.23	1.96] | 
| 05-02 01:37:29 epoch: 2316| time: 1.1s| train loss: +1.642e+01 | test loss: +2.043e+01 | 
| 05-02 01:37:29 epoch: 2316| train loss i: [0.05	1.2 	5.28	4.6 	3.83	1.48] test loss i: [0.06	1.32	6.72	5.41	4.76	2.16] | 
| 05-02 01:37:30 epoch: 2317| time: 1.1s| train loss: +1.655e+01 | test loss: +1.726e+01 | 
| 05-02 01:37:30 epoch: 2317| train loss i: [0.05	0.95	5.23	4.75	3.92	1.65] test loss i: [0.1 	0.76	6.35	5.15	3.32	1.58] | 
| 05-02 01:37:31 epoch: 2318| time: 1.1s| train loss: +1.651e+01 | test loss: +2.283e+01 | 
| 05-02 01:37:31 epoch: 2318| train loss i: [0.05	1.55	5.17	4.75	3.44	1.55] test loss i: [0.12	1.64	6.6 	6.25	5.5 	2.72] | 
| 05-02 01:37:32 epoch: 2319| time: 1.1s| train loss: +1.661e+01 | test loss: +1.820e+01 | 
| 05-02 01:37:32 epoch: 2319| train loss i: [0.06	1.14	5.18	4.74	3.92	1.57] test loss i: [0.08	1.27	5.83	5.  	3.95	2.06] | 
| 05-02 01:37:33 epoch: 2320| time: 1.1s| train loss: +1.759e+01 | test loss: +1.996e+01 | 
| 05-02 01:37:33 epoch: 2320| train loss i: [0.14	1.8 	5.58	4.64	3.9 	1.54] test loss i: [0.2 	2.27	6.6 	5.54	3.46	1.89] | 
| 05-02 01:37:34 epoch: 2321| time: 1.1s| train loss: +1.766e+01 | test loss: +1.388e+01 | 
| 05-02 01:37:34 epoch: 2321| train loss i: [0.13	1.72	5.76	4.58	3.95	1.51] test loss i: [0.05	0.94	3.27	4.47	3.61	1.54] | 
| 05-02 01:37:36 epoch: 2322| time: 1.1s| train loss: +1.632e+01 | test loss: +1.309e+01 | 
| 05-02 01:37:36 epoch: 2322| train loss i: [0.06	0.94	4.8 	5.01	4.  	1.51] test loss i: [0.05	0.2 	4.02	3.75	3.57	1.5 ] | 
| 05-02 01:37:37 epoch: 2323| time: 1.1s| train loss: +1.641e+01 | test loss: +1.799e+01 | 
| 05-02 01:37:37 epoch: 2323| train loss i: [0.06	1.02	5.37	4.91	3.55	1.5 ] test loss i: [0.04	1.74	6.52	4.61	3.7 	1.38] | 
| 05-02 01:37:38 epoch: 2324| time: 1.1s| train loss: +1.689e+01 | test loss: +1.800e+01 | 
| 05-02 01:37:38 epoch: 2324| train loss i: [0.06	1.25	5.47	4.79	3.79	1.55] test loss i: [0.1 	1.65	5.23	4.94	3.88	2.2 ] | 
| 05-02 01:37:39 epoch: 2325| time: 1.1s| train loss: +1.764e+01 | test loss: +1.751e+01 | 
| 05-02 01:37:39 epoch: 2325| train loss i: [0.06	1.38	6.01	4.82	3.85	1.52] test loss i: [0.04	1.51	5.7 	4.09	4.44	1.72] | 
| 05-02 01:37:40 epoch: 2326| time: 1.1s| train loss: +1.788e+01 | test loss: +2.667e+01 | 
| 05-02 01:37:40 epoch: 2326| train loss i: [0.05	1.72	6.07	4.54	3.97	1.53] test loss i: [0.06	3.53	7.76	8.31	4.95	2.06] | 
| 05-02 01:37:41 epoch: 2327| time: 1.1s| train loss: +1.700e+01 | test loss: +1.785e+01 | 
| 05-02 01:37:41 epoch: 2327| train loss i: [0.05	1.51	5.04	4.89	3.96	1.54] test loss i: [0.03	1.21	7.38	4.42	3.2 	1.61] | 
| 05-02 01:37:42 epoch: 2328| time: 1.1s| train loss: +1.667e+01 | test loss: +2.035e+01 | 
| 05-02 01:37:42 epoch: 2328| train loss i: [0.07	1.46	5.45	4.35	3.8 	1.54] test loss i: [0.15	1.37	7.63	5.02	4.24	1.93] | 
| 05-02 01:37:43 epoch: 2329| time: 1.1s| train loss: +1.748e+01 | test loss: +2.264e+01 | 
| 05-02 01:37:43 epoch: 2329| train loss i: [0.06	1.4 	5.68	4.96	3.91	1.47] test loss i: [0.1 	2.36	6.98	6.44	4.9 	1.86] | 
| 05-02 01:37:44 epoch: 2330| time: 1.1s| train loss: +1.652e+01 | test loss: +1.805e+01 | 
| 05-02 01:37:44 epoch: 2330| train loss i: [0.07	1.43	5.42	4.5 	3.6 	1.51] test loss i: [0.07	2.11	6.11	5.01	3.24	1.53] | 
| 05-02 01:37:45 epoch: 2331| time: 1.1s| train loss: +1.713e+01 | test loss: +1.408e+01 | 
| 05-02 01:37:45 epoch: 2331| train loss i: [0.08	1.38	6.06	4.37	3.63	1.6 ] test loss i: [0.05	0.91	4.4 	4.19	3.12	1.41] | 
| 05-02 01:37:46 epoch: 2332| time: 1.1s| train loss: +1.641e+01 | test loss: +1.734e+01 | 
| 05-02 01:37:46 epoch: 2332| train loss i: [0.05	1.04	5.05	5.2 	3.46	1.61] test loss i: [0.05	0.71	6.52	4.41	3.79	1.86] | 
| 05-02 01:37:47 epoch: 2333| time: 1.1s| train loss: +1.693e+01 | test loss: +1.777e+01 | 
| 05-02 01:37:47 epoch: 2333| train loss i: [0.06	1.05	5.54	4.96	3.84	1.49] test loss i: [0.07	1.01	5.04	5.01	4.91	1.73] | 
| 05-02 01:37:48 epoch: 2334| time: 1.1s| train loss: +1.665e+01 | test loss: +1.614e+01 | 
| 05-02 01:37:48 epoch: 2334| train loss i: [0.07	1.43	5.21	4.54	3.86	1.55] test loss i: [0.05	0.63	5.54	4.44	3.71	1.77] | 
| 05-02 01:37:49 epoch: 2335| time: 1.1s| train loss: +1.618e+01 | test loss: +1.865e+01 | 
| 05-02 01:37:49 epoch: 2335| train loss i: [0.06	1.62	4.97	4.35	3.71	1.47] test loss i: [0.05	0.48	6.71	5.58	3.97	1.85] | 
| 05-02 01:37:51 epoch: 2336| time: 1.1s| train loss: +1.687e+01 | test loss: +1.895e+01 | 
| 05-02 01:37:51 epoch: 2336| train loss i: [0.06	0.83	6.13	4.57	3.74	1.55] test loss i: [0.03	2.02	5.93	5.33	4.03	1.61] | 
| 05-02 01:37:52 epoch: 2337| time: 1.1s| train loss: +1.809e+01 | test loss: +1.569e+01 | 
| 05-02 01:37:52 epoch: 2337| train loss i: [0.06	2.23	5.61	4.93	3.71	1.55] test loss i: [0.17	0.6 	5.9 	4.71	2.9 	1.43] | 
| 05-02 01:37:53 epoch: 2338| time: 1.1s| train loss: +1.652e+01 | test loss: +1.846e+01 | 
| 05-02 01:37:53 epoch: 2338| train loss i: [0.08	1.21	4.97	4.84	3.92	1.51] test loss i: [0.05	1.91	5.64	4.97	4.  	1.89] | 
| 05-02 01:37:54 epoch: 2339| time: 1.1s| train loss: +1.729e+01 | test loss: +2.129e+01 | 
| 05-02 01:37:54 epoch: 2339| train loss i: [0.07	1.86	5.18	4.59	4.04	1.55] test loss i: [0.17	3.06	6.1 	5.44	4.3 	2.22] | 
| 05-02 01:37:55 epoch: 2340| time: 1.1s| train loss: +1.747e+01 | test loss: +2.055e+01 | 
| 05-02 01:37:55 epoch: 2340| train loss i: [0.07	1.46	5.45	5.06	3.89	1.55] test loss i: [0.06	0.5 	6.69	5.71	5.44	2.15] | 
| 05-02 01:37:56 epoch: 2341| time: 1.1s| train loss: +1.678e+01 | test loss: +2.280e+01 | 
| 05-02 01:37:56 epoch: 2341| train loss i: [0.08	0.98	5.66	4.9 	3.64	1.52] test loss i: [0.12	2.33	8.01	5.59	4.72	2.04] | 
| 05-02 01:37:57 epoch: 2342| time: 1.1s| train loss: +1.677e+01 | test loss: +1.940e+01 | 
| 05-02 01:37:57 epoch: 2342| train loss i: [0.07	0.78	5.46	4.96	3.99	1.51] test loss i: [0.04	2.11	5.83	5.73	3.97	1.74] | 
| 05-02 01:37:58 epoch: 2343| time: 1.1s| train loss: +1.656e+01 | test loss: +1.795e+01 | 
| 05-02 01:37:58 epoch: 2343| train loss i: [0.07	1.13	5.35	4.72	3.64	1.65] test loss i: [0.05	0.94	6.58	4.76	4.02	1.6 ] | 
| 05-02 01:37:59 epoch: 2344| time: 1.1s| train loss: +1.669e+01 | test loss: +1.663e+01 | 
| 05-02 01:37:59 epoch: 2344| train loss i: [0.05	0.99	5.73	4.59	3.86	1.47] test loss i: [0.04	1.84	5.12	4.42	3.61	1.6 ] | 
| 05-02 01:38:00 epoch: 2345| time: 1.1s| train loss: +1.737e+01 | test loss: +2.100e+01 | 
| 05-02 01:38:00 epoch: 2345| train loss i: [0.06	1.21	5.3 	5.25	3.91	1.64] test loss i: [0.25	1.32	7.11	5.81	4.51	2.01] | 
| 05-02 01:38:01 epoch: 2346| time: 1.1s| train loss: +1.793e+01 | test loss: +1.846e+01 | 
| 05-02 01:38:01 epoch: 2346| train loss i: [0.1 	2.39	5.17	4.88	3.82	1.58] test loss i: [0.07	2.25	5.01	5.08	4.33	1.73] | 
| 05-02 01:38:02 epoch: 2347| time: 1.1s| train loss: +1.631e+01 | test loss: +1.805e+01 | 
| 05-02 01:38:02 epoch: 2347| train loss i: [0.08	0.79	5.73	4.52	3.61	1.59] test loss i: [0.13	1.09	7.01	4.18	4.13	1.51] | 
| 05-02 01:38:03 epoch: 2348| time: 1.1s| train loss: +1.683e+01 | test loss: +1.651e+01 | 
| 05-02 01:38:03 epoch: 2348| train loss i: [0.06	1.64	5.23	4.51	3.86	1.53] test loss i: [0.06	1.  	5.25	3.91	4.45	1.84] | 
| 05-02 01:38:05 epoch: 2349| time: 1.1s| train loss: +1.672e+01 | test loss: +1.951e+01 | 
| 05-02 01:38:05 epoch: 2349| train loss i: [0.07	1.3 	5.57	4.48	3.77	1.53] test loss i: [0.1 	2.3 	4.43	6.14	4.96	1.58] | 
| 05-02 01:38:06 epoch: 2350| time: 1.1s| train loss: +1.645e+01 | test loss: +1.615e+01 | 
| 05-02 01:38:06 epoch: 2350| train loss i: [0.05	1.43	4.8 	4.63	4.04	1.5 ] test loss i: [0.05	0.65	5.94	4.26	3.76	1.48] | 
| 05-02 01:38:07 epoch: 2351| time: 1.1s| train loss: +1.680e+01 | test loss: +1.485e+01 | 
| 05-02 01:38:07 epoch: 2351| train loss i: [0.06	1.04	5.51	4.92	3.7 	1.56] test loss i: [0.05	0.59	5.45	3.53	3.52	1.72] | 
| 05-02 01:38:08 epoch: 2352| time: 1.1s| train loss: +1.727e+01 | test loss: +1.830e+01 | 
| 05-02 01:38:08 epoch: 2352| train loss i: [0.06	1.9 	5.22	4.76	3.79	1.55] test loss i: [0.17	1.36	5.9 	5.45	3.79	1.62] | 
| 05-02 01:38:09 epoch: 2353| time: 1.1s| train loss: +1.631e+01 | test loss: +2.280e+01 | 
| 05-02 01:38:09 epoch: 2353| train loss i: [0.06	1.35	4.97	4.84	3.57	1.51] test loss i: [0.11	1.21	7.64	7.21	4.53	2.1 ] | 
| 05-02 01:38:10 epoch: 2354| time: 1.1s| train loss: +1.759e+01 | test loss: +1.880e+01 | 
| 05-02 01:38:10 epoch: 2354| train loss i: [0.04	1.98	5.08	5.31	3.71	1.48] test loss i: [0.08	0.6 	6.17	5.04	5.16	1.74] | 
| 05-02 01:38:11 epoch: 2355| time: 1.1s| train loss: +1.609e+01 | test loss: +1.518e+01 | 
| 05-02 01:38:11 epoch: 2355| train loss i: [0.05	0.93	5.44	4.57	3.48	1.61] test loss i: [0.03	0.96	5.79	3.61	3.29	1.51] | 
| 05-02 01:38:12 epoch: 2356| time: 1.1s| train loss: +1.747e+01 | test loss: +1.958e+01 | 
| 05-02 01:38:12 epoch: 2356| train loss i: [0.06	1.02	5.63	5.03	4.16	1.57] test loss i: [0.05	1.18	7.04	5.82	3.88	1.61] | 
| 05-02 01:38:13 epoch: 2357| time: 1.1s| train loss: +1.626e+01 | test loss: +2.188e+01 | 
| 05-02 01:38:13 epoch: 2357| train loss i: [0.06	0.88	5.53	4.78	3.45	1.55] test loss i: [0.22	0.81	7.88	6.23	4.63	2.11] | 
| 05-02 01:38:14 epoch: 2358| time: 1.1s| train loss: +1.626e+01 | test loss: +1.882e+01 | 
| 05-02 01:38:14 epoch: 2358| train loss i: [0.05	0.89	5.54	4.48	3.73	1.56] test loss i: [0.08	0.58	7.1 	5.01	3.96	2.09] | 
| 05-02 01:38:16 epoch: 2359| time: 1.1s| train loss: +1.682e+01 | test loss: +1.753e+01 | 
| 05-02 01:38:16 epoch: 2359| train loss i: [0.08	1.27	5.43	4.78	3.74	1.53] test loss i: [0.04	2.01	4.59	4.8 	4.24	1.86] | 
| 05-02 01:38:17 epoch: 2360| time: 1.1s| train loss: +1.671e+01 | test loss: +2.087e+01 | 
| 05-02 01:38:17 epoch: 2360| train loss i: [0.07	1.27	4.99	4.85	3.99	1.54] test loss i: [0.08	0.55	7.01	6.38	4.8 	2.05] | 
| 05-02 01:38:18 epoch: 2361| time: 1.2s| train loss: +1.687e+01 | test loss: +1.535e+01 | 
| 05-02 01:38:18 epoch: 2361| train loss i: [0.09	1.22	5.49	4.88	3.6 	1.59] test loss i: [0.09	2.27	4.51	3.73	3.29	1.47] | 
| 05-02 01:38:19 epoch: 2362| time: 1.2s| train loss: +1.782e+01 | test loss: +1.727e+01 | 
| 05-02 01:38:19 epoch: 2362| train loss i: [0.06	1.66	5.82	4.83	3.93	1.53] test loss i: [0.05	1.43	4.72	5.17	4.29	1.6 ] | 
| 05-02 01:38:20 epoch: 2363| time: 1.2s| train loss: +1.624e+01 | test loss: +2.294e+01 | 
| 05-02 01:38:20 epoch: 2363| train loss i: [0.05	0.81	5.45	4.63	3.81	1.49] test loss i: [0.11	1.78	8.17	5.81	5.11	1.95] | 
| 05-02 01:38:21 epoch: 2364| time: 1.2s| train loss: +1.651e+01 | test loss: +1.479e+01 | 
| 05-02 01:38:21 epoch: 2364| train loss i: [0.05	1.06	5.73	4.34	3.75	1.58] test loss i: [0.03	0.68	4.53	4.63	3.37	1.55] | 
| 05-02 01:38:22 epoch: 2365| time: 1.1s| train loss: +1.647e+01 | test loss: +1.742e+01 | 
| 05-02 01:38:22 epoch: 2365| train loss i: [0.04	0.84	5.56	4.35	4.11	1.56] test loss i: [0.06	1.5 	4.89	4.88	4.41	1.67] | 
| 05-02 01:38:24 epoch: 2366| time: 1.1s| train loss: +1.782e+01 | test loss: +2.342e+01 | 
| 05-02 01:38:24 epoch: 2366| train loss i: [0.05	1.48	6.12	4.83	3.74	1.6 ] test loss i: [0.08	2.38	7.17	5.71	6.26	1.82] | 
| 05-02 01:38:25 epoch: 2367| time: 1.1s| train loss: +1.657e+01 | test loss: +1.832e+01 | 
| 05-02 01:38:25 epoch: 2367| train loss i: [0.05	1.97	4.72	4.59	3.68	1.56] test loss i: [0.11	1.94	5.97	5.1 	3.69	1.51] | 
| 05-02 01:38:26 epoch: 2368| time: 1.1s| train loss: +1.544e+01 | test loss: +1.642e+01 | 
| 05-02 01:38:26 epoch: 2368| train loss i: [0.05	1.09	4.88	4.38	3.53	1.5 ] test loss i: [0.05	2.17	5.02	4.34	3.44	1.4 ] | 
| 05-02 01:38:27 epoch: 2369| time: 1.1s| train loss: +1.700e+01 | test loss: +1.594e+01 | 
| 05-02 01:38:27 epoch: 2369| train loss i: [0.06	1.33	5.96	4.76	3.42	1.47] test loss i: [0.07	0.47	4.54	4.98	4.11	1.78] | 
| 05-02 01:38:28 epoch: 2370| time: 1.1s| train loss: +1.790e+01 | test loss: +1.671e+01 | 
| 05-02 01:38:28 epoch: 2370| train loss i: [0.04	2.2 	5.54	4.82	3.76	1.54] test loss i: [0.03	2.07	5.03	4.37	3.75	1.45] | 
| 05-02 01:38:29 epoch: 2371| time: 1.0s| train loss: +1.653e+01 | test loss: +1.950e+01 | 
| 05-02 01:38:29 epoch: 2371| train loss i: [0.05	0.87	5.31	5.02	3.62	1.66] test loss i: [0.05	0.69	6.41	6.43	4.18	1.75] | 
| 05-02 01:38:30 epoch: 2372| time: 1.0s| train loss: +1.649e+01 | test loss: +1.765e+01 | 
| 05-02 01:38:30 epoch: 2372| train loss i: [0.05	1.37	4.87	4.93	3.74	1.53] test loss i: [0.05	1.76	3.74	5.15	5.27	1.68] | 
| 05-02 01:38:31 epoch: 2373| time: 1.0s| train loss: +1.666e+01 | test loss: +1.463e+01 | 
| 05-02 01:38:31 epoch: 2373| train loss i: [0.05	1.07	5.42	4.61	4.01	1.5 ] test loss i: [0.02	1.07	4.31	4.71	3.08	1.43] | 
| 05-02 01:38:32 epoch: 2374| time: 1.1s| train loss: +1.686e+01 | test loss: +1.692e+01 | 
| 05-02 01:38:32 epoch: 2374| train loss i: [0.08	0.85	5.66	4.88	3.97	1.42] test loss i: [0.16	0.38	5.79	4.96	3.6 	2.02] | 
| 05-02 01:38:33 epoch: 2375| time: 1.1s| train loss: +1.705e+01 | test loss: +2.190e+01 | 
| 05-02 01:38:33 epoch: 2375| train loss i: [0.06	1.17	5.76	4.69	3.7 	1.68] test loss i: [0.07	2.51	6.4 	6.25	4.57	2.1 ] | 
| 05-02 01:38:34 epoch: 2376| time: 1.1s| train loss: +1.615e+01 | test loss: +1.804e+01 | 
| 05-02 01:38:34 epoch: 2376| train loss i: [0.05	1.02	5.27	4.42	3.73	1.67] test loss i: [0.07	0.59	6.7 	4.63	4.3 	1.75] | 
| 05-02 01:38:35 epoch: 2377| time: 1.1s| train loss: +1.574e+01 | test loss: +2.115e+01 | 
| 05-02 01:38:35 epoch: 2377| train loss i: [0.06	0.88	5.23	4.42	3.72	1.43] test loss i: [0.06	1.57	4.85	7.29	5.44	1.93] | 
| 05-02 01:38:36 epoch: 2378| time: 1.1s| train loss: +1.732e+01 | test loss: +1.839e+01 | 
| 05-02 01:38:36 epoch: 2378| train loss i: [0.06	2.13	5.27	4.79	3.56	1.5 ] test loss i: [0.04	0.86	5.98	5.81	3.95	1.76] | 
| 05-02 01:38:37 epoch: 2379| time: 1.1s| train loss: +1.703e+01 | test loss: +2.106e+01 | 
| 05-02 01:38:37 epoch: 2379| train loss i: [0.05	1.48	5.39	4.54	4.03	1.54] test loss i: [0.04	2.05	7.48	5.26	4.39	1.84] | 
| 05-02 01:38:39 epoch: 2380| time: 1.1s| train loss: +1.650e+01 | test loss: +1.922e+01 | 
| 05-02 01:38:39 epoch: 2380| train loss i: [0.04	0.99	5.38	4.89	3.63	1.57] test loss i: [0.06	1.47	5.64	5.31	4.89	1.85] | 
| 05-02 01:38:40 epoch: 2381| time: 1.0s| train loss: +1.673e+01 | test loss: +1.492e+01 | 
| 05-02 01:38:40 epoch: 2381| train loss i: [0.04	1.39	5.29	4.5 	3.94	1.57] test loss i: [0.05	0.33	4.78	4.38	3.9 	1.48] | 
| 05-02 01:38:41 epoch: 2382| time: 1.1s| train loss: +1.619e+01 | test loss: +1.770e+01 | 
| 05-02 01:38:41 epoch: 2382| train loss i: [0.04	0.97	5.17	4.9 	3.59	1.51] test loss i: [0.05	0.76	5.23	5.82	4.11	1.73] | 
| 05-02 01:38:42 epoch: 2383| time: 1.1s| train loss: +1.631e+01 | test loss: +1.384e+01 | 
| 05-02 01:38:42 epoch: 2383| train loss i: [0.05	1.25	4.89	4.7 	3.81	1.61] test loss i: [0.06	0.78	4.63	3.53	3.55	1.29] | 
| 05-02 01:38:43 epoch: 2384| time: 1.1s| train loss: +1.728e+01 | test loss: +1.387e+01 | 
| 05-02 01:38:43 epoch: 2384| train loss i: [0.06	1.6 	5.74	4.81	3.59	1.5 ] test loss i: [0.06	0.68	4.95	4.05	2.66	1.48] | 
| 05-02 01:38:44 epoch: 2385| time: 1.1s| train loss: +1.640e+01 | test loss: +1.922e+01 | 
| 05-02 01:38:44 epoch: 2385| train loss i: [0.06	1.03	5.13	4.94	3.67	1.58] test loss i: [0.06	2.53	5.48	5.41	3.92	1.82] | 
| 05-02 01:38:45 epoch: 2386| time: 1.1s| train loss: +1.674e+01 | test loss: +2.038e+01 | 
| 05-02 01:38:45 epoch: 2386| train loss i: [0.06	1.19	5.17	4.86	3.84	1.61] test loss i: [0.18	2.49	5.56	5.07	5.37	1.71] | 
| 05-02 01:38:46 epoch: 2387| time: 1.1s| train loss: +1.628e+01 | test loss: +1.743e+01 | 
| 05-02 01:38:46 epoch: 2387| train loss i: [0.07	1.34	4.81	4.82	3.67	1.56] test loss i: [0.03	4.42	4.61	4.21	2.61	1.54] | 
| 05-02 01:38:47 epoch: 2388| time: 1.1s| train loss: +1.741e+01 | test loss: +1.581e+01 | 
| 05-02 01:38:47 epoch: 2388| train loss i: [0.08	1.41	5.41	5.14	3.84	1.54] test loss i: [0.04	0.83	5.8 	4.34	3.26	1.53] | 
| 05-02 01:38:48 epoch: 2389| time: 1.1s| train loss: +1.707e+01 | test loss: +2.216e+01 | 
| 05-02 01:38:48 epoch: 2389| train loss i: [0.08	1.82	4.88	4.87	3.83	1.6 ] test loss i: [0.06	2.14	7.81	6.29	4.06	1.8 ] | 
| 05-02 01:38:49 epoch: 2390| time: 1.1s| train loss: +1.703e+01 | test loss: +1.553e+01 | 
| 05-02 01:38:49 epoch: 2390| train loss i: [0.06	1.2 	5.16	5.22	3.86	1.53] test loss i: [0.13	0.39	5.13	4.65	3.75	1.48] | 
| 05-02 01:38:50 epoch: 2391| time: 1.1s| train loss: +1.660e+01 | test loss: +1.796e+01 | 
| 05-02 01:38:50 epoch: 2391| train loss i: [0.05	1.31	5.17	4.71	3.75	1.6 ] test loss i: [0.05	2.59	4.63	5.13	3.94	1.62] | 
| 05-02 01:38:51 epoch: 2392| time: 1.1s| train loss: +1.584e+01 | test loss: +1.903e+01 | 
| 05-02 01:38:51 epoch: 2392| train loss i: [0.05	0.58	4.91	4.95	3.72	1.63] test loss i: [0.04	1.89	5.95	5.56	3.89	1.7 ] | 
| 05-02 01:38:52 epoch: 2393| time: 1.0s| train loss: +1.754e+01 | test loss: +1.935e+01 | 
| 05-02 01:38:52 epoch: 2393| train loss i: [0.05	1.52	5.78	4.71	3.98	1.5 ] test loss i: [0.1 	0.42	6.44	5.73	4.54	2.11] | 
| 05-02 01:38:53 epoch: 2394| time: 1.1s| train loss: +1.601e+01 | test loss: +2.164e+01 | 
| 05-02 01:38:53 epoch: 2394| train loss i: [0.05	0.74	5.31	4.46	3.92	1.53] test loss i: [0.11	2.83	6.67	5.11	5.1 	1.82] | 
| 05-02 01:38:55 epoch: 2395| time: 1.1s| train loss: +1.624e+01 | test loss: +1.421e+01 | 
| 05-02 01:38:55 epoch: 2395| train loss i: [0.04	1.21	5.01	4.64	3.72	1.62] test loss i: [0.04	1.18	3.46	4.37	3.64	1.53] | 
| 05-02 01:38:56 epoch: 2396| time: 1.1s| train loss: +1.620e+01 | test loss: +1.779e+01 | 
| 05-02 01:38:56 epoch: 2396| train loss i: [0.08	0.92	5.53	4.38	3.71	1.6 ] test loss i: [0.04	0.22	5.56	5.81	4.55	1.62] | 
| 05-02 01:38:57 epoch: 2397| time: 1.1s| train loss: +1.710e+01 | test loss: +1.646e+01 | 
| 05-02 01:38:57 epoch: 2397| train loss i: [0.07	1.1 	5.59	4.74	4.04	1.56] test loss i: [0.07	1.26	5.38	4.58	3.55	1.61] | 
| 05-02 01:38:58 epoch: 2398| time: 1.1s| train loss: +1.674e+01 | test loss: +1.990e+01 | 
| 05-02 01:38:58 epoch: 2398| train loss i: [0.08	1.16	5.54	4.62	3.79	1.55] test loss i: [0.12	1.87	6.53	5.29	4.5 	1.59] | 
| 05-02 01:38:59 epoch: 2399| time: 1.1s| train loss: +1.662e+01 | test loss: +1.767e+01 | 
| 05-02 01:38:59 epoch: 2399| train loss i: [0.09	1.26	5.32	4.58	3.82	1.55] test loss i: [0.05	0.76	5.63	5.55	4.  	1.67] | 
| 05-02 01:39:00 epoch: 2400| time: 1.1s| train loss: +1.662e+01 | test loss: +2.094e+01 | 
| 05-02 01:39:00 epoch: 2400| train loss i: [0.06	0.92	4.84	4.97	4.29	1.55] test loss i: [0.11	1.84	6.82	5.9 	4.42	1.84] | 
| 05-02 01:39:01 epoch: 2401| time: 1.1s| train loss: +1.646e+01 | test loss: +1.896e+01 | 
| 05-02 01:39:01 epoch: 2401| train loss i: [0.06	1.33	5.32	4.68	3.6 	1.47] test loss i: [0.06	2.2 	6.25	4.08	4.59	1.77] | 
| 05-02 01:39:02 epoch: 2402| time: 1.1s| train loss: +1.651e+01 | test loss: +1.582e+01 | 
| 05-02 01:39:02 epoch: 2402| train loss i: [0.05	1.08	5.08	4.89	3.82	1.59] test loss i: [0.04	1.09	5.68	4.39	3.08	1.53] | 
| 05-02 01:39:03 epoch: 2403| time: 1.1s| train loss: +1.601e+01 | test loss: +1.348e+01 | 
| 05-02 01:39:03 epoch: 2403| train loss i: [0.05	0.77	5.21	4.65	3.72	1.61] test loss i: [0.02	0.24	4.17	4.57	3.04	1.45] | 
| 05-02 01:39:04 epoch: 2404| time: 1.1s| train loss: +1.700e+01 | test loss: +2.527e+01 | 
| 05-02 01:39:04 epoch: 2404| train loss i: [0.08	1.56	5.14	5.07	3.66	1.5 ] test loss i: [0.05	3.31	8.56	6.92	4.43	2.01] | 
| 05-02 01:39:05 epoch: 2405| time: 1.1s| train loss: +1.696e+01 | test loss: +1.634e+01 | 
| 05-02 01:39:05 epoch: 2405| train loss i: [0.05	1.12	5.24	5.02	3.96	1.56] test loss i: [0.1 	1.19	4.77	4.72	3.9 	1.67] | 
| 05-02 01:39:06 epoch: 2406| time: 1.1s| train loss: +1.679e+01 | test loss: +1.639e+01 | 
| 05-02 01:39:06 epoch: 2406| train loss i: [0.08	1.22	5.18	4.96	3.8 	1.55] test loss i: [0.05	0.68	6.5 	4.33	3.42	1.4 ] | 
| 05-02 01:39:07 epoch: 2407| time: 1.1s| train loss: +1.600e+01 | test loss: +1.521e+01 | 
| 05-02 01:39:07 epoch: 2407| train loss i: [0.06	1.1 	5.04	4.72	3.57	1.5 ] test loss i: [0.14	1.45	4.49	4.6 	3.13	1.4 ] | 
| 05-02 01:39:08 epoch: 2408| time: 1.1s| train loss: +1.686e+01 | test loss: +1.457e+01 | 
| 05-02 01:39:08 epoch: 2408| train loss i: [0.05	1.3 	5.46	4.71	3.81	1.54] test loss i: [0.04	0.12	4.78	4.18	3.89	1.56] | 
| 05-02 01:39:10 epoch: 2409| time: 1.1s| train loss: +1.601e+01 | test loss: +1.473e+01 | 
| 05-02 01:39:10 epoch: 2409| train loss i: [0.07	1.04	5.04	4.68	3.7 	1.49] test loss i: [0.04	0.71	5.06	4.16	3.27	1.49] | 
| 05-02 01:39:11 epoch: 2410| time: 1.1s| train loss: +1.762e+01 | test loss: +1.378e+01 | 
| 05-02 01:39:11 epoch: 2410| train loss i: [0.07	1.9 	5.25	4.95	3.85	1.59] test loss i: [0.06	0.3 	4.43	3.92	3.75	1.32] | 
| 05-02 01:39:12 epoch: 2411| time: 1.1s| train loss: +1.855e+01 | test loss: +1.537e+01 | 
| 05-02 01:39:12 epoch: 2411| train loss i: [0.06	2.16	5.91	4.77	4.07	1.59] test loss i: [0.04	1.22	4.84	4.64	3.01	1.61] | 
| 05-02 01:39:13 epoch: 2412| time: 1.1s| train loss: +1.810e+01 | test loss: +1.553e+01 | 
| 05-02 01:39:13 epoch: 2412| train loss i: [0.07	1.31	5.81	5.33	4.02	1.57] test loss i: [0.03	0.89	5.35	4.23	3.53	1.5 ] | 
| 05-02 01:39:14 epoch: 2413| time: 1.1s| train loss: +1.683e+01 | test loss: +1.770e+01 | 
| 05-02 01:39:14 epoch: 2413| train loss i: [0.09	1.62	5.23	4.71	3.66	1.53] test loss i: [0.13	1.36	6.  	4.56	3.98	1.66] | 
| 05-02 01:39:15 epoch: 2414| time: 1.1s| train loss: +1.602e+01 | test loss: +1.644e+01 | 
| 05-02 01:39:15 epoch: 2414| train loss i: [0.07	1.12	4.87	4.31	4.11	1.55] test loss i: [0.06	1.02	4.81	4.69	4.02	1.84] | 
| 05-02 01:39:16 epoch: 2415| time: 1.1s| train loss: +1.744e+01 | test loss: +1.583e+01 | 
| 05-02 01:39:16 epoch: 2415| train loss i: [0.06	1.37	5.47	5.15	3.85	1.53] test loss i: [0.03	0.72	5.46	4.63	3.57	1.41] | 
| 05-02 01:39:17 epoch: 2416| time: 1.1s| train loss: +1.690e+01 | test loss: +1.732e+01 | 
| 05-02 01:39:17 epoch: 2416| train loss i: [0.06	1.33	5.96	4.56	3.44	1.55] test loss i: [0.05	0.8 	6.  	5.1 	3.69	1.67] | 
| 05-02 01:39:18 epoch: 2417| time: 1.1s| train loss: +1.606e+01 | test loss: +1.891e+01 | 
| 05-02 01:39:18 epoch: 2417| train loss i: [0.06	1.24	5.19	4.22	3.7 	1.64] test loss i: [0.06	0.39	6.7 	5.5 	4.25	2.02] | 
| 05-02 01:39:19 epoch: 2418| time: 1.1s| train loss: +1.644e+01 | test loss: +1.814e+01 | 
| 05-02 01:39:19 epoch: 2418| train loss i: [0.06	1.25	4.78	4.89	3.85	1.61] test loss i: [0.12	1.94	6.45	4.28	3.8 	1.55] | 
| 05-02 01:39:20 epoch: 2419| time: 1.1s| train loss: +1.679e+01 | test loss: +1.497e+01 | 
| 05-02 01:39:20 epoch: 2419| train loss i: [0.08	1.25	5.19	4.79	3.97	1.52] test loss i: [0.03	1.44	4.18	4.63	3.2 	1.49] | 
| 05-02 01:39:21 epoch: 2420| time: 1.1s| train loss: +1.707e+01 | test loss: +2.324e+01 | 
| 05-02 01:39:21 epoch: 2420| train loss i: [0.07	1.14	5.79	4.74	3.79	1.54] test loss i: [0.71	2.67	6.6 	6.73	4.45	2.08] | 
| 05-02 01:39:22 epoch: 2421| time: 1.1s| train loss: +1.674e+01 | test loss: +1.807e+01 | 
| 05-02 01:39:22 epoch: 2421| train loss i: [0.06	1.29	5.31	4.61	3.97	1.5 ] test loss i: [0.08	1.28	5.53	5.15	4.24	1.8 ] | 
| 05-02 01:39:23 epoch: 2422| time: 1.1s| train loss: +1.621e+01 | test loss: +1.929e+01 | 
| 05-02 01:39:23 epoch: 2422| train loss i: [0.06	1.4 	4.84	4.9 	3.47	1.54] test loss i: [0.07	1.49	4.94	7.08	3.95	1.76] | 
| 05-02 01:39:25 epoch: 2423| time: 1.1s| train loss: +1.769e+01 | test loss: +1.614e+01 | 
| 05-02 01:39:25 epoch: 2423| train loss i: [0.06	1.72	5.74	4.93	3.62	1.61] test loss i: [0.09	1.36	5.19	4.38	3.38	1.75] | 
| 05-02 01:39:26 epoch: 2424| time: 1.1s| train loss: +1.644e+01 | test loss: +1.703e+01 | 
| 05-02 01:39:26 epoch: 2424| train loss i: [0.08	1.14	5.37	4.6 	3.7 	1.56] test loss i: [0.05	0.86	5.85	4.97	3.51	1.8 ] | 
| 05-02 01:39:27 epoch: 2425| time: 1.1s| train loss: +1.567e+01 | test loss: +1.838e+01 | 
| 05-02 01:39:27 epoch: 2425| train loss i: [0.05	0.98	4.86	4.41	3.75	1.62] test loss i: [0.06	1.24	6.54	4.51	4.24	1.78] | 
| 05-02 01:39:28 epoch: 2426| time: 1.1s| train loss: +1.700e+01 | test loss: +1.521e+01 | 
| 05-02 01:39:28 epoch: 2426| train loss i: [0.08	1.35	5.43	4.97	3.65	1.51] test loss i: [0.1 	1.78	4.16	4.02	3.63	1.52] | 
| 05-02 01:39:29 epoch: 2427| time: 1.0s| train loss: +1.732e+01 | test loss: +1.687e+01 | 
| 05-02 01:39:29 epoch: 2427| train loss i: [0.06	1.27	5.94	4.69	3.79	1.57] test loss i: [0.08	2.16	4.9 	4.45	3.71	1.56] | 
| 05-02 01:39:30 epoch: 2428| time: 1.1s| train loss: +1.632e+01 | test loss: +1.839e+01 | 
| 05-02 01:39:30 epoch: 2428| train loss i: [0.06	1.15	5.16	4.55	3.85	1.55] test loss i: [0.09	1.9 	5.59	5.32	3.89	1.62] | 
| 05-02 01:39:31 epoch: 2429| time: 1.1s| train loss: +1.681e+01 | test loss: +1.691e+01 | 
| 05-02 01:39:31 epoch: 2429| train loss i: [0.07	1.55	5.34	4.71	3.55	1.58] test loss i: [0.07	1.32	4.65	5.37	3.39	2.11] | 
| 05-02 01:39:32 epoch: 2430| time: 1.1s| train loss: +1.704e+01 | test loss: +1.788e+01 | 
| 05-02 01:39:32 epoch: 2430| train loss i: [0.06	1.71	5.16	4.75	3.88	1.5 ] test loss i: [0.06	1.24	6.11	4.94	3.97	1.56] | 
| 05-02 01:39:33 epoch: 2431| time: 1.1s| train loss: +1.788e+01 | test loss: +1.428e+01 | 
| 05-02 01:39:33 epoch: 2431| train loss i: [0.05	2.37	5.34	4.76	3.86	1.5 ] test loss i: [0.05	1.04	3.85	4.57	3.33	1.44] | 
| 05-02 01:39:34 epoch: 2432| time: 1.1s| train loss: +1.601e+01 | test loss: +1.491e+01 | 
| 05-02 01:39:34 epoch: 2432| train loss i: [0.05	1.31	5.31	4.23	3.52	1.58] test loss i: [0.06	0.32	4.54	4.94	3.21	1.83] | 
| 05-02 01:39:35 epoch: 2433| time: 1.1s| train loss: +1.656e+01 | test loss: +1.686e+01 | 
| 05-02 01:39:35 epoch: 2433| train loss i: [0.05	1.25	5.08	5.11	3.38	1.69] test loss i: [0.05	3.21	4.69	4.47	2.97	1.46] | 
| 05-02 01:39:36 epoch: 2434| time: 1.1s| train loss: +1.785e+01 | test loss: +1.759e+01 | 
| 05-02 01:39:36 epoch: 2434| train loss i: [0.07	2.14	5.55	4.91	3.64	1.54] test loss i: [0.11	0.72	6.45	4.2 	4.26	1.84] | 
| 05-02 01:39:37 epoch: 2435| time: 1.1s| train loss: +1.649e+01 | test loss: +1.803e+01 | 
| 05-02 01:39:37 epoch: 2435| train loss i: [0.09	0.88	5.28	4.76	3.83	1.65] test loss i: [0.04	2.93	5.64	4.65	3.4 	1.36] | 
| 05-02 01:39:38 epoch: 2436| time: 1.1s| train loss: +1.670e+01 | test loss: +2.129e+01 | 
| 05-02 01:39:38 epoch: 2436| train loss i: [0.05	1.46	4.93	4.93	3.74	1.6 ] test loss i: [0.11	0.65	7.47	6.08	4.92	2.07] | 
| 05-02 01:39:40 epoch: 2437| time: 1.1s| train loss: +1.715e+01 | test loss: +1.429e+01 | 
| 05-02 01:39:40 epoch: 2437| train loss i: [0.04	1.55	5.35	4.95	3.7 	1.57] test loss i: [0.06	0.49	4.17	4.93	3.25	1.39] | 
| 05-02 01:39:41 epoch: 2438| time: 1.0s| train loss: +1.623e+01 | test loss: +1.561e+01 | 
| 05-02 01:39:41 epoch: 2438| train loss i: [0.06	1.14	5.26	4.67	3.6 	1.5 ] test loss i: [0.06	0.18	5.02	5.11	3.65	1.6 ] | 
| 05-02 01:39:42 epoch: 2439| time: 1.1s| train loss: +1.763e+01 | test loss: +1.694e+01 | 
| 05-02 01:39:42 epoch: 2439| train loss i: [0.04	1.6 	5.55	4.83	4.07	1.55] test loss i: [0.08	0.65	5.37	5.12	3.85	1.87] | 
| 05-02 01:39:43 epoch: 2440| time: 1.1s| train loss: +1.663e+01 | test loss: +1.898e+01 | 
| 05-02 01:39:43 epoch: 2440| train loss i: [0.05	0.9 	5.32	4.81	3.97	1.6 ] test loss i: [0.05	2.89	4.8 	4.77	4.66	1.81] | 
| 05-02 01:39:44 epoch: 2441| time: 1.1s| train loss: +1.645e+01 | test loss: +1.445e+01 | 
| 05-02 01:39:44 epoch: 2441| train loss i: [0.08	1.05	5.12	4.86	3.81	1.52] test loss i: [0.06	0.83	4.46	3.89	3.72	1.49] | 
| 05-02 01:39:45 epoch: 2442| time: 1.1s| train loss: +1.628e+01 | test loss: +1.579e+01 | 
| 05-02 01:39:45 epoch: 2442| train loss i: [0.07	1.1 	5.38	4.62	3.58	1.52] test loss i: [0.05	1.09	4.75	4.44	3.55	1.91] | 
| 05-02 01:39:46 epoch: 2443| time: 1.1s| train loss: +1.686e+01 | test loss: +1.927e+01 | 
| 05-02 01:39:46 epoch: 2443| train loss i: [0.05	1.71	4.78	4.9 	3.97	1.46] test loss i: [0.07	0.89	6.75	5.86	4.06	1.65] | 
| 05-02 01:39:47 epoch: 2444| time: 1.1s| train loss: +1.601e+01 | test loss: +2.010e+01 | 
| 05-02 01:39:47 epoch: 2444| train loss i: [0.07	0.71	5.03	4.78	3.92	1.49] test loss i: [0.06	5.11	4.91	4.78	3.58	1.64] | 
| 05-02 01:39:48 epoch: 2445| time: 1.1s| train loss: +1.725e+01 | test loss: +2.198e+01 | 
| 05-02 01:39:48 epoch: 2445| train loss i: [0.06	1.97	5.29	4.39	3.97	1.56] test loss i: [0.08	2.59	7.63	5.39	4.7 	1.59] | 
| 05-02 01:39:49 epoch: 2446| time: 1.1s| train loss: +1.670e+01 | test loss: +2.481e+01 | 
| 05-02 01:39:49 epoch: 2446| train loss i: [0.04	1.62	5.14	4.59	3.81	1.51] test loss i: [0.07	0.61	9.92	6.49	5.73	1.99] | 
| 05-02 01:39:50 epoch: 2447| time: 1.1s| train loss: +1.713e+01 | test loss: +1.830e+01 | 
| 05-02 01:39:50 epoch: 2447| train loss i: [0.05	1.47	4.96	5.39	3.76	1.5 ] test loss i: [0.1 	0.47	6.8 	4.97	4.11	1.85] | 
| 05-02 01:39:51 epoch: 2448| time: 1.0s| train loss: +1.801e+01 | test loss: +2.420e+01 | 
| 05-02 01:39:51 epoch: 2448| train loss i: [0.08	1.47	6.24	4.91	3.74	1.57] test loss i: [0.08	2.66	7.63	6.51	5.29	2.04] | 
| 05-02 01:39:52 epoch: 2449| time: 1.0s| train loss: +1.658e+01 | test loss: +1.633e+01 | 
| 05-02 01:39:52 epoch: 2449| train loss i: [0.05	1.21	5.14	4.91	3.78	1.49] test loss i: [0.03	1.06	5.09	4.45	4.29	1.42] | 
| 05-02 01:39:53 epoch: 2450| time: 1.1s| train loss: +1.650e+01 | test loss: +1.687e+01 | 
| 05-02 01:39:53 epoch: 2450| train loss i: [0.08	1.18	5.29	4.58	3.8 	1.57] test loss i: [0.05	0.89	6.21	4.32	3.81	1.59] | 
| 05-02 01:39:55 epoch: 2451| time: 1.1s| train loss: +1.653e+01 | test loss: +1.760e+01 | 
| 05-02 01:39:55 epoch: 2451| train loss i: [0.06	0.77	5.55	4.79	3.88	1.48] test loss i: [0.28	2.38	3.97	5.88	3.75	1.34] | 
| 05-02 01:39:56 epoch: 2452| time: 1.1s| train loss: +1.750e+01 | test loss: +2.195e+01 | 
| 05-02 01:39:56 epoch: 2452| train loss i: [0.07	1.53	5.46	4.97	3.9 	1.57] test loss i: [0.12	2.15	6.77	6.59	4.54	1.78] | 
| 05-02 01:39:57 epoch: 2453| time: 1.1s| train loss: +1.704e+01 | test loss: +1.655e+01 | 
| 05-02 01:39:57 epoch: 2453| train loss i: [0.07	1.35	5.25	5.  	3.77	1.62] test loss i: [0.11	0.87	5.32	4.43	4.14	1.67] | 
| 05-02 01:39:58 epoch: 2454| time: 1.1s| train loss: +1.642e+01 | test loss: +1.821e+01 | 
| 05-02 01:39:58 epoch: 2454| train loss i: [0.06	1.15	5.54	4.4 	3.71	1.57] test loss i: [0.08	1.25	6.2 	4.98	3.86	1.84] | 
| 05-02 01:39:59 epoch: 2455| time: 1.1s| train loss: +1.621e+01 | test loss: +1.546e+01 | 
| 05-02 01:39:59 epoch: 2455| train loss i: [0.05	1.14	5.14	4.61	3.68	1.59] test loss i: [0.12	0.88	4.94	4.53	3.5 	1.49] | 
| 05-02 01:40:00 epoch: 2456| time: 1.1s| train loss: +1.680e+01 | test loss: +2.094e+01 | 
| 05-02 01:40:00 epoch: 2456| train loss i: [0.07	1.4 	5.01	4.86	3.97	1.5 ] test loss i: [0.07	1.78	7.18	5.43	4.67	1.81] | 
| 05-02 01:40:01 epoch: 2457| time: 1.1s| train loss: +1.686e+01 | test loss: +2.275e+01 | 
| 05-02 01:40:01 epoch: 2457| train loss i: [0.11	1.44	5.41	4.51	3.94	1.46] test loss i: [0.13	0.75	6.98	7.9 	5.  	2.  ] | 
| 05-02 01:40:02 epoch: 2458| time: 1.1s| train loss: +1.694e+01 | test loss: +1.791e+01 | 
| 05-02 01:40:02 epoch: 2458| train loss i: [0.04	1.  	6.02	4.62	3.71	1.57] test loss i: [0.1 	1.21	6.67	4.45	3.85	1.64] | 
| 05-02 01:40:03 epoch: 2459| time: 1.1s| train loss: +1.664e+01 | test loss: +2.238e+01 | 
| 05-02 01:40:03 epoch: 2459| train loss i: [0.06	1.42	5.01	4.85	3.73	1.57] test loss i: [0.08	1.71	8.24	5.25	5.14	1.96] | 
| 05-02 01:40:04 epoch: 2460| time: 1.1s| train loss: +1.636e+01 | test loss: +1.678e+01 | 
| 05-02 01:40:04 epoch: 2460| train loss i: [0.04	1.24	5.41	4.61	3.52	1.54] test loss i: [0.06	1.6 	5.8 	4.56	3.24	1.52] | 
| 05-02 01:40:05 epoch: 2461| time: 1.1s| train loss: +1.720e+01 | test loss: +1.661e+01 | 
| 05-02 01:40:05 epoch: 2461| train loss i: [0.05	1.34	5.71	4.66	3.85	1.59] test loss i: [0.05	1.94	4.71	4.54	3.93	1.45] | 
| 05-02 01:40:06 epoch: 2462| time: 1.1s| train loss: +1.630e+01 | test loss: +1.567e+01 | 
| 05-02 01:40:06 epoch: 2462| train loss i: [0.06	1.23	5.27	4.52	3.72	1.5 ] test loss i: [0.04	0.25	5.06	5.13	3.56	1.63] | 
| 05-02 01:40:07 epoch: 2463| time: 1.1s| train loss: +1.667e+01 | test loss: +1.836e+01 | 
| 05-02 01:40:07 epoch: 2463| train loss i: [0.06	0.82	5.79	4.71	3.7 	1.58] test loss i: [0.04	2.33	5.42	4.96	3.88	1.73] | 
| 05-02 01:40:08 epoch: 2464| time: 1.1s| train loss: +1.715e+01 | test loss: +2.092e+01 | 
| 05-02 01:40:08 epoch: 2464| train loss i: [0.09	1.37	5.92	4.41	3.78	1.57] test loss i: [0.1 	2.5 	6.06	5.89	4.2 	2.16] | 
| 05-02 01:40:10 epoch: 2465| time: 1.1s| train loss: +1.693e+01 | test loss: +1.989e+01 | 
| 05-02 01:40:10 epoch: 2465| train loss i: [0.07	1.45	5.32	4.8 	3.79	1.5 ] test loss i: [0.09	1.93	6.67	5.27	4.23	1.71] | 
| 05-02 01:40:11 epoch: 2466| time: 1.1s| train loss: +1.684e+01 | test loss: +1.803e+01 | 
| 05-02 01:40:11 epoch: 2466| train loss i: [0.05	0.92	5.73	4.85	3.75	1.53] test loss i: [0.04	2.23	5.55	4.91	3.6 	1.71] | 
| 05-02 01:40:12 epoch: 2467| time: 1.1s| train loss: +1.659e+01 | test loss: +1.865e+01 | 
| 05-02 01:40:12 epoch: 2467| train loss i: [0.07	1.39	5.28	4.71	3.62	1.52] test loss i: [0.06	1.85	6.71	4.7 	3.63	1.7 ] | 
| 05-02 01:40:13 epoch: 2468| time: 1.1s| train loss: +1.735e+01 | test loss: +1.611e+01 | 
| 05-02 01:40:13 epoch: 2468| train loss i: [0.07	1.87	5.42	4.84	3.62	1.54] test loss i: [0.15	0.4 	5.71	4.34	3.7 	1.81] | 
| 05-02 01:40:14 epoch: 2469| time: 1.1s| train loss: +1.680e+01 | test loss: +1.554e+01 | 
| 05-02 01:40:14 epoch: 2469| train loss i: [0.07	1.48	5.41	4.75	3.57	1.52] test loss i: [0.06	1.17	4.39	4.23	3.91	1.78] | 
| 05-02 01:40:15 epoch: 2470| time: 1.1s| train loss: +1.711e+01 | test loss: +1.712e+01 | 
| 05-02 01:40:15 epoch: 2470| train loss i: [0.05	1.97	4.84	5.04	3.77	1.45] test loss i: [0.03	2.31	5.07	4.54	3.58	1.58] | 
| 05-02 01:40:16 epoch: 2471| time: 1.1s| train loss: +1.670e+01 | test loss: +1.580e+01 | 
| 05-02 01:40:16 epoch: 2471| train loss i: [0.04	0.79	5.25	4.91	4.09	1.63] test loss i: [0.02	1.85	5.19	3.79	3.18	1.77] | 
| 05-02 01:40:17 epoch: 2472| time: 1.1s| train loss: +1.677e+01 | test loss: +1.990e+01 | 
| 05-02 01:40:17 epoch: 2472| train loss i: [0.05	1.42	4.93	5.09	3.74	1.55] test loss i: [1.73	1.3 	7.38	4.54	3.45	1.5 ] | 
| 05-02 01:40:18 epoch: 2473| time: 1.1s| train loss: +1.759e+01 | test loss: +2.316e+01 | 
| 05-02 01:40:18 epoch: 2473| train loss i: [0.06	1.23	5.87	4.91	4.01	1.51] test loss i: [0.08	1.24	7.6 	7.13	5.03	2.08] | 
| 05-02 01:40:19 epoch: 2474| time: 1.1s| train loss: +1.799e+01 | test loss: +1.775e+01 | 
| 05-02 01:40:19 epoch: 2474| train loss i: [0.07	1.26	5.79	5.18	4.1 	1.59] test loss i: [0.04	0.88	5.82	5.16	4.29	1.56] | 
| 05-02 01:40:20 epoch: 2475| time: 1.1s| train loss: +1.639e+01 | test loss: +2.604e+01 | 
| 05-02 01:40:20 epoch: 2475| train loss i: [0.05	1.22	5.25	4.68	3.67	1.53] test loss i: [0.07	3.44	7.63	6.86	6.06	1.98] | 
| 05-02 01:40:21 epoch: 2476| time: 1.1s| train loss: +1.634e+01 | test loss: +1.856e+01 | 
| 05-02 01:40:21 epoch: 2476| train loss i: [0.06	1.06	5.39	4.51	3.73	1.58] test loss i: [0.06	2.36	5.74	4.96	3.78	1.66] | 
| 05-02 01:40:22 epoch: 2477| time: 1.0s| train loss: +1.658e+01 | test loss: +2.368e+01 | 
| 05-02 01:40:22 epoch: 2477| train loss i: [0.06	1.7 	5.04	4.69	3.59	1.5 ] test loss i: [0.05	1.86	9.26	6.66	3.93	1.92] | 
| 05-02 01:40:24 epoch: 2478| time: 1.1s| train loss: +1.718e+01 | test loss: +1.465e+01 | 
| 05-02 01:40:24 epoch: 2478| train loss i: [0.05	1.25	5.8 	4.73	3.85	1.51] test loss i: [0.08	0.5 	4.99	3.92	3.51	1.65] | 
| 05-02 01:40:25 epoch: 2479| time: 1.0s| train loss: +1.759e+01 | test loss: +1.157e+01 | 
| 05-02 01:40:25 epoch: 2479| train loss i: [0.05	1.31	5.64	5.06	4.03	1.5 ] test loss i: [0.05	0.27	3.49	3.52	2.94	1.3 ] | 
| 05-02 01:40:26 epoch: 2480| time: 1.1s| train loss: +1.637e+01 | test loss: +2.602e+01 | 
| 05-02 01:40:26 epoch: 2480| train loss i: [0.06	0.69	5.49	4.65	4.05	1.43] test loss i: [0.11	2.59	9.01	6.32	6.01	1.97] | 
| 05-02 01:40:27 epoch: 2481| time: 1.1s| train loss: +1.773e+01 | test loss: +2.324e+01 | 
| 05-02 01:40:27 epoch: 2481| train loss i: [0.07	1.27	5.74	5.07	4.04	1.54] test loss i: [0.19	2.32	8.44	4.86	5.16	2.28] | 
| 05-02 01:40:28 epoch: 2482| time: 1.1s| train loss: +1.669e+01 | test loss: +1.683e+01 | 
| 05-02 01:40:28 epoch: 2482| train loss i: [0.07	1.49	5.05	4.69	3.81	1.58] test loss i: [0.05	1.61	5.67	4.8 	3.16	1.53] | 
| 05-02 01:40:29 epoch: 2483| time: 1.1s| train loss: +1.749e+01 | test loss: +1.691e+01 | 
| 05-02 01:40:29 epoch: 2483| train loss i: [0.05	1.42	5.49	4.75	4.19	1.58] test loss i: [0.08	1.51	4.97	4.82	4.08	1.46] | 
| 05-02 01:40:30 epoch: 2484| time: 1.1s| train loss: +1.828e+01 | test loss: +1.688e+01 | 
| 05-02 01:40:30 epoch: 2484| train loss i: [0.06	2.66	5.3 	5.02	3.72	1.52] test loss i: [0.05	1.87	4.9 	4.04	4.42	1.61] | 
| 05-02 01:40:31 epoch: 2485| time: 1.1s| train loss: +1.727e+01 | test loss: +2.043e+01 | 
| 05-02 01:40:31 epoch: 2485| train loss i: [0.07	1.22	5.58	5.25	3.67	1.49] test loss i: [0.11	1.59	6.68	5.93	4.31	1.8 ] | 
| 05-02 01:40:32 epoch: 2486| time: 1.2s| train loss: +1.724e+01 | test loss: +2.114e+01 | 
| 05-02 01:40:32 epoch: 2486| train loss i: [0.06	1.43	5.38	4.99	3.73	1.65] test loss i: [0.07	2.44	7.04	5.45	4.4 	1.74] | 
| 05-02 01:40:34 epoch: 2487| time: 1.4s| train loss: +1.763e+01 | test loss: +1.739e+01 | 
| 05-02 01:40:34 epoch: 2487| train loss i: [0.06	1.44	6.01	4.79	3.73	1.6 ] test loss i: [0.06	0.52	6.55	5.09	3.24	1.94] | 
| 05-02 01:40:35 epoch: 2488| time: 1.1s| train loss: +1.690e+01 | test loss: +1.626e+01 | 
| 05-02 01:40:35 epoch: 2488| train loss i: [0.08	0.75	5.89	4.65	4.06	1.46] test loss i: [0.06	1.05	4.93	4.52	4.25	1.45] | 
| 05-02 01:40:36 epoch: 2489| time: 1.1s| train loss: +1.705e+01 | test loss: +1.522e+01 | 
| 05-02 01:40:36 epoch: 2489| train loss i: [0.06	1.08	5.31	5.12	3.91	1.57] test loss i: [0.06	1.25	4.83	4.21	3.35	1.53] | 
| 05-02 01:40:37 epoch: 2490| time: 1.1s| train loss: +1.564e+01 | test loss: +1.672e+01 | 
| 05-02 01:40:37 epoch: 2490| train loss i: [0.05	0.41	5.41	4.66	3.6 	1.51] test loss i: [0.03	0.31	5.69	4.51	4.42	1.76] | 
| 05-02 01:40:38 epoch: 2491| time: 1.1s| train loss: +1.603e+01 | test loss: +2.253e+01 | 
| 05-02 01:40:38 epoch: 2491| train loss i: [0.05	0.9 	5.1 	4.81	3.66	1.51] test loss i: [0.04	4.45	7.04	4.86	3.81	2.32] | 
| 05-02 01:40:39 epoch: 2492| time: 1.1s| train loss: +1.667e+01 | test loss: +1.525e+01 | 
| 05-02 01:40:39 epoch: 2492| train loss i: [0.05	1.53	5.28	4.59	3.72	1.51] test loss i: [0.03	0.5 	4.52	4.9 	3.77	1.52] | 
| 05-02 01:40:40 epoch: 2493| time: 1.1s| train loss: +1.722e+01 | test loss: +1.722e+01 | 
| 05-02 01:40:40 epoch: 2493| train loss i: [0.05	0.76	5.86	4.89	4.07	1.59] test loss i: [0.11	0.9 	6.75	4.28	3.56	1.62] | 
| 05-02 01:40:41 epoch: 2494| time: 1.1s| train loss: +1.706e+01 | test loss: +1.805e+01 | 
| 05-02 01:40:41 epoch: 2494| train loss i: [0.06	1.22	5.35	5.13	3.8 	1.5 ] test loss i: [0.03	2.03	6.04	4.45	3.57	1.93] | 
| 05-02 01:40:42 epoch: 2495| time: 1.1s| train loss: +1.607e+01 | test loss: +1.850e+01 | 
| 05-02 01:40:42 epoch: 2495| train loss i: [0.05	0.74	5.17	4.75	3.86	1.49] test loss i: [0.08	2.81	5.44	4.75	3.88	1.53] | 
| 05-02 01:40:43 epoch: 2496| time: 1.1s| train loss: +1.725e+01 | test loss: +1.433e+01 | 
| 05-02 01:40:43 epoch: 2496| train loss i: [0.04	1.44	5.57	4.84	3.8 	1.56] test loss i: [0.05	1.26	4.08	3.57	3.62	1.74] | 
| 05-02 01:40:45 epoch: 2497| time: 1.1s| train loss: +1.726e+01 | test loss: +2.009e+01 | 
| 05-02 01:40:45 epoch: 2497| train loss i: [0.07	1.34	5.53	5.04	3.73	1.55] test loss i: [0.04	2.07	6.23	5.3 	4.71	1.74] | 
| 05-02 01:40:46 epoch: 2498| time: 1.1s| train loss: +1.725e+01 | test loss: +1.685e+01 | 
| 05-02 01:40:46 epoch: 2498| train loss i: [0.05	1.63	5.36	4.74	3.96	1.51] test loss i: [0.06	1.83	4.88	4.67	3.65	1.75] | 
| 05-02 01:40:47 epoch: 2499| time: 1.1s| train loss: +1.705e+01 | test loss: +1.773e+01 | 
| 05-02 01:40:47 epoch: 2499| train loss i: [0.04	1.62	4.89	4.86	4.03	1.61] test loss i: [0.06	1.84	5.56	4.77	3.76	1.72] | 
| 05-02 01:41:20 sample delta_norm_mean: 0.000e+00 | init delta_norm_mean: 6.514e-01| round init delta_norm_mean: 0.000e+00
